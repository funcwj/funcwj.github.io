<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/wujian-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/wujian-16x16.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/themes/blue/pace-theme-minimal.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/pace/1.0.2/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.funcwj.cn","root":"/","scheme":"Gemini","version":"7.7.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":true},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="本篇文章主要说一下多通道的Hybrid声学模型。Google在CLDNN之后，大约在2015年到2017年之间围绕远场语音识别，做了一系列 [1-6] 的工作，相关的技术也被用在了Google Home [7] 上。17年的时候我看了其中的一部分，觉得工作做的很漂亮，一骑绝尘，一枝独秀。原因主要有两方面，其一是多通道声学模型是一个比较新的概念，当时很少见其他高校和公司有相关的工作，基本还停留在神经">
<meta property="og:type" content="article">
<meta property="og:title" content="Multi-Channel Hybrid AM">
<meta property="og:url" content="https://www.funcwj.cn/2019/11/10/multi-channel-hybrid-am/index.html">
<meta property="og:site_name" content="WJ&#39;s site">
<meta property="og:description" content="本篇文章主要说一下多通道的Hybrid声学模型。Google在CLDNN之后，大约在2015年到2017年之间围绕远场语音识别，做了一系列 [1-6] 的工作，相关的技术也被用在了Google Home [7] 上。17年的时候我看了其中的一部分，觉得工作做的很漂亮，一骑绝尘，一枝独秀。原因主要有两方面，其一是多通道声学模型是一个比较新的概念，当时很少见其他高校和公司有相关的工作，基本还停留在神经">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.funcwj.cn/images/clp-learned-filters.jpg">
<meta property="og:image" content="https://www.funcwj.cn/images/amazon-am-design.png">
<meta property="og:image" content="https://www.funcwj.cn/images/amazon-mc-design.png">
<meta property="article:published_time" content="2019-11-10T13:23:01.000Z">
<meta property="article:modified_time" content="2020-02-19T17:53:33.412Z">
<meta property="article:author" content="WJ">
<meta property="article:tag" content="E2E">
<meta property="article:tag" content="Multi-channel">
<meta property="article:tag" content="Beamformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.funcwj.cn/images/clp-learned-filters.jpg">

<link rel="canonical" href="https://www.funcwj.cn/2019/11/10/multi-channel-hybrid-am/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Multi-Channel Hybrid AM | WJ's site</title>
  


  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?01edb048a0d71e5d0a00ae47bdb0dbe2";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">WJ's site</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">我只是好奇</p>
  </div>

  <div class="site-nav-right"></div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>站点首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于作者</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>文章归档<span class="badge">83</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>文章分类<span class="badge">9</span></a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>站点标签<span class="badge">70</span></a>

  </li>
        <li class="menu-item menu-item-footprint">

    <a href="/footprint/" rel="section"><i class="fa fa-fw fa-map-marker"></i>足迹地图</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>文章搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    

  <a href="https://github.com/funcwj" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://www.funcwj.cn/2019/11/10/multi-channel-hybrid-am/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/avatar.JPG">
      <meta itemprop="name" content="WJ">
      <meta itemprop="description" content="彷徨乎无为其侧，逍遥乎寝卧其下">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="WJ's site">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Multi-Channel Hybrid AM
        </h1>

        <div class="post-meta">
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-10 21:23:01" itemprop="dateCreated datePublished" datetime="2019-11-10T21:23:01+08:00">2019-11-10</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ASR/" itemprop="url" rel="index">
                    <span itemprop="name">ASR</span>
                  </a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>8.5k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>8 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>本篇文章主要说一下多通道的Hybrid声学模型。Google在CLDNN之后，大约在2015年到2017年之间围绕远场语音识别，做了一系列 [1-6] 的工作，相关的技术也被用在了Google Home [7] 上。17年的时候我看了其中的一部分，觉得工作做的很漂亮，一骑绝尘，一枝独秀。原因主要有两方面，其一是多通道声学模型是一个比较新的概念，当时很少见其他高校和公司有相关的工作，基本还停留在神经网络的架构阶段，其二是Google的产出速度非常惊人，而且思路明确，环环相扣。17年之后，Google甩手开始做端到端（E2E）方面的工作，学术界和工业界也开始紧紧跟着不放，之前的工作关注度相比之下，明显低了很多。最近看到Amazon在icassp2019上有了两篇文章 [8-9]，再加上面试百度时他们聊了一些神经网络前端的事（后来确实花功夫宣传了），我就想聊一下这方面的工作和认识。</p>
<a id="more"></a>
<p>先说一下我的看法。在特定的远场环境下直接做多通道声学模型是一个非常有必要的尝试。如果可以将繁杂的前端处理模块（增强，定位，去混等等）集成到声学模型中，那么从系统的角度来看，维护成本，工程量，甚至是系统的延迟都可以明显的得到降低。而从技术本身来说，前后端的不匹配性一直是前后端分离这种模式下需要解决的问题。为了提升最终的识别率，前端需要工程师不断的做优化，后端则需要不断的retrain，而多通道建模则可以让前端自动跟随着后端的准则进行微调和适应。这种联合优化的方式可以较好的解决这种mismatch问题，存在提升系统性能的可能性。</p>
<p>Google和Amazon的工作都是基于固定波束形成的方案。在增强的场景中（即单一目标声源），前后端分离下需要先根据麦克风几何结构设计好一组指向的固定波束和声源定位算法。运行时先根据定位的结果，选取目标方位或者音区内的波束送入声学模型进行识别或者解码，这一过程也称为波束选择。波束形成我在之前的文章中介绍过，在频域可以写为：</p>
<script type="math/tex; mode=display">
s_{t,f} = \mathbf{w}_f^H \mathbf{y}_{t,f} \tag{1}</script><p>其中$\mathbf{w}_{f}\in \mathbb{C}^{M}$表示在频率索引$f$处的滤波系数，$\mathbf{y}_{t,f} = [y_{t,f}^0, \cdots, y_{t,f}^{C - 1}]$表示每个时频点的观测向量，$C$为麦克风数目。对于固定波束而言，之前也提到，会设计一组系数$\mathcal{W}_f = [\cdots, \mathbf{w}_{\theta, f}, \cdots]$，指向不同的方向（look directions），为了后文描述方便，给式$(1)$加上下角标$\theta$表示指向：</p>
<script type="math/tex; mode=display">
s_{t,f}^\theta = \mathbf{w}_{\theta, f}^H \mathbf{y}_{t,f} = \sum_c \left(w_{\theta, f}^c\right)^H y_{t,f}^c \tag{2}</script><p>时域上，对应的可以写成滤波相加的形式：</p>
<script type="math/tex; mode=display">
s_t^\theta = \sum_c \mathbf{y}_t * \mathbf{h}_{\theta, c} \tag{3}</script><p>其中$\mathbf{y}_t = [y_{t - N + 1}, \cdots, y_t]，\mathbf{h}_{\theta, c} = [h_0^\theta, \cdots, h_{N - 1}^\theta]$表示通道$c$处的有限冲击响应（FIR），$N$表示滤波FIR的阶数，$*$表示卷积。在神经网络中，式$(2)$和式子$(3)$分别可用线性层（或者dot &amp; sum等操作）以及一维卷积层实现。</p>
<h3 id="Google"><a href="#Google" class="headerlink" title="Google"></a>Google</h3><p>下面先介绍Google的三个方案，两种时域（Unfactored &amp; Factored）的和一种频域的。Unfactored直接根据$(3)$式使用$P$组$C$个一维卷积对输入的多通道数据进行滤波相加操作，卷积的stride为1，padding设为0，卷积核的维度对应滤波FIR的阶数$N$，$P$表示不同指向的滤波器个数。卷积的输入为切分好的多通道语音块$[\mathbf{y}_0, \cdots, \mathbf{y}_{T-1}]$，原文中采用的帧长为35 ms（$M = 560$），帧移为10 ms，$N = 400$，所以对于每一帧$\mathbf{y}_t \in \mathbb{R}^{C \times M}$，$\theta$指向的一组一维卷积输出为$\mathbf{s}_t^\theta \in \mathbb{R}^{M - N + 1}$，整个层Unfactored的输出维度为$\mathbf{s}_t \in \mathbb{R}^{M - N + 1 \times P}$。最后在$M - N + 1$这个维度上做最大池化，并使用ReLU和log压缩，将$\mathbf{z}_t \in \mathbb{R}^P$输入后端的CLDNN结构中进行训练。这个过程可以用下面的流程表示：</p>
<script type="math/tex; mode=display">
\mathbf{y}_t \in \mathbb{R}^{C \times M} \overset{\text{FS}}{\Longrightarrow} \mathbf{s}_t \in \mathbb{R}^{M - N + 1 \times P} \overset{\text{MP} \cdots}{\Longrightarrow} \mathbf{z}_t \in \mathbb{R}^P</script><p>在实现的时候，可以使用二维组卷积（Group Convolution）代替$P$组$C$个一维卷积，对应的核心代码用PyTorch实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UnfactedFsBeamformer</span><span class="params">(_FsBeamformer)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Unfacted form of FS (filter and sum) beamformer</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_taps=<span class="number">400</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 win_size=<span class="number">560</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_channels=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_filters=<span class="number">256</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 log_compress=True)</span>:</span></span><br><span class="line">        super(UnfactedFsBeamformer, self).__init__(win_size,</span><br><span class="line">                                                   win_size - num_taps)</span><br><span class="line">        self.num_channels = num_channels</span><br><span class="line">        self.log_compress = log_compress</span><br><span class="line">        <span class="comment"># fs beamformer</span></span><br><span class="line">        self.filter = nn.Conv2d(num_channels,</span><br><span class="line">                                num_filters * num_channels, (num_taps, <span class="number">1</span>),</span><br><span class="line">                                stride=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                groups=num_channels,</span><br><span class="line">                                bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        args:</span></span><br><span class="line"><span class="string">            x: multi-channel audio utterances, N x C x S</span></span><br><span class="line"><span class="string">        return:</span></span><br><span class="line"><span class="string">            y: N x P x T, enhanced features</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> x.dim() <span class="keyword">not</span> <span class="keyword">in</span> [<span class="number">2</span>, <span class="number">3</span>]:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">f"Expect 2/3D tensor, got <span class="subst">&#123;x.dim()&#125;</span> instead"</span>)</span><br><span class="line">        <span class="keyword">if</span> x.dim() == <span class="number">2</span>:</span><br><span class="line">            x = x[<span class="literal">None</span>, ...]</span><br><span class="line">        <span class="comment"># N x C x S x 1</span></span><br><span class="line">        x = x[..., <span class="literal">None</span>]</span><br><span class="line">        <span class="comment"># chunks: N x C x S x 1 =&gt; N x CM x T</span></span><br><span class="line">        c = self.unfold(x)</span><br><span class="line">        <span class="comment"># N x C x M x T</span></span><br><span class="line">        c = c.view(x.shape[<span class="number">0</span>], self.num_channels, self.frame_len, <span class="number">-1</span>)</span><br><span class="line">        <span class="comment"># N x CF x M' x T</span></span><br><span class="line">        f = self.filter(c)</span><br><span class="line">        <span class="comment"># N x F x M' x T</span></span><br><span class="line">        f = sum(th.chunk(f, self.num_channels, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># max pool, N x F x 1 x T</span></span><br><span class="line">        y = F.max_pool2d(f, (self.frame_hop + <span class="number">1</span>, <span class="number">1</span>), stride=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># non-linear</span></span><br><span class="line">        y = th.relu(y.squeeze(<span class="number">-2</span>))</span><br><span class="line">        <span class="comment"># log</span></span><br><span class="line">        <span class="keyword">if</span> self.log_compress:</span><br><span class="line">            y = th.log(y + <span class="number">0.01</span>)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<p>Unfactored的一个比较明显的问题在于计算量很大，参考式$(3)$，按照上述实验配置，计算一帧就需要进行$M - N + 1 \times N \times P \times C$次乘法。另一个在于网络需要在给出的输出$\mathbf{z}_t \in \mathbb{R}^P$中同时包含空间和频率上的提取信息，学习难度较大，针对这点，Factored使用了两步卷积操作分别进行特征提取。其中空间滤波阶段采用了低阶的FIR和较小的look directions，这样的设计是希望网络主要学习到空间滤波的任务。此外空间滤波中的卷积对输入进行padding操作，保证输出的结果在时间维度上相同，即$\mathbf{s}_t \in \mathbb{R}^{M \times P}$。之后使用一维卷积层对$\mathbf{s}_t$提取频率特征（look directions维度保持不动）：</p>
<script type="math/tex; mode=display">
\mathbf{w}_{f,t}^p = \mathbf{s}_{t}^p * \mathbf{g}_f \tag{4}</script><p>$\mathbf{g}_f$表示频率$f$上的滤波系数，卷积核维度为$L$，输入通道数为1，输出通道数为$F$，得到结果$\mathbf{w}_t \in \mathbb{R}^{M - L + 1 \times F \times P}$，分别对应时间，频率和空间维度。之后的操作和Unfactored类似，时间维度上进行池化，忽略短时相位信息，加上ReLU和log压缩，得到$\mathbf{z}_t \in \mathbb{R}^{F \times P}$。最终在输入CLDNN声学模型前，将其reshape成一维向量即可。该操作流程可以用下面的流程表示：</p>
<script type="math/tex; mode=display">
\mathbf{y}_t \in \mathbb{R}^{C \times M} \overset{\text{FS}}{\Longrightarrow} \mathbf{s}_t \in \mathbb{R}^{M \times P} \overset{\text{conv}}{\Longrightarrow}  \mathbf{w}_t \in \mathbb{R}^{M - L + 1 \times F \times P} \overset{\text{MP} \cdots}{\Longrightarrow} \mathbf{z}_t \in \mathbb{R}^{F \times P}</script><p>Factored的模型计算一帧需要的乘法次数为$M \times N \times P \times C + P \times L \times M - L + 1\times C$。由于$N，P$的选取都相对较小，所以整体计算量低于Unfactored模型。为了进一步减少计算量，Google将Unfactored对应到频域中，第一步空间滤波采用$(1)$式进行，输入是复数的FFT特征，第二步谱滤波根据$(4)$式的不同，分别对应CLP和LPE模型。区别主要是谱滤波的系数为复数还是实数，均可对应的采用线性进行实现。频域模型的数据变换如下：</p>
<script type="math/tex; mode=display">
\mathbf{y}_t \in \mathbb{R}^{C \times F} \overset{\text{FS}}{\Longrightarrow} \mathbf{s}_t \in \mathbb{R}^{P \times F} \overset{\text{linear}}{\Longrightarrow}  \mathbf{w}_t \in \mathbb{R}^{P \times G}</script><p>其中$F$表示FFT的频点数，$G$表示频率滤波的输出维度。实际学出来的频域滤波系数$\mathbf{G}$分布类似于mel滤波（即log趋势）。在我本人的实验中发现，谱滤波的系数比较容易学得，因为语音的特征主要集中在低频区域，但是网络的性能未必和其存在相关性，下图是某次实验的学习结果，采用CLP模型，绘制的是滤波系数（复数值）的模。</p>
<p><img src="/images/clp-learned-filters.jpg", width="500"></img></p>
<p>和传统的固定波束方法相比， Google的声学建模中，没有设计所谓的波束选择过程，即只保留一路选出的指向波束或者特征输入后端网络，而是将所有的look directions上的频率特征全部保留。</p>
<h3 id="Amazon"><a href="#Amazon" class="headerlink" title="Amazon"></a>Amazon</h3><p>Amazon的方案思路和Google的频域CLP方法类似，但是有一些优势的地方。其一是在波束形成层，使用super-directive（SD）的波束形成器系数做初始化，其二是考虑了波束选择这一过程，保证声学模型的输入和单通道下维度一致，这样就可以做mult-stage训练（用单通道的模型做多通道方案的后端部分初始化）。多通道的声学模型架构如下右图所示：</p>
<p><img src="/images/amazon-am-design.png", width="600"></img></p>
<p>FE网络表示特征提取网络，其中的线性层起到频谱滤波的作用，可以用mel滤波系数初始化，multi-channel (MC) network有三种设计方案，接受多通道的STFT系数，输出一路波束特征。左图表示我前面提到的传统方案，分别对应波束形成，波束选择，特征提取和声学解码。下面我简单的用文字叙述这三种方案：</p>
<p><img src="/images/amazon-mc-design.png", width="600"></img></p>
<p>第一种CAT的方案比较简单，直接使用复数线性变换将多通道拼接的STFT特征投影成单通道维度即可。第二种DSF的方案通过保留每个频率$f$上的候选波束能量最大的值来实现波束选择过程。第三种方案相较方案二，先保留了每个方向和频率上的能量，再使用线性层将其投影到单一波束的维度作为输出。方案二和三均可以使用预先设计好的SD系数进行初始化。原文的示意图如下，其中power表示对波束复数矩阵进行<code>pow()</code>操作，转换成能量表示。训练方面，采用三步进行，第一步使用fbank特征训练单通道的声学模型，第二步使用单通道STFT特征配合FE网络进行训练，最后添加上前端MC的网络。实验结论方面，ESF的方案获得的相对WER降低最多，而使用mel滤波系数和SD系数初始化FE和MC网络，增加麦克风数目均可以提升模型表现。</p>
<p>上述介绍的Google/Amazon方案均没有自适应的机制，因此只能针对固定的麦克风几何结构/数目和声学环境起作用，网络学到的beampattern/指向性也是固定的。优势的话体现在方案的实现比较简单，系统延迟低，如果存在现有的声学模型pipeline和远场的场景，个人还是非常建议做一些对比和尝试。现在再看候选的多通道方案还有不少，本次将这两篇工作进行集中介绍主要是由于它们存在一定的相似性。自适应波束方案上，比较有代表性的是Paderborn的一系列工作 [10-12]，将基于mask的自适应波束形成（MVDR &amp; GEVD）等和后端AM进行联合训练，目前结合E2E的声学模型实践的比较多，后面会考虑写一篇专门进行总结。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]. Hoshen Y, Weiss R J, Wilson K W. Speech acoustic modeling from raw multichannel waveforms[C]//2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2015: 4624-4628.<br>[2]. Sainath T N, Weiss R J, Senior A, et al. Learning the speech front-end with raw waveform CLDNNs[C]//Sixteenth Annual Conference of the International Speech Communication Association. 2015.<br>[3]. Sainath T N, Weiss R J, Wilson K W, et al. Speaker location and microphone spacing invariant acoustic modeling from raw multichannel waveforms[C]//2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU). IEEE, 2015: 30-36.<br>[4]. Sainath T N, Weiss R J, Wilson K W, et al. Factored spatial and spectral multichannel raw waveform CLDNNs[C]//2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2016: 5075-5079. MLA<br>[5]. E. Variani, T. N. Sainath, I. Shafran and M. Bacchiani, “Complex Linear Projection (CLP): A Discriminative Approach to Joint Feature Extraction and Acoustic Modeling,” in Proc. Interspeech, 2016.<br>[6]. T. N. Sainath, R. J. Weiss, K. W. Wilson, B. Li, A. Narayanan, E. Variani, M. Bacchiani, I. Shafran, A. Senior, K. Chin, A. Misra and C. Kim “Multichannel Signal Processing with Deep Neural Networks for Automatic Speech Recognition,” in IEEE Transactions on Speech and Language Processing, 2017.<br>[7]. B. Li, T. N. Sainath, J. Caroselli, A. Narayanan, M. Bacchiani, A. Misra, I. Shafran, H. Sak, G. Pundak, K. Chin, K. Sim, R. J. Weiss, K. W. Wilson, E. Variani, C. Kim, O. Siohan, M. Weintraub, E. McDermott, R. Rose and M. Shannon, “Acoustic Modeling for Google Home,” in Proc. Interspeech, 2017.<br>[8]. Wu M, Kumatani K, Sundaram S, et al. Frequency domain multi-channel acoustic modeling for distant speech recognition[C]//2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019. MLA<br>[9]. Kumatani K, Minhua W, Sundaram S, et al. Multi-Geometry Spatial Acoustic Modeling for Distant Speech Recognition[C]//ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019: 6635-6639.<br>[10]. Heymann J, Drude L, Boeddeker C, et al. Beamnet: End-to-end training of a beamformer-supported multi-channel asr system[C]//2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2017: 5325-5329.<br>[11]. Boeddeker C, Hanebrink P, Drude L, et al. Optimizing neural-network supported acoustic beamforming by algorithmic differentiation[C]//2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2017: 171-175.<br>[12]. Heymann J, Bacchiani M, Sainath T N. Performance of mask based statistical beamforming in a smart home scenario[C]//2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018: 6722-6726.</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>WJ
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://www.funcwj.cn/2019/11/10/multi-channel-hybrid-am/" title="Multi-Channel Hybrid AM">https://www.funcwj.cn/2019/11/10/multi-channel-hybrid-am/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/E2E/" rel="tag"><i class="fa fa-tag"></i> E2E</a>
              <a href="/tags/Multi-channel/" rel="tag"><i class="fa fa-tag"></i> Multi-channel</a>
              <a href="/tags/Beamformer/" rel="tag"><i class="fa fa-tag"></i> Beamformer</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2019/09/30/cacgmm/" rel="prev" title="CACGMM">
      <i class="fa fa-chevron-left"></i> CACGMM
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/01/13/intro-on-se-and-ss/" rel="next" title="Speech Enhancement & Separation简介">
      Speech Enhancement & Separation简介 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#Google"><span class="nav-number">1.</span> <span class="nav-text">Google</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Amazon"><span class="nav-number">2.</span> <span class="nav-text">Amazon</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Reference"><span class="nav-number">3.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="WJ"
      src="/uploads/avatar.JPG">
  <p class="site-author-name" itemprop="name">WJ</p>
  <div class="site-description" itemprop="description">彷徨乎无为其侧，逍遥乎寝卧其下</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">83</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">70</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/funcwj" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;funcwj" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:funcwj@foxmail.com" title="E-Mail → mailto:funcwj@foxmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.zhihu.com/people/jian-fu-16" title="Zhi Hu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;jian-fu-16" rel="noopener" target="_blank"><i class="fa fa-fw fa-book"></i>Zhi Hu</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.funcwj.cn/" title="Jianwu → https:&#x2F;&#x2F;www.funcwj.cn"><i class="fa fa-fw fa-google"></i>Jianwu</a>
      </span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title">
      <i class="fa fa-fw fa-link"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="http://wangbaiyuan.cn/" title="http:&#x2F;&#x2F;wangbaiyuan.cn" rel="noopener" target="_blank">极客人</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://jcf94.com/" title="http:&#x2F;&#x2F;jcf94.com" rel="noopener" target="_blank">jcf94</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://hujian.website/" title="https:&#x2F;&#x2F;hujian.website" rel="noopener" target="_blank">hijkzzz</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://placebokkk.github.io/" title="http:&#x2F;&#x2F;placebokkk.github.io&#x2F;" rel="noopener" target="_blank">Yang Chao</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.cnblogs.com/xingshansi/" title="https:&#x2F;&#x2F;www.cnblogs.com&#x2F;xingshansi&#x2F;" rel="noopener" target="_blank">桂的blog</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://homes.esat.kuleuven.be/~dspuser/dasp/index.html" title="http:&#x2F;&#x2F;homes.esat.kuleuven.be&#x2F;~dspuser&#x2F;dasp&#x2F;index.html" rel="noopener" target="_blank">DASP</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://ccrma.stanford.edu/~jos/sasp/sasp.html" title="https:&#x2F;&#x2F;ccrma.stanford.edu&#x2F;~jos&#x2F;sasp&#x2F;sasp.html" rel="noopener" target="_blank">SASP</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://link.springer.com/book/10.1007%2F978-3-540-78612-2" title="https:&#x2F;&#x2F;link.springer.com&#x2F;book&#x2F;10.1007%2F978-3-540-78612-2" rel="noopener" target="_blank">MASP</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.audiolabs-erlangen.de/home" title="https:&#x2F;&#x2F;www.audiolabs-erlangen.de&#x2F;home" rel="noopener" target="_blank">AudioLibs</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://arxiv.org/list/eess.AS/recent" title="https:&#x2F;&#x2F;arxiv.org&#x2F;list&#x2F;eess.AS&#x2F;recent" rel="noopener" target="_blank">ASLP Arxiv</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://signalprocessingsociety.org/publications-resources/ieeeacm-transactions-audio-speech-and-language-processing" title="https:&#x2F;&#x2F;signalprocessingsociety.org&#x2F;publications-resources&#x2F;ieeeacm-transactions-audio-speech-and-language-processing" rel="noopener" target="_blank">IEEE-TASLP</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.isca-speech.org/iscaweb/index.php/archive/online-archive" title="https:&#x2F;&#x2F;www.isca-speech.org&#x2F;iscaweb&#x2F;index.php&#x2F;archive&#x2F;online-archive" rel="noopener" target="_blank">ISCA</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://ai.google/research/pubs/?area=SpeechProcessing" title="https:&#x2F;&#x2F;ai.google&#x2F;research&#x2F;pubs&#x2F;?area&#x3D;SpeechProcessing" rel="noopener" target="_blank">Google</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www-i6.informatik.rwth-aachen.de/" title="http:&#x2F;&#x2F;www-i6.informatik.rwth-aachen.de" rel="noopener" target="_blank">RWTH</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.merl.com/publications/?ystart=1991&yend=2019&sa=on" title="http:&#x2F;&#x2F;www.merl.com&#x2F;publications&#x2F;?ystart&#x3D;1991&amp;yend&#x3D;2019&amp;sa&#x3D;on" rel="noopener" target="_blank">MERL</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://ei.uni-paderborn.de/en/nt/research-mission/publications/" title="https:&#x2F;&#x2F;ei.uni-paderborn.de&#x2F;en&#x2F;nt&#x2F;research-mission&#x2F;publications&#x2F;" rel="noopener" target="_blank">Paderborn</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://bio-asplab.citi.sinica.edu.tw/p-conference.html" title="http:&#x2F;&#x2F;bio-asplab.citi.sinica.edu.tw&#x2F;p-conference.html" rel="noopener" target="_blank">ASP-LAB</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.kecl.ntt.co.jp/english/index.html" title="http:&#x2F;&#x2F;www.kecl.ntt.co.jp&#x2F;english&#x2F;index.html" rel="noopener" target="_blank">NTT-CSL</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.irisa.fr/metiss/ozerov/" title="http:&#x2F;&#x2F;www.irisa.fr&#x2F;metiss&#x2F;ozerov&#x2F;" rel="noopener" target="_blank">Alexey Ozerov</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://israelcohen.com/" title="https:&#x2F;&#x2F;israelcohen.com" rel="noopener" target="_blank">Israel Cohen</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.eng.biu.ac.il/gannot/" title="http:&#x2F;&#x2F;www.eng.biu.ac.il&#x2F;gannot&#x2F;" rel="noopener" target="_blank">Sharon Gannot</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.danielpovey.com/" title="http:&#x2F;&#x2F;www.danielpovey.com" rel="noopener" target="_blank">Daniel Povey</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://web.cse.ohio-state.edu/~wang.77/pubs_year.html" title="http:&#x2F;&#x2F;web.cse.ohio-state.edu&#x2F;~wang.77&#x2F;pubs_year.html" rel="noopener" target="_blank">Deliang Wang</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://sites.google.com/view/shinjiwatanabe/publications" title="https:&#x2F;&#x2F;sites.google.com&#x2F;view&#x2F;shinjiwatanabe&#x2F;publications" rel="noopener" target="_blank">Shinji Watanabe</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://sites.google.com/site/dongyu888/" title="https:&#x2F;&#x2F;sites.google.com&#x2F;site&#x2F;dongyu888&#x2F;" rel="noopener" target="_blank">Dong Yu</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.citi.sinica.edu.tw/pages/yu.tsao/publications_en.html" title="https:&#x2F;&#x2F;www.citi.sinica.edu.tw&#x2F;pages&#x2F;yu.tsao&#x2F;publications_en.html" rel="noopener" target="_blank">Yu Tsao</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://sites.google.com/site/tsainath/" title="https:&#x2F;&#x2F;sites.google.com&#x2F;site&#x2F;tsainath&#x2F;" rel="noopener" target="_blank">Tara N.</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.jonathanleroux.org/" title="http:&#x2F;&#x2F;www.jonathanleroux.org" rel="noopener" target="_blank">Jonathan</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://speechlab.sjtu.edu.cn/members/yanmin_qian" title="https:&#x2F;&#x2F;speechlab.sjtu.edu.cn&#x2F;members&#x2F;yanmin_qian" rel="noopener" target="_blank">Yanmin Qian</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://www.microsoft.com/en-us/research/people/tayoshio/" title="https:&#x2F;&#x2F;www.microsoft.com&#x2F;en-us&#x2F;research&#x2F;people&#x2F;tayoshio&#x2F;" rel="noopener" target="_blank">Takuya Yoshioka</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://scholar.google.com/citations?user=QG8aWfIAAAAJ&hl=zh-CN" title="https:&#x2F;&#x2F;scholar.google.com&#x2F;citations?user&#x3D;QG8aWfIAAAAJ&amp;hl&#x3D;zh-CN" rel="noopener" target="_blank">Marc Delcroix</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="https://sites.google.com/view/xuyong/home" title="https:&#x2F;&#x2F;sites.google.com&#x2F;view&#x2F;xuyong&#x2F;home" rel="noopener" target="_blank">Yong Xu</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://staff.ustc.edu.cn/~jundu/Publications.html" title="http:&#x2F;&#x2F;staff.ustc.edu.cn&#x2F;~jundu&#x2F;Publications.html" rel="noopener" target="_blank">Jun Du</a>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        
  <div class="beian"><a href="http://www.beian.miit.gov.cn/" rel="noopener" target="_blank">陕ICP备 17010872号-1 </a>
  </div>

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">WJ</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">369k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">5:35</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.7.1
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

</body>
</html>
