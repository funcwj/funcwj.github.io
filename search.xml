<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>INTO WPE</title>
    <url>/2020/06/05/into-wpe/</url>
    <content><![CDATA[<p>WPE作为经典的去混算法，在20世纪初由日本NTT的研究人员提出，并在之后被陆续发展，近些年随着声学前端研究热度的提升，远场语音识别需求的增加以及各类测评竞赛的举办，WPE在工业界和学术界得到了广泛的应用。Google在为Google Home做多通道声学建模的一系列工作中，也包含了WPE在online下对声学模型的优化工作。目前关于WPE有两个方向的工作已经陆续完善，一是信号上做joint WPE和beamforming，separation的工作，这个在WPE提出之后就已经有学者开始了研究，二是和deep learning 相结合，使用神经网络估计WPE step中依赖的统计量，之后做去混或者和后续其他模块联合训练 ，比如增强分离模型，声学模型等等。本篇文章打算先梳理一下WPE相关的一些知识，之后谈目前STOA的DNN support WPE的思路。</p>
<a id="more"></a>
<h2 id="Preliminary"><a href="#Preliminary" class="headerlink" title="Preliminary"></a>Preliminary</h2><p>本站点之前有不少文章已经介绍了远场下的信号模型，主要是针对增强和分离场景。去混任务我们需要从另一个角度分解麦克风接受到的信号：即三部分的叠加，直达声，early reverberation和late reverberation（实际操作也可看成两部分，即early和late reverberation）。early &amp; late reverberation部分的信号可以理解为声源信号和RIR的early/late part卷积产生，考虑单通道，单声源，无噪声下，写成：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{y} & = \mathbf{x} * (\mathbf{r}_{\text{early}} + \mathbf{r}_{\text{late}}) = \mathbf{x} * \mathbf{r}_{\text{early}} + \mathbf{x} * \mathbf{r}_{\text{late}} \notag \\
& = \mathbf{y}_{\text{early}} + \mathbf{y}_{\text{late}} \notag
\end{align} \tag{1}</script><p>其中$\mathbf{x},\mathbf{r}$分别表示声源信号和RIR，同时有$\mathbf{r} = \mathbf{r}_{\text{early}} + \mathbf{r}_{\text{late}}$。一般的，RIR early和late部分的划分以RIR peak处（即直达声）向后50ms为分界（见下图，选自Springer Handbook of Speech Processing）。WPE的目标是消除接收信号$\mathbf{y}$中的late reverberation $\mathbf{y}_\text{late}$部分，即以$\mathbf{y}_\text{early}$为最终期望信号。</p>
<p><img src="http://www.funcwj.cn/images/early-reverberation.png" width="400"></p>
<p>这里再解释两个概念，一个是RT60（RT表示混响时间，有些地方喜欢用T60），通常我们用它来描述混响强度，在RIR生成的时候用到。它描述的是使原始信号能量衰减60dB所经历的时间，值越大表示混响越强。第二个是Sabine公式，描述房间墙面反射系数和RT60之间的关系：</p>
<script type="math/tex; mode=display">
\text{RT}_{60} = \frac{0.161V}{S \cdot \alpha} \tag{2}</script><p>$S, V$分别表示房间的表面积和体积，$\alpha$为房间表面的吸收系数（和反射系数$\beta$的关系为$\alpha^2+\beta^2=1$）。simulate RIR的时候，经常用它计算由RT60到$\alpha/\beta$之间的转换。</p>
<h2 id="Derivation"><a href="#Derivation" class="headerlink" title="Derivation"></a>Derivation</h2><p>先来看一下WPE算法是如何实现去混的。目前主要的引用文章为[1,2]，[1]中分别讨论了时域和频域的实现。考虑当前我们大多选用频域算法，因此本文也在频域讨论它的实现。令麦克风个数为$M$，WPE是希望估计出一组阶数为$K$，可用于预测late reverberation的滤波系数$\mathbf{G}_f = [\mathbf{G}_{f, 0}, \cdots, \mathbf{G}_{f, K - 1}]^\top \in \mathbb{C}^{MK \times M}$，再通过相消的形式拿到$\mathbf{y}_\text{early}$在频域的估计：</p>
<script type="math/tex; mode=display">
\mathbf{y}'_{\text{early}, t, f} \in \mathbb{C}^{M \times 1} = \mathbf{y}_{t, f} - \mathbf{y}'_{\text{late}, t, f} =  \mathbf{y}_{t, f} - \sum_k \mathbf{G}_{f,k}^H \mathbf{y}_{t - \Delta - k} \tag{3}</script><p>其中</p>
<script type="math/tex; mode=display">
\mathbf{G}_{f, k} = 
\begin{bmatrix}
g_{f,k}^{0,0} & \cdots & g_{f,k}^{0,M - 1} \\
g_{f,k}^{1,0} & \cdots & g_{f,k}^{1,M - 1}\\
\vdots & \ddots & \vdots \\
g_{f,k}^{M -1,0} & \cdots & g_{f,k}^{M - 1,M - 1}
\end{bmatrix} \in \mathbb{C}^{M \times M} \tag{4}</script><p>为了方便计算，$\mathbf{y}’_{\text{late},t,f}$可写成如下紧凑的形式：</p>
<script type="math/tex; mode=display">
\mathbf{y}'_{\text{late}, t, f} = \sum_k \mathbf{G}_{f,k}^H \mathbf{y}_{t - \Delta - k} = \mathbf{G}_f^H \overline{\mathbf{y}_{t - \Delta, f}} \tag{4}</script><p>其中$\overline{\mathbf{y}_{t - \Delta, f}}\in \mathbb{C}^{MK \times 1}$，展开为：</p>
<script type="math/tex; mode=display">
\bar{\mathbf{y}}_{t - \Delta, f} = [\mathbf{y}_{t - \Delta}^\top, \cdots, \mathbf{y}_{t - \Delta - K + 1}^\top]^\top \tag{5}</script><p>略微不同于论文[1]中的符号表达，每次单独预测一个通道，重复$M$次，上述过程一次将所有通道的预测输出计算出来，这个过程两者是严格等价的，不过后者更加简洁和通用，因此采用这种方式（即和[2]保持一致）。如果按照[1]中的规则，则$\mathbf{G}_f$退化为$\mathbb{C}^{1 \times M}$的向量，$\bar{\mathbf{y}}_{t - \Delta, f}$退化为$\mathbb{C}^{K \times 1}$的向量，增加通道维度的下脚标，写为：</p>
<script type="math/tex; mode=display">
y'_{\text{early}, t, f, m} = y_{t, f, m} - \mathbf{G}_{f,m}^H \overline{\mathbf{y}_{t - \Delta, f}} \tag{6}</script><p>知道了怎么去混响的过程，接下来就是如何估计滤波系数$\mathbf{G}_f$的问题了，这也是[1]和[2]的区别所在。</p>
<h3 id="WPE"><a href="#WPE" class="headerlink" title="WPE"></a>WPE</h3><p>WPE，即论文[1]中，我们假设声源信号$\mathbf{x}$服从零均值的高斯分布，由此式$(1)$中的$\mathbf{y}_\text{early}$同样服从高斯分布，转到频域对应为复高斯分布。建立这样的假设虽然可以比较容易的推出我们现在看到的WPE似然函数的形式，但是在理论层面存在一些弊端，即在噪声和多说话人场景下，$\mathbf{y}_\text{early}$并不一定能满足高斯分布（因为服从高斯分布的随机变量的加和需要在满足独立性的前提下才能是一个高斯分布），所以需要单独分析，这一点也在论文[2]中指出。不过虽然如此，[1]中导出的WPE形式依旧是目前被广泛使用的一种，比如nara_wpe中的实现，这一点会在文章后面说明。</p>
<p>基于$y’_{\text{early}, t, f, m} \sim \mathcal{N}_c \left(0, \lambda_{t,f,m} \right)$，优化的似然函数定义为：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathcal{L}_{f,m} & \approx \sum_t \log p(y'_{\text{early}, t, f, m} | \overline{\mathbf{y}_{t - \Delta, f}} ) \notag  \\
& = - \sum_t \frac{\left \Vert y'_{\text{early}, t, f, m} - \mathbf{G}_{f,m}^H \overline{\mathbf{y}_{t - \Delta, f}}  \right \Vert_2^2}{\lambda_{t,f,m}^2} - \sum_t \log \lambda_{t,f,m}^2 + \text{const} \notag 
\end{align} \tag{7}</script><p>由于上式存在两个未知量，$\lambda_{t,f,m}$和$\mathbf{G}_{f,m}$，用EM算法进行迭代求解，更新过程为：</p>
<script type="math/tex; mode=display">
\begin{align}
\lambda_{t,f,m}^2 & = (y'_{\text{early}, t, f, m})^2 \notag  \\
\mathbf{G}_{f,m} & = \mathbf{R}_{f,m}^{-1} \mathbf{r}_{f,m} \notag 
\end{align} \tag{8}</script><p>估计方差的时候为了提升准确性，也会考虑增加上下文$L$：</p>
<script type="math/tex; mode=display">
\lambda_{t,f,m}^2 = \sum_{n=-L}^L(y'_{\text{early}, t+n, f, m})^2 / (2L+1) \tag{9}</script><p>$\mathbf{R}_{f,m}/\mathbf{r}_{f,m}$定义为：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{R}_{f,m} &= \sum_t \frac{\overline{\mathbf{y}_{t - \Delta, f, m}} \overline{\mathbf{y}_{t - \Delta, f, m}}^H}{\lambda_{t,f,m}^2} \in \mathbb{C}^{M \times M} \notag  \\
\mathbf{r}_{f,m} &= \sum_t \frac{\overline{\mathbf{y}_{t - \Delta, f, m}} y'^*_{\text{early}, t, f, m}}{\lambda_{t,f,m}^2} \in \mathbb{C}^{M \times 1} \notag 
\end{align} \tag{10}</script><p>迭代的时候，初始化$y’_{\text{early}, t, f, m} = y_{t, f, m}$，之后依次按照$(8,10),(6)$的顺序进行迭代即可。</p>
<h3 id="GWPE"><a href="#GWPE" class="headerlink" title="GWPE"></a>GWPE</h3><p>为了解决WPE中先验假设对单声源和无噪声干扰的依赖，[2]中提出了一种新的优化思路，基于信号的相关性。Dry的语音信号，在时延较大的情况下算自相关系数会趋近于0，但是混响信号则不然。所以GWPE的目标是解相关，即解除每个通道解混信号的时序相关性，使用HF互相关作为代价函数，对多元随机变量$\mathbf{y}’_{\text{early}, t, f} \in \mathbb{C}^{M \times 1}$有：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathcal{L}_f & = \text{HF} \left(\mathbf{y}'_{\text{early}, 0, f}, \cdots, \mathbf{y}'_{\text{early}, T - 1, f} \right) \notag  \\
& = \frac{1}{T} \sum_t \log \det \left( E(\mathbf{y}'_{\text{early}, t, f} \mathbf{y}'^H_{\text{early}, t, f}) \right) - \text{const} \notag 
\end{align} \tag{11}</script><p>可以看出，这里并没有对$\mathbf{y}’_{\text{early}, t, f}$本身的分布做任何假设，因此相较于WPE中提出的$\mathcal{N}_c$先验分布，GWPE理论上更加适合在multi-speaker，noisy的环境下做去混。后面就是针对该代价函数提出的辅助函数方法，用于估计滤波系数$\mathbf{G}_f$，这部分在之前的文章中也简单介绍过，这里就简单提一下。辅助函数法中引入了新的中间变量$\mathbf{\Lambda}_{t,f} \in \mathbb{C}^{M \times M}$，定义为：</p>
<script type="math/tex; mode=display">
\mathbf{\Lambda}_{t,f} = E \left(\mathbf{y}'_{\text{early}, t, f} \mathbf{y}'^H_{\text{early}, t, f} \right) \tag{12}</script><p>获取估计之后，用于更新$\mathbf{G}_f = \mathbf{R}_{f}^{-1} \mathbf{r}_{f}$，其中：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{R}_{f} &= \sum_t \overline{\mathbf{y}_{t - \Delta, f}} *\mathbf{\Lambda}_{t,f}^{-1} \overline{\mathbf{y}_{t - \Delta, f}}^H \in \mathbb{C}^{MK \times MK} \notag  \\
\mathbf{r}_{f} &= \sum_t \overline{\mathbf{y}_{t - \Delta, f}} * \mathbf{\Lambda}_{t,f}^{-1} (\mathbf{y}'_{\text{early}, t, f})^H\in \mathbb{C}^{MK \times M} \notag 
\end{align} \tag{13}</script><p>上式中由于$\overline{\mathbf{y}_{t - \Delta, f}}$和$\mathbf{\Lambda}_{t,f}$大小不匹配，所以$*$符号包含了一些reshape的操作，运算之后的矩阵大小依旧为$MK \times 1$。此时可以发现，式$(12)$和$(9)$在形式上是十分相似的。GWPE论文中指出了四种$\mathbf{\Lambda}_{t,f}$的估计方法，分别为对角矩阵，单位矩阵，全相关矩阵和ICA方法。其中在对角矩阵下，$(13)$和$(10)$式完全等价，此时，$\mathbf{\Lambda}_{t,f}$定义为：</p>
<script type="math/tex; mode=display">
\mathbf{\Lambda}_{t,f} = 
\begin{bmatrix}
\lambda_{t,f,0} & \cdots & 0 \\
0 & \ddots & 0 \\
0 & \cdots & \lambda_{t,f,M-1}
\end{bmatrix} \tag{14}</script><p>其中$\lambda_{t,f,m}^2 = (y’_{\text{early}, t, f, m})^2$。单位矩阵下，$\mathbf{\Lambda}_{t,f}$对角值均取$\sum_m (y’_{\text{early}, t, f, m})^2 / M$，全相关矩阵下和CGMM中类似，增加了一个时不变的全相关矩阵$\mathbf{R}_f$，$\mathbf{\Lambda}_{t,f}$定义为$\lambda_{t,f}\mathbf{R}_f^{-1}$，其中</p>
<script type="math/tex; mode=display">
\begin{align}
\lambda_{t,f} & = \frac{1}{M} (\mathbf{y}'_{\text{early}, t, f})^H \mathbf{R}_f^{-1} \mathbf{y}'_{\text{early}, t, f} \notag  \\
\mathbf{R}_f & = \frac{1}{T} \sum_t \mathbf{y}'_{\text{early}, t, f} (\mathbf{y}'_{\text{early}, t, f})^H / \lambda_{t,f} \notag 
\end{align} \tag{15}</script><p>目前Paderborn开源的nara_wpe工具的实现是单位矩阵形式，因此和WPE的逻辑非常类似，核心代码对应着本文中的公式$(6,8,12,13)$。</p>
<p>上述讨论均是在多通道场景下进行的，单通道时候，$\mathbf{\Lambda}_{t,f}$退化为常数，且：</p>
<script type="math/tex; mode=display">
\mathbf{R}_{f} \in \mathbb{C}^{K \times K}, \mathbf{r}_{f} \in \mathbb{C}^{K \times 1}, \overline{\mathbf{y}_{t - \Delta, f}}\in \mathbb{C}^{K \times 1}, \mathbf{G}_f \in \mathbb{C}^{K \times K} \tag{16}</script><h2 id="DNN-Support"><a href="#DNN-Support" class="headerlink" title="DNN Support"></a>DNN Support</h2><p>通过第二部分的讨论可知，WPE中一共只存在两个变量需要估计，一是early reverberation的方差$\lambda_{t,f}$，其次就是用于去混的滤波系数$\mathbf{G}_f$。在信号处理的框架中，每次迭代中依次更新$\lambda_{t,f}$和滤波系数的估计。和NN结合的WPE思路主要是借用神经网络去预测$\lambda_{t,f}$，之后带入公式$(8,13,6)$中跑一个WPE的step得到最终的去混输出。</p>
<p>$\lambda_{t,f}$的定义可以简单理解为early reverberation的功率谱（幅度谱取平方），目前常用的有两种方式，一是直接预测early reverberation的magnitude（或者功率谱），二是借用TF-mask，做掩蔽得到。不过此时mask的定义和此前文章中增强分离的场景不同，分解信号模型为：</p>
<script type="math/tex; mode=display">
\mathbf{y} = \mathbf{x}_\text{early} + \mathbf{x}_\text{late} + \mathbf{n} \tag{17}</script><p>以ratio mask为例，有：</p>
<script type="math/tex; mode=display">
\mathbf{M}_\text{IRM} = \frac{|\mathbf{X}_\text{early}|}{|\mathbf{X}_\text{early}| + |\mathbf{X}_\text{late}| + |\mathbf{N}|} \tag{18}</script><p>得到网络输出的估计之后，用$\hat{\mathbf{M}} \odot |\mathbf{Y}|^2$作为$\lambda_{t,f}$带入公式即可。在多通道场景下，如果只估计一个通道的TF-mask，可以带入单位矩阵的形式计算，若对每个通道都进行估计，则可以选取对角矩阵的形式。</p>
<p>最后还剩下一个疑问，既然NN已经拿到了$\lambda_{t,f}$的估计，为何不直接像增强一样用带噪相位做iSTFT得到去混输出呢？首先需要明确，早期确实有一些文章，就是通过在频域直接预测early reverberation的幅度谱做去混的，但是和增强类似，存在着相位增强的问题，其次是这种掩蔽和回归这种方式带来的distortion相比linear filtering的做法往往很大，这可能带来后续任务，比如增强，分离，识别在性能上的损失。</p>
<p>打通了NN supported WPE之后，就可以开展很多所谓的joint training或者E2E的工作了，即按照传统信号的pipeline串联三个模型，WPE，Beamforming和ASR。目前将E2E-ASR，NN-WPE和mask-based beamforming联合的工作已经有很多了，这些工作的核心归结于如下三步骤：</p>
<ol>
<li>借用NN估计$\lambda_{t,f}$，做WPE step；</li>
<li>借用NN估计$m_{t,f}$，在1之上做mask-based beamforming；</li>
<li>在2之上接(E2E-)ASR模型，用ASR的准则优化整个网络。</li>
</ol>
<p>插一句：最近也有一些signal的文章做joint WPE &amp; Beamforming，目前计划另起一篇文章单独讨论这块内容。</p>
<p>小结一下。回头看一下NN结合WPE和Beamforming的工作，共同点均是只用网络去估计原信号框架中难以直接预测的一个统计量，并保留linear filtering的部分，以此完成结合。故我们深挖传统信号算法的目的在于三点，一是挖掘如何进行结合可以最大程度的拿到gain，二是排查问题时，可以快读定位问题模块，给出优先级，三是对候选方案进行优先级排序，排除明显违背原理的思路和方法。WPE在ASR，speaker等任务上经常作为一个黑盒工具被大家使用，作为语音行业的从业者，个人还是建议同行们抽时间看一下算法背后的原理和推导，这样当后续相关的论文或者工作出来时，可以较快的抓住作者的思路，批判性的看待。</p>
<h2 id="Related-Paper"><a href="#Related-Paper" class="headerlink" title="Related Paper"></a>Related Paper</h2><p>[1] Tomohiro Nakatani, Takuya Yoshioka, Keisuke Kinoshita, Masato Miyoshi, and Biing-Hwang Juang, “Speech dereverberation based on variance-normalized delayed linear prediction,” IEEE Transactions on Audio, Speech, and Language Processing, vol. 18, no. 7, pp. 1717-1731, Sep. 2010.<br>[2] oshioka, Takuya, and Tomohiro Nakatani. “Generalization of multi-channel linear prediction methods for blind MIMO impulse response shortening.” IEEE Transactions on Audio, Speech, and Language Processing 20.10 (2012): 2707-2720.<br>[3]. Kinoshita, Keisuke, et al. “Neural Network-Based Spectrum Estimation for Online WPE Dereverberation.” <em>Interspeech</em>. 2017.<br>[4]. Heymann, Jahn, et al. “Frame-online DNN-WPE dereverberation.” <em>2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC)</em>. IEEE, 2018.<br>[5]. Heymann, Jahn, et al. “Joint optimization of neural network-based WPE dereverberation and acoustic model for robust online ASR.” <em>ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>. IEEE, 2019.<br>[6]. Caroselli, Joe, et al. “Adaptive Multichannel Dereverberation for Automatic Speech Recognition.” <em>Interspeech</em>. 2017.<br>[7]. Drude, Lukas, et al. “Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation.” <em>Interspeech</em>. 2018.<br>[8]. Drude, Lukas, et al. “NARA-WPE: A Python package for weighted prediction error dereverberation in Numpy and Tensorflow for online and offline processing.” <em>Speech Communication; 13th ITG-Symposium</em>. VDE, 2018.</p>
]]></content>
      <categories>
        <category>Microphone Array Processing</category>
      </categories>
      <tags>
        <tag>WPE</tag>
        <tag>Dereverberation</tag>
      </tags>
  </entry>
  <entry>
    <title>后续文章列表</title>
    <url>/2020/04/11/coming-next/</url>
    <content><![CDATA[<ul>
<li>Update Hexo &amp; Next （站点更新记录）</li>
<li>Permutation Alignment Algorithm （BSS空间聚类算法的后处理对齐算法）</li>
<li>TF-mask &amp; Spectral Gain (噪声抑制算法中的Gain)</li>
<li>Unsupervised Training of FE （前端的一些无监督训练方法）</li>
</ul>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
  </entry>
  <entry>
    <title>Conv1D Operations</title>
    <url>/2020/04/10/conv1d-ops/</url>
    <content><![CDATA[<p>今天来总结一下在我过去的一些任务上用到的一些一维卷积技巧，主要是depthwise和transposed conv1d。之所以写一篇文章是觉得存在两方面的好处，其一是可以加深对现代神经网络架构中卷积操作逻辑的理解，二是能提升编码和运算上的效率，让代码本身更加简洁。</p>
<a id="more"></a>
<h2 id="FSMN-amp-Beamformer"><a href="#FSMN-amp-Beamformer" class="headerlink" title="FSMN &amp; Beamformer"></a>FSMN &amp; Beamformer</h2><p>FSMN之前简单的写过一篇文章做介绍，是Shiliang Zhang在2016年提出的一种无反馈结构的，可以用于长序列建模的网络类型，类似的还有TCN（TDNN的延伸）等等。在第$\ell$层，$t$时刻的输出$\mathbf{h}_{t, \ell}$由如下运算产生：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{t, \ell} = f(\mathbf{W}_{\ell} \mathbf{h}_{t, \ell - 1} + \tilde{\mathbf{W}}_{\ell} \tilde{\mathbf{h}}_{t, \ell - 1} + \mathbf{b}) \tag{1}</script><p>其中$\tilde{\mathbf{h}}_{t, \ell - 1}$被称为memory blocks，用于建模上下文信息，在vectorized版本中，表示成如下加权的形式：</p>
<script type="math/tex; mode=display">
\tilde{\mathbf{h}}_{t, \ell - 1} = \sum_{c = 0}^{C} \mathbf{a}_{c, \ell - 1} \odot \mathbf{h}_{t + c - N_l - 1, \ell - 1} \tag{2}</script><p>其中$C = N_r + N_l + 1，N_l, N_r$分别表示左右context的长度。此式的计算可以理解为一个depthwise的一维卷积过程，其中卷积核的大小为$C$，步长为1（原始版本不做下采样）， 输出通道数为$D$，其中$D$表示$\mathbf{a}_{i, \ell - 1}$和$\mathbf{h}_{i, \ell - 1}$的维度。代码上下面的定义进行卷积：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># definition</span></span><br><span class="line">ctx_conv = nn.Conv1d(memory_size,</span><br><span class="line">                     memory_size,</span><br><span class="line">                     kernel_size=ctx_size,</span><br><span class="line">                     dilation=dilation,</span><br><span class="line">                     groups=project_size,</span><br><span class="line">                     padding=(ctx_size - <span class="number">1</span>) // <span class="number">2</span>,</span><br><span class="line">                     bias=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># call</span></span><br><span class="line"><span class="comment"># h: batch x num_frames x memory_size</span></span><br><span class="line"><span class="comment"># m: batch x num_frames x memory_size</span></span><br><span class="line">m = self.ctx_conv(h)</span><br></pre></td></tr></table></figure>
<p>depthwise conv1d的一个非常常见的应用就是用于替代一组线性层，代码上看起来显得更加简洁，比如multi-head attention，beamformer和这里的FSMN中，都可以加以运用。pytorch的api里面，选取groups的值（通常等于输入通道数）来隔绝输入的通道之间的信息交换（分组进行卷积操作并输出到对应的通道中）即可。</p>
<p>还有一点需要注意的是，虽然结果（数学）上是完全等价的，但是逻辑上， conv1d的操作视角不是以时间为单元（也就是语音帧），而是通道，对应特征的维度。比如在上面的<code>ctx_conv</code>层中，卷积核$\mathbf{K} \in \mathbf{R}^{C \times D}$在$c$个通道上学到的结果对应为$\mathbf{k}_c = [a_{c, i}, \cdots, a_{c, N_r + N_l}]$，跨越时间而通道固定。</p>
<p>拓展一下可以用于实现一组（固定）波束形成器。信号上我们一般这样定义一个指向为$\theta$的波束形成器，即</p>
<script type="math/tex; mode=display">
s_{t,f}^\theta = \mathbf{w}_{\theta, f}^H \mathbf{y}_{t,f} \tag{3}</script><p>其中$\mathbf{w}_{\theta, f}, \mathbf{y}_{t,f} = [y_{0,t,f}, \cdots, y_{M - 1,t,f}] \in \mathbf{C}^{M}$，$M$为通道数。从上式可以看出，beamformer的权重在每个频率上是独立的，因此可以用depthwise conv1d进行实现，加上操作在复数域，再用两个conv1d定义一层复数卷积即可。式$(3)$可用下面的卷积层进行计算，需要注意的是，由于每一帧的操作逻辑相同，因此需要将输入的时间维度和batch的维度（通常也就是第一维）合并：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># definition</span></span><br><span class="line">beamformer = ComplexConv1d(num_bins,</span><br><span class="line">                           num_bins,</span><br><span class="line">                           num_channels,</span><br><span class="line">                           groups=num_bins,</span><br><span class="line">                           padding=<span class="number">0</span>,</span><br><span class="line">                           bias=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># call</span></span><br><span class="line"><span class="comment"># x: batch*num_frames x num_bins x num_channels, complex tensor</span></span><br><span class="line"><span class="comment"># beam: batch*num_frames x num_bins x 1, complex tensor</span></span><br><span class="line">beam = beamformer(x)</span><br></pre></td></tr></table></figure>
<p>如果是$\Theta$个波束形成器，只需要将输出通道数调整为$\Theta \times F$即可，对应的输出则为<code>batch*num_frames x num_beams*num_bins x 1</code>。</p>
<p>最后小结一下，如果想用depthwise conv1d去做一些运算的简化或者实现，需要在原表达式中找到通道维度上的线性变换操作，并且满足一定的独立性要求。合适的使用可以将原本看起来比较复杂的表达式（加和，点乘，线性变换等等）用一个卷积操作完成，代码上精炼很多。</p>
<h2 id="i-STFT"><a href="#i-STFT" class="headerlink" title="(i)STFT"></a>(i)STFT</h2><p>本部分说一下用（转置） conv1d做(i)STFT的逻辑，虽然很早之前就在用了，但是实现上的细节以及背后的原理存在有一些需要解释的地方。信号上的(i)STFT分别对应分帧，加窗，DFT以及iDFT，加窗，重叠相加（Overlap and Add，OLA）的过程，其中分帧和OLA可以借用conv1d和transposed conv1d来进行，同时将卷积核初始化为DFT变换矩阵和窗函数的乘积，以合并加窗和(i)DFT的逻辑。</p>
<p>用$\mathbf{K}_{\text{(i)DFT}} \in \mathbf{C}^{N \ \times N}$表示(i)DFT变换矩阵，满足如下正交关系：</p>
<script type="math/tex; mode=display">
\mathbf{K}_{\text{DFT}}^H \mathbf{K}_{\text{iDFT}} = I \tag{4}</script><p>一般的，为了满足这个条件，有两种可以选择的初始化方法，分别为：</p>
<script type="math/tex; mode=display">
\begin{cases}
\mathbf{K}_{\text{DFT}} = \mathbf{W}/\sqrt{N}, \mathbf{K}_{\text{iDFT}} = \mathbf{W}^H/\sqrt{N} \\
\mathbf{K}_{\text{DFT}} = \mathbf{W}, \mathbf{K}_{\text{iDFT}} = \mathbf{W}^H/N
\end{cases} \tag{5}</script><p>其中$\mathbf{W}$表示单位矩阵的DFT变换结果，即$\mathcal{F}(\mathbf{I})$，$N$为FFT bins的个数。第一种中，正逆变换矩阵为酉矩阵，第二种一般是我们写(i)FFT的逻辑，对iFFT的结果需要除一个$N$，相当于在变换矩阵上加一个同等的系数。语音信号为实信号，所以STFT拿到的实部和虚部可看成是卷积核的实部和虚部单独作用的结果，表示为：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{Y}^R &= \text{conv}_{\text{1D}} \left(\mathbf{x}, \mathbf{K}_{\text{DFT}}^R \odot \mathbf{w}, S\right) \notag \\
\mathbf{Y}^I &= \text{conv}_{\text{1D}} \left(\mathbf{x}, \mathbf{K}_{\text{DFT}}^I \odot \mathbf{w}, S \right)  \notag
\end{align} \tag{6}</script><p>其中$\mathbf{x}$为语音信号序列，$\mathbf{w}$表示STFT的分析窗，$S$为帧移。合并成一个卷积操作后即：</p>
<script type="math/tex; mode=display">
\text{STFT}(\mathbf{x}) = [\mathbf{Y}^R; \mathbf{Y}^I]^T = \text{conv}_{\text{1D}} \left(\mathbf{x}, \left[\mathbf{K}_{\text{DFT}}^R; \mathbf{K}_{\text{DFT}}^I \right]^T \odot \mathbf{w}, S\right) \tag{7}</script><p>$\mathbf{K} = [\mathbf{K}_{\text{DFT}}^R; \mathbf{K}_{\text{DFT}}^I]^T \in \mathbf{R}^{2N \times N}$。Pytorch中可以对应的初始化为（实际需要考虑窗长和FFT bins数不同的情况）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">init_kernel</span><span class="params">(frame_len,</span></span></span><br><span class="line"><span class="function"><span class="params">                frame_hop,</span></span></span><br><span class="line"><span class="function"><span class="params">                window,</span></span></span><br><span class="line"><span class="function"><span class="params">                round_pow_of_two=True,</span></span></span><br><span class="line"><span class="function"><span class="params">                normalized=False,</span></span></span><br><span class="line"><span class="function"><span class="params">                inverse=False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Return STFT kernels</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># FFT points</span></span><br><span class="line">    B = <span class="number">2</span>**math.ceil(math.log2(frame_len)) <span class="keyword">if</span> round_pow_of_two <span class="keyword">else</span> frame_len</span><br><span class="line">    <span class="keyword">if</span> normalized:</span><br><span class="line">        <span class="comment"># make K^H * K = I</span></span><br><span class="line">        S = B**<span class="number">0.5</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        S = <span class="number">1</span></span><br><span class="line">    I = th.stack([th.eye(B), th.zeros(B, B)], dim=<span class="number">-1</span>)</span><br><span class="line">    <span class="comment"># W x B x 2</span></span><br><span class="line">    K = th.fft(I / S, <span class="number">1</span>)[:frame_len]</span><br><span class="line">    <span class="keyword">if</span> inverse <span class="keyword">and</span> <span class="keyword">not</span> normalized:</span><br><span class="line">        <span class="comment"># to make K^H * K = I</span></span><br><span class="line">        K = K / B</span><br><span class="line">    <span class="comment"># 2 x B x W</span></span><br><span class="line">    K = th.transpose(K, <span class="number">0</span>, <span class="number">2</span>) * window</span><br><span class="line">    <span class="comment"># 2B x 1 x W</span></span><br><span class="line">    K = th.reshape(K, (B * <span class="number">2</span>, <span class="number">1</span>, frame_len))</span><br><span class="line">    <span class="keyword">return</span> K</span><br></pre></td></tr></table></figure>
<p>需要对上面的代码做几点解释。第一，为什么要卷积核选择成全DFT的结果而不是rFFT的结果？因为如果只是用于一般声学特征的提取，取<code>K = th.rfft(th.eye(B) / S, 1)[:frame_len]</code>即可。这是考虑到，在做iSTFT的时候我们需要一个全DFT的核。第二，为什么没有给<code>K</code>取逆和共轭。不取逆是因为DFT的矩阵本身是酉矩阵，共轭转置就是自身的逆，因此，在inverse的情况下，返回的卷积核跟实际iDFT使用的其实只差了一个共轭而已，至于这个共轭为何不取，下面的文章会进行解释。</p>
<p>在<code>init_kernel</code>的初始化kernel作用下，返回的STFT结果是一个full FFT的形式，对于一般声学特征的提取，取前$N / 2 + 1$部分就行。若将$[\mathbf{Y}^R; \mathbf{Y}^I]^T $变换到时域，使用一维转置卷积表示为：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{x}' & = \text{deconv}_{\text{1D}}([\mathbf{Y}^R; \mathbf{Y}^I]^T, \left[\mathbf{K}_{\text{DFT}}^R; \mathbf{K}_{\text{DFT}}^I \right]^T \odot \mathbf{w}, S) \notag \\
& = \text{deconv}_{\text{1D}}(\mathbf{Y}^R, \mathbf{K}_{\text{DFT}}^R \odot \mathbf{w}, S) + \text{deconv}_{\text{1D}}(\mathbf{Y}^I, \mathbf{K}_{\text{DFT}}^I \odot \mathbf{w}, S) \notag
\end{align} \tag{8}</script><p>这么做背后的原理有二，其一是iSTFT中，对于每一帧，我们实际只使用iDCT变换的实部，根据复数运算$(a + bi)(c + di) = (ac - bd) + (ad + bc)i$，只需要保留$ac - bd$的实部即可。第二问题就是，$(8)$式中连接实部结果和虚部结果的符号是加号，结果依然正确，如何解释？。因为我们实际使用的卷积核是没有取共轭的结果，所以真实的结果应该是$(a + bi)(c - di) = (ac + bd) + (ad - bc)i$中的$ac + bd$，负号变成加号，和$(8)$式子的结果一致。分析之后，可以简单验证一下一帧变换的结果：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">B = <span class="number">8</span></span><br><span class="line">th.random.manual_seed(<span class="number">666</span>)</span><br><span class="line">w = init_window(<span class="string">"rect"</span>, B)</span><br><span class="line">W = init_kernel(B, B // <span class="number">2</span>, w, normalized=<span class="literal">True</span>)</span><br><span class="line">x = th.rand(<span class="number">1</span>, <span class="number">1</span>, B * <span class="number">2</span>)</span><br><span class="line">x[..., B:] = <span class="number">0</span></span><br><span class="line">p = tf.conv1d(x, W, stride=B, padding=<span class="number">0</span>)</span><br><span class="line">y = tf.conv_transpose1d(p, W, stride=B, padding=<span class="number">0</span>)</span><br><span class="line">print(<span class="string">f"x = <span class="subst">&#123;x.squeeze()&#125;</span>"</span>)</span><br><span class="line">print(<span class="string">f"y = <span class="subst">&#123;y.squeeze()&#125;</span>"</span>)</span><br><span class="line">print(<span class="string">f"error: <span class="subst">&#123;th.sum(x - y).item():f&#125;</span>"</span>)</span><br></pre></td></tr></table></figure>
<p>验证输出</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">x = tensor([0.3119, 0.2701, 0.1118, 0.1012, 0.1877, 0.0181, 0.3317, 0.0846, 0.0000,</span><br><span class="line">        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])</span><br><span class="line">y = tensor([0.3119, 0.2701, 0.1118, 0.1012, 0.1877, 0.0181, 0.3317, 0.0846, 0.0000,</span><br><span class="line">        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])</span><br><span class="line">error: 0.000000</span><br></pre></td></tr></table></figure>
<p>如果不清楚一维转置卷积的逻辑的同学可以写几个toy验证一下overlap and add的结果，这样就能理解到本部分的一些符号表达了。网上有一些关于通用转置卷积的分析，不过理解起来有些麻烦，在一维条件下，从这个角度切入就清晰很多。 最后关于iSTFT的实现还有几个细节问题，解释如下：</p>
<ol>
<li><p>在做iSTFT的时候，如果输入为onesided的STFT结果（即前$N / 2 + 1$个），需要先padding到$N$个，之后参与到转置卷积中去。具体的逻辑就是根据DFT结果的对称性，实部关于$N / 2 + 1$对称，实部共轭对称。</p>
</li>
<li><p>主流的iSTFT会在时域的信号上加一个根据窗函数计算的归一化系数，用于保证变换前后的幅度一致（以及解决窗本身的一些正交性问题），比如<a href="https://github.com/librosa/librosa/blob/6f93e1f2d06af95078195b4e1ecee3ea5843a7e2/librosa/core/spectrum.py#L377" target="_blank" rel="noopener">librosa</a>里面的，和<a href="https://github.com/pytorch/audio/blob/2ebbbf511fb1e6c47b59fd32ad7e66023fa0dff1/torchaudio/functional.py#L171" target="_blank" rel="noopener">torchaudio</a>里面的，逻辑就是对窗函数的能量也做一个OLA的过程，因此同样可以用转置卷积得到：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">win = th.repeat_interleave(window[<span class="literal">None</span>, ..., <span class="literal">None</span>],</span><br><span class="line">                           packed.shape[<span class="number">-1</span>],</span><br><span class="line">                           dim=<span class="number">-1</span>)</span><br><span class="line"><span class="comment"># W x 1 x W</span></span><br><span class="line">I = th.eye(window.shape[<span class="number">0</span>], device=win.device)[:, <span class="literal">None</span>]</span><br><span class="line"><span class="comment"># 1 x 1 x T</span></span><br><span class="line">norm = tf.conv_transpose1d(win**<span class="number">2</span>, I, stride=frame_hop, padding=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>全部分的code由于篇幅我没有放在文章中，按照本文的解释是可以完整无误的写出来的，之后可以测几个音频样例，算一下误差验证算法逻辑。</p>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>最后小结一下吧。这部分内容其实是过去几年经常用到的conv1d操作，乘着最近在做ASR的repo，便来小结一下，关于(i)STFT那部分花了一些时间去理解背后的逻辑和设计问题，早期网上有一些版本的实现，但是个人觉得多少有些问题，比如操作上有偏差或者冗余等等。类似的操作在实际编码中个人觉得还是需要注意的，因为知道每种操作背后的逻辑之后，可以辅助的产生一些高效的编码，一定程度上也可以节省工程或者实验的时间。</p>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>STFT</tag>
      </tags>
  </entry>
  <entry>
    <title>SETK in 2019</title>
    <url>/2020/03/20/setk-in-2019/</url>
    <content><![CDATA[<p>2019年我只对<a href="https://github.com/funcwj/setk" target="_blank" rel="noopener">setk</a>贡献了一些边边角角的东西，没有大的方面的改动。当初写的时候，也多是出于我自身实践上的一些需求，才将常见的操作以脚本的形式固定。但是随着技术的进步，工具链的完善和自身认识的加深，以前的某些需求，在我有了更加高效和便捷的实现方式之后，便没有继续在setk中进行集成。本篇文章主要记录一下过去一年的更新和随之产生的一些想法。</p>
<p>先结合这个工具集合主要包含的部分说一下2019年的更新。1）数据IO和可视化，2）数据预处理，3）数据仿真，4）特征提取，5）评估与后处理。</p>
<a id="more"></a>
<h2 id="数据IO和可视化"><a href="#数据IO和可视化" class="headerlink" title="数据IO和可视化"></a>数据IO和可视化</h2><p>数据IO当初为了兼容Kaldi（特征和recipe），规范和格式基本都跟随它的风格，同时在此之上拓展了一些numpy，matlab，audio的IO支持。Kaldi的IO部分从我另一个repo <a href="https://github.com/funcwj/kaldi-python-io" target="_blank" rel="noopener">kaldi-python-io</a>中修改而来，19年主要更新有二，其一是对vector和matrix两种对象IO进行了统一，不加区分，这样接口使用的时候便捷很多，其二是优化了对compress数据格式的读取，效率上要远超之前。audio的IO采用soundfile替代原来的scipy，主要原因是可以支持chunk-level的读写，在某些情况下可以节省IO时间。可视化上，改进了一下TF矩阵，音频频谱的可视化，控制了一下输出的dpi和默认的字体。</p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>数据预处理部分包含的是一些信号层面的预处理算法，波束形成，声源定位，盲源分离，去混响这些，通常一个脚本对应一个具体的功能。这个方向是我后面想打算强化的，主要原因如下。一是我对前端这块，纯算法和理论一直比较感兴趣，传统的算法虽然效果不如现在的DL模型，但是计算量小，而且无监督，可以拿到即时的反馈，里面有很多概念和原理，即使在DL大行其道的今天，依然能够看到它们的影子。二是不论在产品还是研究上，往往需要一些信号的pipeline去做预处理，或者搭建基线等，显然是需要一个规范易用的工具去做这些事情，减轻这方面的复现工作。2019年增加了基于最大似然和srp-phat的定位脚本，优化了cacgmm/cgmm的盲源分离脚本，同时增加在基于mask的自适应波束形成中增加了一些新的特性和选项，固定波束目前只提供了延迟相加和超指向两种。后面的话，像一些自动增益控制（AGC），噪声抑制（NS），回声消除（AEC），包括GSC结构的波束形成框架，其他的一些定位算法等等，我也是希望可以添加到这一模块中去。</p>
<h2 id="数据仿真"><a href="#数据仿真" class="headerlink" title="数据仿真"></a>数据仿真</h2><p>数据仿真指的是包括rir生成在内的，加噪加混响，产生近/远场训练数据相关的过程。目前我自己形成的一个比较稳定的规范（流程）是将这个过程划分成三步进行。第一步，产生rir和噪声数据，准备原始干净数据。rir仿真的脚本之前已经提供，19年增加了使用gpuRIR的选项，这样可以极大的提升rir仿真的效率。噪声数据一般使用开源的或者自己实录的。第二步，使用脚本产生针对单/多通道，近/远场的数据配置文件，格式统一定义，可以支持增强，分离，识别等多个任务。这么做的目的有多个考虑，一是不用产生实际的数据，避免了磁盘空间的浪费，尤其在数据量很大的情况下，二是可以在训练阶段配合对应的数据加载器，进行在线的数据合成，三是同时固定了训练集的数据，不同模型的对比结果更加客观，四是从数据的角度来看，便于调试和重新配置，五是对于一些完全没有经验进行数据仿真的人来说，按照这个pipeline，只需要配置一些原始数据，噪声，rir，就可以进行数据仿真了。第三步是可选的，如果需要的话，可以用另一个脚本从配置文件生成数据本身，用于数据检查，以及一些不用在线数据加载器的情况下，进行模型训练。目前二三步对应的脚本还没有merge到分支中去，我本人是比较推荐这种逻辑的，也是我实践了很久之后认可的方式。</p>
<h2 id="特征提取"><a href="#特征提取" class="headerlink" title="特征提取"></a>特征提取</h2><p>特征提取这块是变动比较小的一个地方，因为最近一两年来，我基本已经很少用离线特征提取这一方式准备特征了。之前的话，为了兼容Kaldi，在这方面留有一些脚本，包括产生方向特征（只支持线阵和PCA的导向向量估计），IPD特征，谱/mel-filter bank特征，mask的标签等等。如今全部换成在线的特征提取流程，自己也有Pytorch对应常用的声学特征实现，包括单/多通道，增强/识别任务在内的。这样做的好处依旧是可以简化实验的pipeline，基本配置一下数据就可以进行训练，而且免去对磁盘空间的占用。所以后期可能会继续补充，优化一些脚本，不做大用，只是为了拿到一些即时的结果，分析一下数据等等。</p>
<h2 id="评估与后处理"><a href="#评估与后处理" class="headerlink" title="评估与后处理"></a>评估与后处理</h2><p>最后一个部分，评估和后处理。评估这块基本也没有什么新增的内容，由于我一般很少算增强的那些pesq，stoi等指标，目前主要是WER，SNR这些，用于快速评估实验结果。后处理主要包括TF-masking和TF-mapping两种方法的时域音频合成，由于目前多是端到端的结构，前者偶尔会用到，而后者就基本很少用到了。</p>
<p>简单小结一下。在此之前，主要是2018年，setk的编码主要是围绕我个人的需求在里面，因为当时手上的任务很杂，前端后端都要考虑，所以想做的是针对speech这些任务本身，打通前后端的处理流程，后端则主要要对接Kaldi。从去年年初开始，因为在实践中慢慢的产生了一些自己的思考，加上对前端一些算法理解的加深，增加了一部分新的功能，实现上更加高效和全面一些，如上所述。对于2020年，我觉得又迎来了一个新的阶段，已经毕业的我，计划加一些我自己感兴趣的模块和算法进去（主要是前端这块的pipeline），看后面的工作强度和时间安排吧，考虑有时候自己比较佛系，进度上可能会比较慢……。</p>
<p>此外，毕业前还不紧不慢的搭了一个E2E-ASR的repo，围绕着个人的习惯和想法，设计了一些易用的特性，做了点单多通道的实验。 这其实是我早在研一就想做的事（但是当年各方面可能达不到要求），结果被拖到了毕业前才差不多开始。晚做的也有一些好处，就是对任务的理解比较深刻的话，从头实现起来效率挺高，自己在遇到问题之后，也可以明显发现定位，解决的速度快了不少。很多时候这样一种感觉，就是看到一种做法，或者产生一种想法，按照自己的思路实现之后，拿到了一些效果，或者产生一些预期的现象，内心才会产生认可，是比较美妙的一件事情，反之，则会一直留有顾虑，想起来有些心虚。虽然可能有些质疑说，费了很大劲写那么多code，跑出来的结果可能不如其他开源的code，白白浪费不少时间。在我看来，我在意的是这个从无到有的过程，而不是要比结果（硬要调的话，未必会差很多），否则因噎废食，会错过很多美味的。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>SETK</tag>
      </tags>
  </entry>
  <entry>
    <title>frp代理访问学校服务器</title>
    <url>/2020/02/15/frp-ssh/</url>
    <content><![CDATA[<p>由于新冠疫情，学校开学延迟，因此短期内大家还是要维持远程办公的状态。我这边的需求，一是访问实验室内部的wiki， 二是计算资源，也就是服务器。但是由于学校的vpn的问题，连接经常处于极不稳定的状态，因此十分影响心态和效率。本篇文章简单记录了一下如何使用frp跳过学校vpn，远程连接学校服务器。</p>
<a id="more"></a>
<p><a href="https://github.com/fatedier/frp" target="_blank" rel="noopener">frp</a>（快速反向代理）是一个可以用于内网穿透的反向代理应用，很早之前就知道它，但是由于自己一直没有一个公网上的vps，所以没能能拿来做什么事情。一些常见的需求，比如想暴露自己在某个局域网内部（家庭，学校，公司等等）的某些服务（文件，web等等）到公网之外，都可以使用它进行内网穿透（前提是需要有一个公网的主机，进行请求转发）。</p>
<p>ssh连接内网机器的配置README上写的很详细，但是要注意把服务器上对应的端口打开，不然后面ssh的时候会出现”connection refused”的错误。我服务端的系统是centos，可以配合firewall-cmd进行端口管理，写一个脚本<code>run_server.sh</code>：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># wujian@2020</span></span><br><span class="line"></span><br><span class="line">[ <span class="variable">$#</span> -ne 2 ] &amp;&amp; <span class="built_in">echo</span> <span class="string">"script format error: <span class="variable">$0</span>: &lt;server-port&gt; &lt;client-port&gt;"</span> &amp;&amp; <span class="built_in">exit</span> 1</span><br><span class="line"></span><br><span class="line">server_port=<span class="variable">$1</span></span><br><span class="line">client_port=<span class="variable">$2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># check and open service port</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> <span class="variable">$server_port</span> <span class="variable">$client_port</span>; <span class="keyword">do</span></span><br><span class="line">    port_query=$(firewall-cmd --zone=public --query-port=<span class="variable">$p</span>/tcp)</span><br><span class="line">    <span class="keyword">if</span> [[ <span class="variable">$port_query</span> -eq <span class="string">"no"</span> ]]; <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span>: open port <span class="variable">$p</span> ..."</span></span><br><span class="line">        firewall-cmd --zone=public --add-port=<span class="variable">$p</span>/tcp &amp;&amp; <span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span>: open port <span class="variable">$p</span> done"</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$0</span>: port <span class="variable">$p</span> already opened, skip..."</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> SSH_SERVER_PORT=<span class="variable">$server_port</span></span><br><span class="line">./frps -c ./frps.ini 2&gt;&amp;1 &gt; server.<span class="variable">$&#123;server_port&#125;</span>.<span class="built_in">log</span></span><br></pre></td></tr></table></figure>
<p>脚本里面使用环境变量进行server port的设置，因此<code>frps.ini</code>里面对应的使用go模板的方式。firewall-cmd是linux上一个替代iptables的防火墙管理工具，使用文档可以参考这里<a href="https://wangchujiang.com/linux-command/c/firewall-cmd.html" target="_blank" rel="noopener">firewall-cmd</a>。<br>服务端启动起来之后，在学校的服务器上对应的启动客户端的程序，对应使用<code>run_server.sh</code>里面指定的<code>&lt;server-port&gt;</code>和<code>&lt;client-port&gt;</code>:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[common]</span><br><span class="line">server_addr &#x3D; &lt;server-addr&gt;</span><br><span class="line">server_port &#x3D; &lt;server-port&gt;</span><br><span class="line"></span><br><span class="line">[ssh]</span><br><span class="line">type &#x3D; tcp</span><br><span class="line">local_ip &#x3D; 127.0.0.1</span><br><span class="line">local_port &#x3D; 22</span><br><span class="line">remote_port &#x3D; &lt;client-port&gt;</span><br></pre></td></tr></table></figure>
<p>如果两端的log里面没有error，则说明服务启动正常，接下来就可以进行ssh和scp操作了。在上述配置下，对应的连接命令为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ssh -p &lt;client-port&gt; &lt;user-name&gt;@&lt;server-addr&gt;</span><br></pre></td></tr></table></figure>
<p><code>&lt;user-name&gt;</code>为学校服务器的用户名，本地到远程的数据传输命令为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -P &lt;client-port&gt; -r /<span class="built_in">local</span>/data/path  &lt;user-name&gt;@&lt;server-addr&gt;:/remote/data/path</span><br></pre></td></tr></table></figure>
<p>反之为：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scp -P &lt;client-port&gt; -r &lt;user-name&gt;@&lt;server-addr&gt;:/remote/data/path /<span class="built_in">local</span>/data/path</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>frp</tag>
      </tags>
  </entry>
  <entry>
    <title>Speech Enhancement &amp; Separation简介</title>
    <url>/2020/01/13/intro-on-se-and-ss/</url>
    <content><![CDATA[<p>这几年明显感觉做分离增强这块的人越来越多了，一方面学术研究上逐渐成为了一个热点，不断的有新的模型和思路产生，一方面工业界想将技术落到具体的产品中，也必将面临实际声学环境中的各种噪声，说话人干扰问题。我曾经从新人的角度，考虑如下三个因素，推荐对语音感兴趣的人从前端开始着手：1）相比识别任务，没有特征提取，解码，对齐这些繁杂的操作，门槛相对低了很多；2）前端处理的结果，可以通过样例直观的感受到，相比识别WER和解码结果这种反馈度不高的结果，趣味性和吸引力要高很多；3）对数据的依赖较低，识别需要一定量的数据积累，抄本也需要依赖人工标注，而增强分离这些任务，做一些toy的东西，用开源的数据和噪声仿真就行了。当然这些是基于目前主流的深度学习方法所下的论断，在此之前，声学，信号等领域的大佬们已经用他们的才智对抗这些问题很多年了，形成了非常完备的理论系统，如果要深入那些方法的话，数学统计理论的要求自然不可与我们现在单纯训模型并论。</p>
<a id="more"></a>
<h3 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h3><p>最近趁着准备毕业的空挡，从论文中整理了一些增强分离领域中的基本方法和概念，其中有些内容我之前也有单独的文章和内容上的拓展。考虑到这几年的技术进步非常快，本篇文章中罗列的内容大部分已经非常成熟，甚至可以说有些过时，放在这里的目的是想把增强/分离中的一些基本的概念，处理的框架，主流的方法和背后的因果关系串联起来，可以让新人有个大致的印象。对一些最新的工作，本文没有做过多介绍，感兴趣的同学可以后续在近几年的<a href="https://www.isca-speech.org/" target="_blank" rel="noopener">interspeech</a>，icassp和<a href="https://arxiv.org/list/eess.AS/recent" target="_blank" rel="noopener">arxiv-ASLP</a>上自行检索相关文章。</p>
<p>虽然这个站点上记录了一些我自己总结的东西，但是我个人还是建议读者直接从参考的原始文献中去做具体和细致的学习，形成自己的理解。本站上的内容大多是我对相关工作的认识，有我自身主观的成分，通常情况下，我也不会主动将站点上的内容推荐给别人阅读，即使是我实验室的低年级同学，有时间的话，我也是选择当面跟说清重点之后，再让他们去阅读相关文章。一般写作上比较规范的文章，会在文中对相关的工作和基本的原理进行详细的阐述，有不明白的地方，就顺着参考文献继续追踪。通常在语音这块，追踪个十几篇文章就可以对当前的研究领域有个大体的了解。之后的事情，就是实践，这个非常重要，因为个人觉得，文中的具体方法，操作，技巧，只有在自己亲自实验之后，才能放入自我认可的知识库中。很多自己不确定的因素，变量，甚至是对方法的质疑，都可以通过对比实验中的结论得到“确定”，哪怕它们中的一些是数据相关的。</p>
<h3 id="单通道语音增强"><a href="#单通道语音增强" class="headerlink" title="单通道语音增强"></a>单通道语音增强</h3><p>单通道语音增强的信号模型如$(1)$所示，观测的带噪信号$\mathbf{y} = \{y_0, \cdots, y_{N - 1}\}$可以视为由目标干净语音$\mathbf{s} = \{s_0, \cdots, s_{N - 1}\}$和噪声信号$\mathbf{n} = \{n_0, \cdots, n_{N - 1}\}$在时域上的叠加而成，$N$表示信号样本点的个数。经过短时傅里叶变换（Short-Time Fourier Transform，STFT）之后，在频域上同样可以表示为相应的成分叠加形式：</p>
<script type="math/tex; mode=display">
\begin{equation}
\mathbf{y} = \mathbf{s} + \mathbf{n} \overset{\text{STFT}}{\longrightarrow} \mathbf{Y} = \mathbf{S} + \mathbf{N},
\end{equation}</script><p>其中$\mathbf{Y}, \mathbf{S}, \mathbf{N} \in \mathbb{C}^{T \times F}$。$T, F$分别表示STFT的帧数和频点数。需要注意的是，在数据仿真（data simulation）的阶段，我们最好保证上述关系，以便匹配本文后续介绍的一些代价函数。</p>
<p>神经网络大行其道之后，学者借助网络在大量的带噪/干净语料对上，学习到的可以用于恢复目标语音的一些中间变量进行语音增强。早期比较成功的尝试是在频域进行的，即先将音频进行STFT变换，在频域增强之后，再借助逆变换还原，代表性的工作有俄亥俄州立大学汪德亮组提出的频谱掩蔽<sup>[1,2,3]</sup>（Time-frequency Masking） 和佐治亚理工学院李锦辉教授提出的频谱映射<sup>[4,5]</sup>（Spectral Mapping）两种方法。</p>
<p>频谱掩蔽方法通过神经网络从带噪信号的声学特征中估计出每个时频点（Time-Frequency bins，TF-bins）的信号掩码（mask），用于表示目标信号成分的占比。TF-mask的概念最早出现在空间聚类算法和CASA中。基于语谱上的稀疏性原理，我们可以借助逆短时傅里叶变换（inverse Short-Time Fourier Transform，iSTFT）将经TF-mask掩蔽的带噪线性谱从频域还原到时域作为增强语音的结果。由于目标语音的相位信息尚不可知，早期的处理方法是使用原带噪信号的相位信息替代。上述过程可以表示成如下数学表达式：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \hat{\mathbf{s}} = \text{iSTFT} \left(\hat{\mathbf{M}} \odot |\mathbf{Y}|, \angle \mathbf{Y} \right),
\end{equation}</script><p>其中$\hat{\mathbf{M}} \in \mathbb{R}^{T \times F}$表示神经网络预测的目标mask，$|\mathbf{Y}|$和$\angle \mathbf{Y}$分别表示噪声信号的线性谱和相位。谱映射方法采用使用网络直接预测目标的线性谱$|\hat{\mathbf{S}}|$的方式，信号还原过程相应的表示为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \hat{\mathbf{s}} = \text{iSTFT} \left(|\hat{\mathbf{S}}|, \angle \mathbf{Y} \right).
\end{equation}</script><p>在理想的情况下，谱映射的方法比时频掩蔽法的理论上限更高，因为后者即使mask可以完美学得，相比原始干净的谱特征也是存在误差的。但是从训练的角度来说，由于目标mask的值一般落在一个有界的区域，所以相比直接预测线性特征，网络往往更加容易收敛。基于公式$(1)$中定义的信号模型，早期被广泛尝试和使用的用于恢复目标语谱$|\mathbf{S}|$的mask类型主要有如下几种：</p>
<ul>
<li><p>理想二值掩码<sup>[3]</sup>（Ideal Binary Mask，IBM）。IBM的定义可以表示为：</p>
<script type="math/tex; mode=display">
\begin{equation}
  \mathbf{M}^{\text{IBM}}_{t,f} = \mathcal{I} \left(\frac{|\mathbf{S}_{t,f}|}{|\mathbf{N}_{t,f}|} > \theta \right) \in \{0, 1\}.
\end{equation}</script><p>其中$\mathcal{I}(\cdot)$表示指示函数。当TF-bin上的信噪比超出某个阈值$\theta$时，就认为该频点上，目标信号占据统治地位，IBM值取1，反之取0。在一般实验中，我们会取$\theta = 1$。</p>
</li>
<li><p>理想比率掩码<sup>[6]</sup>（Ideal Ratio Mask，IRM）。不同于IBM，IRM的值是受限连续的，它被定义为：</p>
<script type="math/tex; mode=display">
\begin{equation}
  \mathbf{M}^{\text{IRM}}_{t,f} = \frac{|\mathbf{S}_{t,f}|}{|\mathbf{S}_{t,f}| + |\mathbf{N}_{t,f}|} \in [0, 1].
\end{equation}</script><p>IRM的一个性质是信号模型中各个成分的掩码值加和为1（在单通道增强模型中即噪声成分和目标语音成分）。</p>
</li>
<li><p>理想幅度掩码<sup>[7]</sup>（Ideal Amplitude Mask，IAM）。IAM又称FFT-mask，和IRM的定义类似，只是分母被替换为观测信号的模值：</p>
<script type="math/tex; mode=display">
\begin{equation}
  \mathbf{M}^{\text{IAM}}_{t,f} = \frac{|\mathbf{S}_{t,f}|}{|\mathbf{Y}_{t,f}|} \in [0, +\infty].
\end{equation}</script><p>根据复数的三角不等式$|a + b| \leqslant |a| + |b|$，相同的$\mathbf{S}, \mathbf{N}$计算出来的IAM要大于IBM，且在理论上IAM的值没有上限。</p>
</li>
<li><p>相位敏感掩码<sup>[8]</sup>（Phase-Sensitive Mask，PSM）。以上三种TF-mask均没有考虑到目标分量和噪声信号的相位差别，PSM提出使用目标分量在观测信号方向上的投影做为IAM定义式中的分子：</p>
<script type="math/tex; mode=display">
\begin{equation}
  \mathbf{M}^{\text{PSM}}_{t,f} = \frac{|\mathbf{S}_{t,f}| \cos(\angle \mathbf{S}_{t,f} 
  - \angle \mathbf{Y}_{t,f})}{|\mathbf{Y}_{t,f}|} \in [-\infty, +\infty].
\end{equation}</script><p>在增强任务中取得了超越其他实数mask的结论。由于投影结果可正可负，因此，理论上的PSM相比IAM而言，没有下界约束。</p>
</li>
</ul>
<p>一般的，训练阶段将TF-mask或增强谱的预测视为一个回归任务，使用均方误差（Mean Square Error，MSE）作为目标函数进行训练：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathcal{L}_{\text{MSE}} = \left \Vert \hat{\mathbf{M}} - \mathbf{M}_{\text{GT}} \right \Vert_F^2.
\end{equation}</script><p>其中$\hat{\mathbf{M}}$为网络预测的结果，$\mathbf{M}_{\text{GT}}$为对应的真实参照值，$\Vert \cdot \Vert_F$表示矩阵的F范数。对于IBM，因为值是离散的，也可以使用BCE（Binary Cross Entropy）进行优化。此外，在使用IAM或者PSM的时候，有如下两个方面需要注意：</p>
<p>第一是上下界的截断。因为实TF-mask的预测网络一般采用非线性的激活函数（比如ReLU，Sigmoid等等）作为最终输出，预测值非负，所以对于PSM这种可能产生负值的mask，需要加一个下界处理（深入分析之后，这其实是目标语音和带噪语音相位反向条件下的非负最优解）。而为了网络训练的稳定，也会对IAM和PSM进行上界约束，这样得到的mask成为截断的IAM/PSM（tIAM，tPSM）：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
    \mathbf{M}_{\text{tPSM}} & = \min \left(\max(0, \mathbf{M}_{\text{PSM}}), m_{\text{ub}} \right), \\
    \mathbf{M}_{\text{tIAM}} & = \min \left(\mathbf{M}_{\text{IAM}}, m_{\text{ub}} \right),
\end{aligned}
\end{equation}</script><p>其中$m_{\text{ub}}$表示设定的TF-mask值上界。</p>
<p>其二是损失函数的变形。对于这两种mask，我们常常使用信号谱层面重构的MSE来替代在公式$(8)$中mask层面的MSE，这种方法分别被称之为幅度谱近似（Magnitude Spectrum Approximation，MSA）和截断相位敏感谱近似（truncated Phase-sensitive Spectrum Approximation，tPSA），数学表达为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \begin{aligned}
    \mathcal{L}_{\text{MSA}} & = \left \Vert |\mathbf{Y}| \odot \hat{\mathbf{M}}  - |\mathbf{S}| \right \Vert_F^2, \\
    \mathcal{L}_{\text{tPSA}} & = \left \Vert |\mathbf{Y}| \odot 
    \hat{\mathbf{M}} - |\mathbf{S}| \odot \max(0, \cos(\angle \mathbf{S} - \angle \mathbf{Y})) \right \Vert_F^2.
\end{aligned}
\end{equation}</script><p>上述部分已经围绕频谱掩蔽和谱映射两种方法的动机和优化目标进行了简单介绍。它们的共性在于只在语谱特征上进行了增强，相位上并未做进一步的处理。考虑到相位对于提升重构语音质量有着十分明显的作用（体现在一些客观指标上，比如PESQ，SNR等等），因此如何突破相位增强这一问题也逐渐成为学术界研究的重点。由于相位在结构性和稳定性上要比谱特征要差很多，即使原始信号只发生很小量的偏移，每个频率上的相位值也会有较大的变化，再加上其周期性和相位混叠等现象的影响，实际语音的相位往往是十分随机的，因此尝试使用神经网络去直接预测绝对相位十分困难。</p>
<p>一种比较直观的方法即同时恢复目标语音的复数谱$\hat{\mathbf{S}}$，可以借助复数掩码（Complex Masks）或者复数谱映射的方法进行，之后iSTFT的还原操作替换为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \hat{\mathbf{s}} = \text{iSTFT} \left( |\mathbf{\hat{\mathbf{S}}}|, \angle \mathbf{\hat{\mathbf{S}}} \right),
\end{equation}</script><p>其中$\mathbf{\hat{\mathbf{S}}} = \mathbf{Y} \odot \hat{\mathbf{M}_{\text{CM}}}$。2016年Williamson等人提出复数比率掩码<sup>[9]</sup>（Complex Ratio Mask，CRM）定义为$\mathbf{M}_{\text{CRM}} = \mathbf{S} / \mathbf{Y} = |\mathbf{S}| \odot e^{j(\angle \mathbf{S} - \angle \mathbf{Y})} / |\mathbf{Y}|$，由于其实部（即PSM）和虚部都是无界的，实际训练中使用压缩后的结果为目标。测试阶段再对应的进行解压做频谱掩蔽和信号还原。虽然较实mask可以获得一定的提升，但是在实际压缩参数的选取中，不合适的压缩/解压参数对重构影响较大，甚至有可能取得适得其反的结果。此外，一种修正的复数掩码计算方式配合复数卷积网络和时域的代价函数被提出<sup>[10]</sup>，约束了幅制掩码部分的上届，但是允许相位部分自由调节。在我自己的实现中，该方法表现相比CRM要相对鲁棒一些。</p>
<p>此外更加直接的方法是在时域上进行音频的建模和目标函数计算。早在2015年，Yuxuan Wang等人就提出使用iFFT层将掩蔽的频谱转到时域进行重构误差函数的计算和梯度的反向传播<sup>[11]</sup>，虽然当时使用的依旧是噪声的相位，但是在语音增强质量和清晰度指标上都超越了IRM的基线。近几年陆续有一些时域上的结构和方法被提出，比如基于GAN<sup>[12]</sup>和卷积网络<sup>[13,14,15]</sup>的等等。这些方法可以直接生成时域上的样本点，因此免去了频域中iSTFT对相位的依赖，很好的跳过了相位增强这一问题，我们常常在文献中称之为端到端（End-to-End，E2E）的语音增强方法。</p>
<h3 id="单通道语音分离"><a href="#单通道语音分离" class="headerlink" title="单通道语音分离"></a>单通道语音分离</h3><p>单通道语音分离的信号模型和增强类似，只是存在多个说话人的重叠，观测的混合信号$\mathbf{y}$可以视为噪声$\mathbf{n}$和$C$个说话人$\mathbf{s}^i, i \in {0, \cdots, C - 1}$信号的交叠，数学上可以表达为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{y} = \sum_i \mathbf{s}^i + \mathbf{n} 
    \overset{\text{STFT}}{\longrightarrow} \mathbf{Y} = \sum_i \mathbf{S}^i + \mathbf{N}.
\end{equation}</script><p>语音分离即是要从混合的观测信号中恢复每个原始说话人的信号内容。随着深度学习技术在语音增强领域的成功应用，学者开始研究如何将其应用到解决分离问题上去。早期尝试是在我们称之为说话人相关（Speaker Dependent，SD）和目标说话人相关（Target Dependent，TD）的场景下的。SD模型的训练在固定的说话人混合数据上进行<sup>[16]</sup>，网络同时预测每个说话人的TF-mask，测试时说话人种类和训练集保持一致，因此不具备在集外说话人上的泛化能力，想要解决其他说话人组合下的分离问题只能通过训练多个模型来实现。TD模型只能提取单一固定的目标说话人<sup>[17]</sup>，但是对干扰说话人的类型没有限制。这种情景下的解决思路和上一节介绍的语音增强方法非常一致，只是目标从语音信号变成了特定的说话人，想要实现多说话人的提取也必须训练多个模型。学术界和工业界更多期待的是一种被称为说话人无关（Speaker Independent，SI）的分离方法，模型可以泛化到任意新的说话人中去，即测试和训练时候都不受说话人种类的干扰，因此相对而言具备更加广阔的研究和落地前景。</p>
<p>以两个说话人为例，如果采用SD的方法，即同时预测两个说话人的mask，采用的目标函数，比如：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathcal{L}_{\text{MSA, SD}} = \sum_{c = \{0, 1\}} \left \Vert |\mathbf{Y}| \odot \hat{\mathbf{M}}_c  - |\mathbf{S}_c| \right \Vert_F^2.
\end{equation}</script><p>直接在大量的双说话人混合语料上进行训练是无法取得成功的。因为模型在训练阶段面临所谓的标签置换问题<sup>[18]</sup>（Label Permutation Problem）。该问题指的是由于分离模型本身无法决定所分离的说话人顺序，在计算代价函数时我们又需要指定和训练标签对应的匹配顺序，一旦指定的顺序和实际输出的顺序不符，那么网络便会向相反的方向进行优化，从而导致网络训练失败的现象。比如实际预测的说话人mask顺序为$\hat{\mathbf{M}}_1, \hat{\mathbf{M}}_0$，而此时如果还根据公式$(13)$就会产生相反的梯度更新方向。说话人个数越多，计算代价函数时可能的匹配方式就越多，因此网络的优化也越难进行。</p>
<p>最早尝试解决标签置换问题并在说话人无关的语音分离任务上取得成功的是深度聚类<sup>[18]</sup>（Deep Clustering，DPCL）方法。它是由北美三菱电子研究院（MERL）的John R. Hershey等人在2015年提出的，同时还在WSJ数据集上创建了用于分离任务的公开数据集wsj0-2/3mix，极大的推动了说话人无关的语音分离技术的发展。DPCL没有直接尝试在代价函数中解决标签置换问题，而是通过嵌入表示-聚类的思路，得到每个说话人的IBM。具体说来，DPCL使用神经网络将混合语音频谱上的每个TF-bin映射成一个有区分性的$D$维嵌入向量：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{|Y|}^{TF} \to \mathbf{V}^{TF \times D},
\end{equation}</script><p>使得同一个说话人能量占比强的bin对应的嵌入向量距离较近，不同说话人占比强的距离较远。在测试阶段，使用聚类算法，比如K-means等，得到每个TF-bin的聚类标签，进而生成IBM，用于掩蔽混合语谱并还原成语音信号。神经网络的代价函数基于最小化两个亲和性矩阵的距离：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \begin{aligned}
        \mathcal{L}_{\text{DPCL}} & = \Vert \mathbf{V} \mathbf{V}^T - \mathbf{U}\mathbf{U}^T\Vert_F^2 \\
                                  & = \Vert \mathbf{V}^T \mathbf{V} \Vert_F^2 + \Vert \mathbf{U}^T \mathbf{U} \Vert_F^2
                                  - 2 \Vert \mathbf{V}^T \mathbf{U} \Vert_F^2,
    \end{aligned}
\end{equation}</script><p>其中$\mathbf{U} \in \mathbb{R}^{TF \times C}$表示由IBM目标堆叠而成的one-hot编码矩阵。在实际训练中，由于能量较小的时频点难以划分类别归属，一般设置一个阈值将静音的TF-bin在代价函数计算和推断、聚类过程中屏蔽掉。</p>
<p>在DPCL的最早文献中，作者还尝试了一种从代价函数计算上解决标签置换问题的方法，但是没有获得成功。后来，这种方法被微软研究院的Dong Yu等人成功实践，并称之为置换不变训练<sup>[19]</sup>（Permutation Invariant Training，PIT）。PIT的思路是，既然网络无法决定说话人输出的顺序，那么就在代价函数计算时，遍历每个训练样本（帧级别或者句子级别）所有可能的组合方式，选择最小的Loss值进行梯度回传。对于有$C$个说话人的分离问题中，需要遍历$C!$种组合方法。早期由于采用前馈网络进行mask预测，标签置换问题存在于每一帧的输出中，需要在帧级别做PIT。随后改进的网络采用RNN结构，在句子级优化置换不变的目标函数，取得了更好的分离结果，这种方式也被称为句子级的置换不变训练<sup>[20]</sup>（Utterance-level Permutation Invariant Training，uPIT）。以tPSA为例，代价函数可以写为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathcal{L}_{\text{uPIT}, \text{tPSA}} = \min_{\pi \in \mathcal{P}} \sum_c \left \Vert |\mathbf{Y}| \odot 
    \hat{\mathbf{M}}_{\pi(c)} - \max(0, \cos(\angle \mathbf{S}_c - \angle \mathbf{Y})) \odot |\mathbf{S}_c|
    \right \Vert_F^2,
\end{equation}</script><p>其中$\mathcal{P}$表示在$C$个说话时的所有排列方式。Dong Yu等人使用PSA优化训练双向长短时间记忆网络（BLSTM）取得了和DPCL类似的结果。</p>
<p>这两种方法是目前解决说话人无关的语音分离问题中的主要思路。近两年来，基于此也发展出了很多改进的形式和结构，比较具有代表性的有Zhuo Chen等人在DPCL上的后续工作Deep Attractor Network<sup>[21,22]</sup>（DANet），俄亥俄州立大学Zhongqiu Wang提出的Chimera++<sup>[23]</sup>等。DPCL和PIT的思路还被延伸到在多通道语音分离场景中，同样取得了突破性的成果。但是这些工作和增强存在的问题相同，都聚焦于如何最小化估计的TF-mask的误差，以达到频谱增强的目的，重构相位的问题尚未被解决。对此，学者分别从频域和时域上给出了各自的解决方案。</p>
<p>频域上的方法依旧是针对如何修正原始的噪声相位进行，其中增强部分介绍的复数掩码/复数谱映射的思路也是适用的。2018年Zhongqiu Wang借用多输入频谱逆转<sup>[24]</sup>（Multiple Input Spectrogram Inversion，MISI）的方法修正每个说话人的相位信息，同时使用时域上的代价函数，也被称为波形近似（Waveform Approximation，WA），替代之前的PSA，使得mask估计网络和MISI部分可以在时域的代价函数下进行联合优化。WA的定义为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathcal{L}_{\text{uPIT}, \text{WA}} = \min_{\pi \in \mathcal{P}} \left \Vert \hat{\mathbf{s}}_{\pi(c)} - \mathbf{s}_c \right \Vert_1,
\end{equation}</script><p>其中$\Vert \cdot \Vert_1$表示向量的1范数。进行时域和频域变换的关键STFT和iSTFT均使用一维卷积层实现，因此可以进行高效的推断和自动梯度求导。通过MISI-WA的方法在wsj0-2mix的测试集上获得了相比Chimera++网络1个dB的Si-SNR提升。2019年，其又提出了包括改进版的MISI，使用组延迟（Group Delay）以及符号预测网络在内的相位重构方法，获得了在wsj0-2/3mix数据集上最好的分离效果。</p>
<p>时域上建模的方法以哥伦比亚大学Yi Luo等人提出的TasNet<sup>[25]</sup>为代表。TasNet使用一维编码和解码卷积层替代频域方法中的STFT和iSTFT，主分离网络在编码的空间中进行特征学习和解混，并直接使用Si-SNR<sup>[26]</sup>作为时域上重构语音$\mathbf{s}_e$的代价函数，其定义如下：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \text{Si-SNR} \left(\mathbf{s}_e, \mathbf{s}_r \right) = 20 \log_{10} \frac{\Vert \alpha \cdot 
    \mathbf{s}_r \Vert_2}{\Vert \mathbf{s}_e - \alpha \cdot \mathbf{s}_r \Vert_2}.
\end{equation}</script><p>$\alpha = \mathbf{s}_e^T \mathbf{s}_r / \mathbf{s}_r^T \mathbf{s}_r$是一个正交缩放因子，使得loss的值和信号的缩放程度无关，$\mathbf{s}_r$表示目标参考信号。结合PIT，网络的代价函数为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathcal{L}_{\text{uPIT}, \text{Si-SNR}} = \max_{\pi \in \mathcal{P}} \text{Si-SNR} \left(\hat{\mathbf{s}}_{\pi(c)}, \mathbf{s}_c \right).
\end{equation}</script><p>2018年，受WaveNet结构启发，Yi Luo改进了主分离网络的结构，提出了以一维空洞卷积层（TCN结构）堆叠而成的级联块作为分离主体的Conv-TasNet<sup>[27]</sup>，成为首个在wsj0-2mix数据集上超越Oracle Mask掩蔽结果的模型。此结构相比之前的频域模型具有如下两个优势：1）时延低，TasNet的帧长和帧移（2.50/1.25ms）相比频域通常的32/16ms要低的多，因此在一些有实时率要求的场景下有着潜在的应用空间。 2）参数量少，推断速度快。相比频域模型中经常使用的RNN结构，一维卷积在参数量和训练，推理的速度上都有着明显的优势。</p>
<p>以上所述的模型均未使用任何说话人相关的先验信息，也被称为盲源分离算法。它们所共同存在的问题主要如下：其一是存在说话人个数的依赖问题，其二是模型本身不能将分离的信号和具体的说话人对应起来（输出的无序性）。对于第一点，DPCL和PIT系列的表现有所不同。DPCL的模型没有对说话人个数的依赖，但是在测试阶段的聚类中，需要事先指定说话人的个数。而PIT系列，网络的输出分支数决定了所能分离的说话人个数上限。两个模型都可以进行所谓的多说话人训练（Multi-speaker Training），即训练中使用含有不同说话人个数的混合语料，以此达到可以分离不同说话人个数混合的语句的目的。此外，学者还开始了一种被称为知情语音分离（Informed Speech Separation）方案的研究。它指的是假设在可以获得目标说话人相关的一些先验信息，包括说话人的声纹特征（Speaker Embeddings）、方向特征（Directional Features）、视觉特征（Visual Features）的前提下，只进行单一目标说话人抽取的方法。模型的预测和输入的有偏（biased）特征对应的说话人保持一致，同时模型本身不依赖于混合句子中的说话人的个数，比较好的解决了BSS中存在的问题。这一系列的工作主要包括Google的VoiceFilter<sup>[28]</sup>，NTT的SpeakerBeam工作<sup>[29]</sup>，Microsoft的LG（Location Guided）模型<sup>[30]</sup>， Google和Oxford的音视频分离工作<sup>[31,32]</sup>等等。当然弊端就是完全依赖系统中指导特征质量，一旦它们的区分性丧失，分离的效果也就难以得到保证。</p>
<h3 id="多通道增强与分离"><a href="#多通道增强与分离" class="headerlink" title="多通道增强与分离"></a>多通道增强与分离</h3><p>远场语音交互的实际场景，比如会议系统，智能音箱等，常常会使用麦克风阵列技术，同时收集多路语音信号用于前端声学处理，这类增强和语音分离技术我们一般称之为多通道技术。由于不同的麦克风所处的空间位置不同，收集的信号之间会存在相对的延迟，这种时延信息为我们设计算法提供了除了时间，频率之外第三个维度的信息：空间信息（Spatial）。多通道语音增强和分离技术的关键就在于如何利用这里的空间成分。</p>
<p>阵列技术中最具代表性的算法便是波束形成（Beamforming）<sup>[33,34]</sup>，也被称为空间滤波（Spatial Filtering）。其本质是一组线性滤波系数，通过每个频率子带上的滤波操作，对非目标方向上的噪声能量进行抑制，进而达到提升输出语音信号质量目的。由于在波束形成器的设计阶段，会对信号失真度进行约束，因此，它的增强输出不会产生严重的语音失真，对于识别任务而言比较友好，但是在信噪比的提升上也因此受限，不及前文所说的频谱掩蔽算法等等。波束形成可以分为固定波束算法和自适应波束形成算法两大类。固定波束形成器（Fixed Beamformer）需要在已知麦克风阵列几何结构的前提下，先设计好在每个方向上的滤波系数，实际运行中，不进行任何的更新，因此它的指向性是固定的，即每个波束只能对特定方向上的声源进行增强。代表性的算法为延迟相加（Delay and Sum，DS），超指向（Super-Directive，DS）等等。自适应波束形成器的滤波权重可以随着声学环境的变动而自发的调整，即指向性可以自适应的发生变化，因此对新环境的适应能力较强，代表性的算法有多通道维纳滤波（Multi-Channel Wiener Filtering）,最小方差无失真相应（Minimum Variance Distortionless Response，MVDR），广义特征值分解（Generalized Eigenvalue Decomposition，GEVD）。和波束形成相关度比较大的算法是声源定位（Sound Source Localization，SSL），主要用于计算出声源所在方向，常常和固定波束形成器一起使用，用于选择合适的波束。语音分离上则是一些早期为了解决鸡尾酒会问题而专门提出的概念。方法上大体分为两类，一类以ICA，IVA，TRINICON<sup>[35]</sup>为代表，期望从观测信号中估计出一个解混矩阵，可以最大化解混后信号的独立性。另一类以Sawada提出的空间聚类算法为代表<sup>[36]</sup>。这类算法工作的原理是，当声源在空间位置上的分布不同时，其到达麦克风的时延会存在差异，产生不同的相位分布。在每个频率子带的时频点上，能量占优的声源观测到的相位信息会趋于一致，不同的声源差异就会在每个频率上形成聚类效应。所以选择合适的聚类算法在每个频率上对观测结果进行聚类，就可以得到每个声源的TF-mask。空间聚类算法一般假设一个混合模型建模每个TF-bin的观测向量，通过EM算法估计混合模型中每个成分的参数之后，用该观测下的后验概率做为每个声源的TF-mask估计。目前被研究过的混合分布有CWMM<sup>[37]</sup>，CGMM<sup>[38]</sup>和CACGMM<sup>[39]</sup>等等。</p>
<p>神经网络在单通道增强和分离任务中得到广泛应用之后，学者逐渐开始将其拓展到多通道算法中来。其中有一部分用于对上述传统算法的改进和结合，比如Jahn Heymann提出的基于时频掩码的波束形成<sup>[40]</sup>（Mask based Beamforming），使用神经网络预测的TF-mask来估计自适应波束形成算法中的协方差矩阵和导向向量等统计量，相比传统的SSL-MVDR和空间聚类的算法在CHiME3数据上分别取得了25%和12%的WER绝对下降。此外，还有一些空间聚类算法和神经网络结合的思路，比如使用前者估计的TF-mask作为神经网络训练的标签<sup>[41]</sup>，以及使用混合分布模型的log似然作为神经网络优化的目标<sup>[42]</sup>，进行无监督学习；使用DPCL产生的嵌入特征和原始空间上的观测特征在混合模型中联合建模的方法<sup>[43]</sup>等等。</p>
<p>特征方面，单通道的场景下，神经网络只利用单一的谱特征信息进行TF-mask的预测，而在多通道场景中，需要考虑如何让神经网络去有效的利用空间信息。上面提到的和空间聚类算法联合的思路需要依赖额外的模型和处理步骤，因此算法上显得臃肿。而单纯的空间聚类算法却只利用了空间信息，没有对谱特征进行建模，也无法从利用海量数据进行学习。基于这两点考虑，Zhongqiu Wang等人提出了在DPCL和PIT模型中利用通道相位差<sup>[44,45]</sup>（Inter-channel Phase Difference，IPD）的方法增加输入特征的空间信息。通道$i$和$j$之间的IPD定义如下：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \text{IPD}_{ij} = \angle e^{j(\angle \mathbf{Y}_i - \angle \mathbf{Y}_j)} 
    = \text{mod}(\angle \mathbf{Y}_i - \angle \mathbf{Y}_j + \pi, 2\pi) - \pi.
\end{equation}</script><p>由于相位的周期性，IPD这种空间特征是不连续的，cosIPD或者sinIPD在频域可以将IPD转换成连续的螺旋状的分布，对于神经网络而言相对容易建模，因此在实际实验中常常使用它们作为空间特征。其次由于空间混叠的存在，空间特征是存在歧义的，单纯的空间特征不具备足够的区分性，因此还需要和谱特征拼接在一起作为网络输入。IPD首先在DPCL中得到了应用，在2通道的情况下，使用了cosIPD和sinIPD拼接的结果可以在多通道wsj0-2mix数据上拿到2dB的SDR绝对提升，对应的在Chimera++网络中，可以获得2.5dB的SDR绝对提升。</p>
<p>此外，还有一种更具区分性的特征被应用于分离任务中，即角度特征<sup>[30,45,46]</sup>（Angle Feature，也被称为方向特征，Directional Features）。在已知声源方向的条件下，角度特征表示为实际观测到的相位差和该声源波达方向下理想相位差的余弦距离：</p>
<script type="math/tex; mode=display">
\begin{equation} 
    \text{AF}_{ij, \theta} = \cos(\text{IPD}_{ij} - \Delta_\theta),
\end{equation}</script><p>其中$\theta$表示声源方向，$\Delta_\theta$表示该方向下计算得到的参考相位差估计，目前可以使用两种方法计算，一是根据麦克风的拓扑结构，二是用PCA的方法估计，需要借助该声源的TF-mask。如果两者接近，那么在对应的TF-bin上，方向特征的值会趋近于1，不同方向上的说话人特征因此可以被区分开，且分布上和频谱，理想掩码存在一定的相似性，如果存在$P$对麦克风信号对$\psi$，可以通过如下的计算增加其鲁棒性，类似SRP-PHAT算法中的操作：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \text{AF}_{\theta} = \frac{1}{P}\sum_{i,j \in \psi} \cos(\text{IPD}_{ij} - \Delta_\theta).
\end{equation}</script><p>基于上述的多通道空间特征和方案，后续有学者提出了一些针对多通道说话人分离问题的系统性解决方案（即包含定位，分离，增强等模块），有代表性的比如[46,47,48]等。</p>
<p>下面从信号模型入手，导出一下常用的几种自适应波束形成器。信号模型上远场条件下相比单通道要更加复杂，需要考虑声源位置，信号传播，干扰噪声，房间混响等因素。一般的，麦克风$i \in \{0, \cdots, M - 1\}$处接收到的信号$\mathbf{y}_i$可以建模为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \begin{aligned}
        \mathbf{y}_i & = \sum_{j} \mathbf{x}_{ij} + \mathbf{n} \\
                     & = \sum_{j} \mathbf{r}_{ij} * \mathbf{s}_j + \sum_k \mathbf{r}_{ik} * \mathbf{n}_k + \mathbf{n}_i,
    \end{aligned}
\end{equation}</script><p>其中$\mathbf{x}_{ij} = \mathbf{r}_{ij} * \mathbf{s}_j, j \in \{0, \cdots, C - 1\}$。$C$表示说话人个数，$*$表示卷积操作， $\mathbf{r}_{ij}, \mathbf{r}_{ik}$分别为声源$j$和定向噪声$k$到麦克风$i$处的传输函数，$\mathbf{n}_i$表示麦克风$i$处的环境噪声。可以使用STFT将上式在频域表示为：</p>
<script type="math/tex; mode=display">
\begin{equation}
\begin{aligned}
    \mathbf{y}_{i, f} & = \sum_j r_{ij, f} \mathbf{s}_{j, f} + \sum_k r_{ik, f} \mathbf{n}_{k,f} + \mathbf{n}_{i, f} \\
                      & = \sum_j r_{ij, f} \mathbf{s}_{j, f} + \mathbf{n}_{f}.
\end{aligned}
\end{equation}</script><p>$\mathbf{y}_{i, f}, \mathbf{s}_{j, f}, \mathbf{n}_f \in \mathbb{C}^{T}$，$f$表示频率索引。在信号处理中，通常习惯以$\mathbf{y}_{t,f} = [y_{0, tf}, \cdots, y_{M - 1, tf}]$为一个独立的观测向量，上式还可以重写为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{y}_{t, f} = \sum_j \mathbf{r}_{j, f} \cdot s_{j, tf} + \mathbf{n}_{t, f},
\end{equation}</script><p>其中$\mathbf{r}_{j, f} = [r_{0j, f}, \cdots, r_{(M - 1)j, f}]$。一般在增强问题中，$C = 1$，上式可以简化为：</p>
<script type="math/tex; mode=display">
\begin{equation} \label{enh-tf-expr}
    \mathbf{y}_{t, f} = \mathbf{x}_{t, f} + \mathbf{n}_{t, f} = \mathbf{d}_f \cdot s_{t, f} + \mathbf{n}_{t, f}
\end{equation}</script><p>我们将$\mathbf{d}_f = \mathbf{r}_{0, f} \in \mathbb{C}^{M}$称为导向向量（Steer Vector），用于表示声源到阵列处的声学传输过程。这个概念在很多波束形成算法设计中频繁出现，因此十分重要。</p>
<p>波束形成算法的核心问题就是如何估计一组线性滤波系数，对非目标方向上的噪声进行能量抑制。这个过程在频域可以表示为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \hat{s}_{t,f} = \mathbf{w}_f^H \mathbf{y}_{t, f},
\end{equation}</script><p>其中$\mathbf{w}_f \in \mathbb{C}^M$为在频率子带$f$上的滤波系数，$(\cdot)^H$表示共轭转置。固定波束算法中，$\mathbf{w}_f$被提前设计好并在运行时保持不变，而自适应波束形成算法则会根据所处的声学环境自动的更新滤波系数。代表性的自适应波束形成算法有MVDR、GEVD、PMWF等，下面会依次介绍MVDR和GEVD两种方法。</p>
<p>将式$(26)$带入$(27)$可得：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \hat{s}_{t,f} = (\mathbf{w}_f^H \mathbf{d}_f) s_{t, f} + \mathbf{w}_f^H \mathbf{n}_{t, f},
\end{equation}</script><p>其中$\mathbf{w}_f^H \mathbf{n}_{t, f}$被称为残留噪声（Residual Noise）。MVDR的优化目标即是要最小化输出的残留噪声能量，并保证目标语音不失真。该优化问题可以表示为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{w}_f^{\text{MVDR}} = \arg \min_{\mathbf{w}_f} E_t \left[ |\mathbf{w}_f^H \mathbf{n}_{t, f}|^2 \right] 
    \quad \text{s.t} \quad \mathbf{w}_f^H \mathbf{d}_f = 1.
\end{equation}</script><p>使用拉格朗日乘子法可得MVDR滤波系数的解为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{w}_f^{\text{MVDR}} = \frac{(\mathbf{R}_f^n)^{-1} \mathbf{d}_f}{\mathbf{d}_f^H(\mathbf{R}_f^n)^{-1} \mathbf{d}_f},
\end{equation}</script><p>其中$\mathbf{R}_f^n = E_t [\mathbf{n}_{t, f} \mathbf{n}_{t, f}^H] \in \mathbb{C}^{M \times M}$表示噪声成分的协方差矩阵。由此可以看出，MVDR的性能好坏关键在于导向向量$\mathbf{d}_f$和噪声的协方差矩阵$\mathbf{R}_f^n$估计上。传统的方法需要依赖定位模块得到声源的波达方向（Direction of Arrival，DoA），并依据麦克风的阵列结构计算出理想情况下的导向向量。以均匀线性阵列（Uniform Linear Array，ULA）为例子，<br>在平面波，无混响的建模假设下，可以计算出已知波达方向$\theta$时，各路信号相对于0号麦克风的时延向量：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{\tau}_\theta = [0, d\cos(\theta)/c, \cdots, d(M - 1)\cos(\theta)/c],
\end{equation}</script><p>其中$c$表示声音传播速度，$d$表示相邻两个麦克风之间的间距。在信号无衰减的理想情况下，导向向量为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{d}_{\theta, \omega} = [1, e^{-j\omega \tau_{\theta, 1}}, \cdots, e^{-j\omega \tau_{\theta, M - 1}}],
\end{equation}</script><p>其中$\omega = 2\pi f / K$，$K$为FFT全频点数。实际中因为考虑到房间混响，信号衰减等因素，这种方法计算出来的导向向量是不准确的，因此带来的MVDR性能也十分有限，准确的估计导向向量也是传统方法的一个难点。同理，对于噪声的协方差矩阵也是如此。在空间聚类算法中，研究者提出使用借助TF-mask的方法来估计协方差矩阵，即：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{R}_f^{k} = \frac{1}{\sum_t m_{t, f}^k} \sum_t m_{t, f}^k \mathbf{y}_{t, f} \mathbf{y}_{t, f}^H, \; k \in \{n, s\},
\end{equation}</script><p>其中$m_{t, f}^k$为估计的成分$k$在时频点$t,f$处的mask，相关其他的算法介绍将在本文的第二节进行。此外，由于MVDR的计算中存在求逆运算，因此，常常在数值稳定性上也存在一定的隐患。</p>
<p>不同于MVDR，GEVD的优化目标从信噪比出发，希望最大化滤波之后，每个频率上的信噪比：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{w}_f^{\text{GEVD}} = \arg \max_{\mathbf{w}_f} 
    \frac{E_t \left[ |\mathbf{w}_f^H \mathbf{x}_{t, f}|^2 \right]}{E_t \left[ |\mathbf{w}_f^H \mathbf{n}_{t, f}|^2 \right]} 
    = \arg \max_{\mathbf{w}_f} \frac{\mathbf{w}_f^H \mathbf{R}_{f}^s \mathbf{w}_f}{\mathbf{w}_f^H \mathbf{R}_{f}^n \mathbf{w}_f}.
\end{equation}</script><p>$\mathbf{R}_{f}^s$为声源信号的协方差矩阵。上式中的极值是一个瑞利商问题，所以可以用广义特征值算法来进行求解，结果即是$\mathbf{R}_{f}^n$和$\mathbf{R}_{f}^s$的主广义特征向量（最大广义特征值对应的特征向量）。GEVD的滤波的结果可能会引入一定程度的语音失真，即每个频率上的信噪比增益不同。一般的，可以加入一步后滤波操作来缓解这种现象造成的影响，称为Blind Analytic Normalization（BAN）：</p>
<script type="math/tex; mode=display">
\begin{equation}
    g_{f}^{\text{BAN}} = \frac{\sqrt{\mathbf{w}_f^H \mathbf{R}_{f} \mathbf{R}_{f} \mathbf{w}_f / M}}{\mathbf{w}_f^H \mathbf{R}_{f} \mathbf{w}_f}.
\end{equation}</script><p>应用到式$(27)$中：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \hat{s}_{t,f} = g_{f}^{\text{BAN}} \cdot (\mathbf{w}_f^{\text{GEVD}})^H \mathbf{y}_{t, f}.
\end{equation}</script><p>此外，关于$\mathbf{R}_{f}^n$和$\mathbf{R}_{f}^s$，一般会假设目标信号和噪声信号不相关，因此，它们有如下关系，可以用来简化或者演化一些波束形成表达式的等价形式：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{R}_{f}^y = \mathbf{R}_{f}^n + \mathbf{R}_{f}^s,
\end{equation}</script><p>其中$\mathbf{R}_{f}^y = E_t [\mathbf{y}_{t, f} \mathbf{y}_{t, f}^H ]$。比如式$(34)$可以写成：</p>
<script type="math/tex; mode=display">
\begin{equation} 
    \mathbf{w}_f^{\text{GEVD}} = \arg \max_{\mathbf{w}_f}  
    \frac{\mathbf{w}_f^H \mathbf{R}_{f}^y \mathbf{w}_f}{\mathbf{w}_f^H \mathbf{R}_{f}^n \mathbf{w}_f} - 1.
\end{equation}</script><p>式$(30)$也常常写成PMWF中$\beta = 0$的这个无关导向向量的形式：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{w}_f^{\text{PMWF-}\beta} = \frac{(\mathbf{R}_f^n)^{-1} \mathbf{R}_f^s}{\beta + \text{trace}\left[(\mathbf{R}_f^n)^{-1} \mathbf{R}_f^s \right]} \mathbf{u}_r.
\end{equation}</script><p>$\mathbf{u}_r$表示一个one-hot矩阵，用于选择参考麦克风。其中$\beta = 0$时，则对应多通道维纳滤波（MCWF）。这部分的具体推导可见<a href="https://www.funcwj.cn/2019/01/10/rank1-const-pmwf">rank1-const-pmwf</a>。</p>
<p>关于导向向量，目前被广泛使用的是一种被称为主成分分析（PCA）的方法，它使用估计的声源信号协方差矩阵的主特征向量（用$\mathcal{P}(\cdot)$表示）代替：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \mathbf{d}_f = \mathcal{P}(\mathbf{R}_f^s).
\end{equation}</script><p>由于理论上的单一声源协方差矩阵是一个秩为1的埃尔米特矩阵，因此，可以用PCA的方法将估计的$\mathbf{R}_f^s$近似表示为一个秩为1的矩阵，此时主特征向量即发挥着和导向向量相同的作用，可以用它做替代。这种方法得到的导向向量估计准确性较高，且将问题转化到了协方差矩阵的估计上，算法也不需要额外依赖定位等其他模块。而基于时频掩码的自适应波束形成技术就是通过TF-mask的预测来估计式$(33)$中的噪声/声源协方差矩阵，再通过等式$(30), (34), (27)$进行滤波系数计算和语音增强的算法。</p>
<h3 id="新的趋势"><a href="#新的趋势" class="headerlink" title="新的趋势"></a>新的趋势</h3><p>除了上述介绍的这些基础和成熟的方法之外，个人觉得目前的工作大致有如下趋势。首先增强和分离的方法基本被统一在端到端优化的框架下，不论是完全的时域模型还是频域配合时域的代价函数，很少再有围绕着实数谱或者掩码做的工作了。任务上从最近开源的几批数据（文章）上看，解决分离任务的场景已经从单一的说话人干扰，切换到了远场多通道过下，存在方向噪声，混响，多说话人这类比较复杂和实际的场景下了。网络结构方面，基于编/解码器的架构（包括UNet，TasNet，CRNN，TCN这些）替代RNN结构，成为了目前的主流模型。其次是前端和ASR结合的前后端联合工作。由于后端的ASR已经完成了到端到端（RNN-T，CTC，Attention）框架的转换，因此，在此之上结合的多通道前端的工作也在进行中，包括espnet中已经merge的与自适应波束（MVDR）的联合训练方案和一些基于固定波束，注意力机制的方案。这里面我觉得存在的一个可以探究的点在于，我们需要不需要刻意的结合信号领域的一些知识或者操作，去设计一些“有数学意义”网络结构？最后是多模态的工作，无论是视觉组开始做speech（VGG），还是speech的人开始结合视觉（NTT，Tencent，Google，Alibaba，Sougou），音视频融合的增强，分离以及识别，包括TTS等工作从文章数量和公司宣传上看，最近都有所增多和加强。随着后续开源数据的不断放出，也一定会有一些有影响力和代表性的工作产生。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Y. Wang, D. Wang. Boosting Classification Based Speech Separation Using Temporal Dynamics[C]. Thirteenth Annual Conference of the International Speech Communication Association, 2012.<br>[2] Y. Wang, D. Wang. Cocktail Party Processing via Structured Prediction[C]. Advances in Neural Information Processing Systems, 2012:224–232.<br>[3] Y. Wang, D. Wang. Towards Scaling up Classification-based Speech Separation[J]. IEEE Transactions on Audio, Speech, and Language Processing, 2013, 21(7):1381–1390.<br>[4] Y. Xu, J. Du, L.-R. Dai, et al. An Experimental Study on Speech Enhancement Based on Deep Neural Networks[J]. IEEE Signal processing letters, 2013, 21(1):65–68.<br>[5] Y. Xu, J. Du, L.-R. Dai, et al. A Regression Approach to Speech Enhancement Based on Deep Neural Networks[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2014, 23(1):7–19.<br>[6] A. Narayanan, D. Wang. Ideal Ratio Mask Estimation Using Deep Neural Networks for Robust Speech Recognition[C]. 2013 IEEE International Conference on Acoustics, Speech and Signal Processing, 2013:7092–7096.<br>[7] Y. Wang, A. Narayanan, D. Wang. On Training Targets for Supervised Speech Separation[J]. IEEE/ACM transactions on audio, speech, and language processing, 2014, 22(12):1849–1858.<br>[8] H. Erdogan, J. R. Hershey, S. Watanabe, et al. Phase-sensitive and Recognition-boosted Speech Separation Using Deep Recurrent Neural Networks[C]. 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015:708–712.<br>[9] D. S. Williamson, Y. Wang, D. Wang. Complex Ratio Masking for Monaural Speech Separation[J]. IEEE/ACM transactions on audio, speech, and language processing, 2015, 24(3):483–492.<br>[10] H.-S. Choi, J.-H. Kim, J. Huh, et al. Phase-aware Speech Enhancement with Deep Complex U-net[J]. arXiv preprint arXiv:1903.03107, 2019.<br>[11] Y. Wang, D. Wang. A Deep Neural Network for Time-domain Signal Reconstruction[C]. 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2015:4390–4394.<br>[12] S. Pascual, A. Bonafonte, J. Serra. Segan: Speech Enhancement Generative Adversarial Network[J]. arXiv preprint arXiv:1703.09452, 2017.<br>[13] D. Rethage, J. Pons, X. Serra. A Wavenet for Speech Denoising[C]. 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018:50695073.<br>[14] S.-W. Fu, T.-W. Wang, Y. Tsao, et al. End-to-end Waveform Utterance Enhancement for Direct Evaluation Metrics Optimization by Fully Convolutional Neural Networks[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2018, 26(9):1570–1584.<br>[15] Pandey A. and Wang D.L. (2019): A new framework for CNN-based speech enhancement in the time domain. IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 27, pp. 1179-1188.<br>[16] P.-S. Huang, M. Kim, M. Hasegawa-Johnson, et al. Deep Learning for Monaural Speech Separation[C]. 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2014:1562–1566.<br>[17] J. Du, Y. Tu, Y. Xu, et al. Speech Separation of a Target Speaker Based on Deep Neural Networks[C]. 2014 12th International Conference on Signal Processing (ICSP), 2014:473–477.<br>[18] J. R. Hershey, Z. Chen, J. Le Roux, et al. Deep Clustering: Discriminative Embeddings for Segmentation and Separation[C]. 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016:31–35.<br>[19] D. Yu, M. Kolbæk, Z.-H. Tan, et al. Permutation Invariant Training of Deep Models for Speaker-independent Multi-talker Speech Separation[C]. 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017:241–245.<br>[20] M. Kolbæk, D. Yu, Z.-H. Tan, et al. Multitalker Speech Separation with Utterancelevel Permutation Invariant Training of Deep Recurrent Neural Networks[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2017, 25(10):1901–1913.<br>[21] Z. Chen, Y. Luo, N. Mesgarani. Deep Attractor Network for Single-microphone Speaker Separation[C]. 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017:246–250.<br>[22] Y. Luo, Z. Chen, N. Mesgarani. Speaker-independent Speech Separation with Deep Attractor Network[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2018, 26(4):787–796.<br>[23] Z.-Q. Wang, J. Le Roux, J. R. Hershey. Alternative Objective Functions for Deep Clustering[C]. 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018:686–690.<br>[24] Z.-Q. Wang, J. L. Roux, D. Wang, et al. End-to-end Speech Separation with Unfolded Iterative Phase Reconstruction[J]. arXiv preprint arXiv:1804.10204, 2018.<br>[25] Y. Luo, N. Mesgarani. Tasnet: Time-domain Audio Separation Network for Real-time, Single-channel Speech Separation[C]. 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018:696–700.<br>[26] J. Le Roux, S. Wisdom, H. Erdogan, et al. Sdr–half-baked Or Well Done?[C]. ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019:626–630.<br>[27] Y. Luo, N. Mesgarani. Conv-tasnet: Surpassing Ideal Time–frequency Magnitude Masking for Speech Separation[J]. IEEE/ACM transactions on audio, speech, and language processing, 2019, 27(8):1256–1266.<br>[28] Q. Wang, H. Muckenhirn, K. Wilson, et al. Voicefilter: Targeted Voice Separation by Speaker-conditioned Spectrogram Masking[J]. arXiv preprint arXiv:1810.04826, 2018.<br>[29] K. Žmolíková, M. Delcroix, K. Kinoshita, et al. Speakerbeam: Speaker Aware Neural Network for Target Speaker Extraction in Speech Mixtures[J]. IEEE Journal of Selected Topics in Signal Processing, 2019, 13(4):800–814.<br>[30] Z. Chen, X. Xiao, T. Yoshioka, et al. Multi-channel Overlapped Speech Recognition with Location Guided Speech Extraction Network[C]. 2018 IEEE Spoken Language Technology Workshop (SLT), 2018:558–565.<br>[31] T. Afouras, J. S. Chung, A. Zisserman. The Conversation: Deep Audio-visual Speech Enhancement[J]. arXiv preprint arXiv:1804.04121, 2018.<br>[32] A. Ephrat, I. Mosseri, O. Lang, et al. Looking to Listen at the Cocktail Party: A Speaker-independent Audio-visual Model for Speech Separation[J]. arXiv preprint arXiv:1804.03619, 2018.<br>[33] S. Gannot, E. Vincent, S. Markovich-Golan, et al. A Consolidated Perspective on Multimicrophone Speech Enhancement and Source Separation[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2017, 25(4):692–730.<br>[34] J. Benesty, J. Chen, Y. Huang. Microphone Array Signal Processing[M]. Springer Science &amp; Business Media, 2008.<br>[35] H. Buchner, R. Aichner, W. Kellermann. Trinicon: A Versatile Framework for Multichannel Blind Signal Processing[C]. 2004 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2004, 3:iii–889.<br>[36] H. Sawada, S. Araki, S. Makino. Underdetermined Convolutive Blind Source Separation via Frequency Bin-wise Clustering and Permutation Alignment[J]. IEEE Transactions on Audio, Speech, and Language Processing, 2010, 19(3):516–527.<br>[37] D. H. T. Vu, R. Haeb-Umbach. Blind Speech Separation Employing Directional Statistics in an Expectation Maximization Framework[C]. 2010 IEEE International Conference on Acoustics, Speech and Signal Processing, 2010:241–244.<br>[38] T. Higuchi, N. Ito, S. Araki, et al. Online Mvdr Beamformer Based on Complex Gaussian Mixture Model with Spatial Prior for Noise Robust Asr[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2017, 25(4):780–793.<br>[39] N. Ito, S. Araki, T. Nakatani. Complex Angular Central Gaussian Mixture Model for Directional Statistics in Mask-based Microphone Array Signal Processing[C]. 2016 24th European Signal Processing Conference (EUSIPCO), 2016:1153–1157.<br>[40] J. Heymann, L. Drude, R. Haeb-Umbach. Neural Network Based Spectral Mask Estimation for Acoustic Beamforming[C]. 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016:196–200.<br>[41] L. Drude, D. Hasenklever, R. Haeb-Umbach. Unsupervised Training of a Deep Clustering Model for Multichannel Blind Source Separation[C]. ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019:695–699.<br>[42] L. Drude, J. Heymann, R. Haeb-Umbach. Unsupervised Training of Neural Mask-based Beamforming[J]. arXiv preprint arXiv:1904.01578, 2019.<br>[43] L. Drude, R. Haeb-Umbach. Tight Integration of Spatial and Spectral Features for Bss with Deep Clustering Embeddings.[C]. Interspeech, 2017:2650–2654.<br>[44] Z.-Q. Wang, J. Le Roux, J. R. Hershey. Multi-channel Deep Clustering: Discriminative Spectral and Spatial Embeddings for Speaker-independent Speech Separation[C]. 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2018:1–5.<br>[45] Z.-Q. Wang, D. Wang. Integrating Spectral and Spatial Features for Multi-channel Speaker Separation.[C]. Interspeech, 2018:2718–2722.<br>[46] Z.-Q. Wang, D. Wang. All-neural Multi-channel Speech Enhancement.[C]. Interspeech, 2018:3234–3238.<br>[47] T. Yoshioka, H. Erdogan, Z. Chen, et al. Recognizing Overlapped Speech in Meetings: A Multichannel Separation Approach Using Neural Networks[J]. arXiv preprint arXiv:1810.03655, 2018.<br>[48] T. Yoshioka, Z. Chen, C. Liu, et al. Low-latency Speaker-independent Continuous Speech Separation[C]. ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019:6980–6984.</p>
]]></content>
      <categories>
        <category>Speech Separation</category>
        <category>Speech Enhancement</category>
      </categories>
      <tags>
        <tag>Multi-channel</tag>
        <tag>Beamformer</tag>
        <tag>uPIT</tag>
        <tag>Mask</tag>
        <tag>DPCL</tag>
        <tag>Single-channel</tag>
        <tag>MVDR</tag>
        <tag>GEVD</tag>
        <tag>PMWF</tag>
      </tags>
  </entry>
  <entry>
    <title>Multi-Channel Hybrid AM</title>
    <url>/2019/11/10/multi-channel-hybrid-am/</url>
    <content><![CDATA[<p>本篇文章主要说一下多通道的Hybrid声学模型。Google在CLDNN之后，大约在2015年到2017年之间围绕远场语音识别，做了一系列 [1-6] 的工作，相关的技术也被用在了Google Home [7] 上。17年的时候我看了其中的一部分，觉得工作做的很漂亮，一骑绝尘，一枝独秀。原因主要有两方面，其一是多通道声学模型是一个比较新的概念，当时很少见其他高校和公司有相关的工作，基本还停留在神经网络的架构阶段，其二是Google的产出速度非常惊人，而且思路明确，环环相扣。17年之后，Google甩手开始做端到端（E2E）方面的工作，学术界和工业界也开始紧紧跟着不放，之前的工作关注度相比之下，明显低了很多。最近看到Amazon在icassp2019上有了两篇文章 [8-9]，再加上面试百度时他们聊了一些神经网络前端的事（后来确实花功夫宣传了），我就想聊一下这方面的工作和认识。</p>
<a id="more"></a>
<p>先说一下我的看法。在特定的远场环境下直接做多通道声学模型是一个非常有必要的尝试。如果可以将繁杂的前端处理模块（增强，定位，去混等等）集成到声学模型中，那么从系统的角度来看，维护成本，工程量，甚至是系统的延迟都可以明显的得到降低。而从技术本身来说，前后端的不匹配性一直是前后端分离这种模式下需要解决的问题。为了提升最终的识别率，前端需要工程师不断的做优化，后端则需要不断的retrain，而多通道建模则可以让前端自动跟随着后端的准则进行微调和适应。这种联合优化的方式可以较好的解决这种mismatch问题，存在提升系统性能的可能性。</p>
<p>Google和Amazon的工作都是基于固定波束形成的方案。在增强的场景中（即单一目标声源），前后端分离下需要先根据麦克风几何结构设计好一组指向的固定波束和声源定位算法。运行时先根据定位的结果，选取目标方位或者音区内的波束送入声学模型进行识别或者解码，这一过程也称为波束选择。波束形成我在之前的文章中介绍过，在频域可以写为：</p>
<script type="math/tex; mode=display">
s_{t,f} = \mathbf{w}_f^H \mathbf{y}_{t,f} \tag{1}</script><p>其中$\mathbf{w}_{f}\in \mathbb{C}^{M}$表示在频率索引$f$处的滤波系数，$\mathbf{y}_{t,f} = [y_{t,f}^0, \cdots, y_{t,f}^{C - 1}]$表示每个时频点的观测向量，$C$为麦克风数目。对于固定波束而言，之前也提到，会设计一组系数$\mathcal{W}_f = [\cdots, \mathbf{w}_{\theta, f}, \cdots]$，指向不同的方向（look directions），为了后文描述方便，给式$(1)$加上下角标$\theta$表示指向：</p>
<script type="math/tex; mode=display">
s_{t,f}^\theta = \mathbf{w}_{\theta, f}^H \mathbf{y}_{t,f} = \sum_c \left(w_{\theta, f}^c\right)^H y_{t,f}^c \tag{2}</script><p>时域上，对应的可以写成滤波相加的形式：</p>
<script type="math/tex; mode=display">
s_t^\theta = \sum_c \mathbf{y}_t * \mathbf{h}_{\theta, c} \tag{3}</script><p>其中$\mathbf{y}_t = [y_{t - N + 1}, \cdots, y_t]，\mathbf{h}_{\theta, c} = [h_0^\theta, \cdots, h_{N - 1}^\theta]$表示通道$c$处的有限冲击响应（FIR），$N$表示滤波FIR的阶数，$*$表示卷积。在神经网络中，式$(2)$和式子$(3)$分别可用线性层（或者dot &amp; sum等操作）以及一维卷积层实现。</p>
<h3 id="Google"><a href="#Google" class="headerlink" title="Google"></a>Google</h3><p>下面先介绍Google的三个方案，两种时域（Unfactored &amp; Factored）的和一种频域的。Unfactored直接根据$(3)$式使用$P$组$C$个一维卷积对输入的多通道数据进行滤波相加操作，卷积的stride为1，padding设为0，卷积核的维度对应滤波FIR的阶数$N$，$P$表示不同指向的滤波器个数。卷积的输入为切分好的多通道语音块$[\mathbf{y}_0, \cdots, \mathbf{y}_{T-1}]$，原文中采用的帧长为35 ms（$M = 560$），帧移为10 ms，$N = 400$，所以对于每一帧$\mathbf{y}_t \in \mathbb{R}^{C \times M}$，$\theta$指向的一组一维卷积输出为$\mathbf{s}_t^\theta \in \mathbb{R}^{M - N + 1}$，整个层Unfactored的输出维度为$\mathbf{s}_t \in \mathbb{R}^{M - N + 1 \times P}$。最后在$M - N + 1$这个维度上做最大池化，并使用ReLU和log压缩，将$\mathbf{z}_t \in \mathbb{R}^P$输入后端的CLDNN结构中进行训练。这个过程可以用下面的流程表示：</p>
<script type="math/tex; mode=display">
\mathbf{y}_t \in \mathbb{R}^{C \times M} \overset{\text{FS}}{\Longrightarrow} \mathbf{s}_t \in \mathbb{R}^{M - N + 1 \times P} \overset{\text{MP} \cdots}{\Longrightarrow} \mathbf{z}_t \in \mathbb{R}^P</script><p>在实现的时候，可以使用二维组卷积（Group Convolution）代替$P$组$C$个一维卷积，对应的核心代码用PyTorch实现如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">UnfactedFsBeamformer</span><span class="params">(_FsBeamformer)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Unfacted form of FS (filter and sum) beamformer</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_taps=<span class="number">400</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 win_size=<span class="number">560</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_channels=<span class="number">4</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 num_filters=<span class="number">256</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                 log_compress=True)</span>:</span></span><br><span class="line">        super(UnfactedFsBeamformer, self).__init__(win_size,</span><br><span class="line">                                                   win_size - num_taps)</span><br><span class="line">        self.num_channels = num_channels</span><br><span class="line">        self.log_compress = log_compress</span><br><span class="line">        <span class="comment"># fs beamformer</span></span><br><span class="line">        self.filter = nn.Conv2d(num_channels,</span><br><span class="line">                                num_filters * num_channels, (num_taps, <span class="number">1</span>),</span><br><span class="line">                                stride=(<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">                                groups=num_channels,</span><br><span class="line">                                bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        args:</span></span><br><span class="line"><span class="string">            x: multi-channel audio utterances, N x C x S</span></span><br><span class="line"><span class="string">        return:</span></span><br><span class="line"><span class="string">            y: N x P x T, enhanced features</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> x.dim() <span class="keyword">not</span> <span class="keyword">in</span> [<span class="number">2</span>, <span class="number">3</span>]:</span><br><span class="line">            <span class="keyword">raise</span> RuntimeError(<span class="string">f"Expect 2/3D tensor, got <span class="subst">&#123;x.dim()&#125;</span> instead"</span>)</span><br><span class="line">        <span class="keyword">if</span> x.dim() == <span class="number">2</span>:</span><br><span class="line">            x = x[<span class="literal">None</span>, ...]</span><br><span class="line">        <span class="comment"># N x C x S x 1</span></span><br><span class="line">        x = x[..., <span class="literal">None</span>]</span><br><span class="line">        <span class="comment"># chunks: N x C x S x 1 =&gt; N x CM x T</span></span><br><span class="line">        c = self.unfold(x)</span><br><span class="line">        <span class="comment"># N x C x M x T</span></span><br><span class="line">        c = c.view(x.shape[<span class="number">0</span>], self.num_channels, self.frame_len, <span class="number">-1</span>)</span><br><span class="line">        <span class="comment"># N x CF x M' x T</span></span><br><span class="line">        f = self.filter(c)</span><br><span class="line">        <span class="comment"># N x F x M' x T</span></span><br><span class="line">        f = sum(th.chunk(f, self.num_channels, <span class="number">1</span>))</span><br><span class="line">        <span class="comment"># max pool, N x F x 1 x T</span></span><br><span class="line">        y = F.max_pool2d(f, (self.frame_hop + <span class="number">1</span>, <span class="number">1</span>), stride=<span class="number">1</span>)</span><br><span class="line">        <span class="comment"># non-linear</span></span><br><span class="line">        y = th.relu(y.squeeze(<span class="number">-2</span>))</span><br><span class="line">        <span class="comment"># log</span></span><br><span class="line">        <span class="keyword">if</span> self.log_compress:</span><br><span class="line">            y = th.log(y + <span class="number">0.01</span>)</span><br><span class="line">        <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<p>Unfactored的一个比较明显的问题在于计算量很大，参考式$(3)$，按照上述实验配置，计算一帧就需要进行$M - N + 1 \times N \times P \times C$次乘法。另一个在于网络需要在给出的输出$\mathbf{z}_t \in \mathbb{R}^P$中同时包含空间和频率上的提取信息，学习难度较大，针对这点，Factored使用了两步卷积操作分别进行特征提取。其中空间滤波阶段采用了低阶的FIR和较小的look directions，这样的设计是希望网络主要学习到空间滤波的任务。此外空间滤波中的卷积对输入进行padding操作，保证输出的结果在时间维度上相同，即$\mathbf{s}_t \in \mathbb{R}^{M \times P}$。之后使用一维卷积层对$\mathbf{s}_t$提取频率特征（look directions维度保持不动）：</p>
<script type="math/tex; mode=display">
\mathbf{w}_{f,t}^p = \mathbf{s}_{t}^p * \mathbf{g}_f \tag{4}</script><p>$\mathbf{g}_f$表示频率$f$上的滤波系数，卷积核维度为$L$，输入通道数为1，输出通道数为$F$，得到结果$\mathbf{w}_t \in \mathbb{R}^{M - L + 1 \times F \times P}$，分别对应时间，频率和空间维度。之后的操作和Unfactored类似，时间维度上进行池化，忽略短时相位信息，加上ReLU和log压缩，得到$\mathbf{z}_t \in \mathbb{R}^{F \times P}$。最终在输入CLDNN声学模型前，将其reshape成一维向量即可。该操作流程可以用下面的流程表示：</p>
<script type="math/tex; mode=display">
\mathbf{y}_t \in \mathbb{R}^{C \times M} \overset{\text{FS}}{\Longrightarrow} \mathbf{s}_t \in \mathbb{R}^{M \times P} \overset{\text{conv}}{\Longrightarrow}  \mathbf{w}_t \in \mathbb{R}^{M - L + 1 \times F \times P} \overset{\text{MP} \cdots}{\Longrightarrow} \mathbf{z}_t \in \mathbb{R}^{F \times P}</script><p>Factored的模型计算一帧需要的乘法次数为$M \times N \times P \times C + P \times L \times M - L + 1\times C$。由于$N，P$的选取都相对较小，所以整体计算量低于Unfactored模型。为了进一步减少计算量，Google将Unfactored对应到频域中，第一步空间滤波采用$(1)$式进行，输入是复数的FFT特征，第二步谱滤波根据$(4)$式的不同，分别对应CLP和LPE模型。区别主要是谱滤波的系数为复数还是实数，均可对应的采用线性进行实现。频域模型的数据变换如下：</p>
<script type="math/tex; mode=display">
\mathbf{y}_t \in \mathbb{R}^{C \times F} \overset{\text{FS}}{\Longrightarrow} \mathbf{s}_t \in \mathbb{R}^{P \times F} \overset{\text{linear}}{\Longrightarrow}  \mathbf{w}_t \in \mathbb{R}^{P \times G}</script><p>其中$F$表示FFT的频点数，$G$表示频率滤波的输出维度。实际学出来的频域滤波系数$\mathbf{G}$分布类似于mel滤波（即log趋势）。在我本人的实验中发现，谱滤波的系数比较容易学得，因为语音的特征主要集中在低频区域，但是网络的性能未必和其存在相关性，下图是某次实验的学习结果，采用CLP模型，绘制的是滤波系数（复数值）的模。</p>
<p><img src="/images/clp-learned-filters.jpg", width="500"></img></p>
<p>和传统的固定波束方法相比， Google的声学建模中，没有设计所谓的波束选择过程，即只保留一路选出的指向波束或者特征输入后端网络，而是将所有的look directions上的频率特征全部保留。</p>
<h3 id="Amazon"><a href="#Amazon" class="headerlink" title="Amazon"></a>Amazon</h3><p>Amazon的方案思路和Google的频域CLP方法类似，但是有一些优势的地方。其一是在波束形成层，使用super-directive（SD）的波束形成器系数做初始化，其二是考虑了波束选择这一过程，保证声学模型的输入和单通道下维度一致，这样就可以做mult-stage训练（用单通道的模型做多通道方案的后端部分初始化）。多通道的声学模型架构如下右图所示：</p>
<p><img src="/images/amazon-am-design.png", width="600"></img></p>
<p>FE网络表示特征提取网络，其中的线性层起到频谱滤波的作用，可以用mel滤波系数初始化，multi-channel (MC) network有三种设计方案，接受多通道的STFT系数，输出一路波束特征。左图表示我前面提到的传统方案，分别对应波束形成，波束选择，特征提取和声学解码。下面我简单的用文字叙述这三种方案：</p>
<p><img src="/images/amazon-mc-design.png", width="600"></img></p>
<p>第一种CAT的方案比较简单，直接使用复数线性变换将多通道拼接的STFT特征投影成单通道维度即可。第二种DSF的方案通过保留每个频率$f$上的候选波束能量最大的值来实现波束选择过程。第三种方案相较方案二，先保留了每个方向和频率上的能量，再使用线性层将其投影到单一波束的维度作为输出。方案二和三均可以使用预先设计好的SD系数进行初始化。原文的示意图如下，其中power表示对波束复数矩阵进行<code>pow()</code>操作，转换成能量表示。训练方面，采用三步进行，第一步使用fbank特征训练单通道的声学模型，第二步使用单通道STFT特征配合FE网络进行训练，最后添加上前端MC的网络。实验结论方面，ESF的方案获得的相对WER降低最多，而使用mel滤波系数和SD系数初始化FE和MC网络，增加麦克风数目均可以提升模型表现。</p>
<p>上述介绍的Google/Amazon方案均没有自适应的机制，因此只能针对固定的麦克风几何结构/数目和声学环境起作用，网络学到的beampattern/指向性也是固定的。优势的话体现在方案的实现比较简单，系统延迟低，如果存在现有的声学模型pipeline和远场的场景，个人还是非常建议做一些对比和尝试。现在再看候选的多通道方案还有不少，本次将这两篇工作进行集中介绍主要是由于它们存在一定的相似性。自适应波束方案上，比较有代表性的是Paderborn的一系列工作 [10-12]，将基于mask的自适应波束形成（MVDR &amp; GEVD）等和后端AM进行联合训练，目前结合E2E的声学模型实践的比较多，后面会考虑写一篇专门进行总结。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]. Hoshen Y, Weiss R J, Wilson K W. Speech acoustic modeling from raw multichannel waveforms[C]//2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2015: 4624-4628.<br>[2]. Sainath T N, Weiss R J, Senior A, et al. Learning the speech front-end with raw waveform CLDNNs[C]//Sixteenth Annual Conference of the International Speech Communication Association. 2015.<br>[3]. Sainath T N, Weiss R J, Wilson K W, et al. Speaker location and microphone spacing invariant acoustic modeling from raw multichannel waveforms[C]//2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU). IEEE, 2015: 30-36.<br>[4]. Sainath T N, Weiss R J, Wilson K W, et al. Factored spatial and spectral multichannel raw waveform CLDNNs[C]//2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2016: 5075-5079. MLA<br>[5]. E. Variani, T. N. Sainath, I. Shafran and M. Bacchiani, “Complex Linear Projection (CLP): A Discriminative Approach to Joint Feature Extraction and Acoustic Modeling,” in Proc. Interspeech, 2016.<br>[6]. T. N. Sainath, R. J. Weiss, K. W. Wilson, B. Li, A. Narayanan, E. Variani, M. Bacchiani, I. Shafran, A. Senior, K. Chin, A. Misra and C. Kim “Multichannel Signal Processing with Deep Neural Networks for Automatic Speech Recognition,” in IEEE Transactions on Speech and Language Processing, 2017.<br>[7]. B. Li, T. N. Sainath, J. Caroselli, A. Narayanan, M. Bacchiani, A. Misra, I. Shafran, H. Sak, G. Pundak, K. Chin, K. Sim, R. J. Weiss, K. W. Wilson, E. Variani, C. Kim, O. Siohan, M. Weintraub, E. McDermott, R. Rose and M. Shannon, “Acoustic Modeling for Google Home,” in Proc. Interspeech, 2017.<br>[8]. Wu M, Kumatani K, Sundaram S, et al. Frequency domain multi-channel acoustic modeling for distant speech recognition[C]//2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019. MLA<br>[9]. Kumatani K, Minhua W, Sundaram S, et al. Multi-Geometry Spatial Acoustic Modeling for Distant Speech Recognition[C]//ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019: 6635-6639.<br>[10]. Heymann J, Drude L, Boeddeker C, et al. Beamnet: End-to-end training of a beamformer-supported multi-channel asr system[C]//2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2017: 5325-5329.<br>[11]. Boeddeker C, Hanebrink P, Drude L, et al. Optimizing neural-network supported acoustic beamforming by algorithmic differentiation[C]//2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2017: 171-175.<br>[12]. Heymann J, Bacchiani M, Sainath T N. Performance of mask based statistical beamforming in a smart home scenario[C]//2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018: 6722-6726.</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>E2E</tag>
        <tag>Multi-channel</tag>
        <tag>Beamformer</tag>
      </tags>
  </entry>
  <entry>
    <title>CACGMM</title>
    <url>/2019/09/30/cacgmm/</url>
    <content><![CDATA[<p>今天谈一下多通道分离算法里面一个比较成熟的系列，spatial clustering。在声源分布比较分散的情况下，这个算法有着稳定的表现，mask估计也比较准确。NTT在这块做了很多工作，在CHiME3到CHiME5的历次测评中，此算法的合理使用均拿到了十分不错的结果。因为聚类算法都是无监督的，所以相比用网络去估计mask，它的一个好处是不存在数据层面的mismatch，加上复杂度上不算高，online实现也比较简单，因此我觉得它是一套具有优势和潜力的算法。</p>
<a id="more"></a>
<p>我很早之前（应该是17年的时候）就接触过此类算法，是在CHiME4数据上做CGMM的mask估计<sup>[1]</sup>。当时文章看完之后，照猫画虎也能很快的把程序写出来，跑出一个结果。代码上问题主要有两个，一是慢，二是数值上不稳定。程序写的慢是我最难以忍受的两个地方之一（其二是写的丑），加上当时要处理的数据有点多，所以在代码层面就是想办法减少循环（python和matlab道理一样），算法上就是化简运算，最后多任务并行进行提交。关于数值稳定性，因为涉及到埃尔米特矩阵的求逆，遇到奇异矩阵，EM过程就直接退出了，所以代码中一般需要对这些情况进行预防和处理。还有一点就是聚类过程在每个sub-band上是完全独立的，所以聚类的结果在不同的频率上是不一致的，存在一个置换问题，一般是需要一个后处理重新对齐之后才能使用的。CGMM在处理增强问题中（也就是估计speech&amp;noise两类mask），通过合理的初始化，可以免去做这类后处理的需要，因此我后续一般都只用CGMM做多通道的语音增强，而没有在分离任务中使用。</p>
<p>Paderborn那边有几个人一直在用CACGMM<sup>[2]</sup>做分离任务，比如在CHiME5里面的GSS和network的unsupervised训练，最近集中看了一下他们的code<sup>[3]</sup>和文章<sup>[4,5,6]</sup>，并把setk中的cluster部分重写了一下，也顺便写几点小结在这里分享一下。</p>
<h3 id="CG-vs-CACG"><a href="#CG-vs-CACG" class="headerlink" title="CG vs CACG"></a>CG vs CACG</h3><p>这两者的EM过程在化简之后是完全一致的。CGMM的建模对象是直接的观测向量$\mathbf{y}_{tf}$，假定分布服从0均值的CGMM：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{tf} \sim \sum_k \alpha_f^k \mathcal{N}(\mathbf{y}_{tf}; 0, \phi_{tf}^k\mathbf{R}_f^k) \tag{1}</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{align}
\mathcal{N}(\mathbf{y}_{tf}; 0, \phi_{tf}^k \cdot \mathbf{R}_f^k) &= \frac{1}{\det(\phi_{tf}^k \cdot \mathbf{R}_f)} e^{-\mathbf{y}_{tf}^H (\phi_{tf}^k\mathbf{R}_f^k)^{-1}\mathbf{y}_{tf}} \notag \\
& = \frac{1}{\det(\mathbf{R}_f) \cdot (\phi_{tf}^k)^M} e^{-\mathcal{K}_{tf}^k/ \phi_{tf}^k} \tag{2}
\end{align}</script><blockquote>
<p>注：在写分布表达式的时候，我把常数项（比如$\pi$之类的）都去掉了，不影响$\gamma_{tf}^k$的计算和$Q$函数值的相对大小，$\mathcal{K}_{tf}^k = \mathbf{y}_{tf}^H (\mathbf{R}_f^k)^{-1}\mathbf{y}_{tf}$</p>
</blockquote>
<p>我们最终要的TF-mask就是E步中得出的后验概率$\gamma_{tf}^k$</p>
<script type="math/tex; mode=display">
\gamma_{tf}^k = \frac{\alpha_f^k \mathcal{N}(\mathbf{y}_{tf}; 0, \phi_{tf}^k\mathbf{R}_f^k)}{\sum_c \alpha_f^k \mathcal{N}(\mathbf{y}_{tf}; 0, \phi_{tf}^k\mathbf{R}_f^k) } \tag{3}</script><p>CGMM在M步的参数更新为：</p>
<script type="math/tex; mode=display">
\begin{align}
\alpha_f^k & = \frac{1}{T} \sum_t \gamma_{tf}^k \notag \\
\mathbf{R}_f^k & = \frac{\sum_t \gamma_{tf}^k \cdot \mathbf{y}_{tf} \mathbf{y}_{tf}^H \cdot(\phi_{tf}^k)^{-1}} {\sum_t \gamma_{tf}^k}  \tag{4} \\
\phi_{tf}^k & = \frac{1}{M} \mathbf{y}_{tf}^H (\mathbf{R}_f^k)^{-1}\mathbf{y}_{tf} = \frac{\mathcal{K}_{tf}^k}{M} \notag
\end{align}</script><p>可以发现$(4)$中的$\phi_{tf}^k$带入$(2)$，可得</p>
<script type="math/tex; mode=display">
\mathcal{N}(\mathbf{y}_{tf}; 0, \phi_{tf}^k\mathbf{R}_f^k) = \frac{e^{-M}}{\det(\mathbf{R}_f) \cdot (\mathcal{K}_{tf}^k)^M} \tag{5}</script><p>由此，$\gamma_{tf}^k$和$\mathbf{R}_f^k$的表达式也可以继续简化为：</p>
<script type="math/tex; mode=display">
\gamma_{tf}^k = \frac{\alpha_f^k}{\det(\mathbf{R}_f^k)(\mathcal{K}_{tf}^k)^M} \cdot \left(\sum_k \frac{\alpha_f^k}{\det(\mathbf{R}_f^k)(\mathcal{K}_{tf}^k)^M} \right)^{-1} \tag{6}</script><p>和</p>
<script type="math/tex; mode=display">
\mathbf{R}_f^k = M \cdot \frac{\sum_t \gamma_{tf}^k \cdot \mathbf{y}_{tf} \mathbf{y}_{tf}^H \cdot(\mathcal{K}_{tf}^k)^{-1}} {\sum_t \gamma_{tf}^k} \tag{7}</script><p>所以从式子$(6,7)$来看，已经没有必要维护$\phi_{tf}^k$这个中间参数了，而它们正是CACGMM的M步，根据$(5)$式，可知道新的分布可以表示为</p>
<script type="math/tex; mode=display">
\mathcal{A}(\mathbf{z}_{tf}; \mathbf{B}_f) = \frac{1}{\det(\mathbf{B}_f) \cdot \left(-\mathbf{z}_{tf}^H \mathbf{B}_f^{-1}\mathbf{z}_{tf} \right)^M} \tag{8}</script><p>$\mathbf{B}_{f}$主要用于区分$\mathbf{R}_f$。从参数量的角度来说，$\mathcal{A}(\cdot)$相比$\mathcal{N}(\cdot)$少维护了一个$\phi_{tf}^k$。此外还有一点是CACGMM的建模对象是完全的空间信息 $\mathbf{z}_{tf} = \mathbf{y}_{tf} / |\mathbf{y}_{tf}|$，可以证明在$\mathbf{y}_{tf} \sim \mathcal{N}(\cdot)$时，$\mathbf{z}_{tf} \sim \mathcal{A}(\cdot)$。</p>
<h3 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h3><p>这类算法的训练都是EM的过程，每个类别和每个sub-band上的更新都是相对独立的，所以比较直观的写法一定有两个循环（外层频率$F$，内层混合模型的类别$K$）。循环带来的问题就是效率很低，而逻辑上本身是允许在$F\times K$个类别层面上并行的，这里推荐使用十分强大的<code>np.einsum</code>函数进行多维矩阵和向量的运算。关于它网上有一些样例和介绍，我在这里简单举两个例子说明一下如何使用它计算上述几个公式中的变量值。</p>
<p>先提前声明几个变量和对应的shape</p>
<ul>
<li><code>obs</code> $\mathbf{y} \in \mathbf{C}^{F \times M \times T}$</li>
<li><code>gamma</code> $\gamma \in \mathbf{R}^{K \times F \times T}$</li>
<li><code>kernel</code> $\mathcal{K} \in \mathbf{R}^{K \times F \times T}$</li>
</ul>
<ol>
<li><p>计算式$(7)$中的$\mathbf{R}_{f}^k$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">denominator = np.sum(gamma, <span class="number">-1</span>, keepdims=<span class="literal">True</span>)</span><br><span class="line"><span class="comment"># (K x F x T) @ (F x M x T) @ (F x M x T) =&gt; (K x F x M x M)</span></span><br><span class="line">R = M * np.einsum(<span class="string">"...t,...xt,...yt-&gt;...xy"</span>, gamma / kernel, obs, obs.conj())</span><br><span class="line">R = R / denominator[..., <span class="literal">None</span>]</span><br></pre></td></tr></table></figure>
</li>
<li><p>计算$\mathcal{K}_{tf}^k = \mathbf{y}_{tf}^H(\mathbf{R}_f^k)^{-1}\mathbf{y}_{tf}$</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># (F x M x T) @ (F x K x M x M) @ (F x M x T) =&gt; (K x F x T)</span></span><br><span class="line">K = np.einsum(<span class="string">"...xt,...xy,...yt-&gt;...t"</span>, obs.conj(), R_inv, obs)</span><br></pre></td></tr></table></figure>
</li>
<li><p>求$(\mathbf{R}_f^k)^{-1}$和$\det(\mathbf{R}_f^k)$</p>
<p>解决上面这些变量的计算之后，还有一个求逆的问题，即$(\mathbf{R}_f^k)^{-1}$。$(\mathbf{R}_f^k)^{-1}$是一个Hermitian矩阵，但 Hermitian矩阵不一定可逆，举一个极端的例子，$T = 1$，那么$\mathbf{R}_f^k$的秩为1，则不可逆（矩阵奇异）。</p>
<p>实际运算中可以通过保存特征值和特征向量的方法存储协方差矩阵，这样方便矩阵求逆和行列式的计算。对于$\mathbf{R}_{tf}^k$做特征值分解得：</p>
<script type="math/tex; mode=display">
\mathbf{R}_{tf}^k = \mathbf{U}\mathbf{\Lambda}\mathbf{U}^H</script><p>$\mathbf{\Lambda}$为特征值对角矩阵，如果全正，则$\mathbf{R}_{tf}^k$为正定矩阵，一定可逆，且特征向量正交，满足$\mathbf{U}\mathbf{U}^H = \mathbf{I}$，由此可知：</p>
<script type="math/tex; mode=display">
(\mathbf{R}_{tf}^k)^{-1} = \mathbf{U}(\mathbf{\Lambda})^{-1}\mathbf{U}^H</script><p>根据“矩阵的秩等于特征值的乘积”：</p>
<script type="math/tex; mode=display">
\log \det(\mathbf{R}_{tf}^k) = \log \sum \text{diag}(\mathbf{\Lambda})</script><p>在$\mathbf{R}_{tf}^k$不可逆时，$\mathbf{\Lambda}$不能保证非负，因此在EM过程中可以强制加一个最小非负约束。此外通常的解决方法一般都是用diag loading，就是对矩阵加上一个对角量$\epsilon \mathbf{I}$，这种方式不能完全避免矩阵的奇异，而且$\epsilon$的选取也比较关键。</p>
</li>
</ol>
<p>从实现上基本就是这几个地方需要注意一下，整体下来训练速度上明显提升不少，结果也比较正常。CGMM里面如果解决增强问题，初始化可以用：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{R}_{tf}^n &= \mathbf{I} \notag \\
\mathbf{R}_{tf}^s &= \sum_t \mathbf{y}_{tf}^H\mathbf{y}_{tf} \cdot 1/T \notag
\end{align}</script><p>但是也不能完全避免permutation问题的出现，可以在一些样例里面看到一些bad case。CACGMM的初始化完全随机，EM输出的$\gamma$需要在过一遍align算法，这部分算法的原理尚未细看，但是对最终结果的影响是很大的（一旦align处理的不好，完全看不出估计的mask中谱的形状，下面放了一个比较正常的样例，cluster2是noise成分），感兴趣的可以参考一下<a href="https://github.com/fgnt/pb_bss/blob/96fd72cb5934fb3ec21a707cc54ac6263782a71a/pb_bss/permutation_alignment.py#L133" target="_blank" rel="noopener">这里</a>。最终的代码也已经经过测试，merge到<a href="https://github.com/funcwj/setk" target="_blank" rel="noopener">setk</a>中去了。</p>
<p><img src="/images/cacgmm_demo.png" width="600"></p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] Higuchi T, Ito N, Araki S, et al. Online MVDR beamformer based on complex Gaussian mixture model with spatial prior for noise robust ASR[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2017, 25(4): 780-793.<br>[2] Ito N, Araki S, Nakatani T. Complex angular central Gaussian mixture model for directional statistics in mask-based microphone array signal processing[C]//2016 24th European Signal Processing Conference (EUSIPCO). IEEE, 2016: 1153-1157.<br>[3] <a href="https://github.com/fgnt/pb_bss" target="_blank" rel="noopener">https://github.com/fgnt/pb_bss</a><br>[4] Drude L, Hasenklever D, Haeb-Umbach R. Unsupervised training of a deep clustering model for multichannel blind source separation[C]//ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019: 695-699.<br>[5] Drude L, Heymann J, Haeb-Umbach R. Unsupervised training of neural mask-based beamforming[J]. arXiv preprint arXiv:1904.01578, 2019.<br>[6] Kanda N, Boeddeker C, Heitkaemper J, et al. Guided Source Separation Meets a Strong ASR Backend: Hitachi/Paderborn University Joint Investigation for Dinner Party ASR[J]. arXiv preprint arXiv:1905.12230, 2019.</p>
]]></content>
      <categories>
        <category>Speech Separation</category>
      </categories>
      <tags>
        <tag>Multi-channel</tag>
        <tag>CACGMM</tag>
      </tags>
  </entry>
  <entry>
    <title>Steer Vector</title>
    <url>/2019/08/04/steer-vector/</url>
    <content><![CDATA[<p>最近陆续有了一些看了本博客的读者加微信讨论一些问题，我才发现原来自己挂的这个玩意竟然是有人看的。为什么这么说呢，因为从本站点挂到云上起，我就没有在任何社交平台上公开过本博客的链接，即使是github上host的repo我也是设置成私有的状态，所以访客们能够来到这个站点，看来是google在背后起作用了。从内容上说，本站点上的东西并不全面，很多时候是自己看了或者接触了点新的东西，心血来潮想写点什么。所以这里面就存在一个问题，我最初的接触或者理解可能是肤浅的，所以写下的东西未必准确到位，存在误导读者的风险。这也是我不想把这里的内容发布到公共平台上的原因之一。如果看官有什么问题的话，可以加我微信讨论，这一点上我还是非常欢迎的（当然伸手党等人除外）。</p>
<a id="more"></a>
<p>四月份之后我到微软这边实习，手上的工作都比较熟悉，没有接触到什么新的或者有意思的东西，所以也一直没有更新文章，这次就说一个之前频繁提到过的概念，导向向量（steer vector）。在这篇文章中，我会把它和前面几篇博客的内容关联到一起，更加系统的理一遍。</p>
<p>导向向量是在多通道语音信号处理中经常出现的一个概念，从我的接触上说，主要集中在波束形成，声源定位里面。它描述的是声源到每个麦克风处的延时（如果不考虑信号衰减的话），通常将其表示为</p>
<script type="math/tex; mode=display">
\mathbf{d}_{\theta, \omega} = [e^{-j \omega \tau_{0, \theta}}, \dots, e^{-j \omega \tau_{M - 1, \theta}}]</script><p>其中$M$表示阵列个数，$\theta$为声源方位（DoA，暂时不考虑俯仰角），$\omega$为角频率。在平面波的建模下，通常我们会选一个参考麦克风，只需要计算相对时延即可。$\theta$的范围取决于阵列的结构，一般线阵就是0到$\pi$，圆阵拓展到$2\pi$。</p>
<h3 id="Beamformer"><a href="#Beamformer" class="headerlink" title="Beamformer"></a>Beamformer</h3><p>MVDR有几种表达式，其中一种里面有一个对steer_vector的显式依赖，所以传统signal的方法里面，都需要借助一个SSL（Sound/Speech Source Localization）模块用于声源定位得到$\theta$。目前常用的mask-based的方法，使用PCA的方法就可以直接做估计，免去了对SSL的依赖，这部分内容之前的博客已经说过，这里就不做赘述。固定波束的话，从使用的角度来说，需要已知说话人的方位，然后选取这个方向上的beam。从设计的角度说，一般预先在空间划分若干个区域，之后基于这些区域指向的方位上的导向向量进行设计，我所知道的两种设计方法都是如此：</p>
<ol>
<li><p>LSB （Least-square beamformer）<br>LSB思想是借助最优化方法（加上白噪声增益的约束），求解出满足beampattern（也就是MSE）的最优变量作为beam weight。</p>
</li>
<li><p>SDB （Super-directive beamformer）<br>设计公式和MVDR类似，使用oracle的steer vector，noise的协方差矩阵使用一些常见噪声声场的理论值（比如diffused noise field）</p>
</li>
</ol>
<p>其实还有一个最简单的beamformer，延时相加（DS, Delay and Sum），steer vector直接就构成beam的权值（这里再加一个理论常识，拥有$M$个麦克风的阵列最理想情况下，使用DS beamformer可以拿到$M$dB的信噪比提升）。</p>
<p>Beam Pattern其实就是beamformer在每个方向上频率响应的一种表示，事先计算出若干组steer vector，做beamforming之后画出频率响应（$T \times F$的矩阵）就行。前段时间遇到一个问题比较有意思，感觉可以用来当做面试题考察一下信号基础。我拿到一个设计好的fixed beamformer，但是不知道每个beam的指向了，问如何还原出这个信息？其实定义好坐标系，画出beam pattern就一目了然了。比如下图给出了编号为7，8，12，13四个beam的beam pattern，它们的指向依次为120，140，220和240度方向。</p>
<p><img src="http://www.funcwj.cn/images/unknown-beam-peek.png", width="500"></p>
<h3 id="Localization"><a href="#Localization" class="headerlink" title="Localization"></a>Localization</h3><p>我所接触到的定位算法和steer vector相关的（还有一些子空间方法比如MUSIC之类的没有细看）基本都是一个样式，就是formulate成下面的问题：</p>
<script type="math/tex; mode=display">
\theta _\text{SSL} = \arg \max_{\theta} \mathcal{F}(\mathbf{d}_\theta, \mathbf{y})</script><p>简单来说就是用观测信号$\mathbf{y}$和每个方向上的导向向量计算一个$\mathcal{F}(\cdot)$，最大者对应角度就是定位的结果。由于每个麦克风的空间位置不同，因此定向声到达每个麦克风处会形成相应的延迟，空间信息由此产生。延迟是直接和相位相关的（时移在频域中体现为相移），所以我们说spatial的时候，基本都在说相位。这里面还存在一些小问题，其一，相位它是周期的，也就是我们可以从相对距离或者时延推出相位差，但是从相位差不能导出唯一的时延迟或者距离，比方说如果麦克风的间距大于一半波长的时候（所谓的空间混叠）。其二就是相位的绝对值没有什么意义，这也就是单通道中一般很少研究相位这个概念，即使有，比如Group Delay这种还是相对值（一阶差分）。多通道中可以利用的主要是通道信号之间的相位差（IPD，Inter-channal Phase Difference）这个信息。</p>
<p>之前一篇博客也提到过，在短时傅里叶分析中的每个的sub-band上，同向声源能量占比高的TF-bin上观测到的相位差彼此接近，所以这是一个可以帮助做分离/增强的区分性信息。从steer vector中我们可以算出该方向上的声源可被观测到的理想情况下的（oracle）的相移，所以如果观测值和理论值越接近，那么该声源属于此方向上的概率就越高。由此可以将上述定位表达式进一步表示为：</p>
<script type="math/tex; mode=display">
\theta _\text{SSL} = \arg \max_\theta \sum_{<i,j>} \sum_{t,f} \cos\{\angle \mathbf{d}_{i, f}^\theta - \angle \mathbf{d}_{j, f}^\theta - \angle \mathbf{y}_{i, tf} + \angle \mathbf{y}_{j,tf}\}</script><p>$\angle \mathbf{y}_i - \angle \mathbf{y}_j$就是IPD。注意一下，此表达式其实和下面的等价，其中$\mathcal{R}(\cdot)$表示取实部。 GCC/SRP-PHAT一般这么写，但是不太直观，不方便理解，比如为什么取实部之类的意义不明确。</p>
<script type="math/tex; mode=display">
\theta_\text{SSL} = \arg \max_\theta \sum_{<i,j>} \sum_{t,f} \mathcal{R} \left \{ \mathbf{d}_{i,f}^\theta \left(\mathbf{d}_{i,f}^\theta \right)^H \cdot \mathbf{z}_{i, tf} \left(\mathbf{z}_{i, tf} \right)^H \right \}</script><p>其中</p>
<script type="math/tex; mode=display">
\mathbf{z}_i = \frac{\mathbf{y}_i}{|\mathbf{y}_i|} = [e^{-j\theta_0}, \cdots, e^{-j\theta_{M - 1}}]</script><p>知道了基本的定位原理就可以反向利用角度信息。angle/directional feature就是在$\theta$已知的情况下，选取若干麦克风pair按照上面的方法计算出$T \times F$的特征矩阵（免去累加的过程）。和oracle相移越接近的TF bin上，特征的值越大。实际数据上在房间混响不严重，说话人的夹角比较大的情况下，angle feature是一个比较鲁棒的特征，对于分离或者增强模型的帮助也很大。</p>
<script type="math/tex; mode=display">
\mathbf{A}_{t,f}^\theta = \sum_{<i,j>} \cos\{\angle \mathbf{d}^{\theta}_{i,f} - \angle \mathbf{d}^{\theta}_{j, f} - \angle \mathbf{y}_{i,tf} + \angle \mathbf{y}_{j, tf}\}</script><p>再看一下$\theta_\text{SSL}$的表达式，在假设说话人方位不变的情况下，就对整个句子上的每个TF-bin做一个加和，通过$\arg\max$得到DoA的估计值。如果想观测DoA的时变信息，那么可以只在频率轴上做累加，保留时间轴，得到的$T \times D$的矩阵就是所谓的angular spectrogram，这个东西我也在之前的文章中展现过，给出一个比较理想的的样例如下。如果不止一个说话人，还可以通过speaker的TF-mask做weight，从而估计出每一个说话人的角度。</p>
<p><img src="/images/dev1_female3_liverec_130ms_1m_mix.png", width="550"></p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>最后简单的小结一下。我这篇文章没有介绍新的概念，主要借着steer vector把之前说过的beamformer，spatial feature，SSL算法等从一个统一的角度又过了一遍。这些东西呢，一开始也没有理解的十分到位，后面随着做东西的时间长了，反复想了几次，才发现它们背后逻辑的统一性。前端signal的东西有意思的地方主要就是集中在它背后的逻辑性的，当然我接触的只是冰山一角。借着面试时候某大佬和我说过一句话做结束：有很多work后人在复现的时候，都不需要任何signal的背景和知识就可以玩起来，但是在最开始我们做的时候，是一定有着对这些东西比较深刻的见解和认知的。否则路子那么多，你怎么能保证你这么做一定能work呢？</p>
]]></content>
      <categories>
        <category>Microphone Array Processing</category>
      </categories>
      <tags>
        <tag>Multi-channel</tag>
        <tag>Spatial</tag>
      </tags>
  </entry>
  <entry>
    <title>Towards E2E Speech Separation</title>
    <url>/2019/04/30/e2e-separation-s1/</url>
    <content><![CDATA[<p>区别于以频域的标签（比如谱特征，时频掩码等）作为学习目标再通过iSTFT将结果转成时域信号的方法，一般会把直接以目标语音为参考，在时域上计算对应代价函数并优化网络的方法称为端到端（End-to-End，E2E）的方法。现在看来，做增强/分离的文章里面已经很少见频域+掩码预测/语谱回归的方法了，基本就是拿来做个基线的参考。而不断被提出的模型或者架构，也多是跟随这种E2E的思路，否则很难在性能上有所突破。本篇文章会介绍几种在分离领域中直观简单的实现方法。</p>
<a id="more"></a>
<p>原始频域建模的方法中，最制约模型性能的关键在于相位的增强上，也就是重构语音阶段采用的是原始带噪音频的相位这一问题。受制于此，掩码掩蔽和语谱回归的方法均存在upper-bound。其次便是优化模型的性能是否能和最终期望的指标，比如SNR，PESQ等成正相关性。这里面基于mask的方法问题多一些。以IAM和PSM为例子。做过增强/分离实验的人都知道，PSM的性能一般会明显高于IAM，直观上我们理解的PSM就是使用混合语音在ground truth方向上的投影和其的比率。当混合语音的相位和ground truth成反向关系时，这时候PSM的值为负，训练时我们会把这部分截断成0，这便是这种场景下的最优解（向量距离最小）。但是对于IAM而言，由于在重构阶段使用的是噪声相位，其值始又始终为正，所以网络实际估计的值越逼近真实参考值（越大），和ground truth的向量误差就越大，显然不是我们期望的结果。而如果将其转换到时域上进行模型训练，很多时候就不需要显示的定义中间具体的mask参考值，从评估指标的层面自动的去优化mask预测的分布。</p>
<h3 id="Loss-Function"><a href="#Loss-Function" class="headerlink" title="Loss Function"></a>Loss Function</h3><p>在时域上的代价函数最好和模型评估的指标相吻合，比如PESQ，STOI [1]，Si-SNR [2]等等，目前均可以直接用来优化网络。分离中目前用Si-SNR的比较多，其定义如下：</p>
<script type="math/tex; mode=display">
\text{Si-SNR} \left(\mathbf{s}_e, \mathbf{s}_r \right) = 20 \log_{10} \frac{\Vert \alpha \cdot \mathbf{s}_r \Vert_2}{\Vert \mathbf{s}_e - \alpha \cdot \mathbf{s}_r \Vert_2}. \tag{1}</script><p>$\alpha = \mathbf{s}_e^T \mathbf{s}_r / \mathbf{s}_r^T \mathbf{s}_r$是一个正交缩放因子，使得最终计算的值和信号的缩放程度无关，$\mathbf{s}_r$表示目标参考信号，值越大表示信号质量越高。用它写成的网络的代价函数为：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text{uPIT}, \text{Si-SNR}} = \max_{\pi \in \mathcal{P}} \text{Si-SNR} \left(\hat{\mathbf{s}}_{\pi(c)}, \mathbf{s}_c \right). \tag{2}</script><p>$\mathcal{P}$表示说话人的所有排列方式。如将$\alpha$视为一个常数，优化$(2)$式本身相当于优化下面的MSE形式：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text{uPIT}, \text{MSE}} = \min_{\pi \in \mathcal{P}}  \left \Vert \mathbf{s}_{\pi(c)} - \alpha \cdot \mathbf{s}_c \right \Vert_2. \tag{3}</script><p>因此，也有一些文章[3]中用$L_1$代价函数进行代替（但是没有考虑scale的问题）：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{\text{uPIT}, \text{WA}} = \min_{\pi \in \mathcal{P}} \left \Vert \hat{\mathbf{s}}_{\pi(c)} - \mathbf{s}_c \right \Vert_1. \tag{4}</script><h3 id="With-i-STFT"><a href="#With-i-STFT" class="headerlink" title="With (i)STFT"></a>With (i)STFT</h3><p>如果我们想在频域的建模网络中使用时域的代价函数，就需要先对(i)STFT进行分析，加深理解，以便在网络中自由的进行时频转换等操作。时域到频域转换的STFT可以理解为分帧加窗之后，对每一帧$\mathbf{x}_t \in \mathbb{R}^N$进行的DFT变换：</p>
<script type="math/tex; mode=display">
\mathbf{y}_t = \text{DFT}(\mathbf{x}_t) = \mathbf{x}_t \mathbf{K}_{\text{DFT}}, \tag{5}</script><p>其中$N$表示帧长，为了分析方便，这里认为$N$默认取2的幂次。$\mathbf{K}_{\text{DFT}} \in \mathbb{C}^{N \times N}$是DFT变换矩阵，满足酉矩阵的性质。$\mathbf{y}_t$从频域到时域的变换通过iDFT进行：</p>
<script type="math/tex; mode=display">
\mathbf{x}_t = \text{iDFT}(\mathbf{y}_t) = \mathbf{y}_t \mathbf{K}_{\text{DFT}}^{-1} = \mathbf{y}_t \mathbf{K}_{\text{DFT}}^H. \tag{6}</script><p>当帧移为$H$，分析窗函数为$\mathbf{w}$时， STFT的计算可以用一维卷积表达，帧移为卷积的stride步长，卷积核为DFT变换矩阵，虽然其为复数矩阵，但是可以写成实部和虚部拼接的形式：</p>
<script type="math/tex; mode=display">
[\mathbf{Y}^{\mathfrak{R}}, \mathbf{Y}^{\mathfrak{I}}] = \text{conv}_{\text{1D}} \left(\mathbf{x}, 
\mathbf{w} \cdot \left[\mathbf{K}_{\text{DFT}}^{\mathfrak{R}}, \mathbf{K}_{\text{DFT}}^{\mathfrak{I}} \right], H \right), \tag{7}</script><p>其中$\mathbf{Y}^K = [\mathbf{y}_0^K, \cdots, \mathbf{y}_{T - 1}^K], K \in [\mathfrak{R},<br>\mathfrak{I}]$，$(\cdot)^{\mathfrak{R}}, (\cdot)^{\mathfrak{I}}$表示对应矩阵的实部和虚部。由于iDCT变换之后的结果为实数（虚部为0），所以对应的iSTFT可以用转置卷积（解卷积）表示，注意，此处并不需要对$\mathbf{K}_{\text{DFT}}^{\mathfrak{I}}$加一个负号表示共轭，因为我们最终取的是实部：</p>
<script type="math/tex; mode=display">
\mathbf{x} = \text{deconv}_{\text{1D}} \left( \left[\mathbf{Y}^{\mathfrak{R}}, \mathbf{Y}^{\mathfrak{I}} \right], 
\mathbf{w}' \cdot \left[\mathbf{K}_{\text{DFT}}^{\mathfrak{R}}, \mathbf{K}_{\text{DFT}}^{\mathfrak{I}} \right], H \right). \tag{8}</script><p>$\mathbf{w}’$表示使用的合成窗函数，理想情况下，我们希望窗$\mathbf{w}’$和$\mathbf{w}$尽量的满足完美重构准则。由于式$(7)$和$(8)$均是可导操作，因此，我们可以在神经网络中自由的实现信号时域和频域的转换，并在时域上进行代价函数的计算，比如上面提到的$(2,4)$式等。但是，由于一般频域模型通过预测掩码$\hat{\mathbf{M}}$来进行语音增强，实际中，式$(8)$一般写成</p>
<script type="math/tex; mode=display">
\mathbf{x} = \text{deconv}_{\text{1D}} \left( \left[ \left(\mathbf{Y} \odot \hat{\mathbf{M}} \right)^\mathfrak{R}, 
\left(\mathbf{Y} \odot \hat{\mathbf{M}} \right)^\mathfrak{I} \right], 
\mathbf{w}' \cdot \left[\mathbf{K}_{\text{DFT}}^{\mathfrak{R}}, \mathbf{K}_{\text{DFT}}^{\mathfrak{I}} \right], H \right) \tag{9}</script><p>的形式，在重构阶段使用噪声相位，$\mathbf{Y}$表示带噪信号的STFT变换结果。在原始的框架下，使用iSTFT得到增强的时域音频并进行代价函数计算，可以得到更好的结果。但是由于其本身并没有突破相位增强问题这一限制，所以还存在着改进的空间。</p>
<h3 id="Frequency-Domain"><a href="#Frequency-Domain" class="headerlink" title="Frequency Domain"></a>Frequency Domain</h3><p>2018年王中秋首先提出在分离任务中，使用MISI进行相位修正[3]，同时使用代价函数$(4)$进行网络训练，在分离指标SDR上取得了明显的提升。$C$个混合说话人下的算法的描述见下图：</p>
<p><img src="http://www.funcwj.cn/images/misi-algothrim.png" width="600"></p>
<p>在迭代过程中，每个说话人的语谱幅度保持固定，只更新相位估计，并采用混合信号的相位初始化。算法中的(i)STFT使用卷积操作实现，因此可以将MISI和时域的代价函数结合起来，负责修正相位。</p>
<p>此外，在增强中被实践的复数掩码也可以在分离任务中使用。复数比率掩码（Complex Ratio Mask，CRM）最早在工作中被提出，旨在同时恢复目标语音的实部谱和虚部谱。对于增强的信号模型$\mathbf{Y} = \mathbf{S} + \mathbf{N}$，CRM的定义为：</p>
<script type="math/tex; mode=display">
\mathbf{M}_{\text{CRM}} = \mathbf{S} / \mathbf{Y} = |\mathbf{S}| \odot e^{j(\angle \mathbf{S} - \angle \mathbf{Y})} / |\mathbf{Y}|. \tag{10}</script><p>其中的实部对应着PSM。上式中的CRM本身实部和虚部都是无界的，加上符号的问题，直接使用网络预测比较困难。原始文章在训练中使用经双曲正切函数压缩后的结果为目标。测试阶段对应的进行解压之后，再做频谱掩蔽还原增强信号：</p>
<script type="math/tex; mode=display">
\hat{\mathbf{s}} = \text{iSTFT} \left( \left\vert \hat{\mathbf{M}}_\text{CRM} \odot \mathbf{Y} \right \vert, \angle \left(\hat{\mathbf{M}}_\text{CRM} \odot \mathbf{Y} \right) \right). \tag{11}</script><p>然而，这种压缩-解压算法的精度和训练集的掩码分布密切相关，一旦选取的参数失配，则有可能取得适得其反的结果。另一种极坐标形式的复数掩码在中被提出[4]，并配合时域上的代价函数和复数卷积层，取得了相对较好的结果。在本篇文章中，我们称之为PC-CRM（Polar Coordinate-wise CRM）。对于CIM，我们之前也提到，PC-CRM的相位采用网络产生的复数输出$\mathbf{O}_c \in \mathbb{C}^{T \times F}$通过$\hat{\mathbf{M}}_{\text{pha}} = \mathbf{O}_c / \left|\mathbf{O}_c \right|$的计算得到，而复数掩码的模被控制在$[0, 1]$之间：$\hat{\mathbf{M}}_{\text{mag}} = \tanh(|\mathbf{O}_c|) \in \mathbb{R}^{T \times F}$，PC-CRM通过下面的式子产生：</p>
<script type="math/tex; mode=display">
\hat{\mathbf{M}}_{\text{pc}} = \hat{\mathbf{M}}_{\text{mag}} \odot \text{exp} \left(-j \hat{\mathbf{M}}_{\text{pha}} \right). \tag{12}</script><p>因此，整体看来PC-CRM被控制在一个单位圆的分布内。之后配合类似式$(5)$的</p>
<script type="math/tex; mode=display">
\mathbf{x} = \text{deconv}_{\text{1D}} \left( \left[ \left(\mathbf{Y} \odot \hat{\mathbf{M}}_\text{pc} \right)^\mathfrak{R}, 
\left(\mathbf{Y} \odot \hat{\mathbf{M}}_\text{pc} \right)^\mathfrak{I} \right], 
\mathbf{w}' \cdot \left[\mathbf{K}_{\text{DFT}}^{\mathfrak{R}}, \mathbf{K}_{\text{DFT}}^{\mathfrak{I}} \right], H \right) \tag{13}</script><p>就可以将增强之后的复数谱转到时域进行目标优化和网络训练了。后续还有一些频域上针对相位问题的工作，但是介绍起来相对复杂一些，后面会考虑单独写一篇来详细介绍。</p>
<h3 id="Time-Domain"><a href="#Time-Domain" class="headerlink" title="Time Domain"></a>Time Domain</h3><p>在时域上比较有代表性的有罗艺提出的基于编码-解码（Encoder-Decoder）架构的TasNet [2,5]。从本节开始处的对(i)STFT的分析可以看出，频域上的模型本质上是使用了DFT作为编解码操作的核心，只不过它的变换矩阵满足酉矩阵的性质，并且在训练阶段保持不变。罗艺提出使用一维卷积和反卷积的方式，在分离任务的驱动下，自动的学习音频最佳特征的解析与重构。对于混合信号$\mathbf{y} \in \mathbb{R}^{N}$，TasNet首先使用编码操作将其编码成非负的向量表示，可以写成：</p>
<script type="math/tex; mode=display">
\mathbf{W}_y = \text{Encoder}(\mathbf{y}). \tag{14}</script><p>其中$\mathbf{W}_y = [\mathbf{w}_0, \cdots, \mathbf{w}_{T - 1}]$。之后，设计主分离网络Separator，在$\mathbf{W}_y$表示的空间上，估计每个说话人的掩码：</p>
<script type="math/tex; mode=display">
[\mathbf{M}_0, \cdots, \mathbf{M}_{C - 1}] = \text{Separator}(\mathbf{W}_y). \tag{15}</script><p>分离网络的性能对这种结构下的模型表现影响较大，在使用TCN的结构替换双向LSTM之后，模型在wsj0-2mix上超越了oracle IRM的结果。得到说话人$c$的掩码估计之后，再使用解码器将掩蔽的向量表示转换成时域的说话人信号$\hat{\mathbf{s}}_c$：</p>
<script type="math/tex; mode=display">
\hat{\mathbf{s}}_c = \text{Decoder}(\mathbf{M}_c \odot \mathbf{W}_y). \tag{16}</script><p>一维卷积中，卷积核和步长的大小等价于帧长和帧移动，输出通道数相当于频域中的FFT点数，即特征的维度，分别用$K, S, C$表示这些参数时，编解码过程可以表示为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\text{Encoder}(\mathbf{Y}) & = \text{ReLU} \left(\text{conv}_\text{1D}(\mathbf{Y}, K, S, C) \right), \\
\text{Decoder}(\mathbf{M}_c \odot \mathbf{W}_y) & = \text{deconv}_\text{1D}(\mathbf{M}_c \odot \mathbf{W}_y, K, S, C),
\end{aligned} \tag{17}</script><p>其中Encoder的输出$\mathbf{W}_y \in \mathbb{R}^{T \times C}$，ReLU用于保证其非负性。相比频域的DFT，Encoder和Decoder学出来的卷积核是不能保证信号可以被完美重构的，而卷积核本身也没有DFT的正交性质（这一点在后续的一些工作中似乎并不十分重要）。但是时域上建模的好处是可以不用显式考虑相位这一因素，选择鲁棒的分离网络结构，通过端到端的训练，就可以达到媲美频域，甚至超越频域理想掩码的结果。TasNet存在一个问题，在重构的语音语谱上可能会存在一些固定频率上的“亮线”现象，我个人推测是反卷积使用的问题，类似的现象在图像中也存在过，详见<a href="https://distill.pub/2016/deconv-checkerboard/" target="_blank" rel="noopener">Deconvolution and Checkerboard Artifacts</a>。</p>
<p>此外，U形网络（UNet）也是一种基于编解码架构的网络，在增强和audio source分离任务中均有实践，但是结构上没有罗艺设计的所谓分离网络。Encoder使用一维卷积层对输入audio进行降采样，Decoder进行升采样，二者的层数一致，对称的block之间存在残差连接。在Wave-U-Net中，针对使用反卷积进行上采用产生的混叠效应，文章提出使用线性差值层进行改进。我本人还没有将此结构用于分离任务中去，因此不能确定能否在解决混叠效应的同时，保证分离性能。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]. S.-W. Fu, Y. Tsao, X. Lu, and H. Kawai, “End-to-End Waveform Utterance Enhancement for Direct Evaluation Metrics Optimization by Fully Convolutional Neural Networks,” arXiv preprint arXiv:1709.03658, 2017.<br>[2]. Luo Y, Mesgarani N. Tasnet: time-domain audio separation network for real-time, single-channel speech separation[C]//2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018: 696-700. MLA<br>[3]. Wang Z Q, Roux J L, Wang D L, et al. End-to-end speech separation with unfolded iterative phase reconstruction[J]. arXiv preprint arXiv:1804.10204, 2018.<br>[4]. Choi H S, Kim J H, Huh J, et al. Phase-aware speech enhancement with deep complex u-net[J]. arXiv preprint arXiv:1903.03107, 2019.<br>[5]. Luo Y, Mesgarani N. Conv-tasnet: Surpassing ideal time–frequency magnitude masking for speech separation[J]. IEEE/ACM transactions on audio, speech, and language processing, 2019, 27(8): 1256-1266.<br>[6]. Pascual S, Bonafonte A, Serra J. SEGAN: Speech enhancement generative adversarial network[J]. arXiv preprint arXiv:1703.09452, 2017.<br>[7]. Stoller D, Ewert S, Dixon S. Wave-u-net: A multi-scale neural network for end-to-end audio source separation[J]. arXiv preprint arXiv:1806.03185, 2018.</p>
]]></content>
      <categories>
        <category>Speech Separation</category>
      </categories>
      <tags>
        <tag>E2E</tag>
        <tag>BSS</tag>
        <tag>uPIT</tag>
      </tags>
  </entry>
  <entry>
    <title>SETK in 2018</title>
    <url>/2019/03/11/setk-one-year/</url>
    <content><![CDATA[<p>去年四月份的时候，写了一些对这个<a href="https://github.com/funcwj/setk" target="_blank" rel="noopener">repo</a>的想法。最初并没有什么明确的目标，只是单纯的想在kaldi上写一些东西。我那时正在做enhancement相关的任务，最先在python+pytorch环境下跑出的结果，觉得在kaldi上做也不是很难，就想花一些功夫迁一下，把增强任务中一些固定的程序流程集成。最先是从最基本的(i)STFT开始，着手写了一些speech重构，谱，相位特征的一些基础命令。后来因为在nnet3上用Quadratic Loss训练mask模型的效果不错，就增加了一部分训练脚本，mask计算和后处理separation的代码，形成了一个围绕single-channel任务的工具闭环。增强相关的任务，包括特征提取，mask计算，网络训练，语音重构都可以在kaldi上做，验证一些数据的效果也是很快的（记得当时半天就把CHiME4上的一些任务做了重现）。所以当时README上写的就是”Speech Enhancement Toolkit based on Kaldi”。</p>
<a id="more"></a>
<p><img src="http://www.funcwj.cn/images/setk-develop.png" width="500"></p>
<p>后面有一段时候没有做更新，因为本身就single-channel而言，主流的方法，feature mapping和TF-mask已经被全部集成了，一时半会也没有什么额外的需求。所以后面就想着继续拓展到对multi-channel的支持上去。这时候存在的问题就是kaldi中没有complex类型的支持，如果我要在kaldi上实现相关算法，这个基础的组件必须要解决掉。开始还是比较犹豫，之后那段时间手里工作进展不顺利，就想着法子转移注意力了。我花了大约一周多的时间看了一下openblas的api，把complex matrix/vector的class写出来，支持一些常见的数学运算，在此之上实现了一版beamformer（mvdr和max-snr）。后期我和自己的python版本实现对比过，效果会差一些，但是整体问题不大，数值运算也比较稳定。其实这段时期贡献代码的目的十分单纯了，就是闲着想写点东西，包括后期实现的srp，fix beamformer等等。当时还建了sparse NMF和fastICA的branch，但是测试发现结果不太稳定，后期也没有继续做。真从我本身的做实验的角度，我更倾向于使用python版本的代码，这也是我后期主要转到python上去，更新script目录的主要原因。</p>
<p>再往后，前端的任务量越来越多，工具，代码也变的零碎和杂乱。matlab，python，kaldi等的数据格式和某些通用算法实现均不统一，在实验中就会遇到很多麻烦事，比如分帧的逻辑不同造成的时间维度不一致等等。因此我觉得很有必要花一段时间把手头的代码做一次整理，规范特征提取和数据IO，同时把常用的操作功能glue到脚本中去，便于任务并行，提升效率。虽然当时几乎重写了手里的现有代码，但是从后续的体验而言，还是觉得相当值得的。当时的想法主要有</p>
<ol>
<li>统一数据访问。我沿用kaldi的规范考虑下面两点。第一，.scp这种key-value对的文件形式通用性很高，不管原始数据如何分布，拿到scp就可以做随机或者顺序访问，即使有新的数据格式，继承<code>Reader</code>实现一下<code>_load</code>函数即可。第二，对于kaldi的archive归档文件读写，我之前写过python的接口，可以做高效的IO，也同时兼容kaldi的内置命令和脚本。基于这两点，我后来大部分程序的输入和输出都是所谓的.scp或者.ark形式。</li>
<li>统一(i)STFT。我使用的是librosa库的实现，两个原因，其一是那边的开发者项目维护的很频繁，代码规范度较高，社区也比较活跃，其二是我仔细看过它的代码，内在实现的细节比较熟悉。所有频域的特征，算法的实现均在此之上进行，包括spatial/spectra features，mask computation，speech separation/estimation， cgmm，gwpe，beamformer等等，这样可以保证不同命令之间的输入输出可以自由流动，因为底层的时频转换是一致的。</li>
<li>效率和并行。speech相关的任务数据量通常较大，做一些前端的预处理或者特征提取，可能就是几天的时间，程序跑的慢是难以容忍的事情。从优化的角度来说，其一是做并行，这里沿用kaldi的style，几乎所有的脚本都支持并行选项，其二就是优化程序本身，以cgmm为例，前后改了几版，最终效率提了大概30x，原本一天多的实验，后面几个小时就可以解决掉，这对于提升做一些验证性实验或者baseline系统搭建的效率是很有帮助。</li>
<li>通用和独立。separation/enhancement任务中有很多功能独立且固定的模块，以mask为例，单通道上直接做掩蔽，多通道做波束形成，这些脚本一次写成之后，在后续其他的任务中就不需要重复实现，只需要拿到对应的mask就可以做增强分离和性能评估，无关数据，方法和训练工具。其他的诸如特征计算，基准测试和一些signal processing的算法等等，对于新的数据而言也完全就是一行脚本的事。</li>
</ol>
<p>当整个repo原型出来之后，我的实验代码中基本只需要写<code>{nnet,dataset,train.py,infer}.py</code>等几个模型相关的文件，其他的功能在setk中用几行脚本就可以完成，而且不同模型结果之间的对比也更加严谨，毕竟底层的计算逻辑是是完全一致的。考虑到查看特征和mask在增强和分离中都是很常见的操作，后面我也加了几条可视化数据的命令，便于结果查验和特征检测。</p>
<p>上面有一点是我没有提到的，就是数据模拟（data simulation）。增强/分离这个任务上和ASR不太相同，大部分情况下都是在simu的数据集上进行训练，因为这样方便拿到对应的reference做训练target。而simu中的具体参数，比如信噪比，噪声类型，远场的话距离，混响时间，麦克风拓扑等等，都是根据你具体的应用或者假设场景决定的。我有一段时间写了很多的数据模拟相关的程序，考虑到功能不是十分通用（因为和具体的需求相关），除了<code>rir_generate.py</code>之外，并没有public。生成rir的<code>rir-simulate</code>是我参照开源的matlab版本，重新实现的，结果上和原始版本没有差别。主要考虑matlab版本不是非常好用，比如服务器上没有matlab环境等等。</p>
<p>18年九月之后我基本就在python层面维护代码，这时候已经背离原先“based on kaldi的初衷了，因此就更名为“integrated with kaldi”，可以用作对kaldi的一个前端扩展。同时把之前matlab版本的cgmm迁移到python上去，并做了优化，最后测试的结果，在性能和效率上都有了提升。</p>
<p>github上有一些机构和个人开始在python上进行signal processing的算法实现，比如<a href="https://github.com/LCAV/pyroomacoustics" target="_blank" rel="noopener">pyroomacoustics</a>。我对这些项目是非常感兴趣的。早期（可能现在也是）研究signal processing那块的人一直在matlab上做东西，波束形成，定位，降噪，去混响，盲源分离等等，大部分都不做开源。 对于很多新人而言，即使文章看懂了，代码也未必能写的出来（比如我至今写不出TF-GSC）。而有了参考的实现程序就非常有助于自己理解算法的细节，同时直观的体会到对应的实验结果。所以我在github上放出的那些repo，实验代码也好，工具也好，其实大部分并不是想让人clone下来直接用的，而是希望有做相同工作的人看见了，可以做个参考，或者帮助他们理解一下。理解之后，我觉得实现代码只是时间上的问题。反过来想一想现在用pytorch这些工具搭模型就可以复现论文，一方面没有多少理论方面的理解难度，一方面代码实现十分容易，真是赶上research的好时代了。但是也是个人能力有限，还有很多算法没有办法从matlab迁移到python，所以现在这个repo只做到目前这个样子。</p>
<p>最后说一下我对repo里面数据存储一个看法。特征什么的，早期为了兼容kaldi，存下的是archive格式。这个带来两个不方便的地方。其一，模型训练阶段的依赖<a href="https://github.com/funcwj/kaldi-python-io" target="_blank" rel="noopener">kaldi-python-io</a>这个包去load数据，不如pytorch，numpy这些简洁。其二，需要提前提取好特征，这个如果数据量很大的话，会很占磁盘空间。虽然kaldi中可以对特征进行压缩，但是<a href="https://github.com/funcwj/kaldi-python-io" target="_blank" rel="noopener">kaldi-python-io</a>中的解压过程很慢 (比不做压缩的慢上几十倍)，因此我都是不开compress选项，牺牲磁盘空间。目前我更倾向于在dataset里面做online的特征提取，和torch-audio/torch-vision的<code>Transform</code>设计类似，牺牲一点数据加载的时间。或者找到一种比较适合做大文件存储，同时python友好的数据格式进行替换等等。</p>
<p>未来的话，我还有些想法，其一是通过一些egs来解释脚本和命令的用法，现在我只做一个upit，也是给一个样例，怎么使用这些脚本，配合网络训练和后处理的，其二想添加一些signal方向上bss和denoise相关的算法，从个人兴趣上，还是觉得有理论支撑的东西比较优美，而搭网络则更加神奇……</p>
<p>希望所做工作能对同行有所帮助。</p>
<p>写于2019.3</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>SETK</tag>
      </tags>
  </entry>
  <entry>
    <title>Rank1 Constrained in PMWF</title>
    <url>/2019/01/10/rank1-const-pmwf/</url>
    <content><![CDATA[<p>本篇文章说一下波束形成中，对目标信号的协方差矩阵进行秩1的约束（Rank1 Constrained）这一操作。背后的原理之前在导向向量估计的PCA方法中已经进行了介绍，即理想情况下，单一方向声源的协方差矩阵秩$\mathbf{R}_x$为1：目标信号可以写成$\mathbf{s}_{t,f} = \mathbf{d}_f s_{t,f}$的形式，其中$\mathbf{d}_f$为导向向量，则$\mathbf{R}_f^s = r_s \mathbf{d}_f \mathbf{d}_f^H$的秩为1。由于实际估计的$\mathbf{R}_x$并不满足这一条件，因此可以用一个秩1的矩阵近似，这一过程可以用特征值分解来进行，对应的主特征向量便起到了导向向量的作用，可以用其作为估计。所以我们实际在使用含有导向向量的MVDR表达式，并用PCA方法进行估计时，背后其实已经使用了该原理。</p>
<a id="more"></a>
<p>此外MVDR还有另外一种表达式，即：</p>
<script type="math/tex; mode=display">
\mathbf{w}^{\text{MVDR}}_f = \frac{(\mathbf{R}_f^n)^{-1} \mathbf{R}_f^s}{\text{tr}\left[ (\mathbf{R}_f^n)^{-1} \mathbf{R}_f^s\right]} \mathbf{u}_r \tag{1}</script><p>它可以视为PMWF [1]（有的地方也称为SDW-MWF）的一种特殊形式，即$\beta = 0$的情况：</p>
<script type="math/tex; mode=display">
\mathbf{w}^{\text{PMWF-}\beta}_f = \frac{(\mathbf{R}_f^n)^{-1} \mathbf{R}_f^s}{\beta + \text{tr}\left[ (\mathbf{R}_f^n)^{-1} \mathbf{R}_f^s\right]} \mathbf{u}_r \tag{2}</script><p>关于它之前没有深入的做过介绍，本文首先看一下这个表达式是如何导出的。</p>
<h3 id="PMWF-推导"><a href="#PMWF-推导" class="headerlink" title="PMWF 推导"></a>PMWF 推导</h3><p>波束形成器的输出在每个TF-bin上的值$x_{t,f}$，在频域可以写成如下的形式</p>
<script type="math/tex; mode=display">
\begin{aligned}
x_{t,f} & = \mathbf{w}_f^H \mathbf{y}_{t,f} = \mathbf{w}_f^H (\mathbf{s}_{t,f} + \mathbf{n}_{t,f}) \\
& = \mathbf{w}_f^H \mathbf{s}_{t,f} + \mathbf{w}_f^H \mathbf{n}_{t,f}
\end{aligned} \tag{3}</script><p>PMWF求解的优化问题定义如下，最小化残留噪声成分的能量，同时约束目标语音的失真程度：</p>
<script type="math/tex; mode=display">
\mathbf{w} = \arg \min_{\mathbf{w}} E_t\left[ \left|\mathbf{w}_f^H \mathbf{n}_{t,f} \right|^2 \right] \; \text{s.t} \; E_t\left[ \left|\mathbf{w}_f^H \mathbf{s}_{t,f} - s_{t,f} \right|^2 \right] \leqslant \sigma \tag{4}</script><p>通常$s_{t,f}$选择为某一通道的目标信号观测值，可以表示为$s_{t,f} = \mathbf{u}_r^T \mathbf{s}_{t,f}$，其中$\mathbf{u}_r$表示一个one-hot向量，上式中约束项可以改写为：</p>
<script type="math/tex; mode=display">
E_t\left[ \left|(\mathbf{w}_f - \mathbf{u}_r)^H \mathbf{s}_{t,f} \right|^2 \right] \leqslant \sigma \tag{5}</script><p>使用拉格朗日乘子法求解，引入拉格朗日系数$\gamma$后，得到PWMF的初始表达式</p>
<script type="math/tex; mode=display">
\mathbf{w}^{\text{PMWF-}\beta}_f = \left(\mathbf{R}_f^s + \beta \cdot \mathbf{R}_f^n \right)^{-1}\mathbf{R}_f^s\mathbf{u}_r \tag{6}</script><p>其中$\beta = \gamma^{-1}$。虽然文献中经常提到，$(2)$式由$(6)$式导出，但是具体过程的推导之前自己一直没有仔细研究过，最近抽空尝试了一下，但是没有成功，请教了一圈人之后才算把这个推导打通，过程如下。</p>
<p>开始我尝试对$(\mathbf{R}_f^s + \beta \cdot \mathbf{R}_f^n)^{-1}$应用伍德伯里恒等式进行展开：</p>
<script type="math/tex; mode=display">
(A + B)^{-1} = A^{-1} - A^{-1}(I + BA^{-1})^{-1}BA^{-1} \tag{7}</script><p>对应的$A = \beta\mathbf{R}_f^n, B = \mathbf{R}_f^s$，得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
(\mathbf{R}_f^s + \beta \cdot \mathbf{R}_f^n)^{-1} &= \frac{1}{\beta}\left[(\mathbf{R}_f^n)^{-1} - (\mathbf{R}_f^n)^{-1} (\mathbf{I} + \beta^{-1} \mathbf{R}_f^s (\mathbf{R}_f^n)^{-1} )^{-1}  \mathbf{R}_f^s (\mathbf{R}_f^n)^{-1} )\right] \\
& = \frac{1}{\beta}\left[(\mathbf{R}_f^n)^{-1} - \frac{(\mathbf{R}_f^n)^{-1}\mathbf{R}_f^s (\mathbf{R}_f^n)^{-1}}{\beta + \mathbf{R}_f^s (\mathbf{R}_f^n)^{-1}} \right] \\
& = \frac{1}{\beta} \left[ \mathbf{I} -  \frac{(\mathbf{R}_f^n)^{-1}\mathbf{R}_f^s}{\beta + \mathbf{R}_f^s (\mathbf{R}_f^n)^{-1}}\right] (\mathbf{R}_f^n)^{-1}
\end{aligned} \tag{8}</script><p>之后便就发现无法继续下去，因为分母无法化简出$(2)$中的迹的形式。这里困了蛮久，最后发现自己遗漏了一个条件，正是这里面$B$矩阵秩为1这一性质，当$A$和$A + B$可逆的时候，存在如下的定理 [2]：</p>
<script type="math/tex; mode=display">
(A + B)^{-1} = A^{-1} - \frac{1}{1 + g}A^{-1}B A^{-1} \tag{9}</script><p>其中$g = \text{tr}(BA^{-1})$。用此定理可以直接对$(\mathbf{R}_f^s + \beta \cdot \mathbf{R}_f^n)^{-1}$展开就可得到</p>
<script type="math/tex; mode=display">
(\mathbf{R}_f^s + \beta \cdot \mathbf{R}_f^n)^{-1} = \frac{1}{\beta} \left( \mathbf{I} -  \frac{(\mathbf{R}_f^n)^{-1}\mathbf{R}_f^s}{\beta + \text{tr}\left[(\mathbf{R}_f^n)^{-1} \mathbf{R}_f^s \right]}\right) (\mathbf{R}_f^n)^{-1} \tag{10}</script><p>同时，式$(6)$可以做变形如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{w}^{\text{PMWF-}\beta}_f &= \left(\mathbf{R}_f^s + \beta \cdot \mathbf{R}_f^n \right)^{-1}\mathbf{R}_f^s\mathbf{u}_r \\
& = \left(\mathbf{R}_f^s + \beta \cdot \mathbf{R}_f^n \right)^{-1} \left(\mathbf{R}_f^s + \beta \cdot \mathbf{R}_f^n - \beta \cdot \mathbf{R}_f^n\right) \mathbf{u}_r \\
& = \mathbf{I} - \beta\left(\mathbf{R}_f^s + \beta \cdot \mathbf{R}_f^n \right)^{-1}\mathbf{R}_f^n \mathbf{u}_r
\end{aligned} \tag{11}</script><p>带入式$(10)$即可得到式$(2)$中的结果。</p>
<h3 id="Rank1-Constrained-实现"><a href="#Rank1-Constrained-实现" class="headerlink" title="Rank1 Constrained 实现"></a>Rank1 Constrained 实现</h3><p>Rank1约束主要指将PMWF表达式中的$\mathbf{R}_f^s$用一个秩为1的矩阵替代，即：</p>
<script type="math/tex; mode=display">
\mathbf{R}_f^s \simeq \lambda \cdot \mathbf{v}_f \mathbf{v}_f^H \tag{12}</script><p>以去除其中的噪声成分，也更加符合信号模型的假设。实现上最直观的方法使用特征值分解，$\mathbf{v}_f$为主特征向量，$\lambda$表示一个缩放常数：</p>
<script type="math/tex; mode=display">
\lambda = \text{tr} \left(\mathbf{R}_f^s \right) / \text{tr} \left(\mathbf{v}_f \mathbf{v}_f^H \right) \tag{13}</script><p>其次可以通过广义特征分解的方式进行：</p>
<script type="math/tex; mode=display">
\mathbf{v}_f = \mathbf{R}_f^s \cdot \mathcal{P} \left(\mathbf{R}_f^s, \mathbf{R}_f^n \right) \tag{14}</script><p>在我本人的一些初步实验中，确实发现，使用特征值分解或者广义特征值分解的方法，对$\mathbf{R}_f^s$做Rank1约束对识别结果有提升效果，且后者的相对提升高一些，因此在后续使用这种形式的波束形成器时，可以考虑加上Rank1约束，做一组对比实验。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]. M. Souden, J. Benesty, S. Affes. On Optimal Frequency-domain Multichannel Linear Filtering for Noise Reduction[J]. IEEE Transactions on audio, speech, and language processing, 2009, 18(2):260–276.<br>[2]. <a href="http://fourier.eng.hmc.edu/e176/lectures/algebra/node6.html" target="_blank" rel="noopener">http://fourier.eng.hmc.edu/e176/lectures/algebra/node6.html</a><br>[3]. Ziteng Wang, Emmanuel Vincent, Romain Serizel, and Yonghong Yan, “Rank-1 Constrained Multichannel Wiener Filter for Speech Recognition in Noisy Environments,” Jul 2017.</p>
]]></content>
      <categories>
        <category>Speech Enhancement</category>
      </categories>
      <tags>
        <tag>Beamformer</tag>
        <tag>PMWF</tag>
      </tags>
  </entry>
  <entry>
    <title>On Spatial Features</title>
    <url>/2018/11/20/on-spatial-feature/</url>
    <content><![CDATA[<p>考虑到后面的时间可能不会继续深入声学前端这块了，因此想着近期补充一些前面一直想写，没写的东西，趁着年底也算是做一些小结。这次先谈一谈前端中一个比较重要的概念，spatial。</p>
<p>在文献中，spatial和spectral成一对。以前做的声学模型，输入大多采用单通道，从谱上衍生的的声学特征，mfcc/fbank等等，因为这种情况下，谱上的特征区分性更加明显。但是如果可以获取麦克风阵列的多路输入，channel之间的delay就是一个非常重要的提示信息，也是所谓spatial的体现，Source Localization和Spatial Filter就是两个非常典型的应用。相比delay而言，channel之间在谱上的差别通常不会很大，因此，在传统的一些方法中，很少有使用inter-channel的spectral特征进行建模的方法，而以spatial的特征替代。</p>
<a id="more"></a>
<h4 id="Data-Simulation"><a href="#Data-Simulation" class="headerlink" title="Data Simulation"></a>Data Simulation</h4><p>multi-channel的数据可以通过实录或者simulation拿到，后者虽然没有实录的数据真实，但是在时间成本很低，实验验证阶段做一些simu是没有问题的。工程上如果时间/成本允许，还是实录一部分数据比较好。</p>
<p>通常的，multi-channel下的信号模型可以写成下面的形式：</p>
<script type="math/tex; mode=display">
\mathbf{M} = \sum_k \mathbf{R}_k * \mathbf{s}_k + \mathbf{N}</script><p>$\mathbf{s}_i$表示第$i$个声源，$\mathbf{R}_i \in \mathbb{R}^{M \times L}$表示声源$i$到麦克风处的冲击响应（impulse response，包含信号衰减，延迟，房间反射等效应），$*$表示卷积操作，$\mathbf{N} \in \mathbb{R}^{M \times S}$ 表示multi-channel的背景噪声，$\mathbf{M} \in \mathbb{R}^{M \times S}$表示阵列最后接收到的信号，$M$为麦的个数。$\mathbf{R}_i$可以通过<a href="https://github.com/ehabets/RIR-Generator" target="_blank" rel="noopener">image</a>方法生成，也可以采用实录的房间响应，$\mathbf{N}$通常在对应环境下事先录好。</p>
<p>有了close talk，clean的说话人数据$\mathbf{s}_i$，multi-channel的噪声库，再通过image方法生成多路的rir，就可以通过上式生成每个麦克风处的混合信号。$\mathbf{R}_k * \mathbf{s}_k$称为声源$k$在阵列处的image（镜像）。</p>
<p>这里注意几点：</p>
<ol>
<li>背景噪声切勿加成单路信号，否则就会成为一个方向性声源。</li>
<li>通过image方法生成rir的时候，如果配置房间反射系数为0或者T60值为0的话，表示信号模型中不存在混响，这种情况虽然非常理想，但是可以用于数据debug，或者验证性工作。</li>
</ol>
<h4 id="Spatial-Clustering"><a href="#Spatial-Clustering" class="headerlink" title="Spatial Clustering"></a>Spatial Clustering</h4><p>spatial clustering方法指的是利用每个TF-bin上观测向量在空间分布上的规律，根据聚类结果以区分bin的属性的一类方法的总称。这类方法其实我之前也简单做过介绍，比较广为人知的应该是CHiME3上取得成功的CGMM[5]。它实际上同时利用了spectral/spatial特征，因为是直接对每个TF-bin上的观测向量$\mathbf{y}_{tf}$进行建模的，假设每个component服从complex GMM分布：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{tf} \sim \mathcal{N}_c(0, \phi_{tf}\mathbf{R}_f)</script><p>比较“纯正”的方法，通常忽略spectral的差异，仅仅保留方向信息，即对：</p>
<script type="math/tex; mode=display">
\mathbf{z}_{tf} = \frac{\mathbf{y}_{tf}}{\Vert \mathbf{y}_{tf} \Vert}</script><p>进行建模（文献中称为directional statistics）。这类方法有很多，CWMM[3]，caCGMM[4]等等，它们的区别更多的是在对$\mathbf{z}_{tf}$分布的假设上，EM过程都是一样的。最终通过贝叶斯公式，将每个component的似然值转化成后验概率（这里也就是常常说的TF-mask）：</p>
<script type="math/tex; mode=display">
\lambda_{tf, k} = \frac{\alpha_k \mathcal{P}(\mathbf{z}_{tf}, \Theta_k)}{\sum_c \alpha_c \mathcal{P}(\mathbf{z}_{tf}, \Theta_c)}</script><p>$\mathcal{P}$表示对观测假设的先验分布，$\alpha$表示的是每个混合分量在mixture model中的权重，可以随EM过程更新。</p>
<p>spatial clustering的聚类过程在每个subband上独立进行（narrowband method），因此，无法保证最终的聚类结果在frequency上的归属是连续的，存在cross frequency的permutation问题，最终的话，需要进行一个所谓的align过程，将每个band上的聚类结果进行对齐，才能保证结果可用。</p>
<p>聚类算法要work的话，显然，观测的随机变量必然可以在其分布的空间上形成聚类效应。通过聚类结果，拿到了每个TF-bin的归属，就可以以此区分出target/interference。在理想的情况下（无信号衰减，无混响），$\theta$方向上的声源在线阵（$M$麦）上形成的观测向量为：</p>
<script type="math/tex; mode=display">
\mathbf{d}_{\omega,t}^\theta = X_{\omega,t} \cdot [1, e^{-j\omega\tau_1}, \cdots, e^{-j\omega\tau_M}]</script><p>以方位为$\theta_1, \theta_2$的两个说话人为例，混叠的结果可以表示为：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{\omega,t} = \mathbf{d}_{\omega,t}^{\theta_1} + \mathbf{d}_{\omega,t}^{\theta_2}</script><p>根据谱上的稀疏性，每个TF-bin上的混叠结果，是更加倾向于domainant source的（即能量较大的一方），而不同的声源因为$\theta$方位的不同，directional statistics在空间上的分布必然不同，因此可以形成聚类效应。</p>
<p>这个现象可以简单做一下验证，在每个subband上，对directional statistics的幅角分布可视化，或者plot出某几个维度上的坐标点。首先选定声源方位角，麦克风阵列配置（10cm，$M=6$）和房间配置生成rir，卷积之后根据一定信噪比混合。下面给出一个12500Hz上的PCA结果：</p>
<p><img src="http://www.funcwj.cn/images/phase-pca-f4.jpg" width="400"></p>
<p>不同的点色表示使用binary mask区分出的domainant source。比较奇怪的是，这些点并没有按我想象中的聚成两类，而是有6/7个聚类中心，这个现象可能和所谓的spatial aliasing（空间混叠）有关。如果麦克风之间的间距大于该信号波长的一半时，因为不能保证采样点落在一个周期，所以从相位变化上不能反推时间上的delay（换句话说，不同的delay会对应到相近的相位值）。阵列间距变大，或者信号频率变高都会使得空间混叠的发生概率变大。回到这个样例中来，12.5kHz的信号，对应波长2.7cm，满足spatial aliasing的条件，因此最终聚类中心个数不理想（这一段的理解可能存在问题，后期考虑成熟之后会进行修改）。个人觉得线阵中混叠发生的概率还是很高的，因为再考虑入射角进去，在$\theta$方向上的麦克风间距实际是$\cos(\theta) \cdot d$。</p>
<p>最后说一下，clustering方法可以用于增强和分离任务。区别无非是前者的方向性声源只有一个，就是目标的speech成分，后者则可能多个。因此前者建模中，mixture model只存在两个component，而后者则取决于说话人的数量。</p>
<h4 id="Combine-Spatial-amp-Spectral"><a href="#Combine-Spatial-amp-Spectral" class="headerlink" title="Combine Spatial &amp; Spectral"></a>Combine Spatial &amp; Spectral</h4><p>DL的一些方法在对谱特征（实值）利用上表现出了很强的建模能力，但是丢失了我们说的spatial信息。因此，陆续就有人尝试将两者结合起来[1]，[2]，提升系统的鲁棒性。</p>
<p>比较常用的一种方法是将nn的mask用于cgmm的初始化，在之前的一些文献中也有人尝试过，就我本人的实践而言，表现不是十分稳定。[1]中的方法也比较类似，使用cacgmm部署spatral的特征，使用nn弥补directional statistics中丢失的spectral信息，两者联合优化的目标函数表示为：</p>
<script type="math/tex; mode=display">
\mathcal{L}_{tf} = \sum_k p_{\text{nn}}^k(\mathbf{y}_{tf}) \cdot p_{\text{cacgmm}}^k(\mathbf{z}_{tf})</script><p>其中：</p>
<script type="math/tex; mode=display">
p_{\text{nn}}^k(\mathbf{y}_{tf}) = \mathcal{P}(k|\mathbf{y}_{tf}, \Theta_{\text{nn}}) \\
p_{\text{cacgmm}}^k(\mathbf{z}_{tf}) = \mathcal{P}(\mathbf{z}_{tf} | k, \Theta_{\text{cacgmm}})</script><p>再者就是ZQ.Wang最近做的一系列工作了[6],[7],[8],[9]，在分离/增强任务上读取得了不错的成果。他的思想很朴素，主要是尝试将不同的spatial特征和spectral特征进行拼接输入网络，以此达到两者结合的目的，比较常用的有IPD是DF（directional features）。</p>
<p>先说一下IPD（inter-channel phase difference，即相位差），每个TF-bin上，IPD由$ \angle\mathbf{y}_{tf, i} - \angle\mathbf{y}_{tf, j}$得到，需要提前选定两麦作为参考。根据谱上的稀疏性，每个TF-bin上的IPD值必然倾向于domainant source的结果，又因为不同的source时间上的delay不同，因此可以推测，如果空间混叠不会发生，那么在每个frequency上是具备区分性的，但是实际情况不会如此理想。以一个2spk的simu样例为例，画出以IPD和frequency为坐标的每个TF-bin的分布概率图（黑色表示高概率）：</p>
<p><img src="http://www.funcwj.cn/images/ideal-ipd-frequency.jpg" width="400"></p>
<p>从上图中可以看到，IPD在频率轴上是不连续的，以$2\pi$为周期。但是除个别频率之外，基本都可以找到两个IPD的分布峰值，对应两个角度不同的强声源。</p>
<p>ZQ.Wang采取的方法是和spectral特征进行拼接，辅助分离网络，因为spatial的特征存在歧义，这时候还必须依赖spectral特征。在[6]中，一种自IPD衍生的directional feature被使用，基于的思想和IPD类似，但是利用了所有麦克风pair的信息。假定可以拿到关于目标声源delay相关的ground truth，那么和ground truth差别越小的TF-bin，越倾向于属于该方向上的声源，在数学上表达为下式的值接近1：</p>
<script type="math/tex; mode=display">
\text{DF}_{t, \omega} = \frac{\sum_{i=0}^{N-1} \sum_{i=j + 1}^{N-1} \cos \{ \angle\mathbf{y}_{t\omega, i} - \angle\mathbf{y}_{t \omega, j} - \omega \tau_{ij} \}}{N(N-1)}</script><p>实际计算中，由于无法直接估计一个比较准确的delay，文章采用MVDR的steer vector的幅角替代上式中的$\omega \tau$，这样一来，就需要事先使用一个spectral特征输入的的mask网络产生初步的mask，才能完成导向向量的估计和DF特征的计算。在mask估计较准的情况下，可以从特征上看出domainant source的大致分布，如下：</p>
<p><img src="http://www.funcwj.cn/images/df-egs01.png" width="500"></p>
<p>后面还有些文章提出使用维纳滤波的结果作为DF特征（其实就是增强的谱特征）：</p>
<script type="math/tex; mode=display">
\text{DF}_{t,\omega} = \log|\mathbf{w}_{\text{MCWF}, \omega}^H \mathbf{y}_{t,\omega} |</script><p>在CHiME4上作者还曾经使用过一种利用channel之间的相关性的特征，即MSC[6]（magnitude squred coherence），这种特征被用于增强任务中，甚至直接可以当成一种无监督的TF-mask（CHiME3数据上取得了一定的效果，可见图3）。考虑到MSC完全依赖channel之间的相关程度，并没有显式使用方向信息，因此，只在噪声类型相关性较差的情况下，容易区分出speech和noise（speech相关程度高）。而在分离任务中，这种特征并没有多大的使用空间。</p>
<p><img src="http://www.funcwj.cn/images/msc-egs01.png" width="500"></p>
<h4 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h4><p>关于spatial这个概念，我觉得理解的重点在于：</p>
<ol>
<li>基于spatial clustering的算法为什么可以work</li>
<li>所谓spatial的歧义是如何产生的</li>
<li>spatial feature的设计初衷（即为什么可以提升模型效果）</li>
</ol>
<p>目前对于前两点只是在实验过程中初步产生了一些理解和想法，第三点虽然在本人的实验配置中尚未取得gain，但是考虑数据和场景这些因素，也觉得未必是方法和特征本身原因造成的。先写到这里，后面如果有新的理解和体会，再继续补充吧。</p>
<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><p>[1]. Nakatani T, Ito N, Higuchi T, et al. Integrating DNN-based and spatial clustering-based mask estimation for robust MVDR beamforming[C]//Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on. IEEE, 2017: 286-290.<br>[2]. Drude L, Haeb-Umbach R. Tight integration of spatial and spectral features for BSS with deep clustering embeddings[C]//Proc. Interspeech. 2017: 2650-2654.<br>[3]. D.H. Tran Vu and R. Haeb-Umbach, “Blind speech separation employing directional statistics in an ex- pectation maximization framework,” in Proc. ICASSP, Mar. 2010, pp. 241–244.<br>[4]. Ito N, Araki S, Nakatani T. Complex angular central gaussian mixture model for directional statistics in mask-based microphone array signal processing[C]//Signal Processing Conference (EUSIPCO), 2016 24th European. IEEE, 2016: 1153-1157.<br>[5]. Higuchi T, Ito N, Araki S, et al. Online MVDR beamformer based on complex Gaussian mixture model with spatial prior for noise robust ASR[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2017, 25(4): 780-793.<br>[6]. Wang Z Q, Wang D L. On spatial features for supervised speech separation and its application to beamforming and robust asr[C]//2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2018: 5709-5713.<br>[7]. Wang Z Q, Wang D L. Combining Spectral and Spatial Features for Deep Learning Based Blind Speaker Separation[J]. IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2018.<br>[8]. Wang Z Q, Wang D L. Integrating Spectral and Spatial Features for Multi-Channel Speaker Separation[J]. Proc. Interspeech 2018, 2018: 2718-2722.<br>[9]. Wang Z Q, Le Roux J, Hershey J R. Multi-Channel Deep Clustering: Discriminative Spectral and Spatial Embeddings for Speaker-Independent Speech Separation[J]. 2018.</p>
]]></content>
      <categories>
        <category>Speech Separation</category>
      </categories>
      <tags>
        <tag>Multi-channel</tag>
        <tag>Spatial</tag>
      </tags>
  </entry>
  <entry>
    <title>View Beamformer Again</title>
    <url>/2018/11/03/beamformer-details/</url>
    <content><![CDATA[<p>上一篇关于beamformer的文章应该是一年之前，刚入门的时候看了，理解有些粗浅，现在就一些细节上的问题（也是上篇文章中没有提及的地方）补充一些理解，后面实践加深会继续补充。</p>
<h4 id="导向向量估计"><a href="#导向向量估计" class="headerlink" title="导向向量估计"></a>导向向量估计</h4><p>首先，导向向量$\mathbf{d}_f$的估计，$\mathbf{d}_f$描述的是声源的方位信息，对波束形成器的指向性十分关键。目前常见的方法是用协方差矩阵$\mathbf{R}_{xx}$的主特征值进行估计，背后的假设在理想情况下，方向性声源的$\mathbf{R}_{xx}^\theta$是个秩为1的矩阵，即可以表示为：</p>
<script type="math/tex; mode=display">
\mathbf{R}_{xx}^\theta = E[s_f \mathbf{d}_{f}^\theta] = \phi_{ss} \mathbf{d}_{f}^\theta (\mathbf{d}_{f}^\theta)^H</script><a id="more"></a>
<p>而通常我们采用二阶统计量估计出来的协方差矩阵秩是不为1的，因此，采用主特征值的想法是近似一个秩为1的矩阵，提取其方向信息，这种方法也称为PCA方法，因为可以视为PCA算法中主成分设为1时的特殊情况。这时的$\mathbf{R}_{xx}$被近似为：</p>
<script type="math/tex; mode=display">
\mathbf{R}_{xx} \simeq \lambda_{\max}\mathbf{v}\mathbf{v}^H</script><p>考虑到$\mathbf{R}_{xx}$共轭对称，有：</p>
<script type="math/tex; mode=display">
\mathbf{R}_{xx} = \mathbf{V}\mathbf{\Lambda}\mathbf{V}^H = \sum_i^{N-1} \lambda_i \mathbf{v}_i\mathbf{v}_i^H</script><p>其中$\mathbf{\Lambda}$为对角矩阵，$\mathbf{V}$为正交矩阵。</p>
<h4 id="Beamformer等价性"><a href="#Beamformer等价性" class="headerlink" title="Beamformer等价性"></a>Beamformer等价性</h4><p>signal的一些文章中还经常使用到下面两个性质，做一些等价变换</p>
<ul>
<li>$\text{trace}(AB) = \text{trace}(BA) $</li>
<li>$\mathbf{R}_{yy} = \mathbf{R}_{xx} + \mathbf{R}_{vv}$</li>
</ul>
<p>比如：$\mathbf{h}_{\text{MVDR}} = \mathbf{h}_{\text{PMWF-0}}  $，即MVDR和PMWF-0二者等价。</p>
<p>MVDR的weight最常见的表达形式为：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{f,\text{MVDR}} = \frac{\mathbf{R}_{f,vv}^{-1}\mathbf{d}_f}{\mathbf{d}_f^H\mathbf{R}_{f,vv}^{-1}\mathbf{d}_f}</script><p>如果认为$\mathbf{R}_{f,xx} = \phi_{ss} \mathbf{d}_{f}\mathbf{d}_{f}^H$，那么上式可以简化为：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{h}_{f,\text{MVDR}} &= \frac{\phi_{ss} \mathbf{R}_{f,vv}^{-1}\mathbf{d}_f}{\phi_{ss} \mathbf{d}_f^H\mathbf{R}_{f,vv}^{-1}\mathbf{d}_f} = \frac{\phi_{ss} \mathbf{R}_{f,vv}^{-1}\mathbf{d}_f}{\text{tr}[\mathbf{R}_{f,vv}^{-1}\phi_{ss} \mathbf{d}_f\mathbf{d}_f^H]} \notag \\
&= \frac{\phi_{ss} \mathbf{R}_{f,vv}^{-1}\mathbf{d}_f}{\text{tr}\left[\mathbf{R}_{f,vv}^{-1}\mathbf{R}_{f,xx}\right]} = \frac{\phi_{ss} \mathbf{R}_{f,vv}^{-1}\mathbf{d}_f}{\text{tr}\left[\mathbf{R}_{f,vv}^{-1}\mathbf{R}_{f,yy}\right] - N} \notag
\end{align}</script><p>$\mathbf{h}_{\text{PMWF-}\beta}$[2]通常写成：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{f,\text{PMWF-}\beta} = \frac{\mathbf{R}_{f,vv}^{-1}\mathbf{R}_{f,xx} \mathbf{u}_r}{\beta + \text{tr}\left[\mathbf{R}_{f,vv}^{-1}\mathbf{R}_{f,xx}\right]}</script><p>$\beta = 0$时候，$\mathbf{h}_{f,\text{PMWF-}\beta}$和$\mathbf{h}_{f,\text{MVDR}}$只相差一个缩放因子$d_r$：</p>
<script type="math/tex; mode=display">
\mathbf{R}_{f,xx}\mathbf{u}_r = \phi_{ss} \mathbf{d}_{f}\mathbf{d}_{f}^H \mathbf{u}_r = d_r\phi_{ss} \mathbf{d}_f</script><p>关于$\mathbf{u}_r$的选择，可以人为指定，也可以使用SNR选择[3]（遍历channel，选平均snr最大的做参考）：</p>
<script type="math/tex; mode=display">
r = \arg \max_r \text{SNR}_r = \arg \max_r \left(\frac{\sum_f \mathbf{h}_{f,r}^H \mathbf{R}_{f,xx} \mathbf{h}_{f,r}}{\sum_f \mathbf{h}_{f,r}^H \mathbf{R}_{f,vv} \mathbf{h}_{f,r}} \right)</script><p>最后说一下MCWF[1]（考虑后面有人拿它直接做spatial feature），直接以参考信号的MSE为代价函数：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathcal{J}_f & = E \left[|X_{f,r} - \mathbf{h}_{f,\text{MCWF}}^H \mathbf{y}_f|^2 \right] = E \left[|\mathbf{u}_r^H \mathbf{x}_f - \mathbf{h}_{f,\text{MCWF}}^H \mathbf{x}_f - \mathbf{h}_{f,\text{MCWF}}^H \mathbf{v}_f|^2 \right] \\
& = E \left[|(\mathbf{u}_r - \mathbf{h}_{f,\text{MCWF}}) ^H \mathbf{x}_f -\mathbf{h}_{f,\text{MCWF}}^H \mathbf{v}_f|^2 \right] \notag
\end{align}</script><p>通常假设噪声和speech不相关，因此有$\mathbf{R}_{yx} = \mathbf{R}_{xx}$，求解上式：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{f,\text{MCWF}} = \mathbf{R}_{f, yy}^{-1}\mathbf{R}_{f, xx} \mathbf{u}_r</script><p>可以进一步表示为：</p>
<script type="math/tex; mode=display">
\mathbf{h}_{f,\text{MCWF}} = \frac{\mathbf{R}_{f, vv}^{-1}\mathbf{R}_{f, xx} \mathbf{u}_r}{1 + \text{tr}\left[\mathbf{R}_{f, vv}^{-1}\mathbf{R}_{f, xx}\right]}</script><p>由此可以看出，$\mathbf{h}_{\text{MCWF}} = \mathbf{h}_{\text{PMWF-1}}​$，总结即是下面两点：</p>
<ul>
<li>$\mathbf{h}_{\text{MCWF}} = \mathbf{h}_{\text{PMWF-1}}$</li>
<li>$\mathbf{h}_{\text{MVDR}} = \mathbf{h}_{\text{PMWF-0}}$</li>
</ul>
<h4 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h4><p>[1]. Benesty J, Chen J, Huang Y. Microphone array signal processing[M]. Springer Science &amp; Business Media, 2008.<br>[2]. Souden M, Benesty J, Affes S. On optimal frequency-domain multichannel linear filtering for noise reduction[J]. IEEE Transactions on audio, speech, and language processing, 2010, 18(2): 260-276.<br>[3]. Erdogan H, Hershey J R, Watanabe S, et al. Improved MVDR Beamforming Using Single-Channel Mask Prediction Networks[C]//Interspeech. 2016: 1981-1985.</p>
]]></content>
      <categories>
        <category>Speech Enhancement</category>
      </categories>
      <tags>
        <tag>Beamformer</tag>
        <tag>Steer vector</tag>
      </tags>
  </entry>
  <entry>
    <title>AuxIVA Algorithm</title>
    <url>/2018/10/10/auxiva-algorithm/</url>
    <content><![CDATA[<p>这篇文章简单说一下AuxIVA算法，前段时间接触并实现了一下，有些结论和体会，在这里做一下小结。</p>
<p>BSS（Blind Source/Speech/Signal Separation）问题中根据信号混合的方式，可以分为instantaneous/convolutive两种，前者仅仅是简单的线性叠加，和convolutive不同，对信号源到麦克风之间的冲击响应不加以建模；如果根据信号源数目和观测（麦克风）数目划分，有determined和underdetermined两种，前者表示观测信道足够（大于等于信号源数目），后者对应数量不足的情况。因此，BSS问题可以组合成四种case，比较显而易见，underdetermined/convolutive的情况最为复杂。</p>
<p>BSS的解决方法，比较主流的是ICA[2]及其衍生算法，比如IVA[3]，TRINICON[4]等等。相比Frequency-ICA，IVA的优点是不需要解决frequency上的置换问题，显得十分简洁。</p>
<a id="more"></a>
<h3 id="Problem-setup"><a href="#Problem-setup" class="headerlink" title="Problem setup"></a>Problem setup</h3><p>在频域，convolutive mixture情况下（$N$路信号和观测），观测信号$\mathbf{x}_{f,t}$可以写成源信号$\mathbf{s}_{f,t}$的线性叠加：</p>
<script type="math/tex; mode=display">
\mathbf{x}_{f,t} = \boldsymbol{A}_f \mathbf{s}_{f,t}</script><p>其中$ \boldsymbol{A}_f \in \mathbf{C}^{N \times N}$表示子带$f$上的混合矩阵。算法最终需要估计一个对应的解混矩阵$\boldsymbol{A}_f $，使得：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{f,t} = \boldsymbol{W}_f \mathbf{x}_{f,t} \tag{1}</script><p>中的各路信号尽可能相互独立，对应的代价函数用KL散度定义：</p>
<script type="math/tex; mode=display">
\mathcal{J}(\boldsymbol{W}) = D_{KL} \left(q(\mathbf{y}_t^0, \cdots, \mathbf{y}_t^{N-1}) \Vert \prod_n p(\mathbf{y}_t^n) \right) \tag{2}</script><p>其中$\mathbf{y}_t^n = [\mathbf{y}_{0,t}^n, \cdots, \mathbf{y}_{N_f,t}^n]^T$，$p$表示以频率为随机变量的分布密度函数，$q$为联合分布密度函数。$(1)$式最终可以简化成：</p>
<script type="math/tex; mode=display">
\mathcal{J}(\boldsymbol{W}) = -\sum_n E_t \log p(\mathbf{y}_t^n) - \sum_f \log |\det \boldsymbol{W}_f| \tag{3}</script><p>blind情况下，对于$p$一般是事先指定的。</p>
<h3 id="Estimate-Demixing-Matrix"><a href="#Estimate-Demixing-Matrix" class="headerlink" title="Estimate Demixing Matrix"></a>Estimate Demixing Matrix</h3><p>根据式$(1)$，只要估计出了$\boldsymbol{W} = {\boldsymbol{W}_f}_{f=0}^{N_f}$，做iSTFT就可以获得分离的时域信号：</p>
<script type="math/tex; mode=display">
\boldsymbol{W} = \arg \min_{\boldsymbol{W}} \mathcal{J}(\boldsymbol{W})</script><p>对于AuxIVA而言，解混矩阵的估计通过构造辅助函数进行，原始版本是基于自然梯度的梯度下降法，学习率/步长的设置对于最终结果的影响较大，相比之，AuxIVA的收敛更快，结果更加稳定。</p>
<p>令$G(\mathbf{y}_t^n) =- \log p(\mathbf{y}_t^n)$，AuxIVA的更新法则为：</p>
<ol>
<li><p>update auxiliary variables </p>
<script type="math/tex; mode=display">
\boldsymbol{V}_{n,f} = E_t\left[\frac{G'(r_{n,t})}{r_{n,t}} \mathbf{x}_t^n (\mathbf{x}_t^n)^H\right]</script><p>其中$r_{n,t} = \Vert \mathbf{y}_t^n \Vert_2$，$G’(r_{n,t})$一般取1。</p>
</li>
<li><p>update demixing matrix</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{w}_{n,f} &= \left[\boldsymbol{W}_f\boldsymbol{V}_{n,f} \right]^{-1}\mathbf{e}_n \\
\mathbf{w}_{n,f} & = \mathbf{w}_{n,f} / \sqrt{\mathbf{w}_{i,f}^H \boldsymbol{V}_{n,f} \mathbf{w}_{n,f}}
\end{align}</script><p>$\mathbf{w}_{n,f}$表示$\boldsymbol{W}_f$的第$n$行。</p>
</li>
</ol>
<p>参考<a href="https://github.com/LCAV/pyroomacoustics/blob/master/pyroomacoustics/bss/auxiva.py" target="_blank" rel="noopener">pyroomacoustics</a>的实现，上述过程可以写成：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">auxiva</span><span class="params">(X, epochs=<span class="number">20</span>)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">        X: shape in N x T x F</span></span><br><span class="line"><span class="string">    Return</span></span><br><span class="line"><span class="string">        Y: same shape as X</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    N, T, F = X.shape</span><br><span class="line">    <span class="comment"># X: F x T x N</span></span><br><span class="line">    X = X.transpose([<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    <span class="comment"># F x N x N</span></span><br><span class="line">    W = np.array([np.eye(N, dtype=np.complex) <span class="keyword">for</span> f <span class="keyword">in</span> range(F)])</span><br><span class="line">    I = np.eye(N)</span><br><span class="line">    <span class="comment"># Y: F x T x N</span></span><br><span class="line">    Y = np.einsum(<span class="string">"...tn,...nx-&gt;...tx"</span>, X, np.conj(W))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(epochs):</span><br><span class="line">        <span class="comment"># T x N</span></span><br><span class="line">        R = np.sqrt(np.sum(np.abs(Y)**<span class="number">2</span>, axis=<span class="number">0</span>))</span><br><span class="line">        <span class="comment"># N x T</span></span><br><span class="line">        Gr = <span class="number">1</span> / (R.T + EPSILON)</span><br><span class="line">        <span class="keyword">for</span> f <span class="keyword">in</span> range(F):</span><br><span class="line">            <span class="keyword">for</span> n <span class="keyword">in</span> range(N):</span><br><span class="line">                <span class="comment"># compute V</span></span><br><span class="line">                V = (np.dot(np.expand_dims(Gr[n], <span class="number">0</span>) * X[f].T, np.conj(</span><br><span class="line">                    X[f]))) / T</span><br><span class="line">                <span class="comment"># update W</span></span><br><span class="line">                w = np.linalg.solve(np.conj(W[f].T) @ V, I[n])</span><br><span class="line">                W[f, :, n] = w / np.inner(np.conj(w), V @ w)</span><br><span class="line"></span><br><span class="line">        Y = np.einsum(<span class="string">"...tn,...nx-&gt;...tx"</span>, X, np.conj(W))</span><br><span class="line">    <span class="comment"># F x T x N =&gt; N x T x F</span></span><br><span class="line">    Y = np.transpose(Y, [<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    <span class="keyword">return</span> Y</span><br></pre></td></tr></table></figure>
<p>实际表现，IVA的结果给我的感觉不是非常理想（但是相比原始信号，还是可以体会到显著的分离效果），毕竟是完全blind的方法。另外需要注意的是，直接对$(1)$式做iSTFT合成的时域信号在能量上和原始信号不匹配，因此，很多地方都提到了project back这个概念，计算一个scale矩阵，对分离信号的每个bin上的能量进行缩放。<a href="https://github.com/LCAV/pyroomacoustics/blob/master/pyroomacoustics/bss/auxiva.py" target="_blank" rel="noopener">pyroomacoustics</a>中的算法为：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{f,t} = \mathbf{y}_{f,t} \odot  \frac{E(\mathbf{y}_{f,t} \mathbf{x}_t)}{|\mathbf{y}_{f,t}|^2}</script><p>ICA系列比较重要的问题就是如何衡量信号的独立性，依此设计cost function，希望深纠的同学可以详细看一下参考文献[2]中的一些基本概念，对于了解这系列算法挺有帮助。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]. Ono N. Stable and fast update rules for independent vector analysis based on auxiliary function technique[C]//Applications of Signal Processing to Audio and Acoustics (WASPAA), 2011 IEEE Workshop on. IEEE, 2011: 189-192.<br>[2]. Hyvärinen A, Oja E. Independent component analysis: algorithms and applications[J]. Neural networks, 2000, 13(4-5): 411-430.<br>[3]. Kim T, Eltoft T, Lee T W. Independent vector analysis: An extension of ICA to multivariate components[C]//International Conference on Independent Component Analysis and Signal Separation. Springer, Berlin, Heidelberg, 2006: 165-172.<br>[4]. Buchner H, Aichner R, Kellermann W. TRINICON: A versatile framework for multichannel blind signal processing[C]//Acoustics, Speech, and Signal Processing, 2004. Proceedings.(ICASSP’04). IEEE International Conference on. IEEE, 2004, 3: iii-889.</p>
]]></content>
      <categories>
        <category>Speech Separation</category>
      </categories>
      <tags>
        <tag>BSS</tag>
        <tag>IVA</tag>
        <tag>Multi-channel</tag>
      </tags>
  </entry>
  <entry>
    <title>OMLSA - Single-channel Speech Enhancement</title>
    <url>/2018/09/30/omlsa-noise-reduction/</url>
    <content><![CDATA[<p>这次说一个single-channel noise reduction的经典方法，OMLSA（optimally-modified log-spectral amplitude）。这是Cohen在2001年提出的（目前matlab已经开源，在cohen的个人主页上），比较具有代表性，里面牵扯模块也比较多，涉及了很多signal processing领域非常经典的未知量估计问题，后面还被拓展到multi-channel中，和GSC-structure结合，做post-filtering等等，如果想要深纠的话，对这个算法还是要基本了解一下的。我头一次看的时候还被绕进去一两天……</p>
<a id="more"></a>
<h3 id="MCRA"><a href="#MCRA" class="headerlink" title="MCRA"></a>MCRA</h3><p>首先说一下MCRA（minima controlled recursive averaging）算法，这是noise spectrum估计的一个经典算法，后面还有一个improved版本IMCRA。为什么要提它呢？因为OMLSA第一步就要用它估计噪声谱。</p>
<p>估计出来的噪声谱我这里用$\lambda^d_{f,t}$表示。作为算法的入口，MCRA执行的时候，除了信号谱$Y_{f,t}$之外，再没有任何先验知识。</p>
<p>在speech存在/不存在的假设下，$\lambda_{f,t}$的估计方法为：</p>
<script type="math/tex; mode=display">
\begin{align}
\lambda_{f,t + 1} &= \alpha_d \lambda_{f,t} + (1-\alpha_d)|Y_{f,t}|^2 \\
\lambda_{f,t + 1} &= \lambda_{f,t}
\end{align}</script><p>$\alpha_d$为平滑因子，如果已知speech在当前观测$Y_{f,t}$下存在的条件概率$p’_{f,t}$，上面两个式子可以联合写成：</p>
<script type="math/tex; mode=display">
\lambda_{f,t + 1} = p'_{f,t} \lambda_{f,t} + [\alpha_d\lambda_{f,t} + (1-\alpha_d)|Y_{f,t}|^2](1 - p'_{f,t}) \tag{1}</script><p>因此关键在于导出条件概率$p’_{f,t}$，首先对观测谱在频率轴上加窗，时间轴上做平滑，得到$S_{f,t}$：</p>
<script type="math/tex; mode=display">
S_{f,t} = \alpha_s S_{f,t-1} + (1-\alpha_s)S^f_{f,t-1} \\
S^f_{f,t} = \sum_{\delta=-i}^i w(i) |Y_{f, t + i}|^2</script><p>并追踪$S^\min_{f,t}$，定义$S^r_{f,t} = S_{f,t} / S^\min_{f,t}$，$p’_{f,t}$由：</p>
<script type="math/tex; mode=display">
p'_{f,t} = \alpha_p p'_{f,t-1}  + (1-\alpha_p) \delta[S^\min_{f,t} > \Delta]</script><p>$\delta$表示指示函数，$\Delta$表示预先设置的阈值。上式带入$(1)$即可得到noise spectrum的估计。</p>
<h3 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm"></a>Algorithm</h3><p>使用MCRA算法得到noise spectrum之后，现有的已知量包括$Y_{f,t}$和$\lambda^d_{f,t}$，OMLSA算法进行步骤如下：</p>
<ul>
<li><p>用$Y_{f,t}, \lambda^d_{f,t}$计算posterior SNR $\gamma_{f, t}$</p>
<script type="math/tex; mode=display">
\gamma_{f,t} = \frac{|Y_{f,t}|^2}{\lambda^d_{f,t}}</script></li>
<li><p>估计prior SNR $\xi_{f,t}$</p>
</li>
<li><p>估计prior probability for speech absence $q_{f,t}$</p>
</li>
<li><p>计算speech presence probability $p_{f,t}$</p>
<script type="math/tex; mode=display">
\begin{align}
p_{f, t} &= \left \{1 +\frac{q_{f, t}}{1 - q_{f, t}}(1 + \xi_{f, t}) e^{-v_{f, t}} \right \}^{-1} \\
v_{f, t} &= \frac{\gamma_{f, t} \xi_{f, t}}{1 + \xi_{f, t}}
\end{align}</script></li>
<li><p>计算compute spectral gain function $G_{f,t}$</p>
<script type="math/tex; mode=display">
\begin{align}
G_{f, t} &= [G^{H1}_{f,t}]^{p_{f, t}} G_\min ^{1 - p(f, t)} \\
G^{H1}_{f, t} &= \frac{\xi_{f, t}}{1 +\xi_{f, t}} \exp \int^{\infty}_{v_{f,t}} \frac{e^{-t}}{2t} dt
\end{align}</script></li>
</ul>
<p>“Springer Handbook of Speech Processing”中”Spectral Enhancement Methods”一节中，也分别介绍了IMCRA，prior SNR和speech presence probability的估计方法，如果不参考原始论文的话，阅读这部分也完全可以。</p>
<p>OMLSA算法对于瞬时噪声（transient noise）消除能力有限，cohen等人后续还有一系列的工作，比如[2]。对于ASR而言，直接作用OMLSA的效果和masking方法类似，听觉上效果不错，但是一般不能带来WER上的提升，通常以SNR作为衡量指标。下面给出一个sample，直观感受一下OMLSA的去噪效果。</p>
<p><img src="http://www.funcwj.cn/images/omlsa-demo.png" width="500"></p>
<p>此外就是，OMLSA通常应用在single channel场景下，但是可以和beamforming结合，拓展到multi-channel中，比如[2]中的思路：spectral gain function计算涉及的统计量由GSC beamformer的一些中间结果估计得到，最终作用在beamforming output上，相比原始的OMLSA，算法整体的估计细节改动并不大，因此，熟悉这部分的细节对于了解cohen等人的后续工作帮助还是挺大的。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]. Cohen I, Berdugo B. Speech enhancement for non-stationary noise environments[J]. Signal processing, 2001, 81(11): 2403-2418.<br>[2]. Cohen I. Multichannel post-filtering in nonstationary noise environments[J]. IEEE Transactions on Signal Processing, 2004, 52(5): 1149-1160.</p>
]]></content>
      <categories>
        <category>Speech Enhancement</category>
      </categories>
      <tags>
        <tag>Single-channel</tag>
      </tags>
  </entry>
  <entry>
    <title>GWPE - Multi-channel Dereverberation</title>
    <url>/2018/09/20/gwpe-algorithm/</url>
    <content><![CDATA[<p>最近在一批实录的数据上尝试了一下GWPE算法，发现有一定的效果，随之研究了一下原始论文，并在这里对其原理做一下简要介绍。</p>
<p>GWPE算法在提出的时候，对应用的声学环境没有建立一些常见的约束条件，比如speaker数量（原始WPE算法要求single source），noise环境等等，因此在一些复杂条件下的鲁棒性会相对强一些。原论文中将一些随机向量用黑体大写字母表示，实际观测向量用小写字母，在这篇文章中，我统一用后者表示。</p>
<p>从论文题目可以看出，GWPE解决的是MIMO下，impluse response的shorten问题，也可以理解为multi-channel的dereverbration。主要贡献在于使用了一种新的相关性度量作为predict filter估计的代价函数，并导出了对应的估计方法。</p>
<a id="more"></a>
<h3 id="New-Cost-Function"><a href="#New-Cost-Function" class="headerlink" title="New Cost Function"></a>New Cost Function</h3><p>先介绍一下是PE（predict error），$\mathbf{y}_{f,t}$表示$N$路麦克风的观测信号，滤波配置（$\Delta, K, \mathcal{G}_f=\{\boldsymbol{G}_{f,\tau}\}_{\tau = \Delta}^{\Delta + K -1}$）下对$\mathbf{y}_{f,t}$的PE表示为：</p>
<script type="math/tex; mode=display">
\hat{\mathbf{x}_{f,t}} = \mathbf{y}_{f,t} - \sum_{\tau = \Delta}^{\Delta + K - 1} \boldsymbol{G}_{f,t}^H \mathbf{y}_{f,\tau} \tag{1}</script><p>其中第二项</p>
<script type="math/tex; mode=display">
\mathbf{x}_{f,t} = \sum_{\tau = \Delta}^{\Delta + K - 1} \boldsymbol{G}_{f,t}^H \mathbf{y}_{f,\tau}</script><p>称为在该滤波配置下对$\mathbf{y}_{f,t}$的线性预测。$K$表示滤波器阶数，$\Delta$表示延迟，$\boldsymbol{G}_{f,\tau} \in \mathbf{C}^{N \times N}, \mathbf{x}_{f,t}, \mathbf{y}_{f,t} \in \mathbf{C}^{N \times 1}$。</p>
<p>WPE算法中，在PE中引入权重因子作为cost function，GWPE使用新的Hadamard-Fischer mutual correlation作为cost function，定义如下：</p>
<script type="math/tex; mode=display">
C_{HF}(\boldsymbol{U}_1, \dots, \boldsymbol{U}_N) = \frac{1}{N}    \sum_n \log (\det E(\boldsymbol{U}_n\boldsymbol{U}_n^H)) - \log (\det E(\boldsymbol{U}\boldsymbol{U}^H)) \tag{2}</script><p>$\boldsymbol{U}_{1\cdots N}$表示复值随机向量。$C_{HF}$具有非负性，当且仅当$\boldsymbol{U}_{1\cdots N}$两两完全不相关时取0值。</p>
<p>借用$C_{HF}$来衡量在滤波矩阵$\mathcal{G}_f = \{\boldsymbol{G}_{f,\tau}\}_{\tau = \Delta}^{\Delta + K -1}$下线性预测$\mathbf{x}_{f,t} = \sum_{\tau = \Delta}^{\Delta + K - 1} \boldsymbol{G}_{f,t}^H \mathbf{y}_{f,\tau}$的相关性：</p>
<script type="math/tex; mode=display">
\mathcal{J}(\mathcal{G}_f) = \frac{1}{T}\sum_t \log \left( \det E(\mathbf{x}_{f,t}\mathbf{x}_{f,t}^H) \right) - \log (\det E(\boldsymbol{X}_f\boldsymbol{X}_f^H)) \tag{3}</script><p>可以证明，$(3)$式的第二项是一个常数，因此，$\mathcal{J}(\mathcal{G}_f)$可以简化为：</p>
<script type="math/tex; mode=display">
\mathcal{J}(\mathcal{G}_f) = \frac{1}{T}\sum_t \log \left( \det E(\mathbf{x}_{f,t}\mathbf{x}_{f,t}^H) \right) \tag{4}</script><p>上式便是GWPE的cost function。到此为止，MIMO的response shorten问题转化成了：</p>
<script type="math/tex; mode=display">
\mathcal{G}_f = \arg \min_{\mathcal{G}_f} \mathcal{J}(\mathcal{G}_f)</script><p>的优化问题。</p>
<h3 id="Estimate-Filters"><a href="#Estimate-Filters" class="headerlink" title="Estimate Filters"></a>Estimate Filters</h3><p>$(4)$式的最小值没有解析解，因此，需要导出一种稳定的求解方法。论文中给出的辅助函数方法，即构造辅助函数$\mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{L}_f)$，将原始问题分解成两个子问题依次优化：</p>
<script type="math/tex; mode=display">
\mathcal{\hat{L}}_f = \arg \min_{\mathcal{L}_f} \mathcal{\hat{J}}(\mathcal{\hat{G}}_f, \mathcal{L}_f) \tag{5} \\
\mathcal{\hat{G}}_f = \arg \min_{\mathcal{G}_f} \mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{\hat{L}}_f)</script><p>其中$\mathcal{L}_f = \{\boldsymbol{\Lambda}_{f,t} \}_{t = 0}^{T - 1}$。</p>
<p>辅助函数定义为：</p>
<script type="math/tex; mode=display">
\mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{L}_f)  = \frac{1}{T}\sum_t \left( E(\mathbf{x}_{f,t}^H \boldsymbol{\Lambda}_{f,t}^{-1} \mathbf{x}_{f,t}) - N + \log(\det(\boldsymbol{\Lambda}_{f,t})) \right)</script><p>依据性质：</p>
<script type="math/tex; mode=display">
\log \left| \det E(\boldsymbol{U}\boldsymbol{U}^H) \right| \leqslant E(\boldsymbol{U}^H\boldsymbol{\Lambda}^{-1}\boldsymbol{U}) -N + \log(\det \boldsymbol{\Lambda})</script><p>当且仅当$\boldsymbol{\Lambda} = E(\boldsymbol{U}\boldsymbol{U}^H)$时取等号。因此，对于$\mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{L}_f)$：</p>
<script type="math/tex; mode=display">
\mathcal{J}(\mathcal{G}_f) \leqslant \mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{L}_f)</script><p>取得等号时，$(5)$式的解为：</p>
<script type="math/tex; mode=display">
\mathcal{\hat{L}}_f = \{\boldsymbol{\hat{\Lambda}}_{f,t} \}_{t = 0}^{T - 1} = \{E(\mathbf{\hat{x}}_{f,t}\mathbf{\hat{x}}_{f,t}^H)\}_{t=0}^{T-1}</script><p>这一步的核心在于$E(\mathbf{\hat{x}}_{f,t}\mathbf{\hat{x}}_{f,t}^H)$（spatial correlation matrix）的估计，最常见的方法是做time  average：</p>
<script type="math/tex; mode=display">
\boldsymbol{\hat{\Lambda}}_{f,t} = E(\mathbf{\hat{x}}_{f,t}\mathbf{\hat{x}}_{f,t}^H) = \sum_{k=t-\delta}^{t+\delta} = \frac{1}{2\delta+1} \mathbf{\hat{x}}_{f,k}\mathbf{\hat{x}}_{f,k}^H</script><p>论文中也提供了其他四种可选方法，可用于简化计算。</p>
<p>$\mathcal{\hat{G}}_f$的解相推导对麻烦一些，我只说一下计算方法，首先构造$\boldsymbol{\psi}_{f,t}$矩阵：</p>
<script type="math/tex; mode=display">
\boldsymbol{\psi}_{f,t} = [\boldsymbol{Y}_{f,t}^H, \cdots, \boldsymbol{Y}_{f,t-K+1}^H]^T \in \mathbf{C}^{KN^2 \times N}</script><p>其中：</p>
<script type="math/tex; mode=display">
\boldsymbol{Y}_{f,t} = 
\begin{bmatrix}
\mathbf{y}_{f,t} & & \mathbf{o}\\
& \ddots & \\
\mathbf{o} & & \mathbf{y}_{f,t} \\
\end{bmatrix} \in \mathbf{C}^{N^2 \times N}</script><p>其次，计算$\boldsymbol{g}_f = \overline{\boldsymbol{R}_f^{-1}\boldsymbol{r}_f}$，其中：</p>
<script type="math/tex; mode=display">
\begin{align}
\boldsymbol{R}_f &= \sum_t \boldsymbol{\psi}_{f,t - \Delta} \boldsymbol{\hat{\Lambda}}_{f,t} \boldsymbol{\psi}_{f,t - \Delta}^H \in \mathbf{C}^{KN^2 \times KN^2} \\
\boldsymbol{r}_f &= \sum_t \boldsymbol{\psi}_{f,t - \Delta} \boldsymbol{\hat{\Lambda}}_{f,t} \mathbf{y}_{f,t} \in \mathbf{C}^{KN^2 \times 1} 
\end{align}</script><p>$\boldsymbol{g}_f$和$\boldsymbol{G}_{f,\tau}$的对应关系为：</p>
<script type="math/tex; mode=display">
\boldsymbol{g}_l = 
\begin{bmatrix}
\boldsymbol{G}_{f,\Delta,:, 1} \\
\vdots \\
\boldsymbol{G}_{f,\Delta,:, N} \\
\vdots \\
\boldsymbol{G}_{f,\Delta + K - 1,:, N}
\end{bmatrix} \\</script><p>最后reshape一下成为$\mathcal{\hat{G}}_f$的更新值。</p>
<h3 id="Application"><a href="#Application" class="headerlink" title="Application"></a>Application</h3><p>目前GWPE由fgnt开源了一版python的实现（<a href="https://github.com/fgnt/nara_wpe" target="_blank" rel="noopener">https://github.com/fgnt/nara_wpe</a>），效果挺好，可以参考一下实现细节，有空的话，我自己也想实现一版。</p>
<p>GWPE最直接的用处就是multi-channel的dereverbration，如下图（这是4麦的实录数据，混响不是非常严重），对比来看，还是可以比较明显的看出GWPE处理之后的音频扫尾现象少了很多。由于混响对识别任务而言是一个影响较大的因素，因此，在WER上往往可以比较明显的对比出差距。</p>
<p><img src="http://www.funcwj.cn/images/gwpe-demo.png" width="500"></p>
<p>其次就是和前端的一些mask估计，beamforming结合起来用，因为增强/分离/定位这些任务也是混响敏感的，用GWPE做一遍数据预处理通常会有ASR上的增益。fgnt在interspeech2018上有一篇文章[2]专门分析WPE和beamforming的结合，有兴趣的同学可以参考一下。目前我手上的实验也验证了这一点，参考结果如下（WER绝对提升）：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">RAW-CH1</th>
<th style="text-align:center">GWPE-CH1</th>
<th style="text-align:center">DS</th>
<th style="text-align:center">CGMM-MVDR</th>
<th style="text-align:center">GWPE-CGMM-MVDR</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">0%</td>
<td style="text-align:center">2.07%</td>
<td style="text-align:center">1.98%</td>
<td style="text-align:center">3.37%</td>
<td style="text-align:center">4.35%</td>
</tr>
</tbody>
</table>
</div>
<p>可以看出，单独过一遍GWPE就可以获得2%的绝对提升，在CGMM-MVDR基础上，替换输入为GWPE结果之后，可以继续获得一个点的绝对提升。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]. Yoshioka T, Nakatani T. Generalization of multi-channel linear prediction methods for blind MIMO impulse response shortening[J]. IEEE Transactions on Audio, Speech and Language Processing, 2012, 20(10): 2707-2720.<br>[2]. Drude L, Boeddeker C, Heymann J, et al. Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation[J]. Proc. Interspeech 2018, 2018: 3043-3047.</p>
]]></content>
      <categories>
        <category>Microphone Array Processing</category>
      </categories>
      <tags>
        <tag>Multi-channel</tag>
        <tag>WPE</tag>
        <tag>Dereverberation</tag>
      </tags>
  </entry>
  <entry>
    <title>Analysis/Synthesis window of STFT</title>
    <url>/2018/08/13/stft-problem/</url>
    <content><![CDATA[<p>这里提一个(i)STFT的细节。做短时傅里叶分析的时候，通常会选取窗函数，缓解频谱泄露。把频域的谱通过OLA（overlap add）转换到时域上时，我以前的做法是选取相同的窗函数。这么做会带来一个问题，如果直接把OLA的结果写入磁盘，特别容易出现clipping，所以我通常会在OLA之后对samples做一个renorm/rescale操作，避免数值超出wav的采样单元，但是这么一做，往往就丢失了原先音频的能量信息。理想情况下，在频域不做任何处理，变换到时域，应该存在条件，使得时域结果完美重构的。</p>
<p>后来逐渐的在一些文献中看到了一些资料。发现这个窗函数的选取，不是那么随意，要想达到最佳重构，正逆过程的窗需要满足一个约束条件，有些文献中也称为双正交。正过程的窗称为分析（analysis）窗，逆过程的窗（synthesis）称为合成窗。下面导出这个约束条件。</p>
<a id="more"></a>
<p>令$t$表示帧索引，$S$表示帧移，$w, v$分别表示analysis和synthesis window。$s, \hat{s}$表示原始信号和合成信号。</p>
<p>基于以上定义，分帧过程可以表示为：</p>
<script type="math/tex; mode=display">
x_t(n) = w(n) s(n + tS) \tag{1}</script><p>OLA过程表示为：</p>
<script type="math/tex; mode=display">
\hat{s}(n) = \sum_t v(n - tS) x_t(n - tS) \tag{2}</script><p>将式$(1)$重写为：</p>
<script type="math/tex; mode=display">
x_t(n - tS) = w(n - tS) s(n)</script><p>带入$(2)$式</p>
<script type="math/tex; mode=display">
\begin{align}
\hat{s}(n) & = \sum_t v(n - tS) w(n - tS) s(n) \\
 & =  s(n) \sum_t v(n - tS) w(n - tS)
\end{align}</script><p>因此达到完美重构条件（完全相等），analysis和synthesis窗需要满足条件</p>
<script type="math/tex; mode=display">
\sum_t v(n - tS) w(n - tS) = 1 \tag{3}</script><p>此式即为所谓的双正交约束。</p>
<p>另外在做短时傅里叶分析的时候，主流工具喜欢对wave进行padding，以期望达到更好的重构效果，这里这么理解，如果不进行padding的话，第一帧和最后一帧必然存在某些samples，无法通过叠加得到（即仅仅只做了加窗），因此，这些点难以达到完美重构条件，padding的目的是对这些点位置进行shift，尽可能的使它们可能达到完美重构条件（这里理解未必正确，看官需小心）。</p>
<p>其次，librosa和fgnt的实现版本也不完全一样，前者是对合成的samples最后做了normalize，后者则是根据analysis窗，构建synthesis窗，之后进行OLA，我参考后者，在kaldi-enhan上的实现如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ShortTimeFTComputer::CacheSynthesisWindow</span><span class="params">(<span class="keyword">const</span> ShortTimeFTOptions &amp;opts)</span> </span>&#123;</span><br><span class="line">    int32 window_size = opts_.frame_length;</span><br><span class="line"></span><br><span class="line">    Vector&lt;BaseFloat&gt; analysis_window_square(analysis_window_), denominator(window_size);</span><br><span class="line">    analysis_window_square.ApplyPow(<span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    int32 <span class="built_in">width</span> = <span class="keyword">static_cast</span>&lt;int32&gt;((window_size - <span class="number">1</span>) / opts_.frame_shift), s;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (int32 i = -<span class="built_in">width</span>; i &lt;= <span class="built_in">width</span>; i++) &#123;</span><br><span class="line">        s = i * opts_.frame_shift;</span><br><span class="line">        <span class="keyword">if</span> (s &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// [0: end - s] += [-s: end]</span></span><br><span class="line">            denominator.Range(<span class="number">0</span>, window_size + s).AddVec(<span class="number">1</span>, analysis_window_square.Range(-s, window_size + s));</span><br><span class="line">        &#125; <span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="comment">// [s: end] += [0: end - s]</span></span><br><span class="line">            denominator.Range(s, window_size - s).AddVec(<span class="number">1</span>, analysis_window_square.Range(<span class="number">0</span>, window_size - s));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    synthesis_window_.DivElements(denominator);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>关于这里提的问题，在”Springer Handbook of Speech Processing”的12.1节 The Short-Time Fourier Transform中有详细论述，想要继续深入的可以做一下参考。</p>
]]></content>
      <categories>
        <category>Speech Separation</category>
      </categories>
      <tags>
        <tag>STFT</tag>
      </tags>
  </entry>
  <entry>
    <title>From Quasi-recurrent Networks</title>
    <url>/2018/08/02/qrnn-sru/</url>
    <content><![CDATA[<p>最近听说上交提了一个SRNN，相比普通RNN的效率提升100+倍，这让想起了去年的QRNN[1]和SRU[2]，借这篇文章说一下关于RNN的长期依赖和计算效率的问题。</p>
<p>RNN的效率瓶颈在于时间轴上state的传递依赖，借鉴现在大部分DL框架api的设计，可以用下式表示：</p>
<script type="math/tex; mode=display">
\mathbf{y}_t, \mathbf{h}_t = \mathcal{C}(\mathbf{x}_{t - 1}, \mathbf{h}_{t - 1})</script><p>$\mathcal{C}$可以用于表示LSTM，GRU这类cell逻辑。如果具体展开的话，和$x$相关的计算，在每个时间步上没有依赖，因此可以一次计算完毕（即form成矩阵的形式），涉及到$h$相关的计算时，因为$h_{t}$需要等待$h_{t-1}$，因此，整个序列上的$h$推断过程需要串行进行（step by step）。QRNN这类方案的出发点都是对$h$的计算进行局部的依赖解除（但是不能完全解除，否则就不是传统意义上的循环结构了，因此必然存在recurrent逻辑），从而加速inference过程。<br><a id="more"></a></p>
<p>LSTM结构中，每一个门状态的计算都需要依赖$h_{t - 1}$，导致门状态计算时$h_{t - 1}$相关的矩阵运算必须串行进行。QRNN将门状态的计算化简为仅仅对当前输入依赖，即$x_{[t - k + 1 \cdots t]}$，$k$是可配置参数，论文中称为filter width，理解为门输入的context就行，在QRNN的开源实现（<a href="https://github.com/salesforce/pytorch-qrnn" target="_blank" rel="noopener">pytorch-qrnn</a>）中，$k$只支持1和2，用$\mathbf{g}_t$表示门$g$（$g = {z, f, o}$）在$t$时刻的状态值，$\sigma$表示对应的激活函数，那么门状态的计算统一可以用下式表示：</p>
<script type="math/tex; mode=display">
\mathbf{g}_t = \sigma(\mathbf{W}_g * \mathbf{x}_{[t - k +1 \cdots t]}) \tag{1}</script><p>不像LSTM那样存在对$h$的依赖，因此，可以一次计算出所有时刻的门状态值$\mathbf{G}$：</p>
<script type="math/tex; mode=display">
\mathbf{G} = \sigma(\mathbf{W}_g * \mathbf{X}_s) \tag{2}</script><p>$\mathbf{X}_s$表示根据$k$拼帧的结果。需要注意的是，实现的时候，$*$用一个线性层就行了，并没有像论文中所说的卷积操作。</p>
<p>以上是QRNN的parallel部分，不可缺少的recurrent部分，QRNN中称为“dynamic average pooling”，描述cell之间的依赖关系，这部分和LSTM &amp; GRU很像，以fo-pooling为例：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{c}_t &= \mathbf{f}_t \odot \mathbf{c}_{t - 1} + (1 - \mathbf{f}_t) \odot \mathbf{z}_{t - 1} \\
\mathbf{h}_t  &= \mathbf{o}_t \odot \mathbf{c}_t
\end{aligned}</script><p>这部分的计算量集中在Hadamard Product（逐元素相乘）上，相比原始RNN/LSTM中的矩阵乘法，加上在CUDA上的优化，recurrent部分的计算效率得到了极大的提升。</p>
<p>总结一下QRNN的设计思路，将门状态的计算独立到循环逻辑之外，仅仅保留cell的循环依赖，宏观上就是高计算量的部分parallel进行，小计算量的部分串行计算。这时候再看论文中的QRNN的Block diagrams就很容易体会其中的思想了：</p>
<p><img src="http://www.funcwj.cn/images/QRNN.png", width="300"></p>
<p>红色区域表示$(2)$式的计算，一次将门状态计算完毕，之后用”dynamic average pooling“层计算recurrent依赖。</p>
<p>SRU和QRNN中$k = 1$的结构十分相似，思路上也都是解除门状态的依赖关系。不添加highway的情况下只设置一个forget门，网络结构写成：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\hat{\mathbf{x}_t} &= \mathbf{W}_x \mathbf{x}_t \\
 \mathbf{f}_t  &= \sigma(\mathbf{W}_f \mathbf{x}_t  + \mathbf{b}_f) \\
 \mathbf{c}_t &= \mathbf{f}_t \odot \mathbf{c}_{t - 1} + (1 - \mathbf{f}_t) \odot \hat{\mathbf{x}_t}  \\
 \mathbf{h}_t  &= g(\mathbf{c}_t)
 \end{aligned}</script><p>可以看出$\mathbf{f}_t$的计算逻辑也是基于当前输入的一个线性层激活层。</p>
<p><a href="https://arxiv.org/abs/1807.02291" target="_blank" rel="noopener">SRNN</a>（Spliced Recurrent Neural Networks）的逻辑是把长序列划分成若干的等长的子序列，再将每个子序列的最后一个状态视为新的序列进行划分，直到新形成的序列长度不能被继续划分为子序列为止。循环过程在每个子序列中进行，并用每个子序列的最后一个状态值初始化父序列的state。由于同一层的每个子序列之间被强制分割，断开了时间上的依赖性，因此可以并行计算状态值。</p>
<p>根据论文中的结论，如果处理的序列足够长，SRNN的效率提升是惊人的。 当然是否所有任务都满足训练序列越长越好，还需要具体的实验对比。在ASR任务中，我本人并不倾向于选择过长的序列进行训练。</p>
<p>最后我再说一下TDNN[4]和FSMN[5]，这是很早以前我就想写一点的东西。这两种结构在ASR中被广泛应用，对识别率的提升做出了巨大的贡献。由于本质上他们是前馈结构，因此，在训练和推断的效率上相比RNN具有巨大的优势，对于ASR这种在实际应用中对实时要求较高的任务上，这一点就显得尤为重要。</p>
<p>TDNN(Time Delay)的历史十分久远[1]，近年来JHU那边主推，并在kaldi的nnet2/3上做了实现，得到了大规模的尝试和应用。它的思想用四个词来表述就行，即层间拼帧。一般的DNN结构，如果要增加输入信息量，只在输入层做拼帧，但是通常不会拼帧过多，否则会导致输入层参数量过大，因此限制了网络的输入信息量。如果同时允许隐层拼帧，那么在多层叠加的情况下，网络输入的context就可以得到扩展，同时也可以保证每一层的参数量不会十分巨大，如果画出整个TDNN的依赖关系图，会得到一种类似金字塔的结构，如下：</p>
<p><img src="http://www.funcwj.cn/images/tdnn-demo.png", width="500"></p>
<p>以上图为例，输出$t$时刻的后验，输入的context为$[-13, +9]$。</p>
<p>实际熟悉kaldi的人也知道，tdnn层实际配置的时候当成对线性层的一种扩展，添加了拼帧选项而已，可以放在任意网络结构中间，CNN和LSTM等。同时拼帧允许sub-sampling，以上图的layer 2为例子，context为$[-1, +2]$，相比$[-1,0,+1,+2]$，减少了隐层的参数量的同时保证了网络的context。</p>
<p>FSMN的思想来源于信号处理中，一个无限冲击响应可以用高阶的有限冲击响应来近似。它的隐层输入来源于两部分，一部分来自上层的输入，另一部分来自一个称为memory block的结构，写为：</p>
<script type="math/tex; mode=display">
\mathbf{h}_t^{\ell + 1} = f(\mathbf{W}^\ell \mathbf{h}_t^\ell + \mathbf{\tilde{W}}^\ell \mathbf{\tilde{h}}_t^\ell + \mathbf{b}^{\ell})</script><p>其中$ \mathbf{\tilde{h}}_t^\ell$表示$\ell$层的memory block，有两种计算方式：</p>
<script type="math/tex; mode=display">
\mathbf{\tilde{h}}_t^\ell = \sum_{c = -M}^N \alpha_{c + M} \mathbf{h}_{t + c}^\ell \tag{3} \\</script><p>被称为sFSMN（scalar encoding FSMN）以及</p>
<script type="math/tex; mode=display">
\mathbf{\tilde{h}}_t^\ell = \sum_{c = -M}^N \mathbf{c}_{c + M} \odot \mathbf{h}_{t + c}^\ell \tag{4}</script><p>称为vFSMN（vector encoding FSMN）。$N &gt; 0$时，类似于双向RNN的逻辑。从$(3,4)$式可以看出，memory block强制存储下了若干时刻的记忆块，并用于当前时刻的输入，记忆长度以当前时刻为参考为$M + N$。由于最终的输入是记忆块加权和的形式，因此，FSMN的隐层维度同样不会过大。用信号流图来表示因果系统下memory block的计算如下：</p>
<p><img src="http://www.funcwj.cn/images/fsmn.jpg", width="400"></p>
<p>FSMN后续还有相关实验，包括deep FSMN和compact FSMN等等，有兴趣的读者可以参阅一下下面的参考文献。</p>
<blockquote>
<p>[1]. Zhang S, Jiang H, Xiong S, et al. Compact Feedforward Sequential Memory Networks for Large Vocabulary Continuous Speech Recognition[C]//INTERSPEECH. 2016: 3389-3393. </p>
<p>[2]. Zhang S, Lei M, Yan Z, et al. Deep-FSMN for Large Vocabulary Continuous Speech Recognition[J]. arXiv preprint arXiv:1803.05030, 2018. </p>
</blockquote>
<p>最后总结一下，RNN的耗时来自时间轴上的展开过程，原始的LSTM和GRU，门状态的计算存在时间上的依赖，矩阵乘法无法并行。QRNN和SRU的思路都是将门状态的依赖关系解除，放到循环外解决，只保留cell state的时间依赖。FSMN和TDNN虽然是前馈结构，但是通过结构上的设计，强制网络获得额外的context信息，相比RNN在效率上具有很大优势，相比传统的DNN/CNN更加适用于long context建模，在ASR任务上均取得了巨大的成功，其中阿里的线上模型已经由LC-BLSTM替换为FSMN，充分体现了其在ASR和工业界的价值。</p>
<p>参考文献：</p>
<p>[1]. Bradbury J, Merity S, Xiong C, et al. Quasi-recurrent neural networks[J]. arXiv preprint arXiv:1611.01576, 2016.<br>[2]. Lei T, Zhang Y. Training rnns as fast as cnns[J]. arXiv preprint arXiv:1709.02755, 2017.<br>[3]. Waibel A, Hanazawa T, Hinton G, et al. Phoneme recognition using time-delay neural networks[M]//Readings in speech recognition. 1990: 393-404.<br>[4]. Peddinti V, Povey D, Khudanpur S. A time delay neural network architecture for efficient modeling of long temporal contexts[C]//Sixteenth Annual Conference of the International Speech Communication Association. 2015.<br>[5]. Zhang S, Liu C, Jiang H, et al. Feedforward sequential memory networks: A new structure to learn long-term dependency[J]. arXiv preprint arXiv:1512.08301, 2015. </p>
]]></content>
      <categories>
        <category>DL</category>
      </categories>
      <tags>
        <tag>RNN</tag>
        <tag>TDNN</tag>
      </tags>
  </entry>
  <entry>
    <title>Introduction to Wiener Filter</title>
    <url>/2018/07/08/simple-wiener-filter/</url>
    <content><![CDATA[<p>维纳滤波信号领域最基本，最常见的滤波方法之一，陈老师的麦克风阵列处理一书中首先介绍的就是维纳滤波。本篇文章中我简单的介绍一下维纳滤波。</p>
<p>因为是从ASR看到前端来的，因此，对维纳滤波的理解做不到十分深入。在我看来，维纳滤波的典型特征是MMSE准则，由此就带来一个困惑，没有参考信号或者目标信号，如何做均方误差最小化。换句话说，很多时候，如果已经知道参考信号了，那何须继续滤波呢……</p>
<a id="more"></a>
<p>后来我突然想到手机上大部分人容易忽略的一个器件，辅助降噪麦克风（就是那个小圆圈），才对这个疑惑有了解释，在使用维纳滤波的系统中，多少是存在办法获取参考信号的，辅助降噪麦克风的功能不出意外的话，就是采集环境噪声，给系统提供参考信号的统计量。有时间我觉得有必要研究一下webrt中的维纳滤波算法，听说是目前效果最好的实现。</p>
<p>针对单通道的denoise任务，时域上MSE准则写成：</p>
<script type="math/tex; mode=display">
\mathcal{J}(\mathbf{h}) = E\left[\left(z(k) - \mathbf{h}^\top\mathbf{y}(k)\right)^2\right]  \tag{1}</script><p>其中：</p>
<script type="math/tex; mode=display">
\mathbf{y}(k) = [y(k), y(k -1), \cdots, y(k - L + 1)]</script><p>$\mathbf{h}$表示要估计的滤波器系数（有限冲击响应，FIR），$L$表示$\mathbf{h}$的阶数。</p>
<p>解目标函数$(1)$可以得到解析解：</p>
<script type="math/tex; mode=display">
\mathbf{h}_W = \arg \min_{\mathbf{h}} \mathcal{J}(\mathbf{h}) = \mathbf{R}_{yy}^{-1} \mathbf{r}_{yx}</script><p>其中$\mathbf{R}_{yy}$表示观测信号的相关矩阵：</p>
<script type="math/tex; mode=display">
\mathbf{R}_{yy} = E[\mathbf{y}(k)\mathbf{y}(k)^T ]</script><p>$\mathbf{r}_{yx}$表示期望信号和观测信号的协相关矩阵：</p>
<script type="math/tex; mode=display">
\mathbf{r}_{yx} = E[\mathbf{y}(k) x(k)]</script><p>在噪声和期望信号相互独立的假设下，$\mathbf{r}_{yx} $可以写成：</p>
<script type="math/tex; mode=display">
\mathbf{r}_{yx} = \mathbf{r}_{yy}  - \mathbf{r}_{vv} = E[\mathbf{y}(k) y(k)] - E[\mathbf{v}(k) v(k)] \tag{2}</script><p>以降噪麦克风为例，可以获取参考噪声，因此估计$\mathbf{r}_{vv}$十分方便。如果要直接计算$\mathbf{r}_{yx}$，就要得到目标信号参考，这个难度显然要大很多，因此，多用$(2)$式间接计算。在我后面的实验中，取起始的一段噪声信号计算$\mathbf{r}_{vv}$，$\mathbf{r}_{yy}, \mathbf{R}_{yy}$根据观测信号均可直接算出。</p>
<p>下面用一个toy简单验证一下，噪声类型为白噪声</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">wav = <span class="string">'wav/egs1.wav'</span>;</span><br><span class="line">snr = <span class="number">1</span>;</span><br><span class="line">filter_size = <span class="number">512</span>;</span><br><span class="line">warm_up = <span class="number">51200</span>;</span><br><span class="line"></span><br><span class="line">speech = audioread(wav);</span><br><span class="line">M = norm(speech, <span class="built_in">inf</span>);</span><br><span class="line"><span class="comment">% modify matlab's awgn</span></span><br><span class="line">[noisy, noise] = my_awgn(speech, snr, <span class="string">'measured'</span>);</span><br><span class="line">T = <span class="built_in">length</span>(noisy);</span><br><span class="line"></span><br><span class="line">warm_up = <span class="built_in">min</span>(warm_up, T);</span><br><span class="line">fprintf(<span class="string">"using first %d samples to estimate rvv, totally %d samples...\n"</span>, warm_up, T);</span><br><span class="line"></span><br><span class="line">padding = <span class="built_in">zeros</span>(<span class="number">1</span>, filter_size - <span class="number">1</span>);</span><br><span class="line">Y = <span class="built_in">toeplitz</span>([noisy' padding], [noisy(<span class="number">1</span>), padding]);</span><br><span class="line">V = <span class="built_in">toeplitz</span>([noise' padding], [noise(<span class="number">1</span>), padding]);</span><br><span class="line"></span><br><span class="line">Ryy = Y' * Y / T;</span><br><span class="line"></span><br><span class="line">ryy = <span class="built_in">mean</span>(Y(<span class="number">1</span>: T, :) .* noisy, <span class="number">1</span>);</span><br><span class="line">rvv = <span class="built_in">mean</span>(V(<span class="number">1</span>: warm_up, :) .* noise(<span class="number">1</span>: warm_up), <span class="number">1</span>);</span><br><span class="line">ryx = ryy - rvv;</span><br><span class="line"></span><br><span class="line">Hw = Ryy \ ryx';</span><br><span class="line"></span><br><span class="line">denoise = Y * Hw;</span><br><span class="line">denoise = denoise(<span class="number">1</span>: T, :);</span><br><span class="line"></span><br><span class="line">subplot(<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line"><span class="built_in">plot</span>(speech);title(<span class="string">"Clean Speech"</span>);</span><br><span class="line">xlim([<span class="number">1</span>, T]); ylim([<span class="number">-1</span>, <span class="number">1</span>]);</span><br><span class="line">subplot(<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>);</span><br><span class="line"><span class="built_in">plot</span>(noisy / norm(noisy, <span class="built_in">inf</span>) * M);title(<span class="string">"Noisy Speech"</span>);</span><br><span class="line">xlim([<span class="number">1</span>, T]); ylim([<span class="number">-1</span>, <span class="number">1</span>]);</span><br><span class="line">subplot(<span class="number">3</span>, <span class="number">1</span>, <span class="number">3</span>);</span><br><span class="line"><span class="built_in">plot</span>(denoise / norm(denoise, <span class="built_in">inf</span>) * M);title(<span class="string">"Wiener Denoised Speech"</span>);</span><br><span class="line">xlim([<span class="number">1</span>, T]); ylim([<span class="number">-1</span>, <span class="number">1</span>]);</span><br></pre></td></tr></table></figure>
<p>测试的时候其实发现denoise效果一般（如果上面的toy实现没有什么大问题的话）。下面给出一个$\text{SNR}=2$的例子（还是可以看出噪声部分得到了部分削弱）。</p>
<p><img src="http://www.funcwj.cn/images/wiener-demo-1.jpg" alt=""></p>
]]></content>
      <categories>
        <category>Speech Enhancement</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Wiener</tag>
      </tags>
  </entry>
  <entry>
    <title>Speech Separation - DPCL &amp; uPIT</title>
    <url>/2018/07/02/nn-speech-separation/</url>
    <content><![CDATA[<p>上个月做了一下single-channel下supervised语音分离的两种比较经典的方法，DPCL和uPIT，略有感触。在这篇文章中，我结合我的实践和理解，对它们做一些简单介绍。</p>
<p>首先我再次用自己的语言介绍一遍mask，因为前几天突然有非语音相关的人突然问mask相关的概念。单通道的增强或者分离任务中的mask实际全称应该是TF-mask（TF表示time and frequency），定义在T-F域上。TF-mask被定义的前提通常是信号仅仅为加性混叠（分离任务，混叠信号为说话人，增强任务，混叠信号为语音和加性噪声），因此广泛应用于分离，增强，而非解混响等任务中。不做区分，定义混叠信号如下：</p>
<script type="math/tex; mode=display">
\mathbf{x} = \mathbf{s}_1 + \mathbf{s}_2 + \cdots \mathbf{s}_N + \mathbf{n}</script><a id="more"></a>
<p>其中$\mathbf{s}_i$表示第$i$个说话人，$\mathbf{n}$表示加性噪声。变换到短时频域上：</p>
<script type="math/tex; mode=display">
\mathbf{X} = \mathbf{S}_1 + \mathbf{S}_2 + \cdots \mathbf{S}_N + \mathbf{N} \tag{1}</script><p>其中$\mathbf{S}_i = \text{STFT}(\mathbf{s}_i), \mathbf{N} = \text{STFT}(\mathbf{n}) \in \mathbf{C}^{T \times F}$。</p>
<blockquote>
<p>注：$\text{STFT}$表示短时傅里叶变换，其实这里面讲究的东西还是蛮多的，由于我也不确认我的每处理解都十分准确，因此这里不做仔细挖掘。但是有几个概念需要说明一下：</p>
<p>短时傅里叶变换之后的结果$\mathbf{S}$在复数域，我们将$|\mathbf{S}|$称为幅度谱（Magnitude Spectrum），$|\mathbf{S}|^2$称为功率谱（Power Spectrum），$\angle \mathbf{S}$称为相位谱。</p>
</blockquote>
<p>使用mask的初衷是，希望通过TF-mask $\mathbf{M}_i$，最大程度还原出希望的语音信号$\mathbf{s}_i$。使用mask还原出的语音信号定义为（在“语音增强mask方法”中我也提到了）：</p>
<script type="math/tex; mode=display">
\mathbf{s}'_i = \text{iSTFT}(\mathbf{X} \odot \mathbf{M}_i) \tag{2}</script><p>得到还原的信号之后，根据不同的任务，就可以使用SNR，SDR或者WER来衡量质量高低了，一般在分离中使用SDR（signal distortion rate）指标。</p>
<p>目前常用的mask种类有IBM（binary mask），IAM（amplitude mask），IRM（ratio mask），PSM（phase sensitive mask），定义如下：</p>
<ul>
<li><p>IBM：</p>
<script type="math/tex; mode=display">
\mathbf{M}_{\text{IBM}}^i = \left(\bigwedge_{n \ne i}^{N} |\mathbf{S}_i | > |\mathbf{S}_n|\right) \wedge \left(|\mathbf{S}_i | > |\mathbf{N}|\right)</script></li>
<li><p>IAM：</p>
<script type="math/tex; mode=display">
\mathbf{M}_{\text{IAM}}^i = \frac{|\mathbf{S}_i|}{|\mathbf{X}|} = \frac{|\mathbf{S}_i|}{|\sum_i \mathbf{X}_i + \mathbf{N}|}</script></li>
<li><p>IRM：</p>
<script type="math/tex; mode=display">
\mathbf{M}_{\text{IRM}}^i = \frac{|\mathbf{S}_i|}{\sum_{i = 1}^N|\mathbf{S}_i| + |\mathbf{N}|}</script></li>
<li><p>PSM：</p>
<script type="math/tex; mode=display">
\mathbf{M}_{\text{IAM}}^i = \frac{|\mathbf{S}_i| \cos(\angle \mathbf{X} - \angle \mathbf{S}_i )}{|\mathbf{X}|}</script></li>
</ul>
<p>其中，$ \mathbf{M}_{\text{IBM}}^i \in {0, 1}，\mathbf{M}_{\text{IRM}}^i \in [0, 1]$，范围均被限定，PSM可能出现负值。</p>
<p>关于IAM和IRM再多提几点：</p>
<ol>
<li><p>IAM在汪老师的论文里面又被称为SMM（spectral magnitude mask）和FFT-mask，和IRM的关系可以表示为：</p>
<script type="math/tex; mode=display">
\mathbf{M}_{\text{iam}} \geqslant \mathbf{M}_{\text{irm}}</script><p>很多论文采用的loss函数表达为下面形式的：</p>
<script type="math/tex; mode=display">
\mathcal{L} = \Vert \mathbf{M} \odot |\mathbf{Y}| - |\mathbf{X}|\Vert_F^2</script><p>可以等价为IAM为target。</p>
</li>
<li><p>IRM的定义式在俞栋老师和汪老师的论文中略有不同，上面给出的是俞栋老师uPIT论文中的表达式，汪老师的定义如下：</p>
<script type="math/tex; mode=display">
\mathbf{M}_{\text{irm}}^\text{Wang} = \frac{|\mathbf{S}_i|}{\left(\sum_{i = 1}^N|\mathbf{S}_i|^2 + |\mathbf{N}|^2 \right)^{0.5}}</script><p>两者之间的关系为：</p>
<script type="math/tex; mode=display">
\mathbf{M}_{\text{irm}}^\text{Wang} \geqslant \mathbf{M}_{\text{irm}}^\text{Yu}</script><p>汪老师的综述详见：</p>
<blockquote>
<ol>
<li>Wang D L, Chen J. Supervised Speech Separation Based on Deep Learning: An Overview[J]. IEEE/ACM Transactions on Audio Speech &amp; Language Processing, 2018, PP(99):1-1.</li>
</ol>
</blockquote>
</li>
</ol>
<p>在wsj0-mix2数据集上，上面四种mask oracle的分离效果如下（SDR）</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Mask</th>
<th style="text-align:center">FM</th>
<th style="text-align:center">FF</th>
<th style="text-align:center">MM</th>
<th style="text-align:center">FF/MM</th>
<th style="text-align:center">AVG</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">IAM</td>
<td style="text-align:center">12.49</td>
<td style="text-align:center">12.73</td>
<td style="text-align:center">11.58</td>
<td style="text-align:center">11.88</td>
<td style="text-align:center">12.19</td>
</tr>
<tr>
<td style="text-align:center">IBM</td>
<td style="text-align:center">12.94</td>
<td style="text-align:center">13.20</td>
<td style="text-align:center">12.04</td>
<td style="text-align:center">12.35</td>
<td style="text-align:center">12.65</td>
</tr>
<tr>
<td style="text-align:center">IRM</td>
<td style="text-align:center">12.86</td>
<td style="text-align:center">13.14</td>
<td style="text-align:center">11.96</td>
<td style="text-align:center">12.27</td>
<td style="text-align:center">12.57</td>
</tr>
<tr>
<td style="text-align:center">PSM</td>
<td style="text-align:center">15.79</td>
<td style="text-align:center">16.03</td>
<td style="text-align:center">14.90</td>
<td style="text-align:center">15.20</td>
<td style="text-align:center">15.50</td>
</tr>
</tbody>
</table>
</div>
<p>可以看出，oracle的情况下，PSM的优势确实很明显。</p>
<h3 id="Label-Permutation"><a href="#Label-Permutation" class="headerlink" title="Label Permutation"></a>Label Permutation</h3><p>label的置换问题是使用监督性学习解决说话人无关的语音分离问题首先要解决的问题。在增强任务中，我们只需要学习到speech的mask，而分离任务中，则需要学习到多个说话人的mask，由此引入了训练过程中的label置换问题。</p>
<p>置换问题怎么理解？假设网络结构存在两个线性层输出$\mathbf{m}_1$和$\mathbf{m}_2$，对应的label为$s_1, s_2$。这样就存在两种匹配方式，即$\mathbf{m}_1 \to s_1, \mathbf{m}_2 \to s_2$和$\mathbf{m}_1 \to s_2, \mathbf{m}_2 \to s_1$。由此拓展下去，$N$个说话人存在$N!$种对应方式。传统的训练方法，输出和label之间的对应关系是固定的，以增强网络为例，一个对应speech，另一个对应noise，网络收敛之后，label对应speech的输出speech的mask，对应noise的输出noise的mask。在分离任务中，训练语料存在多个说话人（多余网络输出个数），因此，不可能将网络的输出和确定的说话人对应起来，故而无法组织训练。</p>
<p>相关理解可以参考<a href="https://www.zhihu.com/question/268773643/answer/414532531" target="_blank" rel="noopener">如何理解语音分离中的置换问题（permutaiton problem）</a></p>
<p>DPCL和uPIT就是从两个角度入手解决label的置换问题的。</p>
<h3 id="DPCL"><a href="#DPCL" class="headerlink" title="DPCL"></a>DPCL</h3><p>Deep Clustering没有正面和label permutation硬怼，而是绕过了这个问题，尝试将每个TF-bin映射到一个高维的特征上，使得其可以更好的被区分开来。这个embedding过程表示为：</p>
<script type="math/tex; mode=display">
\mathbf{X}_{tf} \to \mathbf{v}_{tf} \in \mathbf{R}^{D \times 1} \tag{3}</script><p>得到embedding $\mathbf{v}_{tf}$之后，接一个分类算法，将类别转换为binary mask就可以根据$(2)$进行分离了。在oracle的情况下，将speaker的IBM one-hot编码的分类结果和IBM可以相互转换。</p>
<p>$(3)$式是对单个TF-bin进行的embedding，实际训练中输入以帧为单位，因此，进行的实际上是</p>
<script type="math/tex; mode=display">
\mathbf{X}_{t\cdot} \to \mathbf{Y}_{t\cdot} \in \mathbf{R}^{DF \times 1}</script><p>的过程。</p>
<p>DPCL的loss function通过亲和性矩阵$\mathbf{A}^\top\mathbf{A}, \mathbf{A} \in \mathbf{R}^{D \times T}$定义，$\mathbf{A}$的列向量表示embedding，$(\mathbf{A}^\top\mathbf{A})_{ij} = 1$表示embedding $\mathbf{A}^\top_i$和$\mathbf{A}^\top_j$属于一个类别。</p>
<p>令$\mathbf{V} \in \mathbf{R}^{S \times F}$表示IBM的one-hot编码结果，$\mathbf{Y} \in \mathbf{R}^{D \times F}$表示DPCL输出embedding。loss function用两种embedding亲和性矩阵之差的F范数表示：</p>
<script type="math/tex; mode=display">
\mathcal{J} = \Vert \mathbf{Y}^\top\mathbf{Y} - \mathbf{V}^\top\mathbf{V}\Vert_F^2</script><p>在具体实现的时候，以整句训练为例，$\mathbf{Y} \in \mathbf{R}^{D \times FT}$。这样$ \mathbf{Y}^\top\mathbf{Y} \in \mathbf{R}^{FT \times FT}$，显存很快就爆掉，可以采用等价计算方式：</p>
<script type="math/tex; mode=display">
\mathcal{J} = \Vert \mathbf{Y}\mathbf{Y}^\top \Vert_F^2 + \Vert \mathbf{V}\mathbf{V}^\top \Vert_F^2 - 2\Vert \mathbf{V}\mathbf{Y}^\top \Vert_F^2 \tag{4}</script><p>进行。</p>
<p>下面提几个比较细节的地方：</p>
<ol>
<li>计算$(4)$式的时候，原始论文应该是mask掉了silence的T-F bin，因此，注意计算的时候掩蔽掉silence部分。是否silence取决于每个TF bin的能量值，论文中将每个句子比最大能量值小40dB的bin认为成silence。</li>
<li>DPCL收敛的loss比较大，我收敛结果是3700+每个TF-bin，参考一下。</li>
<li>训练和测试时候的特征一定要保证一致（是否log，是否cmvn等等），我开始时训练的cmvn代码逻辑有问题，测试时分离效果总是高低频对半分，查了一周多才找到问题所在……</li>
<li>测试时聚类的时候，最好也将silence部分掩蔽掉，提高聚类的效果。</li>
</ol>
<p>整个实验下来，主要是上面的3耗了一点时间，其他过程均比较顺利。代码和结果可以参看<a href="https://github.com/funcwj/deep-clustering" target="_blank" rel="noopener">deep-clustering</a>。</p>
<p>DPCL这块我没有调过多的配置，目前存在的问题是batch训练的时候，效果会比逐句训练差不少（average SDR-impr 只能在8.5这样子），后面有空还要check一下问题所在。</p>
<h3 id="Utterance-Level-PIT"><a href="#Utterance-Level-PIT" class="headerlink" title="Utterance Level PIT"></a>Utterance Level PIT</h3><p>PIT采取的方案就硬怼，既然pair方式有$N!$种，那就直接遍历一遍，把最小的当loss，强制让网络学习align过程和对应的mask。它最早提出的时候，loss定义在帧级别（frame level），但是因为不能保证不同时刻网络的mask和speaker的对应关系保持一致，因此需要加一个speaker tracking的后处理过程（本身论文并没有提出speaker tracking的算法，直接和target比算的oracle结果）。uPIT的u表示utterance level，loss定义在整个句子上，用RNN建模：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathcal{J}_{\text{psm}} & = \arg \min_{\phi \in \mathcal{P}} \sum_s \left \Vert \mathbf{M}_s \odot |\mathbf{X}_s| - |\mathbf{X}_{\phi(s)} | \odot \cos \left( \angle \mathbf{X}_s - \angle \mathbf{X}_{\phi(s)} \right) \right \Vert_F^2 \\
\mathcal{J}_{\text{iam}} & = \arg \min_{\phi \in \mathcal{P}} \sum_s \left \Vert \mathbf{M}_s \odot |\mathbf{X}_s| - |\mathbf{X}_{\phi(s)} | \right \Vert_F^2
\end{aligned}</script><p>$\mathcal{P}$表示$S$个speaker的排列方案。把上述定义成为permutate loss。</p>
<p>uPIT遇到的坑主要是batch情况下，permutate loss的计算。如果N个句子同时训练，permutate loss是每个句子的permutate loss之和。我第一次实现写成了batch的permutate loss，训练不收敛。除此之外，其他过程也都顺风顺水。代码可以参见<a href="https://github.com/funcwj/uPIT-for-speech-separation" target="_blank" rel="noopener">uPIT-for-speech-separation</a>。</p>
<p>uPIT调了几组参数，主要是dropout，weight decay，mask类型，激活函数，输入特征等等，到目前为止总结实验结果如下：</p>
<p><img src="http://www.funcwj.cn/images/upit-experiments.png" alt=""></p>
<p>从表中可以看出，dropout，weight decay等正则化手段对最终的结果提升影响较大，线性谱不做cmvn的效果最好，ReLU在不同的mask类型上表现均强于sigmoid，但是和论文结论不同的是，PSM并没有显示出相对IAM的优势，二者的结果相差不大。</p>
<p>最后再说一点感触吧，现在大家都在用DL做东西，框架也很方便，因此可能最多的时间可能都不是耗在代码实现，而是debug和调参这些比较枯燥的任务上。对于这些，还是将它看成一种能力比较好，网络不收敛，如何找出问题，或者应用trick，如何根据实验结果调整参数，使模型更优，如何（尽量）解释（分析）不同参数对模型的影响等等，这些都是通过不断的实验和观察，才能得出规律，因此，切忌浮躁，多做实验！</p>
]]></content>
      <categories>
        <category>Speech Separation</category>
      </categories>
      <tags>
        <tag>BSS</tag>
        <tag>uPIT</tag>
        <tag>Mask</tag>
        <tag>DPCL</tag>
        <tag>Single-channel</tag>
      </tags>
  </entry>
  <entry>
    <title>TDOA - SRP-PHAT方法</title>
    <url>/2018/05/29/srp-phat-for-tdoa-estimate/</url>
    <content><![CDATA[<p>接着上次GCC-PHAT算法。</p>
<p>GCC-PHAT只利用了两个麦克风的信息，如果麦数多于两路，就可以使用其他的一些方法进行DoA估计，比如Music，SRP算法等等，前者是一个叫做子空间方法的应用，后者这篇文章会进行介绍。</p>
<p>首先认识一下SRP（steered response power）的概念。SRP可以用FS（filter and sum）beamformer的输出功率来表示，如果FS表达为：</p>
<script type="math/tex; mode=display">
Y(\omega, t) = \sum_{m = 1}^M G(\omega)_m X_m(\omega, t) e^{-j\omega \tau_m} \tag{1}</script><p>注：实际中通常在短时频域进行计算，因此，上面的表达式我加上了时间项$t​$。</p>
<a id="more"></a>
<p>其中$\tau_m$表示第$m$个麦克风相对参考麦克风的时间延迟，同上篇GCC-PHAT中的定义，对于线阵而言：</p>
<script type="math/tex; mode=display">
\tau_m = \frac{\cos(\theta)d_m}{c} \tag{2}</script><p>那么：</p>
<script type="math/tex; mode=display">
\text{SRP}_\text{out}(t) = \sum_\omega Y(\omega, t) Y(\omega, t)^* \tag{3}</script><p>表示$t$时刻的SRP值，在FS固定的情况下，它只和波达方向$\theta$相关。把$(1)$带入$(3)$，可得：</p>
<script type="math/tex; mode=display">
\begin{align}
\text{SRP}_{\text{out}}(t)  &= \sum_\omega \left(\sum_{p = 1}^M G(\omega)_p X_p(\omega, t) e^{-j\omega \tau_p} \right) \left(\sum_{q = 1}^M G(\omega)_q X_q(\omega, t) e^{-j\omega \tau_q} \right)^* \\
& = \sum_p^M\sum_q^m \left(\sum_\omega G(\omega)_p G(\omega)^*_q X_p(\omega, t)X_q(\omega, t)^* e^{j\omega(\tau_q - \tau_p)} \right)
\end{align}</script><p>上式中括号中的表达式即为选取麦克风$p,q$时的GCC：</p>
<script type="math/tex; mode=display">
\text{GCC}_{pq}(t) = \sum_\omega G(\omega)_p G(\omega)^*_q X_p(\omega, t)X_q(\omega, t)^* e^{j\omega(\tau_q - \tau_p)} \tag{4}</script><p>因此，SRP是所有麦克风两两组合的GCC之和：</p>
<script type="math/tex; mode=display">
\text{SRP}_\text{out}(t) = \sum_p^M \sum_q^M \text{GCC}_{pq}(t) \tag{5}</script><p>若选取$G(\omega)$为$\frac{1}{X(\omega, t)}$，仅仅保留相位信息，那么此时上式的结果称为SRP-PHAT。</p>
<p>表达式$(4)$中，将$\tau_q - \tau_p$写成$\theta$的函数：</p>
<script type="math/tex; mode=display">
\tau_p - \tau_q = \frac{d_{pq}\cos \theta}{c}</script><p>令</p>
<script type="math/tex; mode=display">
\widehat{X_i}(\omega, t) = G(\omega)_i X_i(\omega, t)</script><p>将GCC对应的表示为时间$t$和波达方向$\theta$的函数：</p>
<script type="math/tex; mode=display">
\text{GCC}_{pq}(t, \theta) = \sum_\omega \widehat{X_p}(\omega, t) \widehat{X_q}(\omega, t)^*  e^{j \omega\cos \theta d_{pq} / c}</script><p>GCC那篇文章已经提过，对$\theta \in [0, \pi]$进行采样，上述结果被称为augular spectrum。在这里，$\text{SRP}_\text{out}(t, \theta)$亦然。</p>
<p>根据式$(5)$，如果已经有了GCC（-PHAT）的实现，得到对应的SRP（-PHAT）并不难，做一次遍历即可：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line">aug = <span class="built_in">zeros</span>(num_frames, num_doa);</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> p = <span class="number">1</span>: num_chs</span><br><span class="line">    <span class="keyword">for</span> q = <span class="number">1</span>: num_chs</span><br><span class="line">        d = topo(p) - topo(q);</span><br><span class="line">        tau = <span class="built_in">linspace</span>(-d / c, d / c, num_doa);</span><br><span class="line">        aug = aug + gcc_phat(Sx(:, :, p), Sx(:, :, q), tau, fs);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>由于SRP的计算涵盖了所有可能组合的GCC值，因此，得到的结果相比GCC稳定性更高，比如4麦的线阵，我对比GCC-PHAT（channel 1, 4）的augular spectrum和SRP-PHAT的结果如下：</p>
<ul>
<li><p>GCC-PHAT</p>
<p><img src="http://www.funcwj.cn/images/gcc-phat-demo.jpg" width="800"></p>
</li>
<li><p>SRP-PHAT</p>
<p><img src="http://www.funcwj.cn/images/srp-phat-demo.jpg" width="800"></p>
</li>
</ul>
<p>图中黄色的斑点表示值大的区域，不难看出，后者augular spectrum的peak点更加明显，非peak区域的数值分布也相对平稳，因此在后处理进行DoA决策的时候，往往可靠性更高。</p>
<p>如果是单一说话人，且说话较为连续时，往往只需要沿时间轴做个平均，之后找到峰值对应的DoA即可。如果涉及到多个说话人，存在背景噪声，且说话不连续的情况，那么角度谱显示的信息就相对较多，比如说话人数量，说话区间，噪声区间等等，此时，如何利用这些信息进行鲁棒的后处理就显得尤为关键。</p>
]]></content>
      <categories>
        <category>Microphone Array Processing</category>
      </categories>
      <tags>
        <tag>DoA</tag>
        <tag>SSL</tag>
        <tag>SRP-PHAT</tag>
      </tags>
  </entry>
  <entry>
    <title>Mask Based Methods</title>
    <url>/2018/05/26/mask-methods/</url>
    <content><![CDATA[<p>嗯，现在正式结合着我自己的实践，开讲mask在Speech Enhancement中的应用。</p>
<p>开门见山，本文主要focus下面三点：</p>
<ul>
<li>mask的定义</li>
<li>mask的估计</li>
<li>mask的使用</li>
</ul>
<a id="more"></a>
<h4 id="Introduction-to-mask"><a href="#Introduction-to-mask" class="headerlink" title="Introduction to mask"></a>Introduction to mask</h4><p>在一个存在加性噪声的场景下，我们观测到信号可以写成如下形式：</p>
<script type="math/tex; mode=display">
y(t) = x(t) + n(t)</script><p>对上式变换到短时频域，有：</p>
<script type="math/tex; mode=display">
\mathbf{Y}(t, f) = \mathbf{X}(t, f) + \mathbf{N}(t, f)</script><p>这里的每个时频点在文献中常常被称为一个T-F bin。如果给每个bin关联一个mask值，那么，就可以根据形成的mask矩阵$\mathbf{M} \in R^{T \times F}$，抽取到一个信号成分，即：</p>
<script type="math/tex; mode=display">
\mathbf{Y}_m = \mathbf{Y} \odot \mathbf{M}</script><p>在这里，考虑一种简单的情况，即对于相对干净的音频，如果以每一帧的能量作为阈值判断，设置$\mathbf{M}_t = {\mathbf{0}, \mathbf{1}}$，那么，此时的mask其实就起到了一个VAD的作用。</p>
<p>回到原题中去，频域中，每个T-F bin上的值落在复数域，如果仅仅从幅值的角度考虑，我们需要恢复出$|\mathbf{X}|$，mask矩阵应该如下计算：</p>
<script type="math/tex; mode=display">
\mathbf{M} = \frac{|\mathbf{X}|}{|\mathbf{Y}|} = \frac{|\mathbf{X}|}{|\mathbf{X}| + |\mathbf{N}|}</script><p>在这种情况下$\mathbf{M}(t, f) \in [0, 1]$，被称为IRM（ideal ratio mask），也是如今最常见的一种mask之一。在IRM之前，传统信号处理往往认为每个T-F bin只是独立的属于某一成分，比如以信噪比来看，认为高于阈值$\delta$的bin属于语音信号，由此，T-F mask成为一个非0即1的量，称为IBM（ideal binary mask），如下</p>
<script type="math/tex; mode=display">
\mathbf{M}(t, f) = 
\begin{cases}
1 \quad \text{SNR} > \delta \\
0 \quad \text{others}
\end{cases}</script><p>但是，如今在NN框架中的mask常常被用来当做网络训练的target，因此，如何让网络学得更加鲁棒，更加稳健的掩蔽能力，就成为语音增强的一个方向。一种是设计新的mask，让网络进行学习，比如complex mask，phase sensitive mask等等（都是汪德亮老师他们实验室的杰作），另一方面就是设计新的训练方法，应用新的网络结构，比如GAN，T-S结构等等。</p>
<p>继续本文之前，先给出IRM和IBM的一个简单的例子，直观的了解一下什么是mask。我以一定的SDR混合spk1和spk2，计算IBM并在T-F bin上做mask，结果如下（简单处理，$\delta = 0$），第一行的图为原始的speaker语谱，第二行为对应的IBM，两者互补，最后一行是在T-F域上做mask的结果。</p>
<p><img src="http://www.funcwj.cn/images/binary-mask-demo.jpg" alt="binary-mask-demo"></p>
<p>由于IBM非零即1，因此，oracle的处理结果在语谱上看的比较别扭，实际中用IBM训练的网络推断时加入sigmoid函数，使得输出在0和1之间，因此掩蔽的效果不会像上图这样，和IRM比较类似。IRM的demo如下，简单期间，将白噪声以一定的信噪比和speech混合：</p>
<p><img src="http://www.funcwj.cn/images/ratio-mask-demo.jpg" alt="ratio-mask-demo"></p>
<p>由上图可以看出，IRM可以很好的反应出原始speech的语谱特征，oracle的掩蔽效果也很完美。</p>
<h4 id="Estimate-mask"><a href="#Estimate-mask" class="headerlink" title="Estimate mask"></a>Estimate mask</h4><p>监督学习方法火起来之后，mask的估计就方便很多，一般是数据准备（加噪），计算mask，模型训练，应用评估这四步就完了，下面简单说一下每一步需要注意的地方。</p>
<ol>
<li>加噪，从实录（noisy）的数据中是无法获得mask信息的（否则你还训模型干啥），因此，数据准备就是要造一批我们知道mask信息的数据，用于网络训练。仅仅是加性噪声的准备非常简单，定义一个信噪比（SNR）范围，从噪声数据库中抽取噪声样本$\mathbf{n}_i$，对原始数据$\mathbf{x}_j$在时域上相加即可：<script type="math/tex; mode=display">
\mathbf{y}_j = \mathbf{x}_j + \sum_i^N \gamma_i\mathbf{n}_i</script>$\gamma_i$根据信噪比得出：<script type="math/tex; mode=display">
\gamma_i = (10^{\frac{-\text{SNR}}{10}} \cdot P_{\mathbf{x}_j}/P_{\mathbf{y}_i})^{0.5}</script></li>
</ol>
<ol>
<li><p>mask计算，这部分不用多说，根据不同mask的定义，根据$\mathbf{x}_j​$和$\mathbf{y}_i​$进行计算即可。</p>
</li>
<li><p>模型训练，分三个点，特征，模型，损失函数。</p>
<ul>
<li><p>特征：一般的网络结构和mask而言，输入特征没有什么限制，fbank，lsp，ivector，mfcc以及multi-channel下的一些spatial特征（GCC，SCM，ITD等等）都可以使用。</p>
</li>
<li><p>模型：目前DNN/LSTM/BLSTM结构都可以使用，multi-task，teacher-student结构等等，没有什么十分特别的地方</p>
</li>
<li><p>损失函数：对于IBM，可以当成二分类任务，用binary CE，其余的mask，通常采用MSE进行优化，即：</p>
<script type="math/tex; mode=display">
\mathcal{J}= \Vert \mathbf{M}_t - \mathbf{M}_p \Vert_F^2</script><p>其中$\mathbf{M}_t,\mathbf{M}_p$分别表示target和网络的预测结果，另外一种常用的方式，优化mask的结果$\mathbf{Y}_s \odot \mathbf{M}_p$：</p>
<script type="math/tex; mode=display">
\mathcal{J}= \Vert \mathbf{Y}_t - \mathbf{Y}_s \odot \mathbf{M}_p \Vert_F^2</script><p>$\mathbf{Y}_t$表示clean的target，$\mathbf{Y}_s$表示对应的noisy数据。这种方式得到的mask更加接近于最终我们期望的target，而且，不需要显式的计算mask作为target，得到了广泛的应用。</p>
</li>
</ul>
</li>
<li><p>应用评估，得到了mask模型之后，根据不同的任务，进行不同的性能评估，一般的，通过：</p>
<script type="math/tex; mode=display">
\mathbf{x}' = \text{iSTFT}(\mathbf{Y}_s \odot \mathbf{M}_p, \phi)</script><p>转换到时域，$\phi​$表示相位信息，对于irm/ibm这类不记录相位信息的mask而言，相位采用noisy的结果。下面给出一个网络的预测样例，一般的，如果可以看到比较清晰的共振峰脉络，那么就可以确定网络的学习结果没有什么严重的问题。</p>
<p><img src="http://www.funcwj.cn/images/nnet-ratio-mask-demo.png", width="500"></img></p>
<p>得到时域音频之后，识别任务通过WER进行，不过由于增强之后的结果会和原始noisy数据训练的am存在较大的mismatch，因此，用增强的数据进行retrain是十分必要的。增强/分离任务通过PESQ，SNR/SDR等指标判定（但是其往往只能在模拟数据上进行，因为指标的计算需要给出相应的reference）。多通道的情况，mask往往在beamformer中用于channel之间协方差矩阵（covariance matrix）的估计（具体参见本文第三部分）。需要提一下，multi-channel情况下，模型对每一个channel都会给出一个mask预测，一般会对这些mask进行average/median等操作来获得一路mask，带入beamformer。</p>
</li>
</ol>
<p>注：mask这个东西和传统信号处理中的一个概念十分相似，叫做SPP（speech presence probability），有兴趣的读者可以查阅一下传统的方法如何进行SPP的估计的。</p>
<p>从上面的第四点也可以看出，mask的应用不仅仅在于single channel processing，也广泛存在于multi-channel的场景下。DL方法诞生之前，如果可以获取多通道的数据，那么mask可以通过NMF，TF-clustering等方法等获得，下面以NTT比较新的CGMM方法，介绍一下TF-clustering的思路。</p>
<blockquote>
<p>CGMM可以参考如下两篇论文</p>
<p>[1]. Higuchi, Takuya, et al. “Online MVDR beamformer based on complex gaussian mixture model with spatial prior for noise robust ASR.” <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em> 25.4 (2017): 780-793.</p>
<p>[2]. Higuchi, Takuya, et al. “Robust MVDR beamforming using time-frequency masks for online/offline ASR in noise.” <em>Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on</em>. IEEE, 2016.</p>
</blockquote>
<p>假设现有$M$路信号（即一个$M$麦的阵列）$\mathbf{Y}$，target成分$K + 1$（$K$个speaker，1个噪声成分），其中</p>
<script type="math/tex; mode=display">
\mathbf{Y} = [\mathbf{Y}_1, \mathbf{Y}_2, \cdots, \mathbf{Y}_M], \;\mathbf{Y}_m \in \mathbf{C}^{F \times T}</script><p>TF-clustering需要引入一个先验，比如在CGMM里面，假设target成分$k$的每个T-F bin服从均值为0，方差为$\phi_{ft}^k$的Complex Gaussian分布，即：</p>
<script type="math/tex; mode=display">
\mathbf{X}_k(f, t) = x_{ft}^k \sim \mathcal{N}_c(0, \phi_{ft}^k)</script><p>令$\mathbf{r}_f^k \in \mathbf{C}^{M \times 1}$表示第$k$个目标成分到每个麦克风，在频率$f$处的响应，将每个T-F bin上，所有channel形成的观测向量称为$\mathbf{y}_{ft}$：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{ft} = [\mathbf{Y}(f, t)_1, \mathbf{Y}(f, t)_2, \cdots, \mathbf{Y}(f, t)_M]</script><p>那么有：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{ft} = \sum_k \mathbf{r}_f^k x_{ft}^k  =\sum_k \mathbf{y}_{ft}^k</script><p>其中$\mathbf{y}_f^k = \mathbf{r}_f^k x_{ft}^k​$，根据$x_{ft}^k​$的分布，有：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{ft}^k \sim \mathcal{N}_c(0, \phi^k_{ft}\mathbf{R}_f^k), \; \mathbf{R}_f^k = \mathbf{r}_f^k(\mathbf{r}_f^k)^H</script><p>$\mathbf{y}_{ft}$用$K + 1$个成分的Complex Gaussian Mixture Model（CGMM）建模：</p>
<script type="math/tex; mode=display">
\mathbf{y}_{ft} \sim \sum_k \alpha_f^k \mathcal{N}_c(0, \phi^k_{ft}\mathbf{R}_f^k)，\; \sum_k \alpha_f^k  = 1</script><p>如果成功的估计了上式中的$\alpha_f^k, \phi_{ft}^k, \mathbf{R}_f^k$，那么，target $k$的mask $m_{ft}^k$可以通过：</p>
<script type="math/tex; mode=display">
m_{ft}^k = \frac{\alpha_f^k \mathcal{N}_c(\mathbf{y}_{ft}|0, \phi^k_{ft}\mathbf{R}_f^k)}{\sum_k \alpha_f^k \mathcal{N}_c(\mathbf{y}_{ft}|0, \phi^k_{ft}\mathbf{R}_f^k)}</script><p>计算得到，之后的事情就行用EM算法估计这三个参数量了，这部分可以参考原始论文，这里不做赘述。</p>
<p>这种在时频域进行聚类的方法有一个严重的问题就是permutation problem（置换问题），这里解释一下：在进行EM过程中，每个频点是完全独立的进行迭代（实现的时候，对频域进行一次扫描，每个频点上独立的进行EM算法估计），因此，不能保证在频率$f_1, f_2$处，$m_{f_1 t}^k$和$m_{f_2t}^k$对应同一个目标成分（比如初始化的原因，可能造成两者的进化方向不同），这就是所谓的置换问题，需要专门的后处理算法解决，将每个频点的mask进行对齐。</p>
<p>假设只有一个target，那么后处理的方式简单很多，正确的初始化也可以解决置换问题，比如论文中建议的，采用单位矩阵初始化$\mathbf{R}_f^n$，观测信号channel之间的协方差矩阵初始化$\mathbf{R}_f^s$，在实践中表现的较好。我的实现最终版本未做后续处理，也取得了不错的结果。下面给出一个CGMM方法估计出的mask，我们可以从中清晰的看出语谱（target speech）的脉络。</p>
<p><img src="http://www.funcwj.cn/images/cgmm-mask-demo.png" alt="cgmm-mask-demo"></p>
<p>我的实现在<a href="https://github.com/funcwj/cgmm-mask-estimator" target="_blank" rel="noopener">cgmm-mask-estimator</a>，感兴趣的看观可以参阅一下。</p>
<h4 id="Using-mask"><a href="#Using-mask" class="headerlink" title="Using mask"></a>Using mask</h4><p>第二部分也提到了一些，得到mask之后，如何使用，主要取决于自己的任务（实际上这一点在表明需要mask之前就应该已经明确）。目前我接触的主要是两点：</p>
<ol>
<li><p>去除噪声/语音分离：</p>
<p>在T-F域上，将target mask和观测信号做Hadamard Product，之后配合相位信息做iSTFT即可。iSTFT一般用overlap add算法实现。</p>
<script type="math/tex; mode=display">
\mathbf{x}' = \text{iSTFT}(\mathbf{Y}_s \odot \mathbf{M}_p, \phi)</script></li>
<li><p>Adaptive beamformer的相应target的相关矩阵估计</p>
<p>主要看使用什么beamformer了，相关矩阵的估计方法上面也已经提到：</p>
<script type="math/tex; mode=display">
\mathbf{R}^k_f = \frac{1}{\sum_t m_{tf}^k}\sum_t m_{tf}^k \mathbf{y}_{tf}^k(\mathbf{y}_{tf}^k) ^H \in \mathbf{C}^{M \times M}</script></li>
</ol>
<h4 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h4><p>TF-mask被研究的时间比较久了，目前在很多地方都可以看到它的身影，比如single channel的分离任务上，uPIT，DAnet等等都有mask相关的东西在里面。传统的BSS方法，很多也是构建生成模型，在T-F bin上做clustering的思路。目前来看，新的mask类型和应用点也还有产生（比如结合NMF和mask），感兴趣的可以关注一下汪德亮老师的实验室主页，前端的一些论文，包括speech separation/enhancement, beamforming在内，以及在CHiME数据集上的一些实验结果和探索。</p>
]]></content>
      <categories>
        <category>Speech Enhancement</category>
      </categories>
      <tags>
        <tag>Beamformer</tag>
        <tag>Mask</tag>
        <tag>CGMM</tag>
      </tags>
  </entry>
  <entry>
    <title>Beam Pattern</title>
    <url>/2018/05/12/beampattern-and-fixed-beamformer/</url>
    <content><![CDATA[<p>在看前端方面的论文的时候，一定会遇到beam pattern这个概念，本篇文章主要讲述beam pattern的意义，应用以及可视化方面的东西。</p>
<p>beamformer很重要的一个性质就是它的指向性，指向性可以反映波束形成器对每个方向的信号，哪些频率进行增强，哪些频率进行抑制。如果可以准确的估计出DoA的话，增强声源方向的信号，抑制其他方向，就成为了beamformer的主要任务。</p>
<a id="more"></a>
<p>根据上述表述，beamformer要想表现的完美，准确的DoA不可或缺。如果可以实时的根据信号环境调整DoA，那么在工作中，beamformer的指向性便会发生改变，这种波束形成器被称为adaptive beamformer。反之，如果固定其指向性，在工作中只增强事先设定的方向信号，便被称为fixed beamformer。反映到beam weights上，如果beam weights被计算出并保持不变，对应后者，如果有声学环境的参数掺杂在其中，或者不断的update DoA，则对应前者，比如MVDR，PMWF，Max-SNR等等。</p>
<p>上篇文章中也提到了，用NN做前端，一般用mask模型估计adaptive beamformer中target的协相关/功率谱密度矩阵，并用其最大特征向量来估计steer vector。我们更加在意系统最终对WER或者PESQ，SDR，SNR等等（根据任务不同）的贡献，而不会刻意的去分析其指向性。这种不涉及麦克风拓扑结构，不涉及声源信息的方法称为Blind方法。</p>
<h4 id="Beam-Pattern"><a href="#Beam-Pattern" class="headerlink" title="Beam Pattern"></a>Beam Pattern</h4><p>现在做如下定义：存在$M$个麦克风的线阵中，第$i$个麦克风相对第一个的距离为$d_i(d_0 = 0, d_i &lt; d_j \;\text{if} \; i &lt; j)$，如果DoA为$\theta(\theta \in [0, \pi])$，声速为$c$，那么，第$i$个麦克风相对第一个的延时$\tau_i$定义为：</p>
<script type="math/tex; mode=display">
\tau_{\theta i}  = \frac{\cos(\theta)d_i}{c}</script><p>以MVDR为例，已知相对延迟$\tau$，beam weights由下式得出：</p>
<script type="math/tex; mode=display">
\mathbf{w}(\omega) = \frac{\mathbf{R}_{vv}^{-1}(\omega) \mathbf{d}_\tau(\omega)}{\mathbf{d}_\tau^H(\omega)\mathbf{R}_{vv}^{-1} (\omega)\mathbf{d}_\tau(\omega)}</script><p>其中：</p>
<script type="math/tex; mode=display">
\mathbf{d}_\tau = [e^{-j\pi \omega\tau_0}, e^{-j\pi \omega\tau_1}, \cdots, e^{-j\pi \omega\tau_{M - 1}}]^T</script><p>如果我们想要分析在该$\mathbf{w}, \mathbf{w} \in \mathbf{C}^{F \times M}​$下，beamformer对任意方向信号的作用，就可以借助beam pattern进行。</p>
<p>令$Z \in \mathbf{C}^{F \times T}$为beamformer输出的信号，那么有（详细见文章“Overview of beamformer”）：</p>
<script type="math/tex; mode=display">
Z(\omega) = \mathbf{w}(\omega)^H \mathbf{y}(\omega)</script><p>其中$\mathbf{y} = [Y_0, Y_1, \cdots, Y_{M-1}] \in \mathbf{C}^{F \times M \times T}$。</p>
<p>把假设DoA为$\theta$下计算的beam weights表示为$\mathbf{w}(\omega, \theta)$：</p>
<script type="math/tex; mode=display">
\mathbf{w}_\theta(\omega) = \frac{\mathbf{R}_{vv}^{-1}(\omega) \mathbf{d}_\theta(\omega)}{\mathbf{d}_\theta^H(\omega)\mathbf{R}_{vv}^{-1}(\omega) \mathbf{d}_\theta(\omega)}</script><p>$\mathbf{d}_\phi​$表示DoA为$\phi​$时的steer vector：</p>
<script type="math/tex; mode=display">
\mathbf{d}_\phi = [e^{-j\pi \omega\tau_{\phi 0}}, e^{-j\pi \omega\tau_{\phi 1}}, \cdots, e^{-j\pi \omega\tau_{\phi{M - 1}}}]^T</script><p>考虑到</p>
<script type="math/tex; mode=display">
\mathbf{y}(\omega) = \mathbf{d}_\phi(\omega) X(\omega) + \mathbf{v}(\omega)</script><p>那么在beam weights为$\mathbf{w}(\omega, \theta)$下，有</p>
<script type="math/tex; mode=display">
Z(\omega) = \mathbf{w}_\theta(\omega)^H \mathbf{y}(\omega) = \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega) X(\omega) +  \mathbf{w}_\theta(\theta)^H\mathbf{v}(\omega)</script><p>把上式中$X(\omega)$的系数称为beam pattern $\mathcal{B}(\omega, \phi)$：</p>
<script type="math/tex; mode=display">
\mathcal{B}(\omega, \phi) = \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega)</script><p>从这里可以看出，beam pattern是频率$\omega​$和DoA $\phi​$的函数，$\mathcal{B}(\omega, \phi)​$越大，表示对应方向上和频率处的信号增益越大。也就是说，通过beam pattern我们可以看出一组空间滤波器在方位轴和频率轴上的表现。这是分析滤波器性能的一个很方便的手段。</p>
<h4 id="Fixed-Beamformer-Design"><a href="#Fixed-Beamformer-Design" class="headerlink" title="Fixed Beamformer Design"></a>Fixed Beamformer Design</h4><p>根据beam pattern的定义，我们可以由$\mathcal{B}(\omega, \phi)$反推$\mathbf{w}_\theta(\omega)$。</p>
<p>假设我们想要增强$\theta$方向的信号，对应的在beam pattern中反映的应该是$\delta \in [\theta - \epsilon,\theta +\epsilon ]$处的beam pattern较大。将其作为beam weights的target，在频率$\omega$处，令：</p>
<script type="math/tex; mode=display">
\mathcal{B}_{\text{target}}(\omega, \delta) = 1</script><p>现在，想要求出$\mathbf{w}_\theta(\omega)​$，使得 $ \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega)​$的结果接近$\mathcal{B}_{\text{target}}​$，转化为下面的优化问题：</p>
<script type="math/tex; mode=display">
\mathbf{w}_\theta(\omega) = \arg \min_{\mathbf{w}_\theta(\omega)} \Vert \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega) - \mathcal{B}_{\text{target}}(\omega) \Vert_2^2</script><p>$\mathbf{d}_\phi(\omega) $的定义和上一部分相同，表示假设DoA为$\phi$时，算出的steer vector矩阵。和MVDR一样，需要限制DoA方向的语音不失真，即：</p>
<script type="math/tex; mode=display">
\mathbf{w}_\theta(\omega)^H\mathbf{d}_\theta(\omega) = 1</script><p>求解上述问题即可得到指向$\theta$方向的beam weights。不过这样求出的beam weights在低频处权值很大，往往上百上千，beamforming之后，低频信号放大的很厉害。通过加入WNG（白噪声增益，White Noise Gain）约束可以缓解这种情况的发生。</p>
<p>WNG定义如下：</p>
<script type="math/tex; mode=display">
A(\omega) = \frac{|\mathbf{w}_\theta(\omega)^H\mathbf{d}_\theta(\omega)|^2}{\mathbf{w}_\theta(\omega)^H\mathbf{w}_\theta(\omega)}</script><p>约束$A(\omega) \geqslant \gamma$可以改写为：</p>
<script type="math/tex; mode=display">
\mathbf{w}_\theta(\omega)^H\mathbf{w}_\theta(\omega) = \Vert\mathbf{w}_\theta(\omega)  \Vert_2^2 \leqslant 1/\gamma</script><p>通常设置$20 \log10(\gamma) = 0, -10 \text{dB}$。</p>
<p>因此，Fixed Beamformer的设计流程如下：</p>
<ol>
<li><p>根据DoA，定义$\mathcal{B}_{\text{target}}(\omega, \delta)$。</p>
</li>
<li><p>求解凸优化问题：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{w}_\theta(\omega) &= \arg \min_{\mathbf{w}_\theta(\omega)} \Vert \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega) - \mathcal{B}_{\text{target}}(\omega) \Vert_2^2 \\
& \text{s.t} \quad \mathbf{w}_\theta(\omega)^H\mathbf{d}_\theta(\omega) = 1, \; \Vert\mathbf{w}_\theta(\omega)  \Vert_2^2 \leqslant 1/\gamma
\end{align}</script></li>
<li><p>分析$\mathcal{B}(\omega, \phi) = \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega)$验证</p>
</li>
</ol>
<h4 id="Visualize-Beam-Pattern"><a href="#Visualize-Beam-Pattern" class="headerlink" title="Visualize Beam Pattern"></a>Visualize Beam Pattern</h4><p>将$\theta = 60^\circ$时的$\mathcal{B}(\omega, \phi)$整体绘制，纵轴表示DoA，横轴表示频率</p>
<p><img src="http://www.funcwj.cn/images/doa60_gamma0.jpg" alt=""></p>
<p>黄色区域表示响应越大，即这个部分的语音gain越多，可以看出，60度方向，全频带范围内gain值都很高，和设计初衷相符。如果固定频率比如5kHz，画出极坐标图，可以得到下面的图（图的幅值方向单位为dB）：</p>
<p><img src="http://www.funcwj.cn/images/5kpolar.jpg" width="400"></p>
<p>在信号处理中，$\mathbf{w}_\theta(\omega)$可以准确的求出，因此，beam pattern是可以求出解析的表达式的，那么往往喜欢用极坐标图的形式显示。</p>
<p>总结下来，这种套路应该是信号那边常见的方法，将beam weights的设计转为凸优化问题进行求解。实际应用中，不同DoA下设计的weights作用在相同的输入上，结果应该会有明显的不同。</p>
<p>另外，需要注意$\omega \in [0, 2 \pi]$这个量，角频率，和频率$f$的关系是：</p>
<script type="math/tex; mode=display">
\omega  = 2\pi f</script><p>DFT中，时域，频域采样数相同，设为$N$，$f$为信号的采样频率，那么</p>
<script type="math/tex; mode=display">
\omega_k = 2 \pi \frac{kN}{T} =  2\pi f_k，f_k = \frac{kN}{T} = 2\pi f \quad 0 \leqslant k < N</script><p>在短时域中，考虑DFT的共轭对称性，只保留前$\frac{N}{2} +1$个点，即$0 \leqslant k \leqslant \frac{N}{2} +1$。</p>
<p>具体编程实现的时候，需要注意它们之间的转换关系。</p>
]]></content>
      <categories>
        <category>Microphone Array Processing</category>
      </categories>
      <tags>
        <tag>Beamformer</tag>
        <tag>Beam Pattern</tag>
      </tags>
  </entry>
  <entry>
    <title>TDOA - GCC-PHAT方法</title>
    <url>/2018/05/10/gcc-phat-for-tdoa-estimate/</url>
    <content><![CDATA[<p>TDOA（Time Difference of Arrival，到达时间差）是一个在语音前端信号处理中很常见的名词，和它比较相像，也同样重要的还有一个DOA（Direction of Arrival，到达方向）。在麦克风拓扑结构已知的情况下，两者可以相互转换。TDOA表示不同通道之间语音信号的延迟程度，是一个相对的概念，一般用$\tau$表示。最简单的beamforming方法delay and sum中的delay针对的就是它。DOA表示信号源相对麦克风的到达角度，一般用$\theta$表示，如果是线阵的话，范围在0到180度之间。如下图所示，假设麦克风1和麦克风2之间的距离为$\delta$，DOA为$\theta_d$，声速$c$，那么$\tau_{12}$可以有简单的数学计算得到：</p>
<a id="more"></a>
<p><img src="http://www.funcwj.cn/images/tdoa_and_doa.png" width="400"></p>
<script type="math/tex; mode=display">
\tau_{12} = \frac{\cos\theta_d \cdot \delta}{c}</script><p>那么DOA/TDOA这个信息怎么用呢？个人觉得可以从下面几个角度理解：</p>
<ol>
<li>如果目标声源只有一个，外加一些环境噪声，那么TDOA可以用来指导beamformer对该方向的信号进行增强。</li>
<li>如果存在多个说话人，且说话人的方位不同，比如圆桌会议这种，那么：<ul>
<li>估计的TDOA的数目可以认为是说话人的数量（speaker counting）</li>
<li>通过跟踪TDOA的变化，追踪特定的说话人</li>
<li>对同一段语音，对估计的DOA方向进行增强，增强说话人</li>
</ul>
</li>
</ol>
<p>当然现实可能不会这么理想，如果说话人距离较远，说话人方向重合，以及环境复杂（噪声，混响）情景下，都会使得估计方法失效或者beamformer不理想等等。鸡尾酒会问题确实是语音这块一个非常难啃的骨头。现在学术界比较流行的一种Blind的方法就是在不知道声源信息和阵列拓扑的情况下，通过一些先验，或者概率模型估计beamforming中的统计量进行计算，我做过的有CGMM，NN-mask+MVDR/GEV等等，在一些数据集上（比如CHiME4）也取得了很好的效果。</p>
<p>在这里我主要说一个最简单的TDOA估计方法，GCC-PHAT。</p>
<p>首先说一下互相关（CC，Cross-Correlation）。信号处理中，互相关可以用来描述两个信号之间的相似性。离散信号$x_k, y_k$的互相关函数定义为：</p>
<script type="math/tex; mode=display">
R^{xy}_\tau = E[x_k y_{k + \tau}] = \sum_k x_k y_{k+\tau}</script><p>从上式可知，CC是相对延时$t​$的一个函数，显然，可以取使得互相关系数最大的延时值作为TDOA的估计，即：</p>
<script type="math/tex; mode=display">
\tau = \arg \max_\tau R^{xy}_\tau</script><p>现在普遍认为，这种算法在实际中容易受到噪声和混响的影响，表现不是很稳定，因此引入了广义互相关的概念（GCC，Generalized Cross-Correlation）。和CC一样，TDOA通过获得最大化GCC函数的延迟值得到：</p>
<script type="math/tex; mode=display">
\mathbf{\tau} = \arg \max_{\tau} \widehat{R}^{xy}_\tau</script><p>其中$\widehat{R}^{xy}_t ​$定义为generalized cross-spectrum的IDTFT：</p>
<script type="math/tex; mode=display">
\widehat{R}^{xy}_\tau = \mathcal{F}^{-1}[\gamma_f \cdot \phi^{xy}_f ]</script><p>$\gamma_f$为频域的权重方程，$\phi_f^{xy}$表示cross-spectrum，定义为$E[X_fY_f^*]$，$*$表示共轭。如果将$\gamma_f$定义为$\frac{1}{|\phi_f^{xy}|}$，那么这种估计方法称为为GCC-PHAT。PAHT表示phase transform，因为做了幅值的归一化之后，相当于只留下了相位信息。</p>
<p>语音信号处理中，我们通常在短时频域上进行。在每一帧上，进行一次$\widehat{R}^{xy}_\tau$计算，可以得到所谓的angular spectrogram：</p>
<script type="math/tex; mode=display">
\varPsi_{\tau t} = \sum_f \overline{H_{tf}} e^{j2\pi f\tau}</script><p>其中$H_{tf} = X_{tf} \odot Y_{tf}^*$，$\overline{H_{tf}}$表示做幅值归一化。实际计算中，构建矩阵$\varOmega \in R^{\varTheta \times F}$，使得</p>
<script type="math/tex; mode=display">
\varOmega_{\tau f} = e^{j2\pi f\tau}</script><p>之后计算矩阵乘法$\varPsi =\overline{H} \varOmega$即可。下面贴一段我写的可视化angular spectrogram的程序，旨在说明计算逻辑：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf-8</span></span><br><span class="line"><span class="comment"># wujian@2018</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> utils</span><br><span class="line"></span><br><span class="line">speech_speed    = <span class="number">340.29</span></span><br><span class="line">distance_of_mic = <span class="number">1</span></span><br><span class="line">samp_frequency  = <span class="number">16000</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_stft</span><span class="params">(wave_path, frame_length, frame_shift)</span>:</span></span><br><span class="line">    wave_samp = utils.audio_read(wave_path)</span><br><span class="line">    <span class="keyword">return</span> utils.stft(wave_samp, frame_length, frame_shift)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_angspect</span><span class="params">(coherence, num_tdoa)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        coherence: num_bins x num_frames</span></span><br><span class="line"><span class="string">        return num_tdoa x num_frames</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># num_bins x num_toda</span></span><br><span class="line">    num_bins, num_frames  = coherence.shape</span><br><span class="line">    max_tdoa = distance_of_mic / speech_speed</span><br><span class="line">    <span class="comment"># from 0 to 180</span></span><br><span class="line">    est_tdoa = np.linspace(-max_tdoa, max_tdoa, num_tdoa)</span><br><span class="line">    sep_freq = np.linspace(<span class="number">0</span>, samp_frequency / <span class="number">2</span>, num_bins)</span><br><span class="line">    <span class="comment"># num_tdoa x num_bins</span></span><br><span class="line">    exp_part = np.outer(<span class="number">2j</span> * np.pi * est_tdoa, sep_freq)</span><br><span class="line">    <span class="keyword">return</span> np.dot(np.exp(exp_part), coherence).real</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">run</span><span class="params">(args)</span>:</span></span><br><span class="line">    stft = [compute_stft(wave, args.frame_length, args.frame_shift) <span class="keyword">for</span> wave <span class="keyword">in</span> sorted(glob.glob(args.pattern))]</span><br><span class="line">    <span class="keyword">assert</span> len(stft) == <span class="number">2</span>, <span class="string">'Check pattern &#123;&#125; please'</span>.format(args.pattern)</span><br><span class="line">    coherence = stft[<span class="number">0</span>] * stft[<span class="number">1</span>].conj() / (np.abs(stft[<span class="number">0</span>]) * np.abs(stft[<span class="number">1</span>]))</span><br><span class="line">    angspect = compute_angspect(coherence， args.num_tdoa)</span><br><span class="line">    angspect[angspect &lt; <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">    plt.subplot(<span class="number">211</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'TDOA index'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Frame index'</span>)</span><br><span class="line">    plt.title(<span class="string">'GCC-PATH Angular Spectrogram'</span>)</span><br><span class="line">    plt.imshow(angspect, cmap=plt.cm.binary, aspect=<span class="string">'auto'</span>, origin=<span class="string">'lower'</span>)</span><br><span class="line">    plt.subplot(<span class="number">212</span>)</span><br><span class="line">    plt.ylabel(<span class="string">'Frequency index'</span>)</span><br><span class="line">    plt.xlabel(<span class="string">'Frame index'</span>)</span><br><span class="line">    plt.title(<span class="string">'Log-Magnitude Spectrogram'</span>)</span><br><span class="line">    plt.imshow(np.log(np.abs(stft[<span class="number">0</span>])), cmap=plt.cm.jet, aspect=<span class="string">'auto'</span>, origin=<span class="string">'lower'</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">"Command to compute angular spectrogram using GCC-PHAT methods"</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'pattern'</span>, type=str, help=<span class="string">'location of 2-channel wave files'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--num-of-tdoa'</span>, type=int, default=<span class="number">128</span>, dest=<span class="string">"num_toda"</span>,</span><br><span class="line">                        help=<span class="string">'Number of todas to estimate'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--frame-shift'</span>, type=int, default=<span class="number">256</span>, dest=<span class="string">"frame_shift"</span>,</span><br><span class="line">                        help=<span class="string">'Frame shift in number of samples'</span>)</span><br><span class="line">    parser.add_argument(<span class="string">'--frame_length'</span>, type=int, default=<span class="number">1024</span>, dest=<span class="string">"frame_length"</span>,</span><br><span class="line">                        help=<span class="string">'Frame length in number of samples'</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    run(args)</span><br></pre></td></tr></table></figure>
<p>注：程序无法完整运行，<code>utils.py</code>我未给出。</p>
<p>在一些比较理想或者simulate的数据下，这种方法work的很好，这部分例子可以参见“Blind Speech Separation and Enhancement With GCC-NMF ”这系列论文以及<a href="https://github.com/seanwood/gcc-nmf" target="_blank" rel="noopener">github</a>。实际的数据中，表现还是差强人意的，我在实录的数据上只在部分条件下（比如说话人距离麦克风较近等等）可以提供较为准确的TDOA估计信息。比如下面几种情况：</p>
<p><img src="http://www.funcwj.cn/images/angular-spectrum-demo1.png" alt="angular-spectrum-demo1"></p>
<p>上图中的angular spectrum中在index-80的位置，在时间轴上出现几段较为明显的峰值，由此可以得到以下信息：</p>
<ol>
<li>峰值出现的所在的index即为估计的最佳TDOA索引。</li>
<li>峰值不连续处表示该说话人尚未说话（起到类似VAD的作用）。</li>
<li>峰值所对应的index分布向着90处移动，说明该说话人可能相对麦克风在移动。</li>
</ol>
<p>如果在不同index处，同时出现峰值，那么就说明存在多个说话人，比如下面这种情况，可以认为在这段语音中，可能存在三个说话人。</p>
<p><img src="http://www.funcwj.cn/images/angular-spectrum-demo2.png" alt="angular-spectrum-demo1"></p>
<p>GCC-PHAT方法的局限性还表现在仅仅只能依据两路信号进行估计。如果现在有多路麦克风，那么就需要在原有算法的基础上进行改进。这部分由于我还没有具体的实践，暂时无法继续深入。</p>
<p>之前也提到过，Blind的方法目前已经摆脱对具体TDOA/DOA的依赖的，以MVDR beamformer为例子，往往会用noise的协相关矩阵的最大特征值作为steer vector的估计。而在传统的信号处理中，TDOA是形成steer vector不可或缺的一个因素，假如已经计算出相对延迟序列$\tau_1, \tau_2, \cdots, \tau_{N-1}$，那么steer vector为：</p>
<script type="math/tex; mode=display">
\mathbf{d}_{\theta} = [1, e^{j\omega \tau_1},  e^{j\omega \tau_2}, \cdots,  e^{j\omega \tau_{N-1}}]</script><p>在beamformer设计中很重要的一个东西是beam pattern，在我们做Blind Source Separation/Enhancement的时候，往往会忽视这个分析手段，只看重最终的WER，在后面我会开一篇文章，介绍使用TDOA进行beamformer，以及使用beam pattern进行分析的方法。什么时候更呢……等哪天准备工作做得充分了吧。</p>
]]></content>
      <categories>
        <category>Microphone Array Processing</category>
      </categories>
      <tags>
        <tag>DoA</tag>
        <tag>GCC-PHAT</tag>
        <tag>SSL</tag>
      </tags>
  </entry>
  <entry>
    <title>Speech Separation - NMF methods</title>
    <url>/2018/05/06/speech-separation-nnmf/</url>
    <content><![CDATA[<p>最近在看一些语音分离的文章，时间旧了，需要做一些总结。这篇文章先说一种传统而有效的方法，NMF（非负矩阵分解）。</p>
<p>将一个矩阵$\mathbf{V}$分解成两个非负矩阵的乘积形式，这种方法就叫非负矩阵分解，数学表达为：</p>
<script type="math/tex; mode=display">
\mathbf{V} \approx \mathbf{W} \mathbf{H}</script><p>若$\mathbf{V} \in \mathbf{R}^{F \times T}$，那么$\mathbf{W} \in \mathbf{R}^{F \times D}, \mathbf{H} \in \mathbf{R}^{D\times T}$，其中$D$为分解过程的一个超参数，在一些文献中，$\mathbf{W}$被称为dictionary或者basis functions，$\mathbf{H}$被称为atoms或者activations，这种称呼的原因会在后文中解释。</p>
<p>下面将从三个方面认识这个概念：</p>
<ol>
<li>如何得到这种表示</li>
<li>这种表示的意义何在</li>
<li>在分离任务中如何应用</li>
</ol>
<a id="more"></a>
<h3 id="NMF"><a href="#NMF" class="headerlink" title="NMF"></a>NMF</h3><p>有定义可知，虽然NMF的分解形式不唯一，但是最终得到的结果，需要尽量降低和原始矩阵的误差（否则恢复不过来，失去意义了），定义$D(\mathbf{V}|\mathbf{WH})$表示误差函数，那么我们要求解的问题就表示为：</p>
<script type="math/tex; mode=display">
\mathbf{W},\mathbf{H} = \arg \min_{\mathbf{W}, \mathbf{H}} \mathcal{D}(\mathbf{V}|\mathbf{\Lambda})</script><p>其中$\mathbf{\Lambda} = \mathbf{WH}$。$\mathcal{D}$不唯一，可以根据任务不同分别定义，如欧式距离，KL散度等等，目前文献中常用$\beta$-divergence统一描述如下</p>
<script type="math/tex; mode=display">
\mathcal{D}_\beta(\mathbf{V} | \mathbf{\Lambda}) = 
\begin{cases}
\frac{\mathbf{V}}{\mathbf{\Lambda}} - \log \frac{\mathbf{V}}{\mathbf{\Lambda}} - 1 & \beta = 0\\
\mathbf{V} (\log \mathbf{V} - \log \mathbf{\Lambda} )  + \mathbf{\Lambda} - \mathbf{V} & \beta = 1\\
\frac{\mathbf{V}^\beta - \mathbf{\Lambda}^\beta -\beta \mathbf{\Lambda}^{\beta - 1}(\mathbf{V} - \mathbf{\Lambda})}{\beta(\beta - 1)} & \beta \in (0, 1)
\end{cases}</script><p>定义$\mathbf{D}_\beta$之后，$\mathbf{W}$，$\mathbf{H}$的求解通过如下迭代的方式进行：</p>
<script type="math/tex; mode=display">
\mathbf{H} \leftarrow \mathbf{H} \odot \frac{\mathbf{W}^\top(\mathbf{V}\odot \mathbf{\Lambda}^{\beta -2})}{\mathbf{W}^\top\mathbf{\Lambda}^{\beta -1}} \\
\mathbf{W} \leftarrow \mathbf{W} \odot \frac{(\mathbf{V}\odot \mathbf{\Lambda}^{\beta -2})\mathbf{H}^\top}{\mathbf{\Lambda}^{\beta -1}\mathbf{W}^\top} \\</script><p>很多时候，我们期望$\mathbf{H}$的具有较高的稀疏程度，因此，$\mathcal{D}$中常常出现关于$\mathbf{H}$的正则项：</p>
<script type="math/tex; mode=display">
\mathbf{W},\mathbf{H} = \arg \min_{\mathbf{W}, \mathbf{H}} \mathcal{D}(\mathbf{V}|\mathbf{\Lambda}) + \mu |\mathbf{H}|_1</script><p>其中$|\cdot|_1$表示$L_1$范数。在这种情况下，需要修正矩阵的更新公式，一种简单的处理方式是保持$\mathbf{W}$的更新法则不变，$\mathbf{H}$更新的分子加上正则系数$\mu$：</p>
<script type="math/tex; mode=display">
\mathbf{H} \leftarrow \mathbf{H} \odot \frac{\mathbf{W}^\top(\mathbf{V}\odot \mathbf{\Lambda}^{\beta -2})}{\mathbf{W}^\top\mathbf{\Lambda}^{\beta -1} + \mu}</script><p>这种NMF在文献[1]中被称为NMF+S（NMF with Sparsity)而非SNMF(Sparse NMF)，后者修正的$\mathbf{W}$的更新公式，且在分离任务中表现优于前者。讨论可以详细参考原始论文，这里不做过多叙述。</p>
<p>NMF历史悠久，实现方便，在MATLAB，sklearn等工具中均有实现，论文[1]也开源了SNMF的MATLAB代码，可以通过<a href="http://www.merl.com/pub/leroux/sparseNMF.zip" target="_blank" rel="noopener">链接</a>下载。</p>
<p>在语音信号处理中，NMF通常用于对信号的频谱进行分解，如下，图（2，1）表示原始的频谱，图（1，2）为NMF近似的结果，使用MERL的SNMF工具，参数配置$\beta = 1, \mu = 5, D = 64$。</p>
<p><img src="http://www.funcwj.cn/images/spectrum_snmf.jpg" alt="spectrum_nmf">如果用MATLAB中的<code>nnmf</code>方法，在相同的配置下，结果如下：</p>
<p><img src="http://www.funcwj.cn/images/spectrum_nnmf.jpg" alt="spectrum_nnmf"></p>
<p>可以看出，SNMF估计的$\mathbf{H}$矩阵稀疏性更高。</p>
<h3 id="如何理解"><a href="#如何理解" class="headerlink" title="如何理解"></a>如何理解</h3><p>关于表达式：</p>
<script type="math/tex; mode=display">
\mathbf{V} = \mathbf{WH}</script><p>我们可以换一种写法，即：</p>
<script type="math/tex; mode=display">
\mathbf{V} =  
\begin{bmatrix}
\mathbf{v}_1,
\mathbf{v}_2,
\cdots,
\mathbf{v}_T
\end{bmatrix}
=
\mathbf{W}
\begin{bmatrix}
\mathbf{h}_1,
\mathbf{h}_2,
\cdots,
\mathbf{h}_T
\end{bmatrix}</script><p>$\mathbf{v}_i, \mathbf{h}_i$表示各自矩阵中第$i$列的列向量。对于$\mathbf{v}_i$，有：</p>
<script type="math/tex; mode=display">
\mathbf{v}_t = \mathbf{W} \mathbf{h}_t = [\mathbf{w}_1, \mathbf{w}_2, \cdots, \mathbf{w}_D] \mathbf{h}_t = \sum_{d = 0}^{D - 1} \mathbf{w}_d \cdot h_{td}</script><p>上式表明，$t$时刻的频谱，可以表示为$\mathbf{W}$矩阵列向量的线性组合，组合系数为$\mathbf{H}$矩阵的第$t$列。也就是说，NMF会将原始矩阵分解成一组非负的向量组，和对应的一组非负权值。理解这点对于理解NMF在语音分离中的应用比较重要。</p>
<p>另外一点需要提到，一般情况下，设置的$D$值小于$T$值，既然$\mathbf{W}$具有描述原始矩阵的性质，那么可以视其为一组具有非负性的特征向量。我们希望使用少数的特征向量就可以表示原始矩阵，一方面可以减少向量之间的相关性，避免冗余，一方面为了计算，存储的高效性。</p>
<p>另外，有时我们会看到如下定义：</p>
<script type="math/tex; mode=display">
\mathbf{V} = \sum_{c}\mathbf{W}_c \mathbf{H}_c</script><p>即几组$\mathbf{W}$和$\mathbf{V}$矩阵的乘积和，典型的比如语音分离任务中。这种形式依旧可以规整成上面的原始表示形式，如下：</p>
<script type="math/tex; mode=display">
\mathbf{V} = \sum_{c}\mathbf{W}_c \mathbf{H}_c = [\mathbf{W}_1, \mathbf{W}_2, \cdots, \mathbf{W}_C]
\begin{bmatrix}
\mathbf{H}_1 \\
\mathbf{H}_2 \\
\cdots \\
\mathbf{H}_C \\
\end{bmatrix}</script><h3 id="语音分离：NMF方法"><a href="#语音分离：NMF方法" class="headerlink" title="语音分离：NMF方法"></a>语音分离：NMF方法</h3><p>在比较理想的情况下，混合语音信号$\mathbf{S}$由多路信号相加表示：</p>
<script type="math/tex; mode=display">
\mathbf{S} = \sum_c \mathbf{S}_c</script><p>对$\mathbf{S}_c$做NMF，有：</p>
<script type="math/tex; mode=display">
\mathbf{S} = \sum_c \mathbf{S}_c = \sum_c \mathbf{W}_c \mathbf{H}_c = \widetilde{\mathbf{W}} \widetilde{\mathbf{H}}</script><p>若$\widetilde{\mathbf{W}} \widetilde{\mathbf{H}}$可被估计，那么，可以下式分离出对应的语音信号：</p>
<script type="math/tex; mode=display">
\mathbf{S}'_c = \frac{\mathbf{W}_c \mathbf{H}_c}{\widetilde{\mathbf{W}} \widetilde{\mathbf{H}}} \odot \mathbf{S}</script><p>supervised NMF方法中，分为训练阶段和测试阶段。训练阶段需要单一说话人的监督数据，用来得到说话人的特征集合$\widetilde{\mathbf{W}} $，测试阶段，将其作为初始$\mathbf{W}$进行NMF，过程中只训练$\mathbf{H}$。收敛之后，用上式做说话人分离。</p>
<p>有一点需要注意，就是测试的时候可以将句子分block进行，类似于声学模型中的拼帧。分离的结果只保留中间位置的帧即可。主要是希望利用picth和vocal在时间轴上的局部相似性，获取更好的分离效果。</p>
<p>我进行了Oracle-NMF作实验验证上述流程，之所以称之为Oracle，是因为我直接从$\mathbf{S}_c$中学习speaker的特征矩阵，将他们进行<code>concat</code>作为NMF中的初始化，得到$\mathbf{H}$进行分离，而非从该说话人的其他说话语料中进行。</p>
<p>实验使用MERL实现的SNMF，数据为wsj0的2spk混合数据（用的Deep Clustering的混合程序，生成16k数据），拼左右4帧，帧长和帧移为64ms，16ms。我可视化几个样例结果如下：</p>
<p><img src="http://www.funcwj.cn/images/online_oracle_snmf_demo1.jpg" alt="online_oracle_snmf_demo1"></p>
<p>从语谱图上可以看出，结果还是比较理想的。下面这个两个例子可以看出，在silence段，NMF的表现也不差。</p>
<p><img src="http://www.funcwj.cn/images/online_oracle_snmf_demo2.jpg" alt="online_oracle_snmf_demo1"></p>
<p><img src="http://www.funcwj.cn/images/online_oracle_snmf_demo3.jpg" alt="online_oracle_snmf_demo1"></p>
<p>参考文献[2]中也使用了NMF，不过整体思路非上面所述，后期我会更一版GCC-PHAT，在那里简单讨论一些它的想法。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1]. Le Roux J, Weninger F J, Hershey J R. Sparse NMF–half-baked or well done?[J]. Mitsubishi Electric Research Labs (MERL), Cambridge, MA, USA, Tech. Rep., no. TR2015-023, 2015.</p>
<p>[2]. Wood S U N, Rouat J, Dupont S, et al. Blind speech separation and enhancement with GCC-NMF[J]. IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP), 2017, 25(4): 745-755.</p>
]]></content>
      <categories>
        <category>Speech Separation</category>
      </categories>
      <tags>
        <tag>BSS</tag>
        <tag>Single-channel</tag>
        <tag>NMF</tag>
      </tags>
  </entry>
  <entry>
    <title>SETK - Speech Enhancement Tools based on Kaldi</title>
    <url>/2018/04/14/setk-speech-enhancement-tookit/</url>
    <content><![CDATA[<p>趁着最近手头上的事比较少，想把自己前段时间的事情总结一下，由于目前主流的开源识别项目Kaldi前端支持较差，我闲着没事干，把前期做的一些事情迁移到Kaldi上来。为啥叫做闲着没事呢，因为这些代码用python或者MATLAB实现相比C++真的太简单了（就当是为开源社区做点贡献吧）……不过话说回来，迁移到Kaldi上还是有一点方便的，就是速度，以后做一些验证性的实验或者前端baseline，前后端打通的话，基本做一下数据准备就OK了，省去了很多重新组织代码，脚本的时间。<br><a id="more"></a></p>
<p>我前期做的一些事情个人感觉比较简单，主要是基于mask的单通道，多通道增强（此处应有汪大师的一系列论文）。目前想做的工作如下：</p>
<ul>
<li>Different mask computation(binary|ratio|complex|phase-sensitive）</li>
<li>CGMM mask estimator on Kaldi</li>
<li>STFT-based feature extraction and wave reconstruction</li>
<li>Adaptive (MVDR/GEV/GSC) beamformer based on mask or signal methods</li>
<li>TDOA estimation algorithm</li>
<li>NMF methods on speech enhancement or seperation</li>
</ul>
<p>repo地址<a href="https://github.com/funcwj/kaldi-enhan" target="_blank" rel="noopener">kaldi-enhan</a>，目前已经实现和测试完成的部分包括</p>
<ol>
<li>Compute binary|ratio masks</li>
<li>Compute (phase angle/power&amp;magnitude spectrum/complex STFT results) of source wave</li>
<li>Seperate target component from source wave according to reference masks</li>
<li>Estimate wave from enhanced spectrum and reference wave</li>
<li>MVDR/GEV beamformer(based on mask model)</li>
</ol>
<p>前端实现的核心库操作主要是复矩阵的运算，我目前已经整体搭建起来了，风格同Kaldi的Matrix/Vector Class，内部调用OpenBlas/CLAPACK接口，目前我在OSX和RedHat上已经<br>测试通过。</p>
<p>关于以上的一些工作我一直觉得比较简单没有写Blog，尤其是single channel的部分，后期考虑有时间的话补上。</p>
<p>写于2018.4.14</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>SETK</tag>
      </tags>
  </entry>
  <entry>
    <title>Overview of E2E Methods</title>
    <url>/2018/03/13/end-to-end-overview/</url>
    <content><![CDATA[<p>本篇Blog虽然看起来像极了新闻稿，但实际上只是自己想做一个E2E的梳理（顺便交了某课程大作业），毕竟这玩意最近这么火。有一部分论文自己只看个大概，说法未必准确，各位看观小心~。</p>
<p>语音识别（Automatic Speech Recognition，ASR）是要完成输入音频的采样序列到字符序列的映射任务。传统识别模块主要包含声学模型，字典，语言模型三个部分，其中声学模型用于将输入特征转化为声学单元的后验概率，字典用于表示声学单元序列到字符的映射关系，而语言模型则用于表示字符上下文之间的条件概率。由于声学模型的训练需要预知声学单元和输入特征之间的对齐信息，而常见的声学单元，比如CD-state，CD-phone等的时间对齐信息无法直接从抄本中的字符序列中获知。因此，DNN等声学模型的训练需要以传统的HMM-GMM模型进行启动引导，获得帧级别的状态标签，这一步操作称为对齐。也正是由于CD-state之类的建模单元颗粒度太小，无法直接转化成字符级别的输出，因此，需要融合字典，语言模型等信息，信息融合在声学解码器中进行。</p>
<a id="more"></a>
<p>因为抄本的长度往往小于特征序列的长度， 所以，实现特征到序列直接映射的核心在于如何处理这种对齐关系。传统的NN-HMM框架正是无法进行这种不等长的序列映射，因此才需要对齐和解码。很显然，我们期望的是一种更加自然的模型结构，可以直接以抄本作为label完成训练，直接以字/词作为输出单元，从而简化训练和解码流程。2012年之后，随着传统声学建模技术的逐渐成熟，国内外学者和研究机构开始基于语音识别这种序列映射的特性，借鉴图像，机器翻译领域的一些成功案例，开始尝试端到端（End-to-End，E2E）的建模方法。</p>
<p>为了保持脉络清晰，本部分会顺着时间线介绍三种比较成熟的端到端的建模方法：CTC<sup>[13][14]</sup>（Connectionist Temporal Classification）RNN Transducer<sup>[12]</sup>，Attention<sup>[5][9][10]</sup>机制及其在声学建模中的应用，中间会穿插一些分析和讨论，帮助理清思路。有些文章中会以Sequence to Sequence（Seq2Seq）的概念表达声学建模中端到端的含义，在这里统一称为E2E。需要注意一点，本节所述方法的输入均为声学特征，并非直接基于原始采样信号（raw waveform）建模。</p>
<h3 id="CTC"><a href="#CTC" class="headerlink" title="CTC"></a>CTC</h3><p>最早被提出用于E2E训练的是Alex Graves在2006年提出的CTC准则<sup>[13]</sup>，当时用于处理一些输入和标签不等长的问题中，比如手写识别，语音识别等等。本质上说，CTC只是一个定义在序列上的损失函数，而非一种新的网络模型。传统声学模型是一个分类器，其损失函数交叉熵是一个定义在帧级别上的度量函数，最大化当前标签被分类正确的概率，并不能很好的反映网络输出的序列特性，而CTC将句子级别的对齐信息融合在了损失函数中，通过最大化所有和和抄本对齐序列的概率和，实现E2E的模型训练，这种方式由于包含了显式的对齐计算，后来也常常称之为硬对齐（hard-alignment）。</p>
<p>对齐路径$\mathbf{\pi}$和抄本$\mathbf{y}$和是多对一关系，为了更好的描述这种关系，Graves额外引入了blank标签$\epsilon$的概念，用于隔断不同字符，比如在$T = 5$的约束下，抄本${a,b}$的对齐序列可以是${a\epsilon b\epsilon \epsilon}$，${a\epsilon\epsilon \epsilon b}$，${\epsilon ab\epsilon \epsilon}$等等。用函数$\mathcal{F}$描述$\pi \to \mathbf{y}$映射关系为$\mathcal{F}(\pi) = \mathbf{y}$。若定义输入特征序列$\mathbf{x} = \{\mathbf{x}_1, \mathbf{x}_1, \cdots, \mathbf{x}_T\}$，那么CTC损失准则表达为：</p>
<script type="math/tex; mode=display">
    \mathcal{L}_{\text{ctc}}(\mathbf{y}|\mathbf{x}) = \sum_{\pi \in \mathcal{F}^{-1}(\mathbf{y})} P(\pi | \mathbf{x})</script><p>考虑$\pi \in \mathcal{F}^{-1}$的元素呈指数级增长，故在实际中采用动态规划原理，即前向-后向算法计算$\mathcal{L}_{\text{ctc}}$。为了计算$P(\pi | \mathbf{x})$，Graves引入假设：在不同时刻，模型的输出概率相互独立，那么根据条件概率公式，有</p>
<script type="math/tex; mode=display">
    P(\pi|\mathbf{x}) = \prod_{t = 1}^T P(y_{\pi}^t | \mathbf{x}_{1 \cdots t})</script><p>其中$P(y_{\pi}^t | \mathbf{x}_{1 \cdots t})$用RNN的输出层概率表示，需要注意的是，由于引入了blank符号$\epsilon$，实际网络建模中输出层节点需要在原建模单元个数之上加1，比如在TIMIT数据上，61个音素单元的输出层个数应为62。网络训练时，用梯度下降法最小化$-\mathcal{L}_{\text{ctc}}$。2006年Graves提出CTC时，用BLSTM建模获得了30.51%的PER，超越了传统的BLSTM-HMM（33.84%）方法。网络收敛时候，各个符号之间被blank隔断，输出概率分布呈现尖峰特性，因此，通过简单的greedy-search或者beam-search方法即可完成序列解码。</p>
<p>不过，CTC最大的诟病在于Graves为了计算$P(\pi|\mathbf{x})$引入的假设，因为无论从声学特性还是语言模型上说，相邻时刻的输出概率往往是极大相关的，因此，后续的其他方法往往会消除这样的假设。</p>
<h3 id="CTC-based-System"><a href="#CTC-based-System" class="headerlink" title="CTC based System"></a>CTC based System</h3><p>CTC被提出之后产生了很多成功的应用案例，结合不断改进的RNN<sup>[27]</sup>，CNN<sup>[32]</sup>用于声学建模的思路不断出现，比较典型的算是百度硅谷研究院的Deep Speech<sup>[2][16]</sup>系列。</p>
<p>Deep Speech 1，2是均以CTC准则构建的端到端识别系统。2014年，Deep Speech 1公布，主体上沿用Graves等人的建模思路，但是在声学模型上做了简化。前三层为使用clipped ReLU（$g(z) = \min \{ \max \{0, z\}, 20 \}$）作为激活函数的全连接网络，第四层采用双向RNN，第五层为全连接层，接受双向RNN的输出，输出层使用CTC作为误差准则。配合数据抖动和dropout等正则化优化技巧，Deep Speech 1最终在SWB+FSH 2000h数据集上超越了当时传统方法最好的开源结果。</p>
<p>2014年到2016年之间，CNN<sup>[1][26]</sup>以及BatchNorm<sup>[1]</sup>等正则化方法相继被引入声学建模中，并取得了很好的结果。Deep Speech 2在2016年公开，和DS1相比，声学模型中加入了如下新的特性：</p>
<ul>
<li>引入卷积层用于特征抽取，替代之前的全连接层，在时域和频域的二维卷积可以明显增强声学模型在噪声环境下的识别鲁棒性</li>
<li>RNN部分采用sequence-wise的BatchNorm，用于加速网络收敛，并且发现，随着网络层数的加深，对收敛度的提升越好</li>
<li>使用Cho等人在2014年提出的GRU代替普通RNN，相比LSTM，GRU<sup>[8]</sup>可以获得相近的结果，同时计算复杂度更小</li>
<li>在GRU层之上加入lookahead卷积层，用于获取一些future context。</li>
</ul>
<p>DS2在普通话和英语上同时取得了可观的结果，在普通话带噪测试集上，使用了BatchNorm和2D卷积的模型相比浅层的RNN在WER上有了48%的相对提升，并且在voice query数据上超越了人类水平。</p>
<p>Google在2017年提出的Neural Speech Recognizer<sup>[29]</sup>也是以CTC为准则的识别系统。NSR采用双向LSTM建模，在超过12万小时的数据上进行训练，对比了CD-phone和word两种建模单元，在YouTube转写任务上，以word作为建模单元的NSR超越了传统CD-phone的ASR效果。</p>
<p>在开源社区CTC也相当活跃，Miao等人基于Kaldi语音识别工具包开源了eesen<sup>[20]</sup>，满足了CTC和传统声学解码器的耦合，Baidu开源了社区效率最高的CTC实现<a href="https://github.com/baidu-research/warp-ctc" target="_blank" rel="noopener">warp-ctc</a>，在同等的计算量下，其耗时远低于其他工具包，Facebook研究院开源了他们基于CTC的端到端识别工具<a href="https://github.com/facebookresearch/wav2letter" target="_blank" rel="noopener">wav2letter</a><sup>[11]</sup>，CUDNN7.0中也增加了CTC的API接口。此外，受到CTC的启发，Dan等人提出的Lattice Free MMI（LF-MMI，chain model）<sup>[22]</sup>获得巨大成功，一方面降低了区分性训练的耗时，另一方面可以获得8%的相对提升，被誉为声学模型近几年最大的创新。</p>
<h3 id="RNN-Transducer"><a href="#RNN-Transducer" class="headerlink" title="RNN Transducer"></a>RNN Transducer</h3><p>为了进一步提升CTC的表现，Graves后来提出了RNN Transducer<sup>[12]</sup>结构，用于修正CTC在计算序列概率中的假设缺陷。思路是保留原CTC声学模型（称为转录网络）的同时，引入一个额外的网络，称为为预测网络，用于对抄本序列的输出进行预测，起到类似语言模型的作用。在$t$时刻，当前符号为$u$时，网络输出符号$k$的概率表示为：</p>
<script type="math/tex; mode=display">
    P(k | t, u) = \frac{\exp(\mathbf{f}_t^k + \mathbf{g}_u^k)}{\sum_{k'} \exp(\mathbf{f}_t^{k'} + \mathbf{g}_u^{k'})}</script><p>其中$\mathbf{f}_t,\mathbf{g}_u$表示转录和预测网络的输出概率向量。训练时，预测网络的输入源自抄本序列，解码时，预测网络的输入来自转录网络的输出，输入采用one-hot编码的形式，因此，在RNN Transducer中，$P(\pi|\mathbf{x})$的计算公式变为：</p>
<script type="math/tex; mode=display">
    P(\pi | \mathbf{x}) = \prod_{t=1}^T P(y_{\pi}^t | \mathbf{x}_{1 \cdots t}, \pi_{\{1,\cdots,t\}})</script><p>从这里可以看出，由于$t$时刻的输出$y<em>{\pi}^t$会作为预测网络的输入，因此，$t + 1$时刻的输出$y</em>{\pi}^{t+1}$不再和$y_{\pi}^t$相互独立，这种条件更加符合语音上下文之间的相关性。实验中，一层128节点的预测网络和两层128节点的转录网络在TIMIT上取得了23.2%的PER，相比纯转录网络（25.5%），降低了2.3%个百分点。</p>
<p>在2013年，Graves用多层LSTM建模<sup>[15]</sup>，并用CTC网络的权值初始化转录网络，在TIMIT上取得了17.7%的PER，成为当时最好的结果，而同结构的CTC结果为18.6%。研究同时表明：</p>
<ul>
<li>LSTM的建模能力远远超越普通RNN</li>
<li>网络走向深度的收益好于扩展宽度</li>
<li>双向网络的建模能力胜于单向网络</li>
</ul>
<p>RT的问题在于，转录网络和预测网络除了通过$P(k|u, t)$进行信息融合之外，并不相互依赖，因此，二者较为独立。其次，RT依旧保持了CTC设计中硬对齐部分，用于计算损失函数，在这点上计算复杂度较高，本质上说，属于对CTC的改进。</p>
<h3 id="Encoder-Decoder-Structure"><a href="#Encoder-Decoder-Structure" class="headerlink" title="Encoder-Decoder Structure"></a>Encoder-Decoder Structure</h3><p>在提Attention机制之前需要先说一下Encoder-Decoder结构。Encoder-Decoder是Cho等人在2014年提出的一种包含两个RNN的网络结构<sup>[8]</sup>，最初用于机器翻译，也正是在这篇论文中，他们提出了LSTM的简化版本GRU（Gated Recurrent Unit）。</p>
<p>在E-D结构中，编码器用于将输入的变长序列$\mathbf{x}$编码成定长表示$\mathbf{c}$，而解码器用于将此定长表示解码成另一种符号序列$\mathbf{y}$，两个网络做联合训练，最大化条件概率$P(\mathbf{y} | \mathbf{x})$，以此完成序列映射。一般的，$\mathbf{c}$用encoder扫描一遍$\mathbf{x}$之后的hidden state表示。对于decoder，在生成$y_t$时，接受上一时刻的输出$y_{t - 1}$和$\mathbf{c}$作为输入，hidden state的更新表示为：</p>
<script type="math/tex; mode=display">
    \mathbf{s}_t = \mathcal{R}(\mathbf{s}_{t - 1}, y_{t - 1}, \mathbf{c})</script><p>在生成$t$时刻生成$y_t$的条件概率$P(y_t | y_{1 \cdots (t - 1)}, \mathbf{x})$表示为：</p>
<script type="math/tex; mode=display">
    P(y_t | y_{1 \cdots (t - 1)}, \mathbf{x}) = \mathcal{G}(\mathbf{s}_t, y_{t - 1}, \mathbf{c})</script><p>其中$\mathcal{G}$可以用一个带有softmax输出层的MLP表示。在E-D结构下，decoder生成序列$\mathbf{y}$的条件概率可以根据条件概率公式得到：</p>
<script type="math/tex; mode=display">
    P(\mathbf{y} | \mathbf{x}) = \prod_t P(y_t |y_{<t}, \mathbf{x}) = \prod_{t} P(y_t | y_{1 \cdots (t - 1)}, \mathbf{c})</script><p>通过引入编码器，使得decoder的输出不再直接依赖于输入$\mathbf{x}$，生成序列的长度也只取决于解码的步数，这是这种结构能够很好的处理变长序列映射问题的关键。但是这种结构会带来两个很明显的问题：</p>
<ul>
<li>由于RNN的记忆遗忘问题，实际中编码器将输入序列全部编码成定长表示会造成表达能力不足以及信息丢失等问题，这种问题往往随着输入序列的增长而愈加明显。</li>
<li>即使全部信息被编码进定长表示，在解码阶段，未必每一步都需要全部的输入信息，比如关联最大的可能仅仅和输入序列对齐部分的上下文区间。</li>
</ul>
<p>正是出于这种考虑，一种称为attention机制的encoder-decoder结构被提出。这种结构摒弃了编码器输出定长编码的限制，将编码器hidden state的加权和输入decoder，权重由网络自身学习得到。这种结构一来避免了长时输入造成的信息丢失，同时允许decoder自行学习注意的内容，更加符合实际。attention最早被应用于机器翻译<sup>[3]</sup>，物体追踪，图像主题生成，后来被Cho等人用于语音识别<sup>[9][10]</sup>，并取得成功。</p>
<h3 id="Attention-Mechanism"><a href="#Attention-Mechanism" class="headerlink" title="Attention Mechanism"></a>Attention Mechanism</h3><p>在引入attention机制的encoder-decoder框架中，encoder用于将输入特征$\mathbf{x}_{1 \cdots T}$转换为高层次的表示特征$\mathbf{h}_{1 \cdots U}$，decoder用于根据表示特征预测序列单元$\mathbf{y}_t$，编码器和解码器之间通过attention机制关联。attention的作用是根据decoder的状态$\mathbf{s}_t$，结合$\mathbf{h}$计算attention context $\mathbf{c}_t$，帮助解码器预测输出$\mathbf{y}_t$。</p>
<p>现在对上述过程进行符号化，不同于纯粹的E-D结构，在生成$t$时刻生成$y_t$的条件概率$P(y_t | y_{1 \cdots (t - 1)}, \mathbf{x})$在引入attention机制之后变为：</p>
<script type="math/tex; mode=display">
    P(y_t | y_{1 \cdots (t - 1)}, \mathbf{x}) = \mathcal{G}(\mathbf{s}_{i}, y_{t - 1}, \mathbf{c}_i)</script><p>attention context $\mathbf{c}_i$为表示特征$\mathbf{h}_{1 \cdots U}$的加权和，用$\alpha_{ij}$表示权值，$\mathbf{c}_i = \sum_{j = 1}^U \alpha_{ij} \mathbf{h}_j$，这里引入的$\alpha_i$就是attention weight，其计算过程可以统一表示为：</p>
<script type="math/tex; mode=display">
\begin{align}
    e_{ij} & = \mathcal{A}(\mathbf{s}_i, \mathbf{h}_j, \alpha_{i -1}) \\
    \alpha_i &= \text{softmax}(e_i)
\end{align}</script><p>$e_{ij}$称为scaler energy，不同的attention其计算过程不同。下面介绍几种常见的attention类型：</p>
<ol>
<li><p>MLP attention<sup>[9]</sup>。<br> 用一个多层感知机（线性网络）表示$\mathcal{A}$的计算过程称为MLP attention，ASR中最早被Cho等人在其研究中使用，输入为向量$\mathbf{s}_i$和$\mathbf{h}_j$的拼接。</p>
</li>
<li><p>Tanh attention<sup>[10]</sup>。<br> Tanh attention又称为content-based attention，最早在机器翻译中使用，Cho等人在2015年提出的ARSG（Attention-based Recurrent Sequence Generator）中借鉴了这种计算方式，提出一种location-aware的计算方法，考虑了上一步生成的attention权值信息$\alpha_{i - 1}$，计算表示如下：</p>
<script type="math/tex; mode=display">
     e_{ij} = w^\top \tanh(\phi(\mathbf{s}_i) + \psi(\mathbf{h}_j) + \theta(\mathbf{f}_{ij}))</script><p> 其中$w$为权值向量，$\phi(\cdot), \psi(\cdot), \theta(\cdot)$均为MLP网络。$\mathbf{f}_i$为一个矩阵，用$\alpha_{i - 1}$和矩阵$\mathbf{F}$卷积得到：</p>
<script type="math/tex; mode=display">
        \mathbf{f}_i = \mathbf{F} * \alpha_{i - 1}</script></li>
<li><p>Dot attention<sup>[5]</sup>。<br> Dot attention是Google Brain团队在LAS（Listen Attend and Spell）结构中使用的计算方法，通过两个MLP网络$\phi(\cdot), \psi(\cdot)$将$\mathbf{s}_i$和$\mathbf{h}_j$embedding成等长向量，二者做点积：</p>
<script type="math/tex; mode=display">
        e_{ij} = \langle \phi(\mathbf{s}_i), \psi(\mathbf{h}_j) \rangle</script><p>  实验表明，在Google voice search traffic任务上，dot-attention的表现比tanh-attention要好。</p>
</li>
<li><p>Multi-Head attention<sup>[30]</sup>。<br>  前面的几种attention计算的共同点在于用$\mathbf{h}$的加权平均作为attention context，这种方式称为single-head attention，scaler energy依赖单一的$\mathbf{s}_i$。multi-head attention（MHA）的机制是Google Brain团队在2017年提出的概念，首先被应用于机器翻译（NMT）。它将$\mathbf{s}_i$做投影变换，产生$M$个embedding，基于此计算出$M$个scaler energy，彼此之间分布不同，最后将各自的attention context拼接成最终的context向    量。这种方式有助于减少context对encoder信息的依赖，同时由于每支head可以从$\mathbf{h}$中提取不同的信息，系统鲁棒性更强。借助上面的符号定义，其计算过程可以表示为：</p>
<script type="math/tex; mode=display">
  \begin{align}
      \mathbf{c}_i &= \mathcal{A}(\mathbf{W}_i \mathbf{s}_i, \mathbf{h}) \\
      \mathbf{c} &=\text{concat}(\mathbf{c}_{1 \cdots M}) \mathbf{W}_o
  \end{align}</script><p>  其中$\mathbf{W}_i$表示变换矩阵，$\mathbf{W}_o$用于减少向量拼接之后的维度。</p>
</li>
</ol>
<p>Attention机制在机器翻译中取得成功之后，被引入语音识别，处理声学特征到抄本之间的序列建模。从2015年开始，Attention based方法逐渐成为研究热点。</p>
<h3 id="Attention-based-Models"><a href="#Attention-based-Models" class="headerlink" title="Attention based Models"></a>Attention based Models</h3><p>2014年，attention机制在TIMIT上最早的尝试取得了18.61%的PER<sup>[9]</sup>。随后，Cho等人提出了ARSG（Attention-based Recurrent Sequence Generator）<sup>[10]</sup>，采用location-aware的attention替换早期的MLP-attention，在TIMIT数据集上获得了17.6%的PER（Phone Error Rate），这一结果已经超越了2013年RNN Transducer的17.7%<sup>[15]</sup>。</p>
<p>谷歌同年提出的LAS（Listen Attend and Spell）<sup>[5]</sup>整体与ARSG类似，不过更加结构化。LAS中encoder称为Listener，decoder称为AttendAndSpeller。Listener是一个金字塔结构的BLSTM-encoder，这种形式可以有效减少表示特征的输出步长，加速网络收敛。Speller是一个两层的LSTM，与ARSG不同的是，attention context采用dot attention计算。LAS的评估在Google voice search任务上进行，和传统方法最好的结果（CLDNN 8.0%）相比，配合语言模型重打分（LM rescore），取得10.3%的WER。</p>
<p>Baidu的Deep Speech 3没有单独的进行模型设计<sup>[4]</sup>，而是从数据，编码器结构，解码配置等方面详细对比了CTC，RNN Transducer和 Attention based方法。在不借助语言模型辅助的条件下，在switchboard数据集上分别取得9.0%，8.5%和8.6%的WER，在更加真实的DeepSpeech数据上，三者的最优表现则较为一致。</p>
<h3 id="Attention-vs-CTC"><a href="#Attention-vs-CTC" class="headerlink" title="Attention vs CTC"></a>Attention vs CTC</h3><p>相比CTC，attention机制更希望attention layer自身学习到对齐信息，用于辅助decoder进行序列预测。训练时的损失度量依旧是传统声学建模的交叉熵，因此，相比CTC具有简洁性。这种方法称为软对齐（soft-alignment）。$\alpha$表示网络学习到的对齐信息，网络收敛之后，其分布往往比较尖锐。</p>
<p>而CTC则是通过显示的计算对齐信息，用于损失函数设计实现端到端的训练，计算复杂度较高。做推断时，输出序列的时序长度和输入一致，而E-D框架中，decoder的输出则没有这一限制，理论上可能是任意长度。对于RNN Transducer，转录网络和预测网络之间仅仅通过输出层做信息耦合（做硬对齐的损失计算），而网络之间的状态信息也没有交互，在这点上没有E-D框架耦合性高。</p>
<p>解码方面，由于CTC的输出分布呈现尖峰特性，大部分时长被blank符号填充，因此，虽然没有在学习过程中学习语言建模，但是也可以采用greedy/beam search的方法进行解码。如果采用细粒度的建模方法，比如CI-phone，也可以使用声学解码器进行解码。</p>
<p>CTC相比attention更易于实现online解码，只需要将声学模型替换为单向RNN（LSTM \&amp; GRU etc.）。而E-D框架中，由于encoder需要扫描一遍输入序列，因此，实时性较差。关于如何进行online的改进，陆续有学者提出了自己的方案进行相关改进。下一部分会介绍其中一种思路。</p>
<h3 id="Online-Attention"><a href="#Online-Attention" class="headerlink" title="Online Attention"></a>Online Attention</h3><p>上面提到的attention也常常被称为full-sequence attention，因为在计算scaler energy时需要利用到整个表示特征$\mathbf{h}_{1\cdots U}$。由此带来的问题是，decoder需要等待encoder完成全部编码表示才能工作，也就意味着decoder无法在线/流式工作，这极大的限制了其在语音交互中的应用。因此，如何进行在线的改善attention模型成为拓展其应用场景必须解决的问题。</p>
<p>Google Brain在2016年提出的Netural Transducer（NT）<sup>[18]</sup>将attention计算的context限制在事先划分的语音段中，假设段长$W$，则$T$帧的数据可以划分为$B = [\frac{T}{W}]$段。在每个块中，NT产生$k$个输出符号，并且强制最后一个符号为$e$，表示该语音段中已经产生完所有输出。根据以上定义，第$b$段语音对应的输出序列$y_{e_b -1 \cdots e_b}$产生的条件概率为：</p>
<script type="math/tex; mode=display">
P(y_{e_b - 1 \cdots e_b} | \mathbf{x}_{1 \cdots bW}) = \prod_{i = e_{b - 1} + 1}^{e_b} P(y_m | \mathbf{x}_{1 \cdots bW}, y_{1 \cdots (i-1)})</script><p>其中$\mathbf{x}_{1 \cdots bW}$和$y_{1 \cdots (i-1)}$分别表示已经观测到的特征和NT的当前输出序列。而scale energy和attention context的计算仅仅只在当前语音段的表示特征$\mathbf{h}_{(b-1)W \cdots bW}$上进行，即$\mathbf{c}_i = \sum_{j = 1}^W \alpha<em>{ij} \mathbf{h}</em>{(b - 1)W + j}$，其中：</p>
<script type="math/tex; mode=display">
\alpha_i = \mathcal{A}(\mathbf{s}_i, \mathbf{h}_{(b - 1)W + j})</script><p>关于attend的具体实现，论文中提出了三种思路，除了LAS中的dot attention之外，还有MLP attention和LSTM attention，即用一个多层感知机或者LSTM网络来计算scale energy。通过调节$W$的值，可以发现LSTM attention的结果更加连贯，配合一个三层的BLSTM-encoder，在TIMIT上可以取得18.2%的PER，和full-sequence attention 17.6%相比，这个结果是可观的。后来文献中常将NT实现online的方法称为limited-sequence attention。</p>
<p>在ARSG中，作者也分析了full-sequence attention容易受到注意力丢失问题的影响，在长句子上的表现普遍不佳。NT中划分语音段的方式帮助模型中的attention前向移动，因此，对此问题的敏感有所降低。但是在更加复杂的任务上，比如Google的voice search，流式/在线的Netural Transducer的表现不如离线的LAS，因此，Google的speech team将NT的思路应用于LAS中，并在原先LAS的设计上做了一些优化工作<sup>[7][25]</sup>，主要包括如下几点：</p>
<ul>
<li>向前拓展注意力计算的context，即回顾若干（$k$）个语音段，同时向后拓展5帧，即将$\mathbf{h}_{(b-1)W + 1, \cdots, bW} $由$\text{Listen}(\mathbf{x}_{(b-1)W + 1, \cdots, bW})$修正为$\text{Listen}(\mathbf{x}_{(b-k)W + 1, \cdots, bW + 5})$，通过引入少量的延时，重复利用之前的历史信息增强了attention信息含量。</li>
<li>使用原先的LAS模型参数初始化LAS-NT。</li>
<li>参照机器翻译中的相关经验，使用字片替代原来的字建模，同时在解码过程中融合一个语言模型。</li>
</ul>
<p>实验结果表明，在Google voice search traffic任务，1,2的改进可以使得single-head NT获得和single-head LAS相媲美的结果（9.9% vs 9.8%），结合3，multi-head NT取得了和multi-head LAS相同的结果（8.6%）。到此，attention具有了在实际场景中部署的基础。</p>
<p>另外一种online改进的思路则是借鉴CTC中hard-alignment的思路，假设网络的对齐是单调的，即注意力沿着时间轴转移，以Google Brain Raffel<sup>[6][24]</sup>等人为代表。目前实际的表现尚不如NT-LAS，Google团队正在进行相关调优工作。</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>本文从2006年被提出的CTC准则出发，依次介绍了RNN Transducer，encoder-decoder框架三种用于端到端声学建模的方法，同时梳理了三者之间的关系及区别，并参阅了近四年来的相关文献，展示了Google，Baidu等语音团队在端到端方向上的实践思路。事实上，关于E2E的实践还远不止本文所述，比如结合attention的LF-MMI<sup>[21]</sup>，基于VDNN（Very Deep Neural Network）<sup>[31]</sup>的建模实践，基于CTC准则的encoder-decoder框架<sup>[28]</sup>，结合RNN Transducer的attention机制<sup>[23]</sup>，CTC attention的联合训练以及CE-CTC的联合训练<sup>[19]</sup>等等。整体来说，端到端是语音领域近两年比较火热的一个方向，由于在真实复杂的场景（噪声，混响，多说话人等等）下，其实际的声学鲁棒性尚不能媲美传统方案，因此还有很多难关等待被攻克。</p>
<h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><p>[1] O. Abdel-Hamid, A.-r. Mohamed, H. Jiang, and G. Penn. Applying convolutional neural networks concepts to hybrid nn-hmm model for speech recognition. In Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on, pages 4277–4280. IEEE, 2012.<br>[2] D. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, Q. Cheng, G. Chen, et al. Deep speech 2: End-to-end speech recognition in english and mandarin. In International Conference on Machine Learning, pages 173–182, 2016.<br>[3] D. Bahdanau, K. Cho, and Y. Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.<br>[4] E. Battenberg, J. Chen, R. Child, A. Coates, Y. Gaur, Y. Li, H. Liu, S. Satheesh, D. Seetapun, A. Sriram, et al. Exploring neural transducers for end-to-end speech recognition. arXiv preprint arXiv:1707.07413, 2017.<br>[5] W. Chan, N. Jaitly, Q. V. Le, and O. Vinyals. Listen, attend and spell. arxiv preprint. arXiv preprint arXiv:1508.01211, 1(2):3, 2015.<br>[6] C.-C. Chiu and C. Raffel. Monotonic chunkwise attention. arXiv preprint arXiv:1712.05382, 2017.<br>[7] C.-C. Chiu, T. N. Sainath, Y. Wu, R. Prabhavalkar, P. Nguyen, Z. Chen, A. Kannan, R. J. Weiss, K. Rao, K. Gonina, et al. State-of-the-art speech recognition with sequence-to-sequence models. arXiv preprint arXiv:1712.01769, 2017.<br>[8] K. Cho, B. Van Merriënboer, C. Gulcehre, D. Bahdanau, F. Bougares, H. Schwenk, and Y. Bengio. Learning phrase representations using rnn encoder- decoder for statistical machine translation. arXiv preprint arXiv:1406.1078, 2014.<br>[9] J. Chorowski, D. Bahdanau, K. Cho, and Y. Bengio. End-to-end continuous speech recognition using attention-based recurrent nn: First results. arXiv preprint arXiv:1412.1602, 2014.<br>[10] J. K. Chorowski, D. Bahdanau, D. Serdyuk, K. Cho, and Y. Bengio. Attention-based models for speech recognition. In Advances in neural information processing systems, pages 577–585, 2015.<br>[11] R. Collobert, C. Puhrsch, and G. Synnaeve. Wav2letter: an end-to-end convnet-based speech recognition system. CoRR, abs/1609.03193, 2016.<br>[12] A. Graves. Sequence transduction with recurrent neural networks. Computer Science, 58(3):235–242, 2012.<br>[13] A. Graves and F. Gomez. Connectionist temporal classification:labelling unsegmented sequence data with recurrent neural networks. In International Conference on Machine Learning, pages 369–376, 2006.<br>[14] A. Graves and N. Jaitly. Towards end-to-end speech recognition with recurrent neural networks. In International Conference on Machine Learning, pages 1764–1772, 2014.<br>[15] A. Graves, A.-r. Mohamed, and G. Hinton. Speech recognition with deep recurrent neural networks. In Acoustics, speech and signal processing (icassp), 2013 ieee international conference on, pages 6645–6649. IEEE, 2013.<br>[16] A. Hannun, C. Case, J. Casper, B. Catanzaro, G. Diamos, E. Elsen, R. Prenger, S. Satheesh, S. Sengupta, A. Coates, et al. Deep speech: Scaling up end-to-end speech recognition. arXiv preprint arXiv:1412.5567, 2014.<br>[17] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International conference on machine learning, pages 448–456, 2015.<br>[18] N. Jaitly, Q. V. Le, O. Vinyals, I. Sutskever, D. Sus- sillo, and S. Bengio. An online sequence-to-sequence model using partial conditioning. In Advances in Neural Information Processing Systems, pages 5067–5075, 2016.<br>[19] S. Kim, T. Hori, and S. Watanabe. Joint ctc-attention based end-to-end speech recognition using multi-task learning. In Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on, pages 4835–4839. IEEE, 2017.<br>[20] Y. Miao, M. Gowayyed, and F. Metze. Eesen: End-to-end speech recognition using deep rnn models and wfst-based decoding. In Automatic Speech Recognition and Understanding (ASRU), 2015 IEEE Work- shop on, pages 167–174. IEEE, 2015.<br>[21] D. Povey, H. Hadian, P. Ghahremani, K. Li, and S. Khudanpur. A time-restricted self-attention layer for asr.<br>[22] D. Povey, V. Peddinti, D. Galvez, P. Ghahremani, V. Manohar, X. Na, Y. Wang, and S. Khudanpur. Purely sequence-trained neural networks for asr based on lattice-free mmi. In Interspeech, pages 2751–2755, 2016.<br>[23] R. Prabhavalkar, K. Rao, T. N. Sainath, B. Li, L. Johnson, and N. Jaitly. A comparison of sequence-to-sequence models for speech recognition. In Proc. Interspeech, pages 939–943, 2017.<br>[24] C. Raffel, T. Luong, P. J. Liu, R. J. Weiss, and D. Eck. Online and linear-time attention by enforcing monotonic alignments. arXiv preprint arXiv:1704.00784, 2017.<br>[25] T. N. Sainath, C.-C. Chiu, R. Prabhavalkar, A. Kan- nan, Y. Wu, P. Nguyen, and Z. Chen. Improving the performance of online neural transducer models. arXiv preprint arXiv:1712.01807, 2017.<br>[26] T. N. Sainath, A.-r. Mohamed, B. Kingsbury, and B. Ramabhadran. Deep convolutional neural networks for lvcsr. In Acoustics, speech and signal process- ing (ICASSP), 2013 IEEE international conference on, pages 8614–8618. IEEE, 2013.<br>[27] H. Sak, A. Senior, K. Rao, and F. Beaufays. Fast and accurate recurrent neural network acoustic models for speech recognition. arXiv preprint arXiv:1507.06947, 2015.<br>[28] H. Sak, M. Shannon, K. Rao, and F. Beaufays. Recurrent neural aligner: An encoder-decoder neural net- work model for sequence to sequence mapping. In Proc. of Interspeech, 2017.<br>[29] H. Soltau, H. Liao, and H. Sak. Neural speech recognizer: Acoustic-to-word lstm model for large vocabulary speech recognition. arXiv preprint arXiv:1610.09975, 2016.<br>[30] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez. Kaiser, and I. Polosukhin. Attention is all you need. In Advances in Neural Information Processing Systems, pages 6000–6010, 2017.<br>[31] Y. Zhang, W. Chan, and N. Jaitly. Very deep convolutional networks for end-to-end speech recognition. In Acoustics, Speech and Signal Processing (ICASSP), 2017 IEEE International Conference on, pages 4845– 4849. IEEE, 2017.<br>[32] Y. Zhang, M. Pezeshki, P. Brakel, S. Zhang, C. L. Y. Bengio, and A. Courville. Towards end-to-end speech recognition with deep convolutional neural networks. arXiv preprint arXiv:1701.02720, 2017.</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Attention</tag>
        <tag>E2E</tag>
        <tag>CTC</tag>
      </tags>
  </entry>
  <entry>
    <title>BPTT of RNN</title>
    <url>/2018/01/05/bptt-of-rnn/</url>
    <content><![CDATA[<p>我在这一篇里推导一下RNN的反向传播算法，尝试从另一个角度来理解在RNN在时间轴上的依赖关系，由此导出所谓的梯度消失问题，即原始的RNN为什么难以训练。</p>
<p>首先定义RNN的前向过程如下：</p>
<script type="math/tex; mode=display">
\mathbf{z}_t = W_x \mathbf{x_t} + W_h \mathbf{h}_{t - 1} + \mathbf{b} \\
\mathbf{h}_{t}  = \tanh(\mathbf{z}_t)</script><p>网上常见的解释是，对于RNN，在$t$时刻的输入不仅可以直接影响当前时刻的输出$\mathbf{h}_t$，而且可以通过$\mathbf{h}_t$对下一时刻的输出$\mathbf{h}_{t + 1}$产生影响，因此计算梯度的时候，需将$t + 1$时刻的误差也传递到当前时刻。个人觉得这种解释没有真实的反映出时间序列上的依赖关系，因为$t$时刻输入会对后续时刻的整个序列的输出产生影响，不仅仅是下一个时刻的输出，因此，从这里理解，$t$时刻的误差应该是后续时间步上误差传递到当前时刻值的总和，也正是由于这种在时间轴上从后向前的传递，导致了在时间步（time step）变大时，靠后时刻的误差不能传递到序列的早期时刻，引发了所谓的梯度消失问题（长期依赖问题）。下面对这段文字描述做数学推导。<br><a id="more"></a></p>
<p>首先定义序列时长为$T$（即time_step = $T$）。假设这是一个多层的many-to-many的RNN，对于其中某一层，输入和输出表示为：</p>
<script type="math/tex; mode=display">
\mathbf{X}_l = \{\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_T\} \\
\mathbf{H}_l = \{\mathbf{h}_1, \mathbf{h}_2, \dots, \mathbf{h}_T\}</script><p>在每个时刻，可以获得由上一层网络的传递得到误差项（实际为梯度，这里为了方便），表示为</p>
<script type="math/tex; mode=display">
\mathcal{L}_l = \{\ell_1, \ell_2, \dots, \ell_T\}</script><p>定义$\delta_k$:</p>
<script type="math/tex; mode=display">
\delta_k = \frac{\partial \mathcal{L}_{k \leqslant t \leqslant T}}{\partial \mathbf{z}_k} = \sum_{k \leqslant t \leqslant T} \frac{\partial \ell_t}{\partial \mathbf{z}_k} = \sum_{k \leqslant t \leqslant T} \delta_k^t</script><p>那么$\delta_k$就表示在当前输入序列下，$k \leqslant t \leqslant T$时刻范围内对$\mathbf{z}_k$的梯度之和，这也是我们最终要求的真实梯度，即在当前输入序列下，可以计算出的误差对$\mathbf{z}_k$的梯度。</p>
<p>再看一下$\delta_k^t$：表示当前输出的误差对$\mathbf{z}_k$的梯度，在feed forward的网络结构中，这里$\delta_k^t = \delta_k$。</p>
<p>根据$\delta_k^t$的性质：</p>
<script type="math/tex; mode=display">
\begin{align}
\delta_k^t & = \frac{\partial \ell_t}{\partial \mathbf{z}_k} = \frac{\partial \ell_t}{\partial \mathbf{z}_{k + 1}} \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} \\ 
& = \delta_{k + 1}^t \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} \\ 
& = \frac{\partial \ell_t}{\partial \mathbf{z}_t} \prod_{k + 1 \leqslant  i \leqslant t} \frac{\partial \mathbf{z}_{i}}{\partial \mathbf{z}_{i - 1}}
\end{align}</script><p>结合$\delta_k^t​$和$\delta_k​$，可以得到$\delta_k​$的表达式：</p>
<script type="math/tex; mode=display">
\delta_k = \sum_{k \leqslant t \leqslant T} \left(\frac{\partial \ell_t}{\partial \mathbf{z}_t} \prod_{k + 1 \leqslant  i \leqslant t} \frac{\partial \mathbf{z}_{i}}{\partial \mathbf{z}_{i - 1}} \right)</script><p>从上面的这个式子可知，如果要计算时刻$k$的梯度，那么需要两层循环，内循环处理连乘，外循环处理加和，显然，实际的bptt实现并没有这个复杂，因为$\delta_k$可以用更简洁的形式表达。下面导出这种具体形式。</p>
<p>首先$\delta_k^t$和$\delta_{k + 1}^t$的关系为：</p>
<script type="math/tex; mode=display">
\delta_k^t  = \frac{\partial \ell_t}{\partial \mathbf{z}_k} = \frac{\partial \ell_t}{\partial \mathbf{z}_{k + 1}}  \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} = \delta_{k + 1}^t \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}}</script><p>根据$\delta_{k + 1}$的表达式，对其右乘$\frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_k}$</p>
<script type="math/tex; mode=display">
\begin{align}
\delta_{k + 1} \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} & = \left(\sum_{k + 1\leqslant t \leqslant T} \delta_{k + 1}^t \right) \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} \\
&= \sum_{k + 1\leqslant t \leqslant T} \left(\delta_{k + 1}^t \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} \right) \\ 
& = \sum_{k + 1\leqslant t \leqslant T} \delta_k^t = \sum_{k\leqslant t \leqslant T} \delta_k^t - \delta_k^k \\
& = \delta_k - \delta_k^k 
\end{align}</script><p>因此得到了递推式：</p>
<script type="math/tex; mode=display">
\delta_k = \delta_{k + 1} \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} + \delta_k^k = \delta_{k + 1} \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}}+ \frac{\partial \ell_k}{\partial \mathbf{z}_k}</script><p>上式就是RNN的BPTT在实现时的逻辑，从这里可以更加容易看出时间依赖的本质，注意$\delta_{k + 1} \ne \delta_{k + 1}^{k + 1}$，$\delta_k$表示的是在时刻$t \in [k + 1, T]$，对时刻$\mathbf{z}_{k + 1}$梯度的累积量，而$\delta_{k + 1}^{k + 1}$仅仅表示$\ell_{k + 1}对$$\mathbf{z}_{k + 1}$的梯度。</p>
<p>因此本质上不能理解成$t$时刻输入$\mathbf{x}_t$仅仅会对$\mathbf{h}_t, \mathbf{h}_{t + 1}$产生影响，就此在反向传播的时候将两个时刻产生的梯度相加，因为时间依赖的本质是可以无限延伸的，即沿着时间轴从$T \to 1$传播，这也就是所谓TT：through time的含义。</p>
<p>这里还要提一下RNN的几种常见结构，many-to-one, one-to-one, one-to-many, 和many-to-many，我上面的分析是针对最后一种即从上层网络传递下来的误差向量维度和输入维度保持一致。前面三种现在理解起来也十分容易了。many-to-one就是要将最后时刻（一般是这样）的梯度传递到输入的每个时刻，one-to-many就是将每个时刻的梯度传递到起始时刻，one-to-one只需要将最后时刻传递到起始时刻就行了，即$\delta_1^T$。</p>
<p>再以one-to-one分析一下梯度消失问题，根据上面的解释，可以写出$\delta_1^T$：</p>
<script type="math/tex; mode=display">
\delta_1^T = \frac{\partial \ell_T}{\partial \mathbf{z}_T} \prod_{2 \leqslant  t \leqslant T} \frac{\partial \mathbf{z}_t}{\partial \mathbf{z}_{t - 1}}</script><p>其中</p>
<script type="math/tex; mode=display">
\frac{\partial \mathbf{z}_t}{\partial \mathbf{z}_{t - 1}} = \frac{\partial \mathbf{z}_t}{\partial \mathbf{h}_t} \frac{\partial \mathbf{h}_t}{\partial \mathbf{z}_{t - 1}} = W_h \mathcal{D}(\tanh'(\mathbf{z}_{t - 1}))</script><p>当时间步$T$过大时，矩阵和激活值的连乘很容易导致$\delta_1^T$过大或者过小。过大的解决方法比较简单，目前都采用梯度裁剪的方法（clip gradient）。过小就是所谓的梯度消失问题，RNN无法从训练中获得远距离梯度的更新，也就无法学习到远距离的依赖关系，解决的方法可以是重新设计循环结构，合理初始化权值以及使用合适的激活函数等等。</p>
]]></content>
      <categories>
        <category>DL</category>
      </categories>
      <tags>
        <tag>RNN</tag>
        <tag>BPTT</tag>
      </tags>
  </entry>
  <entry>
    <title>CSA - Clonal Selection Algorithm</title>
    <url>/2017/12/16/csa-presentation/</url>
    <content><![CDATA[<p>吐槽：其实我特别反感老师自己不上课，让学生挨个领任务的这种行为，虽然好（jiu）像（shi）越来越多的老师喜（bian）欢（de）上（yue）这（lai）一（yue）点（lan）了。课下已经是百分之百靠自学，课上想听一下你的观点这么难？好吧，这个题目，其实是我领的任务……本身我也不想准备这个东西，但是恰逢考试周，老刷那些数学题也没啥意思，就花点时间做了个PPT当放松了。</p>
<p>下面进入正题。</p>
<a id="more"></a>
<p>克隆选择算法（Clonal Selection Algorithm，CSA）是依据克隆选择原理提出的一种进化算法。由于借鉴了生物体免疫系统的免疫过程，算法的很多定义和过程都和生物学中的免疫系统类似，比如抗原，抗体，浆细胞之间的关系和作用等等。从免疫过程中我们知道，只有被抗原刺激的抗体才会增殖（克隆）和分化，形成记忆细胞，从而在下次抗原到来时，加速免疫反应。也就是说，和抗原亲和度高的抗原会以更高的概率保留下来，并增殖分化，这就是CSA的核心思想。</p>
<p>应用到具体的问题中，CSA算法中，可以将抗原视为我们要解决的问题，抗体表示问题的解，而抗原和抗体之间的亲和度可以用解的优良程度来表示。后来的生物学家还研究到，抗体会有一种称之为超突变的机制来增强抗体的免疫性，产生所熟知的交叉免疫现象，即增强的抗体的泛化能力，使得其不仅能够免疫之前刺激的抗原，而且可以免疫和其相类似的抗原。</p>
<p>因此，结合亲和性选择和超突变，CSA算法的一般流程如下：</p>
<ul>
<li>生成候选抗体（解）</li>
<li>根据亲和度，选择优秀的抗体克隆</li>
<li>克隆的结果进行超突变</li>
<li>重新选择突变个体，替换亲和度低的个体成为候选抗体</li>
</ul>
<p>在多目标优化（MO）中，算法没有牵扯到抗原这个概念，因为优化函数唯一且确定，因此可以直接定义亲和性函数$\mathcal{F}$，它的输入为抗体编码，输出为亲和度，用$\mathbf{Ab}$表示抗体，这个过程表示如下：</p>
<script type="math/tex; mode=display">
\mathbf{f}_i = \mathcal{F}(\mathbf{Ab}_i)</script><p>算法框架中，抗体$\mathbf{Ab}$需要以编码的形式进行迭代，令抗体个数为$N$，编码长度为$L$，那么$\mathbf{Ab} \in S^{N \times L}$。</p>
<p>根据亲和度选择好克隆对象之后，就要进行克隆和超突变操作，一般是选择最好的若干个抗原（称之为$\mathbf{Ab}_{\{n\}}$）参与克隆和超突变，这个过程可以表示如下：</p>
<script type="math/tex; mode=display">
\mathbf{A}b_j \xrightarrow{\text{clone}} \mathbf{C}_j \xrightarrow{\text{maturate}} \mathbf{C}_j^* \quad \mathbf{C}_j \in S^{N_c \times L}</script><p>$\mathbf{C}，\mathbf{C^*}$表示克隆后和超突变之后的抗体集合。关于克隆的个数$N_c$，一般的，我们希望亲和度越高的个体克隆的越多，在MO问题中，我没有区分对待每一个待克隆抗体，即对$\mathbf{Ab}_{\{n\}}$的个体取相同的克隆个数，令克隆系数为$\beta$，则</p>
<script type="math/tex; mode=display">
N_c = [\beta N]</script><p>之后对超突变的个体进行重新选择生成下一次迭代的候选解形成Loop就是完整的CSA过程了，有的时候考虑到解的鲁棒性，允许随机产生一些抗原进入下一次迭代的候选解中。以上CAS的MO优化过程可以用下面的流程图表示：</p>
<p><img src="http://www.funcwj.cn/images/csa_process.png" width="300"></p>
<p>下面介绍两个实现的重点：</p>
<ul>
<li><p>浮点编码</p>
<p>  之前也提到了，抗原需要根据问题的定义进行编码之后才能参与CSA过程，以便进行突变操作。多目标优化问题中，$\mathbf{x}$表示最优点的位置坐标，因此，需要对浮点数进行编码。对于$L$位编码长度的序列$(b_0, b_1, \cdots, b_{L - 1})，b_i \in \{0, 1\}$，通过如下方式编码成浮点数$z，z \in [0, 1]$：</p>
<script type="math/tex; mode=display">
  z = \frac{\sum_{n = 0}^{L - 1} b_n 2^n}{2^L - 1}</script><p>  之后配合缩放因子$\xi$，生成编码结果$d$：</p>
<script type="math/tex; mode=display">
  d = -\xi + 2 \xi z，d \in [-\xi, \xi]</script><p>  用MATLAB实现如下：</p>
  <figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">x</span> = <span class="title">decode</span><span class="params">(v, L)</span></span></span><br><span class="line">    <span class="comment">% N x L</span></span><br><span class="line">    s = <span class="built_in">size</span>(v);</span><br><span class="line">    <span class="comment">% 1 x L</span></span><br><span class="line">    b = <span class="number">0</span>: <span class="number">1</span>: L - <span class="number">1</span>;</span><br><span class="line">    <span class="comment">% N x L</span></span><br><span class="line">    bs = <span class="built_in">repmat</span>(<span class="number">2</span> .^ b, s(<span class="number">1</span>), <span class="number">1</span>);</span><br><span class="line">    x = <span class="number">-1</span> + sum(v .* bs, <span class="number">2</span>) .* (<span class="number">2</span> / (<span class="number">2</span> ^ L - <span class="number">1</span>));</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<p>  因此，计算亲和度的时候，将编码序列解码成浮点值，进行克隆和超突变的时候，在原编码序列上进行。</p>
</li>
<li><p>超突变</p>
<p>  由于浮点值被编码成二进制序列，因此，突变即在某些位上的值进行翻转，这一操作可以用异或表示，和1取异或会将原值翻转，比如：</p>
<script type="math/tex; mode=display">
  00110010 \; \text{xor} \; 00010001 \to 00100011</script><p>  只要控制生成的mask中1的概率即可，这个概率称为超突变概率$P_{\text{mu}} $。</p>
</li>
</ul>
<p>关于CSA的介绍，demo实现，实验配置和结果，以及我参阅的参考文献请戳<a href="http://www.funcwj.cn/files/CSA.pdf">CSA-WJ-Presentation</a>，代码比较简单我就不贴了。</p>
<p>PPT模板从阿里带回来的…&gt;_&lt;…</p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>CSA</tag>
      </tags>
  </entry>
  <entry>
    <title>Internship in iDST</title>
    <url>/2017/12/05/internship-in-idst/</url>
    <content><![CDATA[<p>来阿里iDST的第三周了，开始的两天在西溪园区里面还是有点晕头转向，不清楚工作区和食堂的结构，乃至于每次吃饭都从七号楼走到二号楼，因为不知道七号楼和八号楼有食堂……大概到了第四天就基本熟悉了，每天装的像个老员工一样上班，开会，吃饭，午休。</p>
<p>老实说，在这里的感觉和学校很相似，毕竟作为一个实习生，没有工作上的压力，也没有正式员工各种项目和各种会。每天和在校一样，跑实验，写代码，带着期待看实验结果……，效率上还是要优于学校的，很多方面原因吧，机器比实验室的好，实验跑的快，任务相关度较高，也没有学校的很多杂事，每天的精神高度集中，倒是每天早上要开个立会。考虑到人员的分布，所谓的立会也就是个电话会议，汇报一下前一天的工作，我的效率自我感觉还可以，每天的进展还是可以保证的。周末我还是照常去公司，我比较喜欢安静吧，周末去公司的员工比较少，一个人待在里面很安静，毕竟工作日的话，淹没在各种讨论，电话之中，心里还是有些不自在的。<br><a id="more"></a></p>
<p>我在这边做一些前端的工作，来之前向老板主动请缨的。说实话，前端我没有多少积累（但是未知对我有很大的吸引力），来之前花了几周时间看相关论文和麦克风阵列，信号处理相关的东西，到这边之后也差不多够用的。其实这边这个组（智能语音交互团队）在前端方面也没有很多技术积累，主要还是偏声学/语言模型的，因此，没有多少可以与之讨论的人，这点比较遗憾（来之前其实想找个大佬带的）。过去两周终于把CHiME4讯飞的前端复现了，中间出一了一点叉子，耽误了一点时间，好在后来check代码的时候发现了，用一个周末把结果跑出来了。</p>
<p>阿里入职之后的麻烦事还是蛮多的，首先就是各种权限问题，机器账户，网址访问，邮件组等等，每次申请都要一批人挨个审核……，大概前三天基本都在解决权限问题，直到上周才算初步搞定权限。实习生配置的是台式机+显示器+键盘+鼠标，这个真是要吐槽了，台式机意味着我只能在公司工作（并不允许使用自己笔记本，想要远程看个实验结果都不行）……键盘，鼠标，罗技，凑合用吧（我下次还是自备吧），显示器标配DELL P2417H，但是配个台式机并没有什么卵用，连个HDMI接口都不给，因为那个台式机上没有……。前一周的工作基本都是用自己笔记本连阿里guest wifi，远程学校机器做的。机器上只能钉钉，我来了之后基本一个教研室同一届的几个人全配合我装上了钉钉，否则他们找不到我，还有一个原因，给我发数据。我是空手来的，之前的数据，代码全在学校机器上，差不多麻烦他们用钉钉给我传了好几个G的数据，然后，MATLAB和Audition，光下载就下了一天（来之前没带安装包，这边又没有ipv6，虽然阿里网速确实快，但是百度云还是慢啊），前一周基本都在解决这些破事，有点心疼时间。</p>
<p>阿里iDTS给我的印象，实话实说吧，来之前以为是个做research的地方，来之后感觉一股浓浓的产品风。总感觉做搞开发（移动端和web）的和iDST的工位混在一起。我软件工程本科，对产品汪的各种讨论到是感觉倍加亲切，尤其某天中午正在午休，突然被一声“你好，电视”惊醒了，我看着那位对着电视debug的前辈，想起了我当年在实验室做KWS Demo的情景，场面一度十分亲切……不过五楼有个AI LIB，不知道那边在搞些什么（PS：iDST对面是咸鱼）。说到我们这个组吧，大部分人还是在搞项目，在实验室其实不太明白KWS这个东西有什么做头，来了之后倒是明白了，产品驱动，入口嘛……</p>
<p>工作压力这边感觉一般吧，大家一般晚八九点走，周末也没有多少人加班，我和团队的人交流不是很多，一点可能是年龄上有差距，大部分人都是85后，要么成家，要么有对象，和我这个还待在学校里面的人关心的东西已经有很大的不同了感觉（可能我这个人care的东西也不是很主流，只想找个地方安心做事）。其次就是团队有人做AM和LM，貌似还有人搞合成，boss应该也是做AM出身，但是搞前端的人不在这个团队内（貌似在西雅图……钉钉上总有时差），因此技术上的交流也不多，这点还是有些失望的。</p>
<p>工作上，把讯飞的CHiME4的Loop复现了，CGMM的效果还是一般，用NN估计mask表现的我这边普遍比CGMM好，其次就是MVDR和GEV的对比上，GEV虽然语音失真比较厉害，但是可以在eval-real这个集合上获得更低的wer，在其他三个集合上表现不如MVDR，我一直觉得四个测试集合音频的性质有差异，经常出现某个集合上变差，另一个集合上变好的现象。讯飞的思路是用VAD信息和IRM修正CGMM的mask，我这边用增强的数据重新算一遍mask和noisy数据的mask做一个combine，也就是说，NN这里扮演着IRM和mask estimator两个角色，VAD方法和讯飞保证一致，今天总算做出gain了，wer降了一个多点，GEV降到6.0%以下，这个结果还是比较正常的。由于目前这个AM是用6ch的noisy数据训练的，所以我对beamforming的结果用IRM做一个单通道的增强，虽然滤去了大部分噪声，但是在wer上是没有gain的，应该是mismatch更大了吧。其实我还想把mask estimator的NN换一个模型，隐式的学习clean/noise的mask，而不是目前的用人工计算的mask作为target，这个实验室他们搞增强的人试过，听说效果不错，可以拿来一试。</p>
<p>学校的考试还有三周，略慌，要开始复习了&gt;_&lt;。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Internship</tag>
      </tags>
  </entry>
  <entry>
    <title>Overview of Beamformer</title>
    <url>/2017/11/11/overview-of-beamformer/</url>
    <content><![CDATA[<p>好久没更……<br>过去一段时间接触了一下beamforming，连看论文加做实验，大概理出了一些头绪。初步理解beamforming就是对多路信号进行频域滤波，从而获取一路增强信号，所谓的增强就是最大可能的滤除噪声，同时保留我们期望的信号。比较经典的方法有：延时相加，Max-SNR，MVDR，GSC（LCMV）等等（详细可学习陈老师的麦克风阵列信号处理[2]一书）。学习期间会接触到一些非常频繁的概念，比如信噪比，相关系数矩阵，PSD（功率谱密度），steer vector，以及一些数学问题的求解方法，比如拉格朗日乘子法，广义特征值等问题，深层次的理解还是需要扎实的统计，矩阵，优化理论基础，相关概念以后可能会写一篇专做解释。</p>
<p>我这里从DS（延迟相加）开始，引入频域beamforming的一般数学模型，再介绍GEV，MVDR，PMWF三种beamformer。虽然我的出发点和实验都是和NN结合来做的，但是本篇里面不牵扯到NN（神经网络）的东西，只说纯粹的信号处理。</p>
<a id="more"></a>
<p>延时相加（DS）方法是最简单的一种波束形成方法。它利用已知是麦克风阵列的拓扑结构，算出不同通道之间的相对延时，通过对多路信号进行时间上的同步和平均操作完成通道合并和增强效果。</p>
<p>对于有$N$个麦克风的阵列，在$t$时刻，麦克风$n(n = {1, 2, \cdots, N})$处收集的信号$y_n(t)$可以表达为：</p>
<script type="math/tex; mode=display">
y_n(t) = x_n(t) + v_n(t)</script><p>$v_n(t)$表示该处噪声，$x_n(t)$表示声源到达麦克风的信号，考虑麦克风之间的空间分布，声源到达麦克风处的衰减和延迟是不同的，引入衰减因子$\alpha_n$和相对延时$\tau_n$，$x_n(t)$可以表示为：</p>
<script type="math/tex; mode=display">
x_n(t) = \alpha_n s(t - \tau_n)</script><p>$s$表示未知的声源信号。首先对多路信号进行延时操作：</p>
<script type="math/tex; mode=display">
y_n'(t) = y_n(t + \tau_n) = \alpha_ns(t) + v_n(t + \tau_n)</script><p>相加取平均获取DS方法的输出$z_{DS}(t)$：</p>
<script type="math/tex; mode=display">
z_{DS}(t) = \frac{1}{N} \sum_{n = 1}^N y_n'(t) = \frac{1}{N}\left[ \left(\sum_{n = 1}^N \alpha_n \right) s(t) + \sum_{n = 1}^N v_n(t + \tau_n) \right]</script><p>令$\alpha_{DS} = \sum_n \alpha_n, v_{DS}(t + \tau_n) = \sum_n v_n(t + \tau_n)$，定义输出信号的SNR：</p>
<script type="math/tex; mode=display">
\text{oSNR} = \alpha_{DS}^2 \frac{E[s(t)^2]}{E[v_{DS}(t + \tau_n)^2]} = \left( \sum_{n = 1}^N \alpha_n \right)^2 \frac{\sigma_s^2}{\sigma_{v_{DS}}^2}</script><p>以$s_1(t)$为参考，定义此处的信噪比：</p>
<script type="math/tex; mode=display">
\text{SNR} = \frac{\sigma_{x_1}^2}{\sigma_{v_1}^2} = \alpha_1^2 \frac{\sigma_s^2}{\sigma_{v_1}^2}</script><p>显然，期望的波束形成结果应该满足$\text{oSNR} &gt; \text{SNR}$。</p>
<p>若$\alpha_i = 1, \sigma_{v_1}^2 = \sigma_{v_2}^2 = \cdots = \sigma_{v_n}^2$且$v_i(t)$之间互不相关（因此不同噪声信号之间的协方差为0），那么：</p>
<script type="math/tex; mode=display">
\sigma_{v_{DS}}^2 = \sum_{n = 1}^N \sigma_{v_n}^2 = N \sigma_{v_1}^2</script><p>故$\text{oSNR} = N \cdot \text{SNR}$。在DS方法中，准确的估计$\tau_n$十分重要，在线阵中，需要知道各个麦之间的间距$d$以及以及声源波面和线阵形成的夹角$\theta$。假设各麦间距相同，那么TDOA计算有简单的几何关系得到：</p>
<script type="math/tex; mode=display">
\tau_n = (n - 1)d \cos(\theta) / c</script><p>其中$c$表示声速。</p>
<p>以上分析是在时域上进行的，上面的各个变量下标为$t$，DS首先需要做的是在时域上进行对齐，之后叠加取均值。若变换到频域，那么$y_n(t) = x_n(t) + v_n(t)$写为：</p>
<script type="math/tex; mode=display">
Y_n(\omega) = X_n(\omega) + V_n(\omega)</script><p>由$x_n(t) = \alpha_n s(t - \tau_n)$：</p>
<script type="math/tex; mode=display">
X_n(\omega) = \alpha_n \cdot X(\omega) \cdot e^{-j\omega\tau_n}</script><p>令：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{y}(\omega) &= [Y_1(\omega), Y_2(\omega), \cdots, Y_N(\omega)]^T \\
\mathbf{d}(\omega) &= [\alpha_1e^{-j\omega\tau_1}, \alpha_2e^{-j\omega\tau_2}, \cdots, \alpha_Ne^{-j\omega\tau_N}]^T \\
\mathbf{v}(\omega) &= [V_1(\omega), V_2(\omega), \cdots, V_N(\omega)]^T
\end{align}</script><p>这里$\mathbf{d}(\omega)$称为steer vector。那么频域关系可以用向量形式描述为：</p>
<script type="math/tex; mode=display">
\mathbf{y}(\omega) = \mathbf{d}(\omega) X(\omega) + \mathbf{v}(\omega)</script><p>在频域上，波束形成是要在每个频率点上操作，完成$\mathbf{y}(\omega)$到$Z(\omega)$的映射，这种映射关系通过设计滤波器$\mathbf{h}(\omega)$实现，即：</p>
<script type="math/tex; mode=display">
Z(\omega) = \mathbf{h}^H(\omega) \mathbf{y}(\omega)</script><p>注意，这里的$Z(\omega)$为数值，而$\mathbf{h}(\omega), \mathbf{y}(\omega)$为向量，实际的操作为：</p>
<script type="math/tex; mode=display">
Z(\omega) = \sum_{n = 1}^N \overline{H}_n(\omega) Y_n(\omega)</script><p>其中，$\mathbf{h}(\omega) = [H_1(\omega), H_2(\omega), \cdots, H_N(\omega)]^T$, $\overline{H}_n(\omega)$表示$H_n(\omega)$的共轭。</p>
<p>从频域来看，DS设计的beamformer应该是：</p>
<script type="math/tex; mode=display">
\mathbf{h}(\omega) = \frac{1}{N} [\alpha_1^{-1}e^{j\omega\tau_1}, \alpha_2^{-1} e^{j\omega\tau_2}, \cdots, \alpha_N^{-1} e^{j\omega\tau_N}]^T</script><p>使得$\mathbf{h}^H(\omega) \mathbf{d}(\omega) = 1$。</p>
<p>更一般的表示，可令$\mathbf{x}(\omega) =  \mathbf{d}(\omega) X(\omega)$，则：</p>
<script type="math/tex; mode=display">
\mathbf{y}(\omega) = \mathbf{d}(\omega) X(\omega) + \mathbf{v}(\omega) =\mathbf{x}(\omega) + \mathbf{v}(\omega)</script><p>带入$Z(\omega)$可知，滤波器同时作用于$\mathbf{x}(\omega)$和$\mathbf{v}(\omega)$：</p>
<script type="math/tex; mode=display">
\mathbf{y}(\omega) = \mathbf{h}^H(\omega) \mathbf{x}(\omega) + \mathbf{h}^H(\omega) \mathbf{v}(\omega)</script><p>一般的可以将作用于前者的结果$\mathbf{h}^H(\omega) \mathbf{x}(\omega)$称为增强信号或者输出信号（desired speech），因为这是我们最终期望的结果，作用后者的结果$\mathbf{h}^H(\omega) \mathbf{v}(\omega)$称为残留噪声（residual noise）。显然，我们期望滤波器对前者产生增强效果，对后者产生削弱效应。</p>
<p>再往下需要补充一个关于PSD（power spectrum density，功率谱密度）的定义，对于复数域的向量$\mathbf{v}(\omega)$，称：</p>
<script type="math/tex; mode=display">
\mathbf{\Phi}_{vv}(\omega) = E[\mathbf{v}(\omega) \mathbf{v}^H(\omega)]</script><p>为$\mathbf{v}(\omega)$的PSD。假设噪声和原始信号之间是不相关的，那么$\mathbf{x}(\omega), \mathbf{v}(\omega), \mathbf{y}(\omega)$之间的PSD满足如下关系：</p>
<script type="math/tex; mode=display">
\mathbf{\Phi}_{yy}(\omega) = \mathbf{\Phi}_{xx}(\omega) + \mathbf{\Phi}_{vv}(\omega)</script><p>对于$Z(\omega) =  \mathbf{h}^H(\omega) \mathbf{y}(\omega) =  \mathbf{h}^H(\omega) \mathbf{x}(\omega) +  \mathbf{h}^H(\omega) \mathbf{v}(\omega)​$，有：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{\Phi}_{zz}(\omega) &= \mathbf{h}^H(\omega) \mathbf{\Phi}_{yy}(\omega) \mathbf{h}(\omega) \\
&= \mathbf{h}^H(\omega) \mathbf{\Phi}_{xx}(\omega) \mathbf{h}(\omega) + \mathbf{h}^H(\omega) \mathbf{\Phi}_{vv}(\omega) \mathbf{h}(\omega)
\end{align}</script><p>在每个频率点$\omega​$上，定义一个局部信噪比（local SNR）:</p>
<script type="math/tex; mode=display">
\text{SNR}(\omega) = \frac{E \left[|\mathbf{h}^H(\omega) \mathbf{x}(\omega)|^2 \right]}{E\left[|\mathbf{h}^H(\omega) \mathbf{v}(\omega)|^2\right]} = \frac{\mathbf{h}^H(\omega) \mathbf{\Phi}_{yy}(\omega) \mathbf{h}(\omega) }{\mathbf{h}^H(\omega) \mathbf{\Phi}_{vv}(\omega) \mathbf{h}(\omega) } - 1</script><p>所谓GEV（Generalized Eigenvalue Decomposition） beamformer，就是要设计一个滤波器$\mathbf{h}(\omega)$，使得在频率点$\omega$处$\text{SNR}(\omega)$达到最大，即：</p>
<script type="math/tex; mode=display">
\mathbf{h}_\text{GEV}(\omega) = \arg \max_{\mathbf{h}} \text{SNR}(\omega)</script><p>称之为GEV，是因为该极值求解问题是一个瑞利商问题，可以用广义特征值来求解，即$\mathbf{h}_\text{GEV}(\omega)$实际上就是$\mathbf{\Phi}_{vv}^{-1}(\omega)\mathbf{\Phi}_{yy}(\omega)$最大特征值对应的特征向量。在编程实现的时候，遍历每一个$\omega$就可以得到每个频率上对应的滤波系数了。</p>
<p>接下来引入使用非常广泛的一种波束形成方法：MVDR（Minimum Variance Distortionless Response ）。它通过最小化残留噪声的能量，同时约束期望（方向）的信号不失真来实现。</p>
<p>引入GEV的过程中，通过$\mathbf{x}(\omega)$将$\mathbf{d}(\omega) X(\omega)$整体看待，在DS中，$\mathbf{d}(\omega)$（steer vector）描述的是衰减因子和延时的综合作用，现在推广它的含义，用$\mathbf{d}(\omega)$描述声源到每一个麦克风的转移方程，那么：</p>
<script type="math/tex; mode=display">
Z(\omega) = \mathbf{h}^H(\omega) \mathbf{y}(\omega) = \mathbf{h}^H(\omega)\mathbf{d}(\omega) X(\omega) + \mathbf{h}^H(\omega) \mathbf{v}(\omega)</script><p>MVDR的求解问题可以表示为：</p>
<script type="math/tex; mode=display">
\mathbf{h}_\text{MVDR}(\omega) = \arg \min_{\mathbf{h}} E\left[ |\mathbf{h}(\omega)^H \mathbf{v}(\omega)|^2\right] \;\text{s.t} \;\;\mathbf{h}(\omega)^H \mathbf{d}(\omega) = 1</script><p>约束条件$\mathbf{h}(\omega)^H \mathbf{d}(\omega) = 1$可以保证MVDR滤波器在满足转移方程$\mathbf{d}(\omega)$的方向或者条件下，增强的信号不失真。同时也表示$\mathbf{d}(\omega)$需要估计或者已知。用拉格朗日乘子法得到$\mathbf{h}_\text{MVDR}$的数学表达式：</p>
<script type="math/tex; mode=display">
\mathbf{h}_\text{MVDR} = \frac{\mathbf{\Phi}_{vv}^{-1}(\omega) \mathbf{d}^H(\omega)}{\mathbf{d}^H(\omega)\mathbf{\Phi}_{vv}^{-1}(\omega) \mathbf{d}^H(\omega)}</script><p>现在可以对MVDR的约束条件加以推广，MVDR约束信号不失真通过转移方程或者steer vector完成，约束residual noise通过获取最小化能量完成。如果定义一个参考信号/麦克风（reference microphone ）$r$，那么衡量信号的失真程度可以通过误差$\epsilon_r(\omega)$进行：</p>
<script type="math/tex; mode=display">
\epsilon_r(\omega) = X_r(\omega) - \mathbf{h}^H(\omega)  \mathbf{x}(\omega) = [\mathbf{u}_r - \mathbf{h}(\omega)]^H \mathbf{x}(\omega)</script><p>其中$\mathbf{u}_r = [0_1, 0_2, \cdots, 1_r, 0_{r + 1}, \cdots, 0_N]^T​$用于选择出第$r​$路参考信号。</p>
<p>仿照MVDR，写下约束优化问题：</p>
<script type="math/tex; mode=display">
\mathbf{h}(\omega) = \arg \min_{\mathbf{h}} E \left[ |\mathbf{h}^H(\omega) \mathbf{x}(\omega)|^2\right] \; \text{s.t} \;\; E\left[\epsilon_r(\omega)^2 \right] \leqslant \sigma^2(\omega)</script><p>该问题的解称之为PMWF（Parameterized Multichannel Wiener Filter ）:</p>
<script type="math/tex; mode=display">
\mathbf{h}_\text{PMWF}(\omega) = \left[\mathbf{\Phi}_{xx}(\omega) + \beta \cdot \mathbf{\Phi}_{vv}(\omega)\right]^{-1} \mathbf{\Phi}_{xx}(\omega)\mathbf{u}_r</script><p>$\beta = 1 / \gamma$，其中$\gamma$是拉格朗日乘子。利用$\mathbf{\Phi}_{xx}(\omega)$的秩为1（因为$\mathbf{\Phi}_{xx}(\omega) = \Phi_{ss}(\omega)\mathbf{d}(\omega)\mathbf{d}^H(\omega)$），可将解化简为以下形式：</p>
<script type="math/tex; mode=display">
\mathbf{h}_\text{PMWF}(\omega) = \frac{\mathbf{\Phi}_{vv}^{-1}(\omega)\mathbf{\Phi}_{xx}(\omega)}{\beta + \lambda(\omega)} \mathbf{u}_r</script><p>其中$\lambda(\omega) = \text{tr}[\mathbf{\Phi}_{vv}^{-1}(\omega)\mathbf{\Phi}_{xx}(\omega)]$。其中的数学推导可以参见[1]。</p>
<p>从编程的角度说，获取到不同beamformer的滤波系数$\mathbf{h}(\omega)$之后，就可以对多路的麦克风信号进行滤波和重建。假设谱中有$F$个频率点（bin），麦克风数量为$N$个，语音段帧数为$T$，在频率$f$上，滤波操作为：</p>
<script type="math/tex; mode=display">
\mathbf{s}(f)_{1 \times T} = \mathbf{h}(f)_{1 \times M} \mathbf{X}(f)_{M \times T}</script><p>遍历频率bin一次就可以得到滤波后的频谱$S_{F \times T}$，使用重叠相加即可对其进行重建。同样，计算PSD的时候，不同频率点之间的计算是完全不相关的，在每个频率上，将通道视为随机变量，计算相关系数矩阵，得到$R(f)_{M \times M}$即为PSD。</p>
<p>参考文献：</p>
<p>[1]. On Optimal Frequency-Domain Multichannel Linear Filtering for Noise Reduction<br>[2]. Microphone Array Signal Processing<br>[3]. Blind Acoustic Beamforming Based on Generalized Eigenvalue Decomposition<br>[4]. Performance Study of the MVDR Beamformer as a Function of the Source Incidence Angle</p>
]]></content>
      <categories>
        <category>Microphone Array Processing</category>
      </categories>
      <tags>
        <tag>Multi-channel</tag>
        <tag>Beamformer</tag>
        <tag>MVDR</tag>
        <tag>GEVD</tag>
      </tags>
  </entry>
  <entry>
    <title>Deep RNN in Acoustic Model</title>
    <url>/2017/10/08/deep-rnn/</url>
    <content><![CDATA[<p>话说图像分类那边喜欢把网络往深处设计，语音这边也跟风走势，DeepRNN和DeepCNN接连出现在各种实验论文中。不过在网络成功走向深处之前，它的难点也是疑问在于，不加修正的加深网络层数，并不能获得相应的结果提升。于是各方大佬就进行了各种尝试和改良。截止目前，成功尝试包括以下三种：</p>
<ul>
<li>Highway Network</li>
<li>Residual Network，可以看做HN的特殊情况，ResNet在图像分类上用的很成功</li>
<li>Recurrent Highway Network，中了ICML2017</li>
</ul>
<p>语音这边也基本是拿大佬们成功的实践往声学模型上尝试，也得到了一些识别率上的提升。<br><a id="more"></a></p>
<h3 id="再谈RNN"><a href="#再谈RNN" class="headerlink" title="再谈RNN"></a>再谈RNN</h3><p>这里主要以pytorch为参考，说明一下RNN的输入输出关系以及内在设计思路，从而加深对RNN的理解。对于BaseRNN，GRU，LSTM，我们可以用一个笼统的式子表示其内在变换：</p>
<script type="math/tex; mode=display">
y, s_T = \mathcal{H}(x, s_0)</script><p>$s$表示state，即RNN内在的状态值，这个状态的解释如下：</p>
<ul>
<li>对于BaseRNN和GRU而言，状态表示RNN之前某时刻的输出，即$h_t$，原式可写为：$y, h_T = \mathcal{H}(x, h_0)$</li>
<li>对于LSTM而言，由于cell存储了主要信息，状态表示之前某时刻下的输出和cell值，原式可写为：$y, h_T, c_T = \mathcal{H}(x, h_0, c_0)$</li>
</ul>
<p>$x, y$分别表示$t$时刻的输入和对应的输出。$\mathcal{H}$用来描述不同RNN对输入和状态的一系列操作。如果是LSTM的话，首先计算$i, f, g, o$各个门的值，之后更新cell值$c_t$，给出输出值$h_t$；GRU则计算$r, z$以及候选$\hat{h}_t$，给出$h_t$。</p>
<p>pytorch里面，考虑到批训练准则（min-batch SGD），输入$x$的维度被设计为$[T, N, I]$，分别表示<code>time_steps,batch_size, input_size</code>，其中<code>time_steps</code>的存在由RNN的BPTT训练算法决定。与此对应的输出维度为$[T, N, O]$。$s_t$则记录下了每一个batch对应的每一层的状态值。如果不做sequence训练的话，那么一般是不需要使用$T$时刻的状态值$s_T$的，只需要拿到$y$将其返回给后续网络做输入即可。但是在类似CharRNN的任务中，仍旧需要将$T$时刻的状态传递下去，作为初始的$s_0$输入，这时候状态这个量就起到相应的作用了。</p>
<p>以上这个过程是一个高度封装的结果，因为它既包含了时间轴上的展开，也包含了层间的传递，深入一点，即如何做时间展开（定义在<code>Recurrent</code>中），层与层之间如何堆叠传递（定义在<code>StackedRNN</code>中，实际上是在每一层中依次做的时间展开），可以参考pytorch的源码，RNN这部分代码主要分布在如下几个地方：</p>
<ul>
<li><code>pytorch/torch/nn/_functions/thnn/rnn.py</code>：实际定义了RNN的各种cell和层次封装</li>
<li><code>pytorch/torch/nn/_functions/backends</code>：1和3之间的grue</li>
<li><code>pytorch/torch/nn/_functions/modules/rnn.py</code>：最外层的封装，核心调用<code>backends.RNN</code></li>
</ul>
<h3 id="Deep-RNN"><a href="#Deep-RNN" class="headerlink" title="Deep RNN"></a>Deep RNN</h3><p>定义$h_l^t$表示DeepRNN中第$l$层$t$时刻的输出，$s_l^t$为第$l$层$t$时刻的状态，那么依据StackRNN的前一层的输入作为后层输入的关系，有：</p>
<script type="math/tex; mode=display">
h_l^t = \mathcal{H}(h_{l - 1}^t, s_l^{t - 1})</script><p>从上式可以看出，$l - 1$层的输入信息是无法直接到达下一层的。网络走向Deep的方案之一就是通过创建一条旁路（skip connection），允许输入通过，直接汇入输出中，这就是所谓的Highway Network（高速路网络，HWN）和Residual Network（残差网络， ResNet）的设计思路。通用的表示如下：</p>
<script type="math/tex; mode=display">
h_l^t = h_{l - 1}^t \odot w_i + \mathcal{H}(h_{l - 1}^t, s_l^{t - 1}) \odot w_o</script><p>HWN的形式更加通用一些，它允许网络动态的学习,权衡两者的权值$w_i, w_o$，即用一层仿射变换定义权值：</p>
<script type="math/tex; mode=display">
h_l^t = h_{l - 1}^t \odot C(h_{l -1}^t) + \mathcal{H}(h_{l - 1}^t, s_l^{t - 1}) \odot T(h_{l -1}^t)</script><p>也可以减少一部分学习参数，将$C$用$1 - T$来表示。ResNet可以看做HWN的一种特殊形式，即$C = T = 1$：</p>
<script type="math/tex; mode=display">
h_l^t = h_{l - 1}^t  + \mathcal{H}(h_{l - 1}^t, s_l^{t - 1})</script><p>强制网络的输出学习$\mathcal{F} - h_l^t$，其中$\mathcal{F}$表示我们期望的结果。Interspeech2017上谷歌有一篇文章（相关文献[5]）对比了两种跳转方案的优劣，发现HWN的学习能力强大一些。</p>
<p>LSTM的情况可能要特殊一点，因为除了和RNN&amp;GRU共有的$h$之外，自己还有一个细胞状态$c$。我个人觉得如果按照上面的框架只考虑输出状态也是可行的，毕竟LSTM的输出也是读取了cell的结果。HW-LSTM和Res-LSTM的设计和应用可以参见相关文献[4]，[6]。</p>
<p>在[4]中，LSTM的cell之间被加入了一个称为gated connection的东西$d$，将其用于修正LSTM中$c$的计算逻辑，即联通相邻层的cell。标准的LSTM，$c_t$计算逻辑如下：</p>
<script type="math/tex; mode=display">
c_t^l = f_t^l \odot c_{t - 1}^l + i_t^l \odot g_t^l</script><p>其中</p>
<script type="math/tex; mode=display">
g_t^l = \tanh(\mathbf{W}^l_{xg} x_t^l +\mathbf{W}^l_{hg}h_{t-1}^l + b_g)</script><p>上面的公式加上上标$l$是为了和HW-LSTM做对比。标准的LSTM仅仅允许$l$层的输出作为下一层的输入，不允许层间cell的信息流动。HW-LSTM添加了这种流动路径，将其修改为：</p>
<script type="math/tex; mode=display">
c_t^l = d_t^l \odot c_t^{l-1} + f_t^l \odot c_{t-1}^l + i_t^l \odot g_t^l</script><p>从上面的公式可以看出，$d_t^l$决定了下一层cell信息流动到当前层的量，值有下式给出：</p>
<script type="math/tex; mode=display">
d_t^l = \sigma(\mathbf{W}_{xd}^l x_t^l + \mathbf{w}_{cd}^l \odot c_t^{l - 1} +\mathbf{w}_{ld}^l \odot c_t^l + b_d)</script><p>文章中的示意图如下，红色区域即为添加的用来允许cell之间信息流动的connection：</p>
<p><img src="http://www.funcwj.cn/images/HW-LSTM.JPG" alt="HW-LSTM"></p>
<p>[6]中所谓Res-LSTM的设计就没有考虑cell之间的信息流动，仅仅在输出门上加了shortcut路径。不考虑Project层的话，输出$h_t$由$o_t \odot \tanh(c_t)$变为$h_t = o_t \odot (\tanh(c_t) + x_t)$。如果考虑Project层，那么考虑到project之后的维度和LSTM输入的维度未必保持一致，因此需要给$x_t$乘一个变换矩阵$\mathbf{W}_H$，即：</p>
<script type="math/tex; mode=display">
h_t = o_t \odot (\mathbf{W}_p p_t + \mathbf{W}_H x_t)</script><p>以上主要是通过HWN和ResNet使得RNN变得Deeper，ICML2017上出现了一种新的结构，循环高速网络，针对RNN提出的加深方案。</p>
<p>Recurrent Highway Networks（简称RHN吧）中定义了一种新层：RHN层，并将该层的深度称为Recurrent Depth（简称RD）。对于RD为$L$的RHN层而言，它由一层RNN层和$L - 1$层HW层构成，若$L = 1$，那么所谓的RHN就和传统的RNN一致了，论文中配的单层RHN示意图如下：</p>
<p><img src="http://www.funcwj.cn/images/recurrent-highway-networks.JPG" alt="RHN-structure"></p>
<p>图中的$C,T,H$均表示激活变换（先进行仿射变换，再输入激活函数），输入有箭头的指向决定。可以看出，实际只有第一层输入了上一时刻的历史信息，但是每一层都有HW的逻辑在里面，最后一层的输出作为下一时刻第一层的输入。可以这么理解，传统的RNN保留当前层的输出作为自己的状态值，RHN允许RNN层的输入继续传递若干个HW层的输出作为状态值保留。</p>
<p>对于$l(l &gt; 1)$层而言，输出$s_l^t$可以表达为：</p>
<script type="math/tex; mode=display">
s_l^t  = s_{l-1}^{t} \odot T( s_{l - 1}^{t}) + H(s_{l - 1}^{t}) \odot T(s_{l - 1}^{t})</script><p>$l = 1$时：</p>
<script type="math/tex; mode=display">
s_1^t  = s_{L}^{t - 1} \odot T(x_1, s_{L}^{t - 1}) + H(x_1, s_{L}^{t - 1}) \odot T(x_1, s_{L}^{t - 1})</script><p>以上所说只是一层RHN层，只是这一层里面有着$L$层的HW层。增大网络深度可以从增大RD和增加RHN层层数两个角度入手，在相关文献[5]中发现，堆叠RHN层比增大RD在近似参数量下更加有效（堆叠RHN引入了更多的Recurrent成分）。</p>
<h3 id="相关文献"><a href="#相关文献" class="headerlink" title="相关文献"></a>相关文献</h3><p>[1]. <a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf" target="_blank" rel="noopener">Deep residual learning for image recognition</a><br>[2]. <a href="https://arxiv.org/pdf/1505.00387.pdf" target="_blank" rel="noopener">Highway Networks</a><br>[3]. <a href="https://arxiv.org/abs/1607.03474" target="_blank" rel="noopener">Recurrent highway networks</a><br>[4]. Highway long short-term memory RNNS for distant speech recognition<br>[5]. Highway-LSTM and Recurrent Highway Networks for Speech Recognition<br>[6]. Residual LSTM: Design of a Deep Recurrent Architecture for Distant Speech Recognition </p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title>CNN in Acoustic Model</title>
    <url>/2017/10/07/CNN-for-ASR-1/</url>
    <content><![CDATA[<p>ASR这块的CNN&amp;RNN大约从13年开始就已经被陆续玩烂了。从CLDNN之后，最近几年貌似在深度和端到端上更加引人关注，例如DeepRNN（Highway, Residual等等）声学建模，DeepCNN的前端增强，前段时间看了一下Interspeech的论文，发现声学模型这块RNN和E2E明显成为两大热门专题。我之前看过KWS和解码的一些东西，没有过多的花精力在声学模型上。因此，也一直想多搭搭模型，跑跑实验，测测WER。<br><a id="more"></a></p>
<p>我想将声学模型这块任务从kaldi迁移到pytorch/tensorflow上，理由是自己可以多了解一些流程上的具体工作。kaldi的强大在于，它从前端的特征提取，数据准备，语料对齐，到声学模型的训练，后期的解码，提供了整套的服务。但是问题是，很多人跑完脚本之后，并不知道我这个模型的输入构建，以及训练流程具体是怎么进行的，除非细致的看一下代码。我个人认为这对学习者而言不是什么好事。因此考虑切换工具，自己把控数据格式，模型搭建和训练流程。</p>
<p>这里先说一下CNN。</p>
<h3 id="CNN概述"><a href="#CNN概述" class="headerlink" title="CNN概述"></a>CNN概述</h3><p>卷积这个操作在信号领域本身就是含有特殊意义的，传统的方法可以人工设计一个滤波器（高通/低通/带通之类的）对输入信号进行信息/特征提取或者过滤，它不像仿射变换，很难理解它在实际问题中到底做了什么。比如在图像中，高通滤波可以检测出图片的边缘信息，这就可以理解成一种图像特征（边缘特征）。检测出这种特征的滤波器当然不止一种，边缘检测这块就有Roberts，Sobel，Prewitt等等算子（具体可以参见冈萨雷斯的数字图像处理，本科的东西有点忘了）。 CNN的卷积层就可以理解为一组（假设为$N$）这样的滤波器，分别对输入信号进行卷积（根据输入的维度，可以是一维/二维的），得到$N$组特征。CNN的训练就是要训出这样的一组滤波器。 使得在这组滤波特征之上，配合激活，池化，以及feed后续网络层的操作使得模型分类/回归效果最佳。</p>
<p>实际网络输入都是离散化（经过采样）的值，因此所谓的卷积均为离散形式。记得在数字信号里面，解释卷积是这么回事：</p>
<blockquote>
<p>信号$A$和$B$卷积，将$B$翻转，从左往右的逐步移动，每移动一次，计算对应位置的乘积之和，直到两者完全不相交为止</p>
</blockquote>
<p>这个时域上的翻转比较难理解，但是如果$B$是卷积核，又是对称的，那么解释卷积就变成了模板操作，即将卷积核/模板$B$在$A$上移动，在$A$被$B$覆盖的区域内（感受野）两者对应相乘。所以实际操作中并不考虑这个翻转操作。也可以这么理解，CNN训练之前，各个滤波器/卷积核/模板都是未知的，卷积的时候不做翻转，那么最终训出的结果就是翻转之后的结果，道理是一样的。另外需要注意的是，信号里面的卷积默认做padding的，即超出被卷信号$A$的时长部分按照0处理，因此卷积之后的结果一定比原来信号时长长，我记得好像有个结论$M+N-1$之类的。但是CNN里面的卷积（以二维为例），如果设置padding大小，那么卷出来的结果是越来越小的。</p>
<p>因此卷积这一步有如下概念：</p>
<ol>
<li>卷积核大小</li>
<li>卷积核移动步长，即每次在特定方向上移动多少步</li>
<li>是否要做边缘padding，是否要边缘补充0</li>
</ol>
<p>类似的，池化操作也有以上概念。池化层相当于一组特征的滤波器/卷积核，它对输入进行特定的变换，比如取最大（maxpool）或者取平均（avgpool）等等。池化层的作用在于减少信息冗余量，提高特征鲁棒性。CNN设计者认为卷积层之后的结果在空间上是具有variation的，对相邻区域的特征进行将采样，可以减少这种variation带来的不稳定性。另外池化层需要放在激活层之后。</p>
<p>在设计CNN的时候，需要关注输入输出信号之间的大小关系，定义在某方向上的卷积核大小为$N_k$，移动步长为$N_s$，padding长度为$N_p$，该方向上输入信号长度为$N_i$，那么对应方向上输出长度$N_o$由下式得出：</p>
<script type="math/tex; mode=display">
N_o = \text{floor}((N_i + 2N_p - (N_k - 1) - 1) / N_s + 1)</script><p>如果要保证输入输出信号大小不发生变化，那么保证$N_s = 1$，$N_p = (N_k - 1) / 2$。</p>
<p>CNN这块还有一个信道（channel）的概念，比如语音信号中的delta，图像的RGB等等。假设输入为3个信道，那么$N$个卷积核产生的特征个数是$3N$还是$N$？我的理解还是$N$，只不过卷积需要在三个信道上进行，并将对应的结果相加，表示如下：</p>
<script type="math/tex; mode=display">
O_i = \sigma \left(\sum_j^J I_j * W_{ji} \right)</script><p>其中$J$表示输入信道个数，$I,O$表示输入输出，$W_{ij}$表示输入信道$i$和输出信道$j$之间的卷积核。</p>
<p>补充，<a href="https://github.com/vdumoulin/conv_arithmetic" target="_blank" rel="noopener">Github上关于卷积的一个可视化</a></p>
<h3 id="CNN-in-ASR"><a href="#CNN-in-ASR" class="headerlink" title="CNN in ASR"></a>CNN in ASR</h3><p>首先需要说明，CNN在语音中被设计来降低频域的variation（时域的variation是用HMM来建模）的，因此很多声学模型中的CNN仅仅在输入特征的频率轴上进行卷积（已经有实验验证，在频率轴上卷积的效用更大一些。频率轴卷积是什么意思后面给出自己的理解）。故输入CNN的特征不可以是MFCC（因为其中做了iFFT，破坏了频谱的局部相关性），只能是谱特征以及其衍生特征比如FBANK等等。通过语谱图可以知道，同一个音素的发音在各个频率的分布是有规律的，但是不同的人，不同的性别在频率轴上的共振峰会有shift。通过卷积和池化操作可以降低这种shift带来的影响，相当于提取了一个更加鲁棒的特征。</p>
<p>其次，就是卷积这个操作的参数量很少，对于$N$个卷积核，一层仅仅会产生$N \times K_x \times K_y$个参数，因此在移动终端设备上的应用前景很大（模型复杂度低，计算量少，不同卷积之间可以并行等等）。CNN常见的使用方式是通过卷积层提取鲁棒特征，作为后续的全连接层的输入。</p>
<p>图像自然就是二维的，语音的基本单位为帧，一帧特征对应的只是向量，输入CNN的话，取一个时间窗$T$内的特征构成二维的频谱图$F_{B \times T}$。我对进行频率轴上的卷积的理解如下：</p>
<p>即卷积核的长度和时间窗保持一致，宽度自定（也就是指定的filter_size），移动仅仅在频率轴上进行。这样实际上卷积的结果是一个向量。而如果在时间轴也进行卷积，那么卷积核的大小均可以自定，卷积产生一个矩阵。</p>
<p>但是在文献[4]中提出了两种组织方式，这里以40维FBANK特征来说明：</p>
<ol>
<li>组织成$N$个$T \times F$的矩阵，故进行二维卷积。$N$为feature maps的个数，取决于是否进行delta</li>
<li>组织成$N \times T$个向量，故进行一维卷积。每个向量长度为$F$，$N \times T$为feature maps的个数，取决于是否delta以及上下文的宽度。</li>
</ol>
<p>ASR这边的文献中有几个常见的概念，我的理解如下：</p>
<ul>
<li>feature maps：$N$个卷积核卷积输入信号得到$N$组卷积特征，每一组滤波特征称为一个feature maps，等于卷积层的输出信道数目，可以理解为信道。</li>
<li>feature bands：以40维FABNK特征为例子，每一维上的特征序列称为一个feature band。如果连续多帧，一个feature band对应一个特征向量，单帧仅仅为一个数值。</li>
<li>LWS/FWS（local/full weight sharing）：默认一个卷积核一次卷积操作中保持不变，称为FWS，如果在不同的频率值上允许卷积核变化，称为LWS。</li>
</ul>
<p>沿着频率轴的FWS卷积过程可以参考下图理解，图选自相关文献[2]：<br><img src="http://www.funcwj.cn/images/convolution-along-frequency.PNG" width="500"></p>
<p>CNN在文献[4]中总结的比较全面，[4]和[1]，[2]的第一作者都是一个人，因而可以看做他工作的总结。</p>
<h3 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h3><p>目前在TIMIT语料上简单跑了几组实验，与很多文献不同的是，我的建模单元采用对齐模型(SAT)的1923个pdf，而不是$61 \times 3 = 183$个。评估方法依旧是标准test集合的PER。主要和传统的DNN比较结果（RNN的结果还没有出来）。模型用pytorch训练，解码使用kaldi内置的<code>latgen-faster-mapped</code>命令，将模型后验转为lattice进行PER的打分计算。其中CNN部分的频轴卷积是按照我自己的理解实现的。实验结果如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">MODEL</th>
<th style="text-align:center">PER</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">DNN(3X1024) + BN</td>
<td style="text-align:center">25.3%</td>
</tr>
<tr>
<td style="text-align:center">DNN(4X512) + BN</td>
<td style="text-align:center">24.1%</td>
</tr>
<tr>
<td style="text-align:center">DNN(4X512) + BN + Dropout</td>
<td style="text-align:center">23.8%</td>
</tr>
<tr>
<td style="text-align:center">DNN(4X1024) + BN + Dropout</td>
<td style="text-align:center">23.7%</td>
</tr>
<tr>
<td style="text-align:center">CNN(K10,P6) + DNN(2X512)</td>
<td style="text-align:center">23.1%</td>
</tr>
<tr>
<td style="text-align:center">CNN(K10,P6) + DNN(2X512) + BN + Dropout</td>
<td style="text-align:center">22.7%</td>
</tr>
</tbody>
</table>
</div>
<p>从实验记录中可以看出：</p>
<ol>
<li>BN和Dropout的正面作用。</li>
<li>DNN中深度比宽度更有助于提高识别率。</li>
<li>CNN的声学建模的鲁棒性（参数量最少，但是获得了最低的错误率）。</li>
</ol>
<h3 id="相关文献"><a href="#相关文献" class="headerlink" title="相关文献"></a>相关文献</h3><p>[1]. <a href="http://ieeexplore.ieee.org/abstract/document/6288864/&amp;hl=zh-CN&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;ei=0EjXWdjBLIS1jwSCnorQCw&amp;scisig=AAGBfm3sg32eAxnNkrdEEWI_LCFG1_--hg" target="_blank" rel="noopener">Applying convolutional neural networks concepts to hybrid NN-HMM model for speech recognition</a><br>[2]. <a href="https://pdfs.semanticscholar.org/655a/e6f82c24e3e01b2b27c56512b06ba36d49c1.pdf&amp;hl=zh-CN&amp;sa=T&amp;oi=gsb-ggp&amp;ct=res&amp;cd=0&amp;ei=_kjXWciYBafajgS1iql4&amp;scisig=AAGBfm0dMFE-emqMrMYpuAXNvTtis2pCSA" target="_blank" rel="noopener">Exploring convolutional neural network structures and optimization techniques for speech recognition.</a><br>[3]. <a href="http://ieeexplore.ieee.org/abstract/document/6639347/&amp;hl=zh-CN&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;ei=KknXWYbGFMbFjwSsyICADQ&amp;scisig=AAGBfm2F0Zlu0ciUwadzshNNm80IQQhuhA" target="_blank" rel="noopener">Deep convolutional neural networks for LVCSR</a><br>[4]. <a href="http://ieeexplore.ieee.org/abstract/document/6857341/&amp;hl=zh-CN&amp;sa=T&amp;oi=gsb&amp;ct=res&amp;cd=0&amp;ei=SEnXWYPOC9DzjgT5uBY&amp;scisig=AAGBfm1PlLteiDuanigiEmvVCvtC99jA3g" target="_blank" rel="noopener">Convolutional neural networks for speech recognition</a></p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title>搭建SSR服务</title>
    <url>/2017/10/02/building-ssr-service/</url>
    <content><![CDATA[<blockquote class="blockquote-center"><font face="consolas">Hello, Google!</font> </blockquote>
<p>本来出发点只是找一个托管blog的server……<br><a id="more"></a></p>
<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>之前的博客是搭在腾讯云上面的，考虑到当时临近毕业，就没有做学生认证。开学之后，没有找到认证入口，提交工单之后却被告知活动取消了，取消了（&gt;_&lt;）……</p>
<p>话说腾讯云的租赁费用对于在校学生而言还是蛮高的，于是就转投阿里云。阿里云的经历也是奇葩，找不到（没有）腾讯云那样的工单系统，几乎全是机器客服，因此出现了一点问题便很难得到及时的答复。具体经历如下：</p>
<ol>
<li>注册阿里云之后，进行学生认证，提示可以从支付宝导入认证信息，但是支付宝上的信息是本科阶段的，目前已经失效，而且无法更改（&gt;_&lt;），所以，只能在阿里云网页端重新认证。</li>
<li>找入学年份竟然没有2017年（&gt;_&lt;）！！！这已经是2017年的九月份了……</li>
<li>估计是开学认证的人多了，过了大约一个星期，入学年份增加了2017一项，进行认证，失败，提示学信网没有我的学业信息……</li>
<li>后来就继续等学信网更新，更新之后，再次注册，还是失败（&gt;_&lt;），无解弃坑……</li>
</ol>
<p>后来又用github的学生优惠想先使用一年的DigitalOcean（简称DO）吧，注册PayPal的时候因为没有信用卡也卡住了（因为需要先充值激活）。</p>
<p>后来发现推荐Vultr的也比较多，加上官网做的清爽，支持支付宝（支付），价格也可以接受，因此就此尝试一下。实际上我在购买的时候新用户的优惠已经没有了，而且最低价的2.5\$的VPS已经售罄，所以选了5\$（一个月三十多）的方案。考虑到毕竟VPS搞到了国外，不做点什么有点遗憾，就此搭一个SS服务，也不需要购买什么VPN的服务了。</p>
<h2 id="SS搭建"><a href="#SS搭建" class="headerlink" title="SS搭建"></a>SS搭建</h2><p>我这个时间段有点不讨巧，随着国家对网络安全的重视，近几个月来已经有一大批VPN提供商销声匿迹（GreenVPN等等），IOS的App Store也做出响应，把相关的软件下架，比如我使用过了Wingy以及大家推荐的什么土豆丝，shadowrocks等等，如果不换换美区的账号下载的话，实际上在iphone上是没法享受自建的服务的。还有就是关于shadowsocks（简称SS）和shadowsockR（简称SSR）的停止更新。目前github上相关的项目也只留下了一个”romoved according to regulations”的提示。话说前端时间这两个作者貌似吵起来了，我竟然没怎么关注……</p>
<p><img src="http://www.funcwj.cn/images/hello-google.png" width="500"></p>
<p>部署服务还是很简单的，网上的一键脚本很多，教程也不少，关于SS和SSR的区别以及概念相关的东西可以参见<a href="https://doub.io/" target="_blank" rel="noopener">DB根据地</a>，这个网站上的东西写的很详细，因此也被墙了。</p>
<p>Vultr节点选区的话，可以看一下网上推荐，如果不确定可以多部署几个，测一下速度再把慢的删掉。实测东京节点ping值100多ms，相比洛杉矶300ms+还是明显要快很多。</p>
<p>我这边主要搭的是SSR服务和优化加速服务，单用户的SSR安装时需要确定端口号和密码，脚本有默认值，他们是需要在客户端使用的，安装完成之后的配置在<code>/etc/shadowsocks.json</code>里面（不同版本的配置文件位置不同）。加速服务一般推荐的是锐速或者BBR。我使用的是bbr，在自动安装的过程中如果遇到不支持的内核会做一个自动的内核更新。两者的安装脚本可以在<a href="https://github.com/teddysun" target="_blank" rel="noopener">teddysun</a>的github上找到。熟悉linux的话安装是没有什么困难的。</p>
<p>BBR装好之后我测试了一下Youtube的1080p播放效果，确实加速明显。虽然我不大可能经常逛这个视频网站，作为一种好奇心理还是确认了一下效果。<br><img src="http://www.funcwj.cn/images/youtube-test.PNG" width="500"></p>
<p>有的时候需要看一下ssr的log，所以还改了一下vps的时间，和本地保持一致。之后就是客户端的问题了。win和mac下的客户端蛮友好的，基本输入服务地址，端口和对应的密码和加密方式之后连接即可，我在使用的时候，这两个平台很快能接入的。我在在学校的主力机是Ubuntu，却一直没有找到方便的客户端（尝试了很多，没有成功）为此暂时转战windows了（考虑可以服务端换成ss，客户端应该方便一点）。</p>
<p>这里没有写的太细，一是因为这方面网上资料很多，过程也很简单，个人感觉不是小白的话，基本都可以轻车熟路。二是考虑敏感话题，尽量少写一点吧。</p>
<h2 id="后续体验"><a href="#后续体验" class="headerlink" title="后续体验"></a>后续体验</h2><p>Google Drive，Gmail，Google Search完美体验，唯一的不爽是谷歌学术访问不了。访问网页的时候，会出现 </p>
<blockquote>
<p>We’re sorry…<br>… but your computer or network may be sending automated queries. To protect our users, we can’t process your request right now.</p>
</blockquote>
<p>的提示，网上多说是因为Vultr的东京和新加坡的ipv4已经被谷歌全部禁调了，我尝试部署了一台洛杉矶的主机，但是卡的要死，所以还是选择坚持东京的主机。</p>
<p>搜了很久，看见网上有人提出强制用ipv6地址访问的方法，亲测有效，才算是解决了这个问题。首先可以使用<code>ping -6</code>得到谷歌学术的ipv6地址，在<code>hosts</code>文件中配置一下，之后重启机器即可（也有说重启服务的）。话说这个问题还是困扰了一天的。</p>
<p>再者就是Dropbox和Google Drive了。在Windows下代理模式设置为全局之后，就可以直接上手了。Mac上的Dropbox可以在Preference里面手动设置一下本地代理，选sock5配置localhost:default_port即可。Google Drive目前没有自动设置代理的功能，可以下载一个Proxifier，配置一下代理，<a href="https://zhineng.li/google/using-google-photos-backup-in-china.html" target="_blank" rel="noopener">比如</a>。关于Proxifier需要说几句，这个Mac下的软件可以为不能够自动检测代理或者不支持sock5代理的软件配置代理规则，比如iTerm（终端github加速），Google Drive这些，因为并不是所有的需求通过浏览器就可以满足。下面记两个参考链接</p>
<ol>
<li><a href="https://www.zybuluo.com/yiranphp/note/611721" target="_blank" rel="noopener">解决mac终端上代理的难题</a></li>
<li><a href="https://www.zybuluo.com/qidiandasheng/note/546822" target="_blank" rel="noopener">Mac全局代理</a></li>
</ol>
<p>后来有一次突然网络断了，发现vps的v4地址Ping不通，数据包到陕西商洛就丢了，考虑到vps还有一个v6地址，那为何不用它来指定主机？。然后就突发奇想，既然v6地址可以直接路由到主机，那何不将校园网下线？在本地主机拥有v6地址的情况下，配合本地的ss代理（代理指定远程ss服务器的v6地址），就可以实现直接实现上网的功能，而无需通过校园网客户端的认证。如果想要机器上的其他软件（Dropbox可以自动检测代理）比如QQ，云音乐也顺利联网，需要借助之前提到的Proxifier工具，强制指定一下转发规则。当然这时ss需要设置成全局模式，唯一的缺陷就是访问国内站点，使用日常软件的话，速度稍慢，但不是太影响体验。vultr日本节点的速度确实可以，全局模式下，IDM下载速度还是足够的。由于自己购买的方案流量足够，因此，可以体验一下避开校园网认证的生活了。</p>
<p>总的来说，5\$的主机资源对于个人还是有点资源过剩，1G内存，25GSSD和1000G/月的带宽用作Web/SSR的Server绰绰有余。还有，博客部署在Vultr上，但是DNS解析还是用的腾讯云，只是把IP换了一下，Vultr也提供了DNS解析服务，我在这里并没有使用。</p>
<p>注：本篇目的仅在于记录SS搭建过程的相关感受，无推销，教唆等不良他意。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>SSR</tag>
      </tags>
  </entry>
  <entry>
    <title>Kaldi中iVector的提取【二】</title>
    <url>/2017/08/29/kaldi-ivector-extract-2/</url>
    <content><![CDATA[<p>本篇接着kaldi中ivector的提取【一】继续分析ivector的在线提取方法。<br><a id="more"></a></p>
<h3 id="特征设计"><a href="#特征设计" class="headerlink" title="特征设计"></a>特征设计</h3><p>在feed模型之前，前端的特征处理操作包括如下：</p>
<ul>
<li>基本的特征提取（PLP，MFCC，FBANK）</li>
<li>拼帧</li>
<li>Delta</li>
<li>线性变换（LDA，PCA）</li>
<li>特征融合（MFCC + Pitch）</li>
<li>归一化（CMVN）</li>
</ul>
<p>在线状态下，由于上述操作必须online的进行，kaldi将上述操作封装成下面几个类，定义在<code>online-feature.h</code>中</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 模板类，提取PLP,MFCC,FBANK特征</span></span><br><span class="line"><span class="comment">// typedef OnlineGenericBaseFeature&lt;MfccComputer&gt; OnlineMfcc;</span></span><br><span class="line"><span class="comment">// typedef OnlineGenericBaseFeature&lt;PlpComputer&gt; OnlinePlp;</span></span><br><span class="line"><span class="comment">// typedef OnlineGenericBaseFeature&lt;FbankComputer&gt; OnlineFbank;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OnlineGenericBaseFeature</span>;</span></span><br><span class="line"><span class="comment">// 在线拼帧</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OnlineSpliceFrames</span>;</span></span><br><span class="line"><span class="comment">// delta</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OnlineDeltaFeature</span>;</span></span><br><span class="line"><span class="comment">// LDA等线性变换</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OnlineTransform</span>;</span></span><br><span class="line"><span class="comment">// 特征拼接:MFCC+Pitch</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OnlineAppendFeature</span>;</span></span><br><span class="line"><span class="comment">// 在线cmvn</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OnlineCmvn</span>;</span></span><br></pre></td></tr></table></figure>
<p>以上特征类继承<code>OnlineFeatureInterface</code> 通过<code>GetFrame(int32, VectorBase&lt;BaseFloat&gt;*)</code>获取特征输出，在构造函数中指定输入源。</p>
<p>比如，在ivector提取中，UBM模型的输入特征需要经过online-CMVN+Splice+LDA，那么最终的特征构造如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// base表示基本声学特征PLP/MFCC/FBANK</span></span><br><span class="line"><span class="comment">// cmvn表示对base做了cmvn的结果</span></span><br><span class="line"><span class="function">OnlineCmvnState <span class="title">naive_cmvn_state</span><span class="params">(info.global_cmvn_stats)</span></span>;</span><br><span class="line">cmvn = <span class="keyword">new</span> OnlineCmvn(info.cmvn_opts, naive_cmvn_state, base);</span><br><span class="line"><span class="comment">// splice_normalized表示对cmvn进行在线拼帧</span></span><br><span class="line">splice_normalized = <span class="keyword">new</span> OnlineSpliceFrames(info_.splice_opts, cmvn);</span><br><span class="line"><span class="comment">// lda_normalized表示对splice_normalized进行在线LDA</span></span><br><span class="line">lda_normalized = <span class="keyword">new</span> OnlineTransform(info.lda_mat, splice_normalized);</span><br></pre></td></tr></table></figure>
<p>可以这么理解这种设计，将<code>OnlineFeatureInterface</code>的基类理解为一个节点，那么制定每个节点之间的输入输出关系，输入节点为原始音频采样数据，调用输出节点的<code>GetFrame()</code>函数即可获得最终的特征，计算逻辑在节点的内部实现。</p>
<p>在<code>ivector-extract-online2.cc</code>中，实现ivector提取的类<code>OnlineIvectorFeature</code>也是<code>OnlineFeatureInterface</code>的基类。调用<code>GetFrame(int32, VectorBase&lt;BaseFloat&gt;*)</code>即可获得截止当前帧的估计ivector。</p>
<p>在ivector提取的过程中，需要用到两种特征</p>
<ul>
<li>Splice + LDA：作为ivector的零阶统计量</li>
<li>CMVN + Splice + LDA：作为UBM的输入，获取后验概率 </li>
</ul>
<p>在<code>OnlineIvectorFeature</code>中，用成员<code>lda_</code>和<code>lda_normalized_</code>表示。</p>
<h3 id="在线估计"><a href="#在线估计" class="headerlink" title="在线估计"></a>在线估计</h3><p><code>OnlineIvectorFeature</code>类内部使用<code>num_frames_states_</code>来追踪上次估计的时间戳，每一次估计首先遍历新增的帧，更新统计量，并以一定的周期提取ivector。这个周期是可以设置的，代码逻辑如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (; num_frames_stats_ &lt;= frame; num_frames_stats_++) &#123;</span><br><span class="line">	<span class="comment">// 更新统计量</span></span><br><span class="line">  	UpdateStatsForFrame(num_frames_stats_, <span class="number">1.0</span>);</span><br><span class="line">  	<span class="comment">// 以一定的周期提取ivector</span></span><br><span class="line">  	<span class="keyword">if</span> (t % ivector_period == <span class="number">0</span>)</span><br><span class="line">      	<span class="comment">// ivector_stats_: OnlineIvectorEstimationStats</span></span><br><span class="line">		ivector_stats_.GetIvector(num_cg_iters, &amp;current_ivector_);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>更新的统计量包括通过UBM获取的后验和Splice+LDA的特征。<code>GetIvector</code>函数内部使用共轭梯度法计算ivector，（没有直接计算ivector）主要考虑这么做可以减少计算耗时。</p>
<p><code>OnlineIvectorEstimationStats</code>类中具体实现ivector的在线估计算法，核心函数是累积统计量的<code>AccStats(IvectorExtractor, VectorBase&lt;BaseFloat&gt;, std::vector&lt;std::pair&lt;int32, BaseFloat&gt; &gt;)</code>和ivector估计函数<code>GetIvector(int32, VectorBase&lt;double&gt;*)</code>。</p>
<p>首先看一下ivector的计算：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">OnlineIvectorEstimationStats::GetIvector</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    int32 num_cg_iters,</span></span></span><br><span class="line"><span class="function"><span class="params">    VectorBase&lt;<span class="keyword">double</span>&gt; *ivector)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line"> 	<span class="keyword">if</span> (num_frames_ &gt; <span class="number">0.0</span>) &#123;</span><br><span class="line">    	<span class="comment">// 也可以这么做得到准确结果</span></span><br><span class="line">    	<span class="comment">// SpMatrix&lt;double&gt; quadratic_inv(quadratic_term_);</span></span><br><span class="line">    	<span class="comment">// quadratic_inv.Invert();</span></span><br><span class="line">    	<span class="comment">// ivector-&gt;AddSpVec(1.0, quadratic_inv, linear_term_, 0.0);</span></span><br><span class="line">    	<span class="keyword">if</span> ((*ivector)(<span class="number">0</span>) == <span class="number">0.0</span>)</span><br><span class="line">      	(*ivector)(<span class="number">0</span>) = prior_offset_;</span><br><span class="line">    	LinearCgdOptions opts;</span><br><span class="line">    	opts.max_iters = num_cg_iters;</span><br><span class="line">    	LinearCgd(opts, quadratic_term_, linear_term_, ivector);</span><br><span class="line">  	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    	ivector-&gt;SetZero();</span><br><span class="line">    	(*ivector)(<span class="number">0</span>) = prior_offset_;</span><br><span class="line">  	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>根据注释部分，ivector提取方式为：</p>
<script type="math/tex; mode=display">
\mathbf{w}' = \mathbf{w} + \mathbf{Q}^{-1}\mathbf{L} \tag1</script><p>$\mathbf{Q}$（<code>quadratic_term_</code>），$\mathbf{L}$（<code>linear_term_</code>）在<code>AccStats</code>中完成估计。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">OnlineIvectorEstimationStats::AccStats</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> IvectorExtractor &amp;extractor,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> VectorBase&lt;BaseFloat&gt; &amp;feature,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::pair&lt;int32, BaseFloat&gt; &gt; &amp;gauss_post)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  	<span class="function">Vector&lt;<span class="keyword">double</span>&gt; <span class="title">feature_dbl</span><span class="params">(feature)</span></span>;</span><br><span class="line">  	int32 ivector_dim = <span class="keyword">this</span>-&gt;IvectorDim(),</span><br><span class="line">    quadratic_term_dim = (ivector_dim * (ivector_dim + <span class="number">1</span>)) / <span class="number">2</span>;</span><br><span class="line">  	<span class="function">SubVector&lt;<span class="keyword">double</span>&gt; <span class="title">quadratic_term_vec</span><span class="params">(quadratic_term_.Data(), quadratic_term_dim)</span></span>;</span><br><span class="line"></span><br><span class="line">  	<span class="keyword">for</span> (<span class="keyword">size_t</span> idx = <span class="number">0</span>; idx &lt; gauss_post.<span class="built_in">size</span>(); idx++) &#123;</span><br><span class="line">      int32 g = gauss_post[idx].first;</span><br><span class="line">      <span class="keyword">double</span> weight = gauss_post[idx].second;</span><br><span class="line">      <span class="keyword">if</span> (weight == <span class="number">0.0</span>)</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      linear_term_.AddMatVec(weight, extractor.Sigma_inv_M_[g], kTrans,</span><br><span class="line">                             feature_dbl, <span class="number">1.0</span>);</span><br><span class="line">      <span class="function">SubVector&lt;<span class="keyword">double</span>&gt; <span class="title">U_g</span><span class="params">(extractor.U_, g)</span></span>;</span><br><span class="line">      quadratic_term_vec.AddVec(weight, U_g);</span><br><span class="line">  	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>离线方法中，$\mathbf{L},\mathbf{Q}$的计算如下：</p>
<script type="math/tex; mode=display">
\mathbf{L}_{R \times 1} = \sum_{c = 1}^C (\mathbf{B}_c^T)_{R \times F} (\mathbf{F}_c)_{F \times 1} \\
\mathbf{Q}_{R \times R} = \sum_{c = 1}^C \mathbf{U}_c\gamma_c + \mathbf{I}</script><p>在线方法中，一帧一帧的以累加形式不算修正：</p>
<script type="math/tex; mode=display">
\mathbf{L}_{R \times 1}' = \mathbf{L}_{R \times 1} +  \sum_{c = 1}^C (\mathbf{B}_c^T)_{R \times F} (p_c \mathbf{x})_{F \times 1} \\
\mathbf{Q}_{R \times R}' =\mathbf{Q}_{R \times R} + \sum_{c = 1}^C  p_c\mathbf{U}_c</script><p>$\mathbf{Q}$被初始化为$\mathbf{I}$。$\mathbf{x}$表示当前输入特征（<code>feature_dbl</code>），$p_c$表示以$\mathbf{x}$为输入的情况下，UBM第$c$个component的后验。$\mathbf{B}_c$和$\mathbf{U}_c$为ivector提取器中的<code>Sigma_inv_M_[g]</code>和<code>U_g</code>。</p>
<p>结合对<code>OnlineIvectorEstimationStats::GetIvector</code>的分析，式子$(1)$可以写成：</p>
<script type="math/tex; mode=display">
\mathbf{w}' = \mathbf{w} + (\mathbf{Q}'_{R \times R})^{-1}\mathbf{L}'_{R \times 1}</script><p>综上所述，考虑到在线方法中的ivector输出周期，因此，一个句子（$T$帧）作为输入往往可以得到$N$个ivector（$N &lt; T$）。</p>
<h3 id="共轭梯度法"><a href="#共轭梯度法" class="headerlink" title="共轭梯度法"></a>共轭梯度法</h3><p>考虑到效率问题，每次计算$\mathbf{w}$的时候都需要对矩阵求逆，共轭梯度法在这里起的作用是在不进行矩阵求逆的操作下求出$\mathbf{Q}\mathbf{w} = \mathbf{L}$的解$\mathbf{w}$，即线性方程组求解问题。</p>
<p>使用共轭梯度法求解线性方程组的思想是将$\mathbf{w}$看成方程：</p>
<script type="math/tex; mode=display">
f(\mathbf{w}) = \mathbf{w}^\top \mathbf{Q} \mathbf{w} / 2 - \mathbf{L}^\top \mathbf{w}</script><p>的驻点。此时$\nabla_w f(\mathbf{w}) = \mathbf{Q}\mathbf{w} - \mathbf{L} = 0$。</p>
<p>定义$\mathbf{d}_1, \mathbf{d}_2$，若满足$\mathbf{d}_1^\top \mathbf{Q} \mathbf{d}_2 = 0$，那么称$\mathbf{d}_1, \mathbf{d}_2$关于$\mathbf{Q}$共轭。令$\mathbf{d}_k$表示迭代第$k$次的搜索方向，那么第$k + 1$次的搜索方向$\mathbf{d}_{k + 1}$为：</p>
<script type="math/tex; mode=display">
\mathbf{d}_{k+1} = - \mathbf{g}_{k + 1} + \beta_k \mathbf{d}_k</script><p>$\beta_{k}$使得$\mathbf{d}_{k + 1}$和$\mathbf{d}_k$关于$\mathbf{Q}$共轭。它的计算可以通过FR和PR算法得到，kaldi中使用的FR算法如下：</p>
<script type="math/tex; mode=display">
\beta_k = \frac{\mathbf{g}_k^\top \mathbf{g}_k}{\mathbf{g}_{k-1}^\top \mathbf{g}_{k - 1}}</script><p>在第$k$步的搜索步长$\alpha_k$使得解从$\mathbf{w}_k$迁移到$\mathbf{w}_{k + 1}$：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{w}_{k + 1} & = \mathbf{w}_k + \alpha_k \mathbf{d}_k \notag \\
\mathbf{g}_{k + 1} & = \mathbf{g}_k + \alpha_k \mathbf{Q} \mathbf{d}_k \notag
\end{align}</script><p>其中$\alpha_k$计算如下：</p>
<script type="math/tex; mode=display">
\alpha_k = \frac{\mathbf{g}_k^\top \mathbf{g}_k}{\mathbf{d}_{k}^\top \mathbf{Q} \mathbf{d}_k}</script><p>共轭梯度法初始化$\mathbf{w}_0$为之前估计的ivector：</p>
<script type="math/tex; mode=display">
\begin{align}
\mathbf{g}_0 &= \mathbf{Q}\mathbf{w}_0 - \mathbf{L} \notag \\
\mathbf{d}_0  &= \mathbf{g}_0 \notag
\end{align}</script><p>之后反复的计算$\mathbf{w}_k,\mathbf{g}_k,\mathbf{d}_k$，直到$\mathbf{g}_k = \mathbf{0}$的时候，$\mathbf{w}_k$即为所求的ivector。</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Kaldi</tag>
        <tag>iVector</tag>
      </tags>
  </entry>
  <entry>
    <title>RNN &amp; LSTM &amp; GRU</title>
    <url>/2017/08/23/rnn-lstm-gru/</url>
    <content><![CDATA[<p>一直觉得RNN是一个可玩性很高的模型，因为现实中我们需要建模的对象往往都可以理解为时间或者空间上的序列（sequence），比如语音，视频，字迹，文本，这种特性极大丰富了RNN处理问题的种类（语言模型，声学模型，机器翻译等等）。一直很火的End-to-End，比如我知道的CTC，RNN-Transducer，Attention（encoder-decoder）也全部based on RNN。既然它可以对序列建模，那么根据不同的输入和输出设计，就可以完成Classification（one-to-one），Embedding（many-to-one），序列生成（one-to-many），seq2seq（many-to-many）等任务。<br><a id="more"></a></p>
<h3 id="RNN的进化"><a href="#RNN的进化" class="headerlink" title="RNN的进化"></a>RNN的进化</h3><p>简单说一下RNN的发展，由于FNN（前馈网络）的结果只依赖于当前输入，而实际处理问题的序列特征往往是上下文相关的，因此融入上下文信息是可以提高模型的准确度的，这一点在FNN中是通过单纯的增加输入信息量完成的。后来就有人提出了将网络隐层上一时刻的输出再次作为输入传递到下一时刻，以此获取所谓的历史信息。考虑到网络节点的信息流走向存在了自环，故称之为RNN（Recurrent，循环）。一开始纯粹的RNN会出现所谓的梯度消失问题无法长久记忆历史信息，为了解决这个问题，1997年Hochreiter &amp; Schmidhuber提出了所谓的LSTM。</p>
<p>后来就是LSTM的不断改进，一开始LSTM的一个记忆块只有输入输出和细胞三个元素，后来在1999年，F.A.Gers et al.等人增加了遗忘门，2003年在各个门和cell之间增加了Peephole Connections，2005年，Graves &amp; Schmidhuber写了一本书《Supervised Sequence Labelling with Recurrent Neural Networks》，里面对LSTM的结构描述如下（虚线表示peephole connections）：<br><img src="http://www.funcwj.cn/images/LSTM.png" width="300"/></p>
<p>再后来，2014年谷歌的Hasim Sak et al.提出在LSTM层之后加上一个project层（如下图表示，recurrent表示recurrent project layer，memory block表示和Graves的是等效的），即LSTMP用于语音识别中；多伦多大学的Cho et al. 提出RNN encoder-decoder框架的时候设计了一种新的隐藏单元GRU，单元中只含有重置门和更新门（reset and update gate），计算复杂度更小。<br><img src="http://www.funcwj.cn/images/LSTMP-illustration.png" width="400"/></p>
<h3 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h3><p>普通RNN涉及到自环和上一时刻的输入，定义$n$隐层的RNN，隐层输入，输出，输入变换矩阵，自环变换矩阵以及偏置向量为$(\boldsymbol{i}_i, \boldsymbol{o}_i, \boldsymbol{W}{i}, \boldsymbol{H}_{i}, \boldsymbol{b}_i)$，激活函数为$\theta$，那么前向传播可以表示为：</p>
<script type="math/tex; mode=display">
\begin{align}
    \boldsymbol{z}_i^t &= \boldsymbol{W}_{i} \boldsymbol{i}_i^t + \boldsymbol{H}_{i} \boldsymbol{o}_{i}^{t - 1} + \boldsymbol{b}_i \notag \\
    \boldsymbol{o}_i^t &= \theta(\boldsymbol{z}_i^t) \notag
\end{align}</script><p>$t$时刻的网络输出$\boldsymbol{y}^t$（$f$为输出层激活函数）表示为：</p>
<script type="math/tex; mode=display">
\begin{align}
    \boldsymbol{z}_o^t &= \boldsymbol{W}_o \boldsymbol{o}_n^t + \boldsymbol{H}_{o} \boldsymbol{o}_n^{t - 1} + \boldsymbol{b}_o \notag \\
    \boldsymbol{y}^t &= f(\boldsymbol{z}_o^t) \notag
\end{align}</script><h3 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h3><p>注：个人觉得一般情况下一个memory block中只含有一个cell，存储一个浮点值（虽然它们的关系是一对多的），所以如果说LSTM层cell个数为$N_c$个，那么意味着该层含有$N_c$个记忆块，用向量表示，该层的各个门和cell的长度均为$N_c$。</p>
<p>参照图1中的信息流，定义输入门，输出门，遗忘门和记忆单元的激活值$\boldsymbol{i}, \boldsymbol{o}, \boldsymbol{f}$, $\boldsymbol{h}$为最终输出，那么，在$t$时刻，各门的激活值和输出由以下各式计算得到：</p>
<script type="math/tex; mode=display">
\begin{align}
\boldsymbol{i}_t &= \sigma(\boldsymbol{W}_{ix}\boldsymbol{x}_t + \boldsymbol{W}_{ih}\boldsymbol{h}_{t - 1} + \boldsymbol{W}_{ic}\boldsymbol{c}_{t - 1} + \boldsymbol{b}_i) \notag \\
\boldsymbol{f}_t &= \sigma(\boldsymbol{W}_{fx}\boldsymbol{x}_t + \boldsymbol{W}_{fh}\boldsymbol{h}_{t - 1} + \boldsymbol{W}_{fc}\boldsymbol{c}_{t - 1} + \boldsymbol{b}_f) \notag \\
\boldsymbol{c}_t &= \boldsymbol{f}_t \odot \boldsymbol{c}_{t - 1} + \boldsymbol{i}_t \odot g(\boldsymbol{W}_{cx}\boldsymbol{x}_t + \boldsymbol{W}_{ch}\boldsymbol{h}_{t - 1} + \boldsymbol{b}_c) \notag \\
\boldsymbol{o}_t &= \sigma(\boldsymbol{W}_{ox}\boldsymbol{x}_t + \boldsymbol{W}_{oh}\boldsymbol{h}_{t - 1} + \boldsymbol{W}_{oc}\boldsymbol{c}_t + \boldsymbol{b}_o) \notag \\
\boldsymbol{h}_t &= \boldsymbol{o}_t \odot h(\boldsymbol{c}_t) \notag
\end{align}</script><p>$\boldsymbol{W}_{*h}$表示peephole connection（对角矩阵），$\sigma, g, h$为对应门的激活函数（一般$h = \tanh$，$g, \sigma$为sigmoid），$\odot$表示逐元素的相乘。project层（如果存在的话）$\boldsymbol{p}_t$由下式得到：</p>
<script type="math/tex; mode=display">
\boldsymbol{p}_t = \boldsymbol{W}_{pr}\boldsymbol{h}_t</script><p>tensorflow里面LSTM的细胞有两个实现版本，LSTMCell和BasicLSTMCell。前者相对丰富一些，可以选择配置peephole，project layer，cell clipping，而后者是没有这些功能的。根据代码注释，BasicLSTMCell参考论文为[7]（LSTM记忆块结构如下），而LSTMCell为Acoustic Modeling那篇。<br><img src="http://www.funcwj.cn/images/LSTM-illustration-in-tensorflow.png" width="400"/></p>
<p>从图中也可以看出，输入输出和遗忘门和cell之间没有peephole connection。这篇文章的重点是提出了一种在LSTM中使用dropout达到正则化效果的建议，即dropout不要在循环信息上作用，仅仅作用在节点的当前输入输出即可。</p>
<h3 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h3><p>GRU（Gated recurrent unit）这个循环单元直观上看起来和LSTM还是有很大差别的，论文中只用了一个很简单的图示就说明了其结构（如下）。单元中仅仅含有一个更新门$z$和重置门$r$。这两个门的计算逻辑也是相同的（类似LSTM的输入输出遗忘三个门），更新门决定了当前的输入结果的影响大小，可以理解为一个权值。两者由下式得出：<br><img src="http://www.funcwj.cn/images/GRU-illustration.png" width="300"/></p>
<script type="math/tex; mode=display">
\boldsymbol{r}_t = \sigma(\boldsymbol{W}_{rx}\boldsymbol{x}_t + \boldsymbol{W}_{rh}\boldsymbol{h}_{t - 1}) \\
\boldsymbol{z}_t = \sigma(\boldsymbol{W}_{zx}\boldsymbol{x}_t + \boldsymbol{W}_{zh}\boldsymbol{h}_{t - 1})</script><p>最终的单元输出$\boldsymbol{h}_t$计算如下：</p>
<script type="math/tex; mode=display">
\boldsymbol{h}_t = (1 - \boldsymbol{z}_t) \odot \boldsymbol{h}_{t - 1} + \boldsymbol{z}_t \odot \phi(\boldsymbol{W} \boldsymbol{x}_t + \boldsymbol{U}(\boldsymbol{r}_t \odot \boldsymbol{h}_{t - 1}))</script><p>更新门作为上一时刻信息的系数，控制着上一时刻到当前时刻的信息流量。如果更新门$\boldsymbol{z}_t \to \mathbf{0}$，那么$\boldsymbol{h}_t$的第二项忽略，该层忽略了当前输入。将$\phi(\boldsymbol{W} \boldsymbol{x}_t + \boldsymbol{U}(\boldsymbol{r}_t \odot \boldsymbol{h}_{t - 1}))$理解为新的状态计算候选值，若$\boldsymbol{r}_t \to \mathbf{0}$，该候选值则相当于遗忘了历史信息的候选值，仅仅依赖当前输入$\boldsymbol{x}_t$。</p>
<p>对比GRU和LSTM，可以发现：</p>
<ol>
<li>LSTM的cell溢出信息被输出门控制，而GRU的单元信息是完全暴露的（可以理解为删除了输出门控）。</li>
<li>LSTM并不直接的从上一时刻中获取信息，而是通过输入门和遗忘门对待选cell值和上一时刻cell值的加权得到的，GRU可以直接通过更新门获取上一时刻信息。</li>
<li>GRU中的信息直接存储在历史状态$h$中，而LSTM存储在cell中。更新门对应遗忘门，重置门对应输入门。</li>
</ol>
<p><img src="http://www.funcwj.cn/images/GRU-LSTM-compare.png" width="500"/></p>
<p>上图是论文[8]中对两种结构单元的对比图，详细的分析和实验对比也可以看一下这篇论文。</p>
<h3 id="相关文献"><a href="#相关文献" class="headerlink" title="相关文献"></a>相关文献</h3><ul>
<li>[1]. Long short-term memory（Hochreiter &amp; Schmidhuber et al.）</li>
<li>[2]. Learning to forget: Continual prediction with LSTM（F.A.Gers et al.）</li>
<li>[3]. Learning precise timing with LSTM recurrent networks（F.A.Gers et al.）</li>
<li>[4]. Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation（Cho et al.）</li>
<li>[5]. Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling（Hasim Sak et al.）</li>
<li>[6]. LSTM: A Search Space Odyssey（Klaus Greff et al.）</li>
<li>[7]. Recurrent Neural Network Regularization（Wojciech Zaremba）</li>
<li>[8]. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling（J Chung et al.）</li>
</ul>
]]></content>
      <categories>
        <category>DL</category>
      </categories>
      <tags>
        <tag>RNN</tag>
        <tag>LSTM</tag>
        <tag>GRU</tag>
      </tags>
  </entry>
  <entry>
    <title>DL中的常见正则化方法</title>
    <url>/2017/08/18/regularization-in-deeplearning/</url>
    <content><![CDATA[<p>平时训练模型的时候知道一些常见的防止过拟合的tricks，但是也只是拿来用一下，比如dropout和BN等等，基本没有了解过why层面的东西。最近看了一下dropout，batch-normalization的论文，以及DeepLearning Book里面正则化那一章，做一下小结。<br><a id="more"></a></p>
<h3 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h3><p>Dropout的提出者（Srivastava etc.）认为使用多个模型的平均结果是十分有效的一种正则化方法，即从不同的模型获取结果进行加权平均。但是它的缺点显而易见，一个是需要大量模型的训练（要么网络架构不同，要么数据集不同），另一个就是较高的计算复杂度（获取输出+平均操作）。Dropout的巧妙之处在于通过它可以在同一个模型上实现类似模型平均的效果。</p>
<p>Dropout是指训练阶段对网络的隐藏节点以一定的概率独立的在网络中丢弃的操作（见下图）。某个节点被丢弃，意味着它的输出输出一并不再存在。丢弃节点之后的网络称为瘦身网络（减少了节点数）。排列组合一下，对于节点数为$N$的网络，其可能存在的瘦身网络为$2^N$个。对于每一批输入数据，反向传播阶段仅仅是对当前采样生成的瘦身网络进行训练，因此从整个网络的训练过程来看，可以认为成是对指数级个子网络的同时训练，而这些网络是共享权值的。</p>
<p><img src="http://www.funcwj.cn/images/dropout-illustration.png" width="500"></p>
<p>如果要等效模型平均，Dropout网络的前向过程（推断）必须具有average的功能。一般的隐层节点的dropout/采样概率$\mathbf{r}_l^i$服从伯努利分布，推断过程进行如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\widehat{\mathbf{x}}_l & = \mathbf{r}_l * \mathbf{x}_l \\
\mathbf{x}_{l + 1} &= f(\mathbf{W}_l \widehat{\mathbf{x}}_l + \mathbf{b}_l)
\end{aligned}</script><p>在DeepLearning Book里面提到了正则化的Bagging方法（多模型结果的加权平均），Dropout可以理解为指数级别集成网络的Bagging方法。</p>
<h3 id="参数正则"><a href="#参数正则" class="headerlink" title="参数正则"></a>参数正则</h3><p>参数正则这里包括$L^1$（promote sparsity）和$L^2$（weight decay）正则，虽然这两个概念经常见到，但是我却在相当长的一段时间内没有去理解其背后的原理。看到DeepLearning Book就顺便和Dropout在一起总结一下了。</p>
<p>参数正则是指对原目标函数$J$加上一个参数相关的惩罚项$\ell$：</p>
<script type="math/tex; mode=display">
J'(\mathbf{w}) = J(\mathbf{w}) + \alpha \ell(\mathbf{w})</script><p>梯度更新变化为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{w}' & = \mathbf{w} - \eta \nabla_w J'(\mathbf{w}) \\
& = \mathbf{w} - \eta \nabla_w J(\mathbf{w}) - \eta \alpha  \nabla_w\ell(\mathbf{w})
\end{aligned}</script><p>一般的正则项只针对网络中的权值（和偏置无关），系数$\alpha$控制惩罚项作用大小。$L^1$和$L^2$正则的$\ell$定义如下：</p>
<script type="math/tex; mode=display">
\ell(\mathbf{w}) = 
\begin{cases}
\Vert \mathbf{w} \Vert_1 = \sum_i \vert w_i \vert & \text{for}\; L^1 \\
\Vert \mathbf{w} \Vert_2^2 = \mathbf{w}^\top \mathbf{w} &
\text{for}\; L^2
\end{cases}</script><p>带入$\mathbf{w}’$：</p>
<script type="math/tex; mode=display">
\mathbf{w}' = 
\begin{cases}
(1 - \eta \alpha)\mathbf{w} - \eta \nabla_w J'(\mathbf{w}) & \text{for}\; L^1\\
\mathbf{w} - \eta \alpha \cdot \text{sgn}(\mathbf{w})- \eta \nabla_w J'(\mathbf{w}) &
\text{for}\; L^2
\end{cases}</script><p>根据DeepLearning Book中的表述，$L^1$正则会产生更加稀疏的解，即权值矩阵中零元素增加，而$L^2$正则不具有这种效果，它会使权重的分布更加接近于原点。</p>
<h3 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h3><p>Batch-Normalization（简称BN）的提出是要解决一个叫Internal Covariate Shift的问题，如果将DNN简单理解成为若干个层级子网络的堆叠，那么网络训练的收敛可以认为是后继网络不断学习其前置网络的数据分布的过程。但是由于学习过程中参数不断变化，各个子网络的分布也会随之变化，由此带来了所谓的Internal Covariate Shift问题。BN的解决思路也比较简单，就是normalize上述层级子网络输入的均值和方差，BN的论文中认为其优势在于：</p>
<ol>
<li>加速网络的收敛，即可以在较小的steps下达到相同的收敛程度（相对于没有BN层）</li>
<li>允许使用较大的学习率</li>
<li>减少对参数初始化的敏感度</li>
<li>减少Dropout的需要</li>
</ol>
<p>之前往往只是对训练数据的分布进行归一化操作，BN相当于是将这种normalize引入了网络中成为独立的BN层，随之而来的问题就是BN层如何设计以及如何训练的问题了。</p>
<p>对于特征$<br>\mathbf{x} \in \mathbf{R}^D$，将输入网络前的归一化操作 $\widehat{\mathbf{x}} = \text{Norm}(\mathbf{x})$：</p>
<script type="math/tex; mode=display">
\widehat{\mathbf{x}}_d = (\mathbf{x}_d - E[\mathbf{x}_d]) / V[\mathbf{x}_d]</script><p>引入网络层间，$\mathbf{x}$即为每个子网络对应的输入。根据论文中的表述，$\widehat{\mathbf{x}}$和$\mathbf{x}$的表征能力并不完全相同，因而引入一个逆操作Scale and Shift，对normalized的特征进行重新表示：</p>
<script type="math/tex; mode=display">
\mathbf{y}_d = \gamma_d\widehat{\mathbf{x}}_d + \beta_d</script><p>其中$\gamma_d, \beta_d$是需要学习的参数。</p>
<p>在SGD框架中，使用一个mini-batch内的数据来预估$E[\mathbf{x}_d]$和$V[\mathbf{x}_d]$，定义batch-size为$m$，那么BN层的变换可以表示为$\text{BN}_{\gamma, \beta}(\mathbf{x}, \mathbf{y})$：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mu_{\mathcal{B}} & = E[\mathbf{x}_{1\cdots m}] \\
\sigma^2_{\mathcal{B}} & = V[\mathbf{x}_{1\cdots m}] \\
\widehat{\mathbf{x}}_i & = \text{Norm}(\mathbf{x}; \mu_{\mathcal{B}}, \sigma^2_{\mathcal{B}}) \\
\mathbf{y}_i & = \gamma \widehat{\mathbf{x}}_i + \beta
\end{aligned}</script><p>训练阶段，已知$\frac{\partial \ell}{\partial \mathbf{y}_i}$，需要计算出$\frac{\partial \ell}{\partial \gamma}, \frac{\partial \ell}{\partial \beta}, \frac{\partial \ell}{\partial \mathbf{x}_i}$（用于BP传递梯度到前一层）：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\frac{\partial \ell}{\partial \gamma} & = \sum_{i = 1}^m \frac{\partial \ell}{\partial \mathbf{y}_i} \widehat{\mathbf{x}}_i \\
\frac{\partial \ell}{\partial \beta} & = \sum_{i = 1}^m \frac{\partial \ell}{\partial \mathbf{y}_i} \\
\frac{\partial \ell}{\partial \mathbf{x}_i} & =
\frac{\partial \ell}{\partial \widehat{\mathbf{x}}_i} \frac{\partial \widehat{\mathbf{x}}_i}{\partial \mathbf{x}_i} + \frac{\partial \ell}{\partial \sigma_{\mathcal{B}}^2}\frac{\partial \sigma_{\mathcal{B}}^2}{\partial \mathbf{x}_i} + \frac{\partial \ell}{\partial \mu_{\mathcal{B}}} \frac{\partial \mu_{\mathcal{B}}}{\partial \mathbf{x}_i} \\
& = \frac{\partial \ell}{\partial \widehat{\mathbf{x}}_i} \frac{1}{\sqrt{\sigma_{\mathcal{B}}^2 + \epsilon}} + \frac{\partial \ell}{\partial \sigma_{\mathcal{B}}^2} \frac{2(\mathbf{x}_i - \mu_{\mathcal{B}})}{m}+ \frac{\partial \ell}{\partial \mu_{\mathcal{B}}} \frac{1}{m}
\end{aligned}</script><p>在训练阶段，参数的更新是依赖当前的batch的，但是单纯的使用模型的时候，必须使得当前输入的结果仅仅依赖当前输入，因此需要解决BN变换中的均值方差估计问题。</p>
<p>BN层的均值方差可以通过对若干个mini-batch处理结果的平均得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
E[\mathbf{x}] & = E_{\mathcal{B}}[\mu_{\mathcal{B}}] \\
V[\mathbf{x}] & = \frac{m}{m - 1}E_{\mathcal{B}}[\sigma^2_{\mathcal{B}}]
\end{aligned}</script><p>对于输入$\mathbf{x}$，使用训练好的参数$\gamma, \beta$和估计好的均值方差，BN层的整体变换可以表示为：</p>
<script type="math/tex; mode=display">
\mathbf{y} = \gamma \cdot \frac{\mathbf{x} - E[\mathbf{x}]}{\sqrt{V[\mathbf{x}] + \epsilon}} + \beta</script><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul>
<li>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</li>
<li>Batch normalization-accelerating deep network training by reducing internal covariate shift</li>
<li>DeepLearning Book</li>
</ul>
]]></content>
      <categories>
        <category>DL</category>
      </categories>
      <tags>
        <tag>Regularization</tag>
      </tags>
  </entry>
  <entry>
    <title>梯度下降中的优化策略</title>
    <url>/2017/08/17/optimization-in-sgd/</url>
    <content><![CDATA[<p>模型训练中的学习率是最重要的超参数之一，目前的学习率优化方法主要有两大类，一类可以在训练过程中定义存在其他动态的超参数参与的调整更新规则，另一类是预先设定的更新（一般是衰减）规则，比如线性衰减，指数衰减等。</p>
<p>min-batch SGD从训练集中随机fetch出大小为m的batch，执行更新规则如下：</p>
<script type="math/tex; mode=display">
\mathbf{g}_t = \nabla_\theta \sum_{i = 1}^m \mathcal{L}(\mathbf{x}_i, \mathbf{y}_i, \theta_t) / m \\
\theta_{t + 1} = \theta_t - \eta \mathbf{g}_t</script><a id="more"></a>
<p>动量法在SGD之上考虑了之前的梯度方向对当前更新梯度的影响，即用动量$\mathbf{m}$来代替梯度更新超参数，动量的计算依赖上一时刻的动量和当前梯度（也可以理解为之前的累计梯度的信息）：</p>
<script type="math/tex; mode=display">
\mathbf{m}_{t + 1} = \mu \mathbf{m}_t + \mathbf{g}_t \\
\theta_{t + 1} = \theta_t - \eta \mathbf{m}_{t + 1}</script><p>动量因子$\mu$可以描述之前累计的梯度对当前梯度的影响，假设在SGD过程中梯度抖动的十分厉害（方向，大小），那么引入动量可以一定程度上对这种抖动起到抑制作用。反之如果保持相对平稳，那么动量可以起到放大梯度的作用（相当于增大步长）。</p>
<p>此外还有一种称为Nesterov动量的变式，在计算$\mathbf{g}_t$时，用的不是参数$\theta_t$，而是施加了动量$\mathbf{m}_t$之后的参数，即：</p>
<script type="math/tex; mode=display">
\mathbf{g}_t = \nabla_\theta \sum_{i = 1}^m \mathcal{L}(\mathbf{x}_i, \mathbf{y}_i, \theta_t -\eta\mu\mathbf{m}_t) / m</script><p>之后再进行$\mathbf{m}_{t + 1}, \theta_{t + 1}$的更新。</p>
<p>下面是三个常见的自适应学习率调整方法，即AdaGrad，RMSProp，Adam：</p>
<h3 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h3><p>AdaGrad每一次会更急累计更新梯度的平方和，对当前得出的梯度矩阵进行缩放。缩放大小反比与该平方和的平方根，即累计损失越多的方向学习率越高：</p>
<script type="math/tex; mode=display">
\mathbf{n}_{t + 1} = \mathbf{n}_t + \mathbf{g}_t^2 \\
\theta_{t + 1} = \theta_t - \;\frac{\eta \mathbf{g}_t}{\sqrt{\mathbf{n}_{t + 1}} + \epsilon}</script><p>注：缩放方式为对应元素的缩放。</p>
<h3 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h3><p>从AdaGrad的更新公式可以看出，累积量$\mathbf{n}_t$在时间轴上是没有加权的，RMSProp丢弃较远的历史信息，将累计平方梯度更新公式变换为：</p>
<script type="math/tex; mode=display">
\mathbf{n}_{t + 1} = \rho\mathbf{n}_t + (1 - \rho)\mathbf{g}_t^2</script><h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>Adam结合了动量和和RMSProp，将动量并入一阶矩的估计，同时加入偏差修正，更新过程如下：</p>
<script type="math/tex; mode=display">
\mathbf{m}_{t + 1} = \mu \mathbf{m}_t + (1 - \mu)\mathbf{g}_t \\
\mathbf{m}_{t + 1}' = \frac{\mathbf{m}_{t + 1}}{1 + \mu^{t + 1}} \\
\mathbf{n}_{t + 1} = \rho \mathbf{n}_t + (1 - \rho)\mathbf{g}_t^2 \\
\mathbf{n}_{t + 1}' = \frac{\mathbf{n}_{t + 1}}{1 + \rho^{t + 1}} \\
\theta_{t + 1} = \theta_t - \;\frac{\eta \mathbf{m}_{t + 1}'}{\sqrt{\mathbf{n}_{t + 1}'} + \epsilon}</script><p>除此之外还有AdaDelta，AdaDec等优化方法在相应的论文中，这里有时间再加上……</p>
<p>一些常用衰减规则主要有：</p>
<ol>
<li>Exponential Scheduling：在nnet2/3中使用的是指数衰减，计算出训练需要的轮数，在设置的初始学习率和终止学习率之间进行指数衰减。</li>
<li>Power Scheduling</li>
<li>Performance Scheduling：一般在测试集上的loss不再下降时（或者满足某种折半条件），将学习率乘以一个decay rate，比如在nnet1中进行折半（乘以0.5）。</li>
</ol>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul>
<li>DeepLearning Book第八章</li>
<li>An empirical study of learning rates in deep neural networks for speech recognition</li>
</ul>
]]></content>
      <categories>
        <category>DL</category>
      </categories>
      <tags>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>Sequence Training in ASR</title>
    <url>/2017/08/13/sequence-training/</url>
    <content><![CDATA[<p>在识别任务中，我们会产生这样的一个疑问，即分类器训练的越充分，是否会带来更高的识别率？从经验上来说不能承认这一点，因为基于CE的分类只是针对frame级别的判别（误差定义在frame上）而识别的本质是一个序列mapping的任务。序列区分性训练尝试在识别序列上定义误差，从这一点上来看，更加接近于识别的最终目标，因而也会相应的获得较高的识别率。</p>
<a id="more"></a>
<p>目前的区分性准则（在kaldi中）主要有MMI（最大互信息），MPE（最小音素错误），MBR（最小贝叶斯风险，一般是state-level的，称为sMBR）。</p>
<h3 id="CE"><a href="#CE" class="headerlink" title="CE"></a>CE</h3><p>将$y_{ut}$定义为softmax层的输出，$\alpha_{ut}$定义为softmax层的输入，网络的每个输出节点对应一个pdf（状态s）的后验：</p>
<script type="math/tex; mode=display">
y_{ut}(s) = \frac{e^{\alpha_{ut}(s)}}{\sum_{s'}e^{\alpha_{ut}(s')}}</script><p>交叉熵的代价函数定义为：</p>
<script type="math/tex; mode=display">
\mathcal{F}_{CE} = -\sum_{t}\sum_{s} p(s)\log y_{ut}(s) \\
= -\sum_{t}\log y_{ut}(s_{ut})</script><p>和交叉熵比较相似的一个概念是相对熵（也称为KL散度），用来衡量两个分布之间的差异（egs. $p, q$）：</p>
<script type="math/tex; mode=display">
D_{KL}(p || q) = \sum_{i} p(i) \log \frac{p(i)}{q(i)} \\
= \sum_{i}p(i) \log p(i) - \sum_{i}p(i) \log q(i)</script><p>其中，$- \sum_{i}p(i) \log q(i)$就是交叉熵：</p>
<script type="math/tex; mode=display">
H(p, q) = - \sum_{i}p(i) \log q(i)</script><p>$p$为真实分布，$q$为网络拟合的分布，网络训练的目标是让$q$的分布接近于$p$，在$p$已知的情况下，$\sum_{i}p(i) \log p(i)$为常数，因此$D_{KL}$和$H$同时取得最小值，因此可用交叉熵来替代KL散度作为目标函数。</p>
<p>执行分类任务时候，先验分布编码为one-hot形式，即$p(s) = \delta_{s, s_{ut}}$，$\delta$为克罗内克函数，$s_{ut}$为句子$u$在$t$时刻的label（类别）索引。因此在表达式$\mathcal{F}_{CE}$中，有</p>
<script type="math/tex; mode=display">
\sum_{s} p(s)\log y_{ut}(s) = \log y_{ut}(s_{ut})</script><h3 id="MMI"><a href="#MMI" class="headerlink" title="MMI"></a>MMI</h3><p>定义特征（观测）序列 $\mathbf{O}_u = \{\mathbf{o}_{u1}, \mathbf{o}_{u2}, \cdots, \mathbf{o}_{uT_u}\}$，$W_u$为句子$u$的抄本序列，$S_u$为在抄本$W_u$下对齐得到的中间状态序列$\{\mathbf{s}_{u1}, \mathbf{s}_{u2}, \cdots, \mathbf{s}_{uT_u}\}$。MMI准则下的目标函数为：</p>
<script type="math/tex; mode=display">
\mathcal{F}_{MMI} = \log \frac{p(\mathbf{O}_u | S_u)^k p(W_u)}{\sum_W p(\mathbf{O}_u | S)^k p(W)}</script><p>显然，MMI是定义在整个句子上的，直观的理解就是要最大化正确解码序列概率在所有可能序列中的占比（关注句子的正确率）。</p>
<h3 id="MPE-sMBR"><a href="#MPE-sMBR" class="headerlink" title="MPE/sMBR"></a>MPE/sMBR</h3><p>延续MMI中的定义，MPE和sMBR的目标函数可以统一用下面的式子表示：</p>
<script type="math/tex; mode=display">
\mathcal{F}_{MPE} = \frac{\sum_W p(\mathbf{O}_u | S)^k p(W) A(W, W_u)}{\sum_W p(\mathbf{O}_u | S)^k p(W)}</script><p>其中$A(W, W_u)$表示以$W_u$为参考，音素（MPE）和状态（sMBR）的正确率。也就是说，它们更加关注解码序列中的音素/状态的正确率。</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Sequence Training</tag>
      </tags>
  </entry>
  <entry>
    <title>对Kaldi中Online-Decoder的分析</title>
    <url>/2017/08/02/kaldi-online-decoder/</url>
    <content><![CDATA[<p>解码是指在构建好的解码网络（图）中，根据输入的音频，生成最优序列的过程。在kaidi中，解码之前，解码网络（实际上是一个巨大的WFST）是已经构建好了的（一般称之为静态解码器），也就是熟知的HCLG。在这张图中，状态节点并无太大意义（毕竟不是自动机），信息存储在状态和状态的转移边之间。输入为tid（tid为0表示没有输入/输入为空$\epsilon$，因而可以连续跳转），输出为词，权值为语言模型的权值。解码过程中，声学模型的后验概率需要实时计算得出（特征+声学模型）。理解解码过程需要弄清以下几个方面：<br><a id="more"></a></p>
<p><img src="http://www.funcwj.cn/images/decoding-shotcut.png" alt="decoding-shotcut.png-163.9kB"></p>
<ul>
<li>解码过程中使用到的数据结构及其拓扑关系</li>
<li>解码过程中的剪枝策略（个人觉得这部分比较抽象）</li>
<li>解码过程中的特征供给</li>
</ul>
<p>下面是以<code>LatticeFasterOnlineDecoder</code>为分析对象的一些记录。</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>解码过程是一帧一帧进行的，在约束图（解码图）中，$t$时刻可以到达的状态必然是由$t - 1$时刻的状态出发的，也就是说，信息流从$t - 1$时刻向$t$时刻传递。如果不考虑效率问题，将每个时刻可能到达的状态按照时间展开，那么就可以得到一颗巨大的树。每一个从根节点到叶子节点的路径都可以理解为一条可能路径，只不过有的出现概率高，有的低而已。</p>
<p>用token表示上述过程中描述的信息，那么每一时刻，每一状态维护一个token，在$t \in [0, T]$时刻，新的一轮token由$t - 1$时刻的token和解码图的路径约束共同形成。kaldi中token用结构体<code>Token</code>来描述，同一时刻的token通过<code>next</code>指针相连，从该时刻可以传递到的状态用<code>ForwardLink</code>描述，前一时刻的token由<code>HashList&lt;StateId, Token*&gt;</code>描述（这是一个kaldi自己实现的模板，其中的Hash元素本质上是使用链表连接的，但是也可以像Hash表一样随机获取），而整个解码过程中每一时刻产生的token（相当于上面说的树）用<code>std::vector&lt;TokenList&gt;</code>描述，下标为当前帧数，<code>TokenList</code>相当于一个<code>Token</code>的链表头，通过它可以依次获取到相应时刻的所有活跃token，具体的成员及其含义如下：</p>
<ul>
<li><p>Token</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Token</span> &#123;</span></span><br><span class="line">    BaseFloat tot_cost;     <span class="comment">// 到该状态的累计cost</span></span><br><span class="line">    BaseFloat extra_cost; </span><br><span class="line">    ForwardLink *links;     <span class="comment">// 也是一个链表，因为由该token可以到达下一时刻的token不止一个</span></span><br><span class="line">    Token *next;            <span class="comment">// 指向同一时刻的下一个token</span></span><br><span class="line">    Token *backpointer;     <span class="comment">// 指向上一时刻的最佳token，相当于一个回溯指针，</span></span><br><span class="line">                            <span class="comment">// 到达该状态的token可能会有很多，但只取最优的一个</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>ForwardLink</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ForwardLink</span> &#123;</span></span><br><span class="line">    Token *next_tok;    <span class="comment">// 这条链接指向的token</span></span><br><span class="line">    Label ilabel;       <span class="comment">// 这下面的四个量取自解码图中的跳转/弧/边，因为每一个状态</span></span><br><span class="line">    Label olabel;       <span class="comment">// 维护一个token，那么token到token之间的连接信息和状态到状态之间的信息</span></span><br><span class="line">    BaseFloat graph_cost;       <span class="comment">// 应该保持一致，所以会有输入（tid），输出，权值（就是graph_cost）</span></span><br><span class="line">    BaseFloat acoustic_cost;    <span class="comment">// acoustic_cost就是tid对应的pdf_id的在声学模型中的后验</span></span><br><span class="line">    ForwardLink *next;          <span class="comment">// 链表结构，指向下一个</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>TokenList</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TokenList</span> &#123;</span></span><br><span class="line">  Token *toks;        <span class="comment">// 同一时刻的token链表头</span></span><br><span class="line">  <span class="keyword">bool</span> must_prune_forward_links;  <span class="comment">// 这两个是Lattice剪枝标记</span></span><br><span class="line">  <span class="keyword">bool</span> must_prune_tokens;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>这几部分的关系可以用下图描述：</p>
<p><img src="http://www.funcwj.cn/images/token-struct.jpg"></p>
<p>另一个重要的数据结构是kaldi中自己实现的<code>HashList</code>，一个类似于跳表的数据结构，里面维护的元素本质上以链表的形式相连，同时通过一个Hash表建立索引。元素和哈希通过<code>Elem</code>和<code>HashBucket</code>实现：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Elem</span> &#123;</span></span><br><span class="line">    I key;      <span class="comment">// State</span></span><br><span class="line">    T val;      <span class="comment">// Token</span></span><br><span class="line">    Elem *tail; <span class="comment">// 链表，指向下一个元素</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">HashBucket</span> &#123;</span></span><br><span class="line">    <span class="keyword">size_t</span> prev_bucket;     <span class="comment">// 指向前一个桶的下标，类似静态链表的索引方法</span></span><br><span class="line">    Elem *last_elem;        <span class="comment">// 指向挂在该桶上的最后一个元素，找到他就可以索引该桶上所有元素了</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>整个哈希结结构存在容器<code>std::vector&lt;HashBucket&gt; buckets_</code>中，通过<code>SetSize()</code>可以分配<code>buckets_</code>的大小。需要注意的是，前一个<code>HashBucket</code>的<code>last_elem.tail</code>指向当前<code>HashBucket</code>的第一个元素。其他重要的变量如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">Elem *list_head_;   <span class="comment">// Elem链表会不断释放，分配，该变量记录链表头部</span></span><br><span class="line">Elem *freed_head_;  <span class="comment">// 记录空闲链表的头部，分配新的Elem就是从该头部取出一个空闲Elem</span></span><br><span class="line"><span class="keyword">size_t</span> bucket_list_tail_;   <span class="comment">// 当前活跃的最后一个桶的下标</span></span><br><span class="line"><span class="keyword">size_t</span> hash_size_;          <span class="comment">// 当前活跃的桶的个数</span></span><br></pre></td></tr></table></figure></p>
<p>该数据结构的操作逻辑如下：</p>
<ol>
<li><p>获取当前活跃的所有元素<code>Elem</code><br>只需要返回<code>list_head</code>即可，通过链表的遍历即可访问到所有活跃元素（即上一时刻的State和对应的Token）。</p>
</li>
<li><p>如何遍历Hash<br>通过<code>bucket_list_tail_</code>获取到最后一个活跃桶下标，通过<code>HashBucket.prev_bucket</code>访问到前一个，直到访问到-1标记结束位为止。</p>
</li>
<li><p>如何清空Hash<br>清空Hash只需要将相应的标记置为“空”即可，不需要实际释放元素内存。对于Hash而言，遍历一遍，将<code>HashBucket.last_elem</code>置为<code>NULL</code>，<code>bucket_list_tail_</code>置为-1，对于<code>Elem</code>而言，将链表头部<code>list_head_</code>置为<code>NULL</code>即可。</p>
</li>
<li><p>如何删除元素<br>将需要删除的元素从<code>list_head_</code>中插入到<code>freed_head_</code>中，采用头插法（插入<code>freed_head_</code>头部）</p>
</li>
<li><p>如何查找元素<br>首先通过哈希函数对<code>Key</code>哈希到下标，定位到具体的bucket，之后，根据之前提到的关系：“前一个<code>HashBucket</code>的<code>last_elem.tail</code>指向当前<code>HashBucket</code>的第一个元素<code>*first_elem</code>”，就可以在链表头尾之间遍历查询了。</p>
</li>
<li><p>如何增加元素<br>如果<code>freed_head_</code>不为空，那么意味着存在可用的空闲元素，将<code>free_head_</code>指向的元素返回，并后移一位即可，如何已经耗尽，那么新分配一批（默认是1024个）<code>Elem</code>赋给<code>free_head_</code>，重复之前的过程即可。</p>
</li>
<li><p>如何插入元素<br>首先拿出一个空闲的元素，赋值为相应的<code>Key/Value</code>，使用<code>Key</code>哈希到bucket的下标：</p>
</li>
</ol>
<ul>
<li>如果该桶不为空，将该元素插入到当前桶的尾部即可</li>
<li>若该桶为空，需要将<code>bucket_list_tail_</code>指向该桶，还要修正该桶的<code>prev_bucket</code>（指向修改前的<code>bucket_list_tail_</code>）以及<code>last_elem</code>（指向该元素）。</li>
</ul>
<p>如果调用<code>toks = HashList.Clear()</code>，那么拿到的<code>toks</code>实际上是被置为<code>NULL</code>之前的<code>HashList.list_head_</code>的值，也就是清空前哈希的链表结构，这时候由于<code>HashList</code>已经重置过了，所以<code>toks</code>成为了前一状态产生的哈希/<code>Elem</code>链表的唯一引用。之后再对<code>HashList</code>操作都不会干扰到<code>toks</code>。因此，可以用<code>toks</code>来替代<code>prev_toks</code>，清空之后的<code>HashList</code>代替<code>cur_toks</code>。由于我们只需要遍历<code>toks</code>，用一下token中的信息，使用完之后，通过<code>Delete</code>函数，就可以将<code>toks</code>中的元素插入到<code>HashList.free_head_</code>中，实现内存的回收。</p>
<h2 id="解码逻辑"><a href="#解码逻辑" class="headerlink" title="解码逻辑"></a>解码逻辑</h2><p>解码的逻辑非常简单，在解码正式开始之前调用<code>InitDecoding()</code>做一些初始化的工作，之后就是不断接受新的音频数据，调用<code>AdvanceDecoding()</code>（每一次<code>DecodableInterface</code>中的新的可用特征一次解码完毕），直至音频输入终止，调用<br><code>FinalizeDecoding()</code>结束解码。</p>
<p>在<code>AdvanceDecoding()</code>中，对于每一帧调用<code>ProcessEmitting()</code>和<code>ProcessNonemitting()</code>，后者处理<code>ilabel == 0</code>的token传递（考虑到解码图中每一个状态均有自环，所以可以肯定的是，自环的输入label必然不能为空，否则就会陷入死循环）。每隔几帧剪一次枝。主要逻辑代码如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 解码到没有为止</span></span><br><span class="line"><span class="comment">// NumFramesDecoded(): active_toks_.size() - 1</span></span><br><span class="line"><span class="keyword">while</span> (NumFramesDecoded() &lt; target_frames_decoded) &#123;</span><br><span class="line">    <span class="comment">// 剪枝：默认25</span></span><br><span class="line">    <span class="keyword">if</span> (NumFramesDecoded() % config_.prune_interval == <span class="number">0</span>) &#123;</span><br><span class="line">        PruneActiveTokens(config_.lattice_beam * config_.prune_scale);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 这里active_toks_扩充一个空间</span></span><br><span class="line">    BaseFloat cost_cutoff = ProcessEmitting(decodable);</span><br><span class="line">    ProcessNonemitting(cost_cutoff);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>下面对每个函数块逐一分析：</p>
<h3 id="ProcessEmitting"><a href="#ProcessEmitting" class="headerlink" title="ProcessEmitting"></a>ProcessEmitting</h3><p>这部分代码主要实现两个功能，一个是token信息沿着输入不为空的弧上的传递，另一个就是若干剪枝阈值的评估。这部分的剪枝有两层，第一层决前一时刻的token能否继续存在，也就是说，如果前一时刻某一个token的<code>tot_cost</code>相比最好的token的<code>tok_cost</code>差的太多，那么它就没有必要继续传递下去了（这条路径概率过低）。第二层决定前一时刻的token是否能将信息沿着解码图中的路径约束传递到当前时刻，这一步需要预估一个当前时刻的最优权值，如果token沿着某条弧转移过来过低于我们这个预估的值，那么也不允许它传递（因为就算传递了，也会在下一时刻的第一层剪枝中被剪掉）。</p>
<p>解释一下所谓的beam，beam的含义是，允许过滤项和最优项之间的差距在beam之内。解码过程中的cost越低越优，因此，当得出所谓的<code>best_cost</code>之后，往往将<code>best_cost + beam</code>最为剪枝的阈值。</p>
<p>代码中将上述第一层剪枝的阈值命名为<code>cur_cutoff</code>，第二层剪枝阈值命名为<code>next_cutoff</code>。第一层剪枝阈值的计算在函数<code>GetCutoff()</code>中实现，这个函数不只计算出前一时刻的剪枝阈值，同时得出前一时刻token链表中token的个数，最佳token，以及估计<code>next_cutoff</code>需要的<code>adaptive_beam</code>。</p>
<p>考虑到解码中允许设置<code>--max-active(default = MAX_INT)</code>和<code>--min-active(default = 200)</code>，不同的设置在<code>GetCutoff()</code>中的计算逻辑不同，因为<code>beam</code>本身就是一个容差估计（只是这种估计并没有什么参照标准），但是现在有新的约束条件（token数目）约束了，因而需要结合在这种约束下的估计值选一个。分如下两种情况：</p>
<ol>
<li><p>假设没有约束，即某一时刻的token数目没有限制，那么使用<code>beam</code>作为容差（默认为16），即：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">cur_cutoff = best_weight + config_.beam; <span class="comment">// default config_.beam = 16.0</span></span><br><span class="line">adaptive_beam = config_.beam;</span><br></pre></td></tr></table></figure>
</li>
<li><p>存在$[N_{min}, N_{max}]$约束：<br>那么令$C_{min}$(<code>max_active_cutoff</code>)和$C_{max}$(<code>min_active_cutoff</code>)分别为token链中第max-active和min-active小的cost。显然，前者小于后者（约束更紧）。用$W_{best}$表示<code>best_weight</code>，$b$表示<code>config_.beam</code>:<br>那么<code>cur_cutoff</code>取$\min_{2nd}(W_{best} + b, C_{min}, C_{max})$。如果结果是$W_{best} + b$，那么和情况1结果保持一致，否则<code>adaptive_beam</code>计算如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// config_.beam_delta = 0.5</span></span><br><span class="line">adaptive_beam = cur_cutoff - best_weight + config_.beam_delta;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>因此，<code>adaptive_beam</code>的作用是作为<code>next_cutoff</code>的<code>beam</code>替代，在<code>--min-active/--max-active</code>形成约束力的时候。</p>
<p>对于<code>next_cutoff</code>，使用上一时刻最优token前向传递产生的cost（加上<code>adaptive_beam</code>）作为初始值。之后在处理token第二层剪枝过程中，如果传递形成的新的cost高于<code>next_cutoff</code>，则不予传递，否则产生新的token。若<code>tot_cost + adaptive_beam &lt; next_cutoff</code>，则更新<code>next_cutoff</code>。这部分代码如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"> <span class="keyword">for</span> (Elem *e = final_toks, *e_tail; e != <span class="literal">NULL</span>; e = e_tail) &#123;</span><br><span class="line">    StateId state = e-&gt;key;</span><br><span class="line">    Token *tok = e-&gt;val;</span><br><span class="line">    <span class="keyword">if</span> (tok-&gt;tot_cost &lt;=  cur_cutoff) &#123;</span><br><span class="line">        <span class="keyword">for</span> (fst::ArcIterator&lt;fst::Fst&lt;Arc&gt; &gt; aiter(fst_, state);</span><br><span class="line">           !aiter.Done();</span><br><span class="line">           aiter.Next()) &#123;</span><br><span class="line">            <span class="comment">// 遍历状态的连接弧</span></span><br><span class="line">            <span class="keyword">const</span> Arc &amp;arc = aiter.Value();</span><br><span class="line">            <span class="keyword">if</span> (arc.ilabel != <span class="number">0</span>) &#123;</span><br><span class="line">                BaseFloat ac_cost = cost_offset -</span><br><span class="line">                    decodable-&gt;LogLikelihood(frame, arc.ilabel),</span><br><span class="line">                    graph_cost = arc.weight.Value(),</span><br><span class="line">                    cur_cost = tok-&gt;tot_cost,</span><br><span class="line">                    tot_cost = cur_cost + ac_cost + graph_cost;</span><br><span class="line">                <span class="comment">// 剪枝</span></span><br><span class="line">                <span class="keyword">if</span> (tot_cost &gt; next_cutoff) <span class="keyword">continue</span>;</span><br><span class="line">                <span class="comment">// 继续更新，这是一个不断估计的过程</span></span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (tot_cost + adaptive_beam &lt; next_cutoff)</span><br><span class="line">                    next_cutoff = tot_cost + adaptive_beam; </span><br><span class="line">                <span class="comment">// 一开始调用时tok_已经是空的了。这一步产生的是新的tok</span></span><br><span class="line">                Token *next_tok = FindOrAddToken(arc.nextstate,</span><br><span class="line">                                               frame + <span class="number">1</span>, tot_cost, tok, <span class="literal">NULL</span>);</span><br><span class="line">                <span class="comment">// 把当前时刻的新token加入上一时刻的前向链表中</span></span><br><span class="line">                tok-&gt;links = <span class="keyword">new</span> ForwardLink(next_tok, arc.ilabel, arc.olabel,</span><br><span class="line">                                           graph_cost, ac_cost, tok-&gt;links);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 下一个element</span></span><br><span class="line">    e_tail = e-&gt;tail;</span><br><span class="line">    <span class="comment">// 从链表中拿掉/回收</span></span><br><span class="line">    toks_.Delete(e);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>函数<code>FindOrAddToken()</code>的作用是创建新的token（当前时刻）或者更新已有token的参数（<code>tot_cost</code>或者回溯指针等等）。因为同一个状态可能会有不同的token带着不同的<code>tot_cost</code>到达，但是只保留最优的一个。之前也说过，新建的token以链表形式相连，头部挂在<code>std::vector&lt;TokenList&gt; active_toks_</code>中：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">FindOrAddToken(StateId state, int32 frame_plus_one, BaseFloat tot_cost,</span><br><span class="line">            Token *backpointer, <span class="keyword">bool</span> *changed) &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    Token *&amp;toks = active_toks_[frame_plus_one].toks;   <span class="comment">// 注意引用，实际修改了</span></span><br><span class="line">    Elem *e_found = toks_.Find(state);</span><br><span class="line">    <span class="keyword">if</span> (e_found == <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">const</span> BaseFloat extra_cost = <span class="number">0.0</span>;</span><br><span class="line">        <span class="comment">// NULL表示暂时没有forwardlinks，t时刻只能形成t-1时刻的前向链表</span></span><br><span class="line">        <span class="comment">// 头插法：这里new_tok.next = toks</span></span><br><span class="line">        <span class="comment">// 这里的new_tok暂时不释放的</span></span><br><span class="line">        Token *new_tok = <span class="keyword">new</span> Token (tot_cost, extra_cost, <span class="literal">NULL</span>, toks, backpointer);</span><br><span class="line">        toks = new_tok; </span><br><span class="line">        num_toks_++;    <span class="comment">// 整个解码过程中的token数目</span></span><br><span class="line">        <span class="comment">// 插入hash中维护，维护的是Elem，删除它不会释放token</span></span><br><span class="line">        toks_.Insert(state, new_tok);</span><br><span class="line">        <span class="keyword">if</span> (changed) *changed = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">return</span> new_tok;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><code>active_toks_</code>也是一个十分重要的变量，它的大小是逐渐增加的，每一次调用<code>ProcessEmitting()</code>都会扩充一次。整个解码器用它的大小来追溯已经处理了的总帧数：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> int32 <span class="title">NumFramesDecoded</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123; <span class="keyword">return</span> active_toks_.<span class="built_in">size</span>() - <span class="number">1</span>; &#125;</span><br></pre></td></tr></table></figure><br>假设现在处理的是第frame帧（frame从0开始计数），那么要获得该帧产生的token链表，<code>active_toks_</code>的index应该是frame + 1。</p>
<h3 id="ProcessNonemitting"><a href="#ProcessNonemitting" class="headerlink" title="ProcessNonemitting"></a>ProcessNonemitting</h3><p>从函数名可以看出，这一步处理的当前帧下输入为$\epsilon$的跳转/弧，也就是说没有声学的观测概率。这部分代码如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">ProcessNonemitting(BaseFloat cutoff) &#123;</span><br><span class="line">    KALDI_ASSERT(!active_toks_.empty());</span><br><span class="line">    <span class="comment">// active_toks_在ProcessEmitting()中已经扩容了/+1，所以要访问</span></span><br><span class="line">    <span class="comment">// 当前帧需要-2</span></span><br><span class="line">    int32 frame = <span class="keyword">static_cast</span>&lt;int32&gt;(active_toks_.<span class="built_in">size</span>()) - <span class="number">2</span>;</span><br><span class="line">    KALDI_ASSERT(queue_.empty());</span><br><span class="line">    <span class="comment">// push当前时刻到达的状态</span></span><br><span class="line">    <span class="comment">// toks_.GetList()获取的是在ProcessEmitting()中新产生的token</span></span><br><span class="line">    <span class="comment">// 也就是当前时刻的token</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">const</span> Elem *e = toks_.GetList(); e != <span class="literal">NULL</span>;  e = e-&gt;tail)</span><br><span class="line">        queue_.push_back(e-&gt;key);</span><br><span class="line">    <span class="comment">// queue_中存储的是由当前时刻token对应的状态出发，可以通过空跳转</span></span><br><span class="line">    <span class="comment">// 到达的所有状态</span></span><br><span class="line">    <span class="keyword">while</span> (!queue_.empty()) &#123;</span><br><span class="line">        StateId state = queue_.back();</span><br><span class="line">        queue_.pop_back();</span><br><span class="line"></span><br><span class="line">        Token *tok = toks_.Find(state)-&gt;val;</span><br><span class="line">        BaseFloat cur_cost = tok-&gt;tot_cost;</span><br><span class="line">        <span class="keyword">if</span> (cur_cost &gt; cutoff)</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        <span class="comment">// 一般而言，当前时刻的token没有前向链表</span></span><br><span class="line">        tok-&gt;DeleteForwardLinks();</span><br><span class="line">        tok-&gt;links = <span class="literal">NULL</span>;</span><br><span class="line">        <span class="keyword">for</span> (fst::ArcIterator&lt;fst::Fst&lt;Arc&gt; &gt; aiter(fst_, state);</span><br><span class="line">             !aiter.Done();</span><br><span class="line">             aiter.Next()) &#123;</span><br><span class="line">            <span class="keyword">const</span> Arc &amp;arc = aiter.Value();</span><br><span class="line">            <span class="comment">// ilabel == 0表示non-emitting</span></span><br><span class="line">            <span class="keyword">if</span> (arc.ilabel == <span class="number">0</span>) &#123;  <span class="comment">// propagate nonemitting only...</span></span><br><span class="line">                BaseFloat graph_cost = arc.weight.Value(),</span><br><span class="line">                tot_cost = cur_cost + graph_cost;   <span class="comment">// acoustic_cost = 0</span></span><br><span class="line">                <span class="keyword">if</span> (tot_cost &lt; cutoff) &#123;</span><br><span class="line">                    <span class="keyword">bool</span> changed;</span><br><span class="line">                    Token *new_tok = FindOrAddToken(arc.nextstate, </span><br><span class="line">                                                    frame + <span class="number">1</span>, tot_cost,</span><br><span class="line">                                                    tok, &amp;changed);</span><br><span class="line">                    <span class="comment">// ilabel == 0则acoustic_cost = 0</span></span><br><span class="line">                    <span class="comment">// tok指的是当前时刻的token</span></span><br><span class="line">                    tok-&gt;links = <span class="keyword">new</span> ForwardLink(new_tok, <span class="number">0</span>, arc.olabel,</span><br><span class="line">                                               graph_cost, <span class="number">0</span>, tok-&gt;links);</span><br><span class="line">                    <span class="comment">// 形成新的token或者更新了权值，说明新状态可到达</span></span><br><span class="line">                    <span class="keyword">if</span> (changed) queue_.push_back(arc.nextstate);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>总体而言，解码过程就是不断的对一帧处理可观测跳转和空跳转，在拓展token的过程中执行剪枝策略，并将每一时刻的token链保存在<code>active_tok_</code>中，用于最终形成Lattice。</p>
<h3 id="PruneActiveTokens"><a href="#PruneActiveTokens" class="headerlink" title="PruneActiveTokens"></a>PruneActiveTokens</h3><p>除了在token传递过程中执行剪枝，kaldi还会每隔几帧执行一次<code>PruneActiveTokens</code>操作。该操作虽然也会删掉一些不必要的token，但是阈值的计算是在<code>active_toks_</code>中进行的（存在时间跨度）。首先执行<code>PruneForwardLinks()</code>，剪去一些token的前向指针，之后会调用<code>PruneTokensForFrame()</code>，将前向链接为空的token删去。</p>
<p>在<code>PruneForwardLinks()</code>中，对于当前时刻的每一个token，程序会遍历其ForwardLinks，算出每一条link和最优路径的cost差/距离<code>link_extra_cost</code>，如果差距过大（大于<code>lattice_beam</code>）就剪掉该link。<code>token-&gt;extra_cost</code>置为所有前向链接的<code>link_extra_cost</code>中最小的一个（如果前向链接被删完了，<code>token-&gt;extra_cost</code>会被置为无穷）。在下一步的<code>PruneTokensForFrame()</code>就是通过<code>token-&gt;extra_cost</code>来断定该token是否有前向链接的。整个搜索过程是一个时间轴上的回溯过程，即从当前时刻向初始时刻0开始。这里需要注意一个顺序问题，比如在$t - 1$时刻执行<code>PruneForwardLinks()</code>，需要用到$t$时刻的token信息，因此这里的执行顺序应该是先执行$t$时刻的Links剪枝，再执行$t + 1$时刻的Token剪枝。<code>PruneForwardLinks()</code>核心操作代码如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">PruneForwardLinks(int32 frame_plus_one, <span class="keyword">bool</span> *extra_costs_changed,</span><br><span class="line">                    <span class="keyword">bool</span> *links_pruned, BaseFloat delta) &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">bool</span> changed = <span class="literal">true</span>; <span class="comment">// 新的tok_extra_cost - 旧的tok_extra_cost &gt; 1.0 ?</span></span><br><span class="line">    <span class="keyword">while</span> (changed) &#123;</span><br><span class="line">        changed = <span class="literal">false</span>;</span><br><span class="line">        <span class="comment">// 当前时刻的每一个token</span></span><br><span class="line">        <span class="keyword">for</span> (Token *tok = active_toks_[frame_plus_one].toks;</span><br><span class="line">            tok != <span class="literal">NULL</span>; tok = tok-&gt;next) &#123;</span><br><span class="line"></span><br><span class="line">            ForwardLink *link, *prev_link = <span class="literal">NULL</span>;</span><br><span class="line">            BaseFloat tok_extra_cost = <span class="built_in">std</span>::numeric_limits&lt;BaseFloat&gt;::infinity();</span><br><span class="line">            <span class="comment">// 对于每一个token的每一个前向链接</span></span><br><span class="line">            <span class="comment">// tok_extra_cost 取最小的link_extra_cost</span></span><br><span class="line">            <span class="keyword">for</span> (link = tok-&gt;links; link != <span class="literal">NULL</span>; ) &#123;</span><br><span class="line">                Token *next_tok = link-&gt;next_tok;</span><br><span class="line">                <span class="comment">// extra_cost 初始化的时候为0</span></span><br><span class="line">                <span class="comment">// 和最优路径的差距</span></span><br><span class="line">                <span class="comment">// (tok-&gt;tot_cost + link-&gt;acoustic_cost + link-&gt;graph_cost)</span></span><br><span class="line">                <span class="comment">// - next_tok-&gt;tot_cost &gt;= 0</span></span><br><span class="line">                BaseFloat link_extra_cost = next_tok-&gt;extra_cost +</span><br><span class="line">                    ((tok-&gt;tot_cost + link-&gt;acoustic_cost + link-&gt;graph_cost)</span><br><span class="line">                    - next_tok-&gt;tot_cost);</span><br><span class="line">                <span class="comment">// 超过了阈值，删掉link</span></span><br><span class="line">                <span class="keyword">if</span> (link_extra_cost &gt; config_.lattice_beam) &#123;</span><br><span class="line">                    ForwardLink *next_link = link-&gt;next;</span><br><span class="line">                    <span class="keyword">if</span> (prev_link != <span class="literal">NULL</span>) prev_link-&gt;next = next_link;</span><br><span class="line">                    <span class="keyword">else</span> tok-&gt;links = next_link;</span><br><span class="line">                    <span class="keyword">delete</span> link;</span><br><span class="line">                    link = next_link;</span><br><span class="line">                    *links_pruned = <span class="literal">true</span>;   <span class="comment">// 表示有link删除，可能产生没有link的token了</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;   <span class="comment">// 更新tok_extra_cost，保留link</span></span><br><span class="line">                    <span class="keyword">if</span> (link_extra_cost &lt; <span class="number">0.0</span>) &#123;    <span class="comment">// 正常不会这样</span></span><br><span class="line">                        <span class="keyword">if</span> (link_extra_cost &lt; <span class="number">-0.01</span>)</span><br><span class="line">                            KALDI_WARN &lt;&lt; <span class="string">"Negative extra_cost: "</span> &lt;&lt; link_extra_cost;</span><br><span class="line">                        link_extra_cost = <span class="number">0.0</span>;</span><br><span class="line">                    &#125; <span class="comment">// keep最小的</span></span><br><span class="line">                    <span class="keyword">if</span> (link_extra_cost &lt; tok_extra_cost)</span><br><span class="line">                        tok_extra_cost = link_extra_cost;</span><br><span class="line">                    <span class="comment">// 指向没有被删除的最后一个</span></span><br><span class="line">                    prev_link = link;</span><br><span class="line">                    link = link-&gt;next; <span class="comment">// 下一个link</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="comment">// ForwardLink循环结束</span></span><br><span class="line">            <span class="comment">// delta默认1.0</span></span><br><span class="line">            <span class="comment">// 新的tok_extra_cost - 旧的tok_extra_cost &gt; 1.0</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="built_in">fabs</span>(tok_extra_cost - tok-&gt;extra_cost) &gt; delta)</span><br><span class="line">                changed = <span class="literal">true</span>;</span><br><span class="line">            tok-&gt;extra_cost = tok_extra_cost;</span><br><span class="line">            <span class="comment">// 要么+infinity 要么 &lt;= lattice_beam_</span></span><br><span class="line">            <span class="comment">// +infinity就会被剪掉</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 曾经有一次是true，它就是true</span></span><br><span class="line">        <span class="comment">// extra_costs_changed表示tok-&gt;extra_cost更新了</span></span><br><span class="line">        <span class="comment">// 因此前一时刻的tokens的extra_cost也需要重新计算了</span></span><br><span class="line">        <span class="keyword">if</span> (changed) *extra_costs_changed = <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><code>PruneForwardLinks()</code>会在两中情况下被执行：</p>
<ol>
<li>在<code>active_toks_</code>中有新的<code>TokenList</code>被拓展，因为初始化的时候<code>must_prune_forward_links</code>和<code>must_prune_tokens</code>为<code>true</code>。</li>
<li>下一时刻的<code>TokenList</code>中，有<code>token</code>的<code>extra_cost</code>变化了，所以之前时刻都需要重新计算。<br><code>PruneActiveTokens()</code>的核心代码如下：<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">PruneActiveTokens(BaseFloat delta) &#123;</span><br><span class="line">    <span class="comment">// ...</span></span><br><span class="line">    <span class="keyword">for</span> (int32 f = cur_frame_plus_one - <span class="number">1</span>; f &gt;= <span class="number">0</span>; f--) &#123;</span><br><span class="line">        <span class="keyword">if</span> (active_toks_[f].must_prune_forward_links) &#123;</span><br><span class="line">        <span class="keyword">bool</span> extra_costs_changed = <span class="literal">false</span>, links_pruned = <span class="literal">false</span>;</span><br><span class="line">        PruneForwardLinks(f, &amp;extra_costs_changed, &amp;links_pruned, delta);</span><br><span class="line">        <span class="comment">// extra_costs_changed表示f时刻的token-&gt;extra_cost发生了变化</span></span><br><span class="line">        <span class="comment">// 因此之前时刻的token-&gt;extra_cost的需要相应的重新计算</span></span><br><span class="line">        <span class="keyword">if</span> (extra_costs_changed &amp;&amp; f &gt; <span class="number">0</span>)</span><br><span class="line">            active_toks_[f<span class="number">-1</span>].must_prune_forward_links = <span class="literal">true</span>;</span><br><span class="line">        <span class="comment">// links_pruned 表示是否有link被剪掉了</span></span><br><span class="line">        <span class="keyword">if</span> (links_pruned)</span><br><span class="line">            active_toks_[f].must_prune_tokens = <span class="literal">true</span>;</span><br><span class="line">        <span class="comment">// 剪完了</span></span><br><span class="line">        active_toks_[f].must_prune_forward_links = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// f + 1 != cur_frame_plus_one - 1 还没有ForwordLink</span></span><br><span class="line">        <span class="comment">// f + 1时刻</span></span><br><span class="line">        <span class="keyword">if</span> (f+<span class="number">1</span> &lt; cur_frame_plus_one &amp;&amp;</span><br><span class="line">            active_toks_[f+<span class="number">1</span>].must_prune_tokens) &#123;</span><br><span class="line">            PruneTokensForFrame(f+<span class="number">1</span>);</span><br><span class="line">            active_toks_[f+<span class="number">1</span>].must_prune_tokens = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="特征供给"><a href="#特征供给" class="headerlink" title="特征供给"></a>特征供给</h2><p>这部分会和ivector的在线提取放在一起，说明kaldi对Online-Feature的包装。</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Decoder</tag>
        <tag>Code</tag>
        <tag>Kaldi</tag>
      </tags>
  </entry>
  <entry>
    <title>Kaldi中iVector的提取【一】</title>
    <url>/2017/07/28/kaldi-ivector-extract-1/</url>
    <content><![CDATA[<p>kaldi中ivector的提取程序在<code>ivector-extract</code>和<code>ivector-extract-online2</code>中，分别提取离线和在线的ivector。考虑到后续需要分析online的解码逻辑，所以在第二篇笔记中会仔细介绍在线情况下统计信息的累计和ivector估计方法。本篇主要介绍离线方法以及在线方法的整体框架。<br><a id="more"></a></p>
<h3 id="离线方法"><a href="#离线方法" class="headerlink" title="离线方法"></a>离线方法</h3><p>离线方法是指，在事先获取了句子的特征和高斯后验的情况下，估计出一个ivector向量。<br>对于句子 $\mathbf{U}_{T \times F} = \{\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_T\}^T$和对应的高斯后验 $\mathbf{P}_{T \times C}= \{\mathbf{p}_1, \mathbf{p}_2, \cdots, \mathbf{p}_T\}^T$，首先得到提取ivector所需要的零阶和一阶统计量：</p>
<script type="math/tex; mode=display">
\gamma_c = \sum_{t = 1}^T \mathbf{p}_{t,c} \\
\mathbf{F}_c = \sum_{t = 1}^T \mathbf{p}_{t,c} \mathbf{x}_t</script><p>存储在$\boldsymbol{\gamma}_{C \times 1}$和$\mathbf{F}_{C \times F}$中。</p>
<p>之后利用加载好的ivector提取器，调用<code>GetIvectorDistribution</code>函数并传入上述统计量将得到的均值作为ivector。ivector提取器<code>IvectorExtractor</code>中维护ivector提取过程中说话人无关的一些量，比如$\mathbf{T}$矩阵和UBM方差等等，由于kaldi代码中变量命名和我们常见的公式中不一致，这里以论文中常见的表示为标准。比较重要的量如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Matrix&lt;<span class="keyword">double</span>&gt; &gt; M_;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;SpMatrix&lt;<span class="keyword">double</span>&gt; &gt; Sigma_inv_;</span><br><span class="line">Matrix&lt;<span class="keyword">double</span>&gt; U_; <span class="comment">//上三角作为一行</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Matrix&lt;<span class="keyword">double</span>&gt; &gt; Sigma_inv_M_;</span><br></pre></td></tr></table></figure></p>
<p>其中<code>M_</code>表示$\mathbf{T}_{C \times F \times R}$，表示为：</p>
<script type="math/tex; mode=display">
\mathbf{T} = [\mathbf{T}_1, \mathbf{T}_2, \cdots, \mathbf{T}_C]</script><p><code>Sigma_inv_</code>表示$\mathbf{\Sigma}^{-1}_{C \times F \times F}$，表示为：</p>
<script type="math/tex; mode=display">
\mathbf{\Sigma}^{-1} = [\mathbf{\Sigma}^{-1}_1, \mathbf{\Sigma}^{-1}_2, \cdots, \mathbf{\Sigma}^{-1}_C]</script><p><code>U_</code>和<code>Sigma_inv_M_</code>由上面两个变量计算得到，分别定义为$\mathbf{U}_{C \times R \times R}, \mathbf{B}_{C \times F \times R}$：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{U} & = \mathbf{T}^T \cdot \mathbf{\Sigma}^{-1} \cdot \mathbf{T} = [\mathbf{T}_1^T \mathbf{\Sigma}^{-1}_1\mathbf{T}_1, \mathbf{T}_2^T \mathbf{\Sigma}^{-1}_2\mathbf{T}_2, \cdots, \mathbf{T}_C^T \mathbf{\Sigma}^{-1}_C\mathbf{T}_C ] \\
\mathbf{B} & = \mathbf{\Sigma}^{-1} \cdot \mathbf{T} = [\mathbf{\Sigma}^{-1}_1\mathbf{T}_1, \mathbf{\Sigma}^{-1}_2\mathbf{T}_2, \cdots, \mathbf{\Sigma}^{-1}_C \mathbf{T}_C]
\end{aligned}</script><p>令$\mathbf{w} = \mathbf{Q}^{-1}\mathbf{L}$，那么$\mathbf{Q}, \mathbf{L}$的计算过程如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{L}_{R \times 1} & = \sum_{c = 1}^C (\mathbf{B}_c^T)_{R \times F} (\mathbf{F}_c)_{F \times 1} \\
\mathbf{Q}_{R \times R} & = \sum_{c = 1}^C \mathbf{U}_c\gamma_c + \mathbf{I}
\end{aligned}</script><p>观察到$\mathbf{T}_i^T \mathbf{\Sigma}^{-1}_i\mathbf{T}_i$为对称矩阵，所以为了存储高效，保留上三角即可，因而$\mathbf{U}_{C \times R \times R}$可以退化为$\mathbf{U}_{C \times (R + 1) / 2}$，写成：</p>
<script type="math/tex; mode=display">
\mathbf{U}_{C \times (R + 1) / 2} = 
\begin{vmatrix}
\text{Utri}(\mathbf{T}_1^T \mathbf{\Sigma}^{-1}_i\mathbf{T}_1) \\
\text{Utri}(\mathbf{T}_2^T \mathbf{\Sigma}^{-1}_i\mathbf{T}_2) \\
\cdots \\
\text{Utri}(\mathbf{T}_C^T \mathbf{\Sigma}^{-1}_i\mathbf{T}_C)
\end{vmatrix}</script><p>那么$\mathbf{Q}_{R \times R}$可由$\mathbf{U}^T_{(R + 1) / 2 \times C} \boldsymbol{\gamma}_{C \times 1}$计算得到。</p>
<p>上述过程对应的代码在下面的函数中实现，参数<code>mean</code>即为传入的ivector向量。<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">IvectorExtractor::GetIvectorDistribution</span> <span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> IvectorExtractorUtteranceStats &amp;utt_stats,</span></span></span><br><span class="line"><span class="function"><span class="params">    VectorBase&lt;<span class="keyword">double</span>&gt; *mean,</span></span></span><br><span class="line"><span class="function"><span class="params">    SpMatrix&lt;<span class="keyword">double</span>&gt; *var)</span> <span class="keyword">const</span></span></span><br></pre></td></tr></table></figure></p>
<h3 id="在线方法"><a href="#在线方法" class="headerlink" title="在线方法"></a>在线方法</h3><p>在线方法需要提供一个配置文件，这个文件使用脚本<code>prepare_online_decoding.sh</code>生成，一个典型的配置文件如下：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">--splice-config=$PREFIX/exp/nnet2_online/nnet2_ms_online/conf/splice.conf</span><br><span class="line">--cmvn-config=$PREFIX/exp/nnet2_online/nnet2_ms_online/conf/online_cmvn.conf</span><br><span class="line">--lda-matrix=$PREFIX/exp/nnet2_online/nnet2_ms_online/ivector_extractor/final.mat</span><br><span class="line">--global-cmvn-stats=$PREFIX/exp/nnet2_online/nnet2_ms_online/ivector_extractor/global_cmvn.stats</span><br><span class="line">--diag-ubm=$PREFIX/exp/nnet2_online/nnet2_ms_online/ivector_extractor/final.dubm</span><br><span class="line">--ivector-extractor=$PREFIX/exp/nnet2_online/nnet2_ms_online/ivector_extractor/final.ie</span><br><span class="line">--num-gselect=5</span><br><span class="line">--min-post=0.025</span><br><span class="line">--posterior-scale=0.1</span><br><span class="line">--max-remembered-frames=1000</span><br><span class="line">--max-count=100</span><br></pre></td></tr></table></figure></p>
<p>其中前六个比较熟悉，分别是拼帧配置，在线cmvn配置，LDA变换矩阵，全局cmvn统计量，UBM和训练好的ivector提取器。还有两个配置参数比较重要，分别是<code>--use_most_recent_ivector</code>和<code>--ivector_period</code>。前者默认为<code>true</code>，表示每次使用最估计的ivector，否则计算出的ivector需要缓存下来，以便获取到设定时间估计出的ivector，后者设置每多少帧估计一个ivector。</p>
<p>这些配置文件用来初始化<code>OnlineIvectorExtractionConfig</code>，具体的对象载入在<code>OnlineIvectorExtractionInfo</code>中完成，前者作为后者初始化的参数。核心代码流程如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (; !spk2utt_reader.Done(); spk2utt_reader.Next()) &#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">string</span> spk = spk2utt_reader.Key();</span><br><span class="line">    <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">string</span>&gt; &amp;uttlist = spk2utt_reader.Value();</span><br><span class="line">    <span class="comment">// adaptation_state是针对一个同一个说话人的，结构体成员：</span></span><br><span class="line">    <span class="comment">// OnlineCmvnState cmvn_state;  </span></span><br><span class="line">    <span class="comment">// OnlineIvectorEstimationStats ivector_stats;</span></span><br><span class="line">    <span class="function">OnlineIvectorExtractorAdaptationState <span class="title">adaptation_state</span><span class="params">(ivector_info)</span></span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 对于同一个说话人的所有句子</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; uttlist.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">string</span> utt = uttlist[i];</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 得到该句子的特征</span></span><br><span class="line">        <span class="keyword">const</span> Matrix&lt;BaseFloat&gt; &amp;feats = feature_reader.Value(utt);</span><br><span class="line">        <span class="function">OnlineMatrixFeature <span class="title">matrix_feature</span><span class="params">(feats)</span></span>;</span><br><span class="line">        <span class="comment">// 根据ivector_info初始化一系列具体的online特征</span></span><br><span class="line">        <span class="comment">// 比如OnlineSpliceFrames，OnlineTransform，OnlineCmvn等等</span></span><br><span class="line">        <span class="function">OnlineIvectorFeature <span class="title">ivector_feature</span><span class="params">(ivector_info, &amp;matrix_feature)</span></span>;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// ivector_stats_和cmvn_初始化</span></span><br><span class="line">        ivector_feature.SetAdaptationState(adaptation_state);</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// repeat 默认false，ivector_period表示每多少帧取一个ivector，默认为10</span></span><br><span class="line">        int32 T = feats.NumRows(),</span><br><span class="line">            n = (repeat ? <span class="number">1</span> : ivector_config.ivector_period),</span><br><span class="line">            num_ivectors = (T + n - <span class="number">1</span>) / n;</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// num_ivectors 决定一句话提取多少个ivector</span></span><br><span class="line">        <span class="function">Matrix&lt;BaseFloat&gt; <span class="title">ivectors</span><span class="params">(num_ivectors, ivector_feature.Dim())</span></span>;</span><br><span class="line">    </span><br><span class="line">        <span class="keyword">for</span> (int32 i = <span class="number">0</span>; i &lt; num_ivectors; i++) &#123;</span><br><span class="line">            int32 t = i * n;</span><br><span class="line">            <span class="comment">// 对应第i个ivector</span></span><br><span class="line">            <span class="function">SubVector&lt;BaseFloat&gt; <span class="title">ivector</span><span class="params">(ivectors, i)</span></span>;</span><br><span class="line">            <span class="comment">// 核心过程，调用函数UpdateStatsUntilFrame</span></span><br><span class="line">            ivector_feature.GetFrame(t, &amp;ivector);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// Update diagnostics.</span></span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">        <span class="comment">// 更新adaptation_state</span></span><br><span class="line">        ivector_feature.GetAdaptationState(&amp;adaptation_state);</span><br><span class="line">        <span class="comment">// 完成提取</span></span><br><span class="line">        ivector_writer.Write(utt, ivectors);</span><br><span class="line">        num_done++;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>上述过程的核心：<code>GetFrame</code>方法的逻辑会在kaldi中ivector的提取【二】中详细分析。</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Kaldi</tag>
        <tag>iVector</tag>
      </tags>
  </entry>
  <entry>
    <title>iVector的初步了解</title>
    <url>/2017/07/27/learn-about-ivector/</url>
    <content><![CDATA[<p>本篇主要解释我在学习ivector中遇到的一些比较困惑的点。在kaldi的nnet3中传统声学模型加上ivector已经成为online模型的标配。对于在线模型的特征提取，传统的方法采取全局和滑动窗的CMVN对输入特征进行归一化，而kaldi推荐的方案是使用ivector加上原始声学特征（参见论文A time delay neural network architecture for efficient modeling of long temporal contexts）。</p>
<a id="more"></a>
<h3 id="supervector"><a href="#supervector" class="headerlink" title="supervector"></a>supervector</h3><p>超向量是一个比较重要的概念，在说话人识别和自适应中被广泛使用。对于一个GMM，一般将它的均值向量连接成的向量称为supervector。若特征维度为$F$，混合高斯数目为$C$，那么超向量的长度即为$F \times C$。它被认为包含了一个说话人相关的所有信息，后续要引出的本征音，联合因子分析（JFA）等方法也是从超向量的分解的角度来切入的。</p>
<h3 id="UBM和MAP"><a href="#UBM和MAP" class="headerlink" title="UBM和MAP"></a>UBM和MAP</h3><p>在训练ivector的提取器之前，需要训练一个UBM，那么就产生了两个问题，UBM是什么以及UBM起到什么作用，UBM如何训练等等。</p>
<p>UBM翻译为统一背景模型，它是一个包含很多分量的GMM（文献中一般分量个数为2048）。在说话人识别任务中，如果我们对每一个说话人的特征用一个GMM来建模，那么，得到的一系列GMM就是说话人相关的。而UBM用来对说话人无关的信息进行建模。为什么需要说话人无关的模型呢？因为我们可以认为说话人相关的建模目标可以通过训练数据和一种适应方法修正UBM达到。而这种适应/调节方法称为MAP（最大后验概率），UBM在其中作为先验模型。最终得出的结论是，相比针对每一个说话人训练一个GMM，从一个好的UBM出发进行adaptation的方法表现的更好。</p>
<p>对于说话人数据${\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_T}$，对于含有$C$个分量的UBM，观测$\mathbf{x}_i$来自第$c$个分量的概率记为：</p>
<script type="math/tex; mode=display">
\gamma_i^c = \frac{\pi_c \mathcal{N}_c(\mathbf{x}_i|\Theta_c)}{\sum_{c = 1}^C \pi_c \mathcal{N}_c(\mathbf{x}_i|\Theta_c)}</script><p>由此可以得到每个分量的零阶，一阶和二阶统计量，分别记为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
N_c & = \sum_{i = 1}^T \gamma_i^c \\
\mathbf{F}_c & = \sum_{i = 1}^T \gamma_i^c \mathbf{x}_i \\
\mathbf{S}_c & = \sum_{i = 1}^T \gamma_i^c \mathbf{x}_i \mathbf{x}_i^T
\end{aligned}</script><p>MAP按照如下更新方法调整UBM中的统计参数（Bayesian adaptation）：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\pi'_c & = [\alpha_c N_c / T + (1 - \alpha_c)\pi_c]\beta \\
\mu'_c & = \alpha_c E_c(\mathbf{x}) + (1 - \alpha_c)\mu_c \\
\mathbf{\Sigma}'_c & = \alpha_c E_c(\mathbf{x}^2) + (1 - \alpha_c)(\mathbf{\Sigma}_c + \mu_c\mu_c^T) - \mu'_c \mu'^T_c
\end{aligned}</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{aligned}
E_c(\mathbf{x}) & = \mathbf{F}_c / N_c \\
E_c(\mathbf{x}^2) & = \mathbf{S}_c / N_c \\
\alpha_c & = N_c / (N_c + r)
\end{aligned}</script><p>$r$一般在$C = 2048$时取16，$\beta$用来保证$\sum_{c = 1}^C\pi’_c = 1$。$\alpha_c$这个量用来表示UBM受新数据影响的程度。比如$\alpha_c \to 1$时，更新公式中原来的参数受到屏蔽，更多的依赖新一轮的统计信息，因而更加的偏向说话人相关的概率模型。</p>
<p>把adaptation得到的模型均值取出来进行拼接得到的超向量再加上一些后处理方法，比如cos距离或者SVM分类，就可以搭建最基本的说话人系统了。</p>
<h3 id="supervector的分解"><a href="#supervector的分解" class="headerlink" title="supervector的分解"></a>supervector的分解</h3><p>上面提到，既然supervector可以作为一个很好的说话人特征，那么就可以着手对其进行集中分析了。目前形成的体系是对说话人相关的超向量$\mathbf{s}$视为以下几个部分的叠加：</p>
<ol>
<li>说话人/信道无关的分量</li>
<li>说话人相关的分量</li>
<li>信道相关的分量</li>
<li>其余动态分量</li>
</ol>
<p>用公式可以表示为：</p>
<script type="math/tex; mode=display">
\mathbf{s} = \mathbf{m}_0 + \mathbf{m}_{spk} + \mathbf{m}_{chn} + \mathbf{m}_{res}</script><p>其中说话人/信道无关的分量可以用UBM的超向量来表示。对于剩下的三个分量的处理，目前形成的方法主要有本征音（Eigenvoice），本征信道（Eigenchannel），联合因子分析（JFA），ivector等几种方法，它们对应的分解形式如下：</p>
<ul>
<li><p>Eigenvoice针对说话人信息</p>
<script type="math/tex; mode=display">\mathbf{s} = \mathbf{m}_0 + \mathbf{V}\mathbf{y}</script></li>
<li><p>Eigenchannel针对信道信息</p>
<script type="math/tex; mode=display">\mathbf{s} = \mathbf{m}_0 + \mathbf{D}\mathbf{z} + \mathbf{U}\mathbf{x}</script></li>
<li><p>JFA结合了Eigenvoice和Eigenchannel</p>
<script type="math/tex; mode=display">\mathbf{s} = \mathbf{m}_0 + \mathbf{V}\mathbf{y} + \mathbf{D}\mathbf{z} + \mathbf{U}\mathbf{x}</script></li>
<li><p>ivector将Eigenvoice和Eigenchannel两个空间合并为一个统一变化空间进行分析</p>
<script type="math/tex; mode=display">\mathbf{s} = \mathbf{m}_0 + \mathbf{T}\mathbf{w}</script></li>
</ul>
<p>$\mathbf{w}$即是传说中的ivector。我这里重点关注它和Engenvoice，一来是目前ivector已经被广泛应用，二是$\mathbf{T}$矩阵的训练和$\mathbf{V}$的训练过程相同，只需要将训练集合中的每个句子都视为不同的说话人即可。ivector这里也有如下几个疑问：</p>
<ol>
<li>$\mathbf{T}$矩阵如何训练</li>
<li>$\mathbf{w}$如何计算</li>
<li>ivector怎么用</li>
</ol>
<h3 id="ivector的计算"><a href="#ivector的计算" class="headerlink" title="ivector的计算"></a>ivector的计算</h3><p>注：这部分没有加上说话人的下表$s$，在下一部分“$\mathbf{T}$矩阵的训练”中再添加下标。</p>
<p>ivector计算和训练过程中有这样的一个假设，即$\mathbf{w}$服从正态分布$\mathcal{N}(\mathbf{w}; \mathbf{0}, \mathbf{I})$，基于这个假设，可以得到如下如下推论：</p>
<blockquote>
<p>$\mathbf{w}$在说话人数据$\mathcal{X}$上满足高斯分布，即 $p(\mathbf{w}|\mathcal{X}) = \mathcal{N}(\mathbf{w}|\mathbf{L}^{-1}\mathbf{T}^T\mathbf{\Sigma}^{-1}\mathbf{F}, \mathbf{L}^{-1})$，其中：</p>
<script type="math/tex; mode=display">
\mathbf{L} = \mathbf{I} + \mathbf{T}^T\mathbf{\Sigma}^{-1}\mathbf{N}\mathbf{T}</script></blockquote>
<p>用$\mathbf{N}_{c}, \mathbf{F}_{c}$表示数据集合$\mathcal{X}$上第c个分量的零阶和归一化的一阶统计量：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbf{N}_{c} & = \sum_{i = 1}^T \gamma_i^c \\
\mathbf{F}_{c} & = \sum_{i = 1}^T \gamma_i^c (\mathbf{x}_i - \mu_c)
\end{aligned}</script><p>$\mu_c，\Sigma_c$为UBM中第$c$个分量的均值和方差。那么$\mathbf{N}, \mathbf{F}$表示为：</p>
<script type="math/tex; mode=display">
\mathbf{N}_{CF \times CF} = 
\begin{vmatrix}
\mathbf{N}_1\mathbf{I} &  &  &\\
 & \mathbf{N}_2\mathbf{I} &  & \\
 &  & \cdots & \\
 &  &  & \mathbf{N}_c\mathbf{I}\\
\end{vmatrix} \quad
\mathbf{F}_{CF \times 1} = 
\begin{vmatrix}
\mathbf{F}_1\\
\mathbf{F}_2\\
\cdots\\
\mathbf{F}_c\\
\end{vmatrix} \\</script><p>$\mathbf{\Sigma}$定义为：</p>
<script type="math/tex; mode=display">
\mathbf{\Sigma}_{CF \times CF} = 
\begin{vmatrix}
\Sigma_1 &  &  &\\
 & \Sigma_2 &  & \\
 &  & \cdots & \\
 &  &  & \Sigma_c\\
\end{vmatrix}</script><p>$\mathbf{T}$是需要训练的，它的维度是$CF \times R$，因而计算出来的$\mathbf{L}$维度为$R \times R$。要计算的ivector就是分布$p(\mathbf{w}|\mathcal{X})$的均值，加上说话人下标$s$，写成：</p>
<script type="math/tex; mode=display">
\mathbf{w}_s = \mathbf{L}_s^{-1}\mathbf{T}^T\mathbf{\Sigma}^{-1}\mathbf{F}_s</script><p>$\mathbf{w}_s$的维度为$R \times 1$。分布$p(\mathbf{w}|\mathcal{X})$的均值和方差是如何得出的？它的处理思路是这样的，应用贝叶斯公式可以将该条件分布写成：</p>
<script type="math/tex; mode=display">
p(\mathbf{w}|\mathcal{X}) = \frac{p(\mathcal{X} | \mathbf{w})p(\mathbf{w})}{p(\mathcal{X})} \propto p(\mathcal{X} | \mathbf{w}) \mathcal{N}(\mathbf{w}| \mathbf{0}, \mathbf{I})</script><p>$p(\mathcal{X} | \mathbf{w})$也是可以推出的，由此就可以得到现在看到的$\mathbf{w}$的分布结果了。所以在训练出$\mathbf{T}$矩阵之后，就可以求出所谓的ivector了。</p>
<h3 id="T矩阵的训练"><a href="#T矩阵的训练" class="headerlink" title="T矩阵的训练"></a>T矩阵的训练</h3><p>在ivector中$\mathbf{T}$矩阵的训练过程和JFA以及Eigenvoice里面的$\mathbf{V}$矩阵的训练过程类似。训练过程如下：</p>
<ul>
<li>E步：<script type="math/tex; mode=display">
\mathbf{C}_c = \sum_{s} \mathbf{F}_{c, s} \mathbf{w}_s^T \\
\mathbf{A}_c = \sum_{s} N_{c, s} (\mathbf{L}_s^{-1} + \mathbf{w}_s \mathbf{w}_s^T)</script></li>
<li>M步：<script type="math/tex; mode=display">
\mathbf{T} = 
\begin{vmatrix}
\mathbf{T}_1 \\
\mathbf{T}_2 \\
\cdots \\
\mathbf{T}_C \\
\end{vmatrix} =
\begin{vmatrix}
\mathbf{C}_1 \mathbf{A}_1^{-1} \\
\mathbf{C}_2 \mathbf{A}_2^{-1} \\
\cdots \\
\mathbf{C}_C \mathbf{A}_C^{-1} \\
\end{vmatrix}</script></li>
</ul>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul>
<li>Speaker recognition by machines and humans A tutorial review</li>
<li>Comparison of background normalization methods for text-independent speaker verification</li>
<li>Eigenvoice modeling with sparse training data</li>
<li>Front-End Factor Analysis forSpeaker Verification</li>
<li>Speaker recognition by machines and humans A tutorial review</li>
</ul>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>iVector</tag>
      </tags>
  </entry>
  <entry>
    <title>使用自然梯度的神经网络并行训练【译】</title>
    <url>/2017/07/25/parallel-training-by-ng/</url>
    <content><![CDATA[<p>本篇是对论文 <a href="https://arxiv.org/abs/1410.7455" target="_blank" rel="noopener">Parallel training of DNNs with Natural Gradient and Parameter Averaging</a>前几个部分的翻译。</p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>我们描述了一种在kaidi语音识别工具中使用的一种面向多核，多GPU机器的神经网络训练框架。为了尽可能与硬件无关，我们需要一种方法来使用多台机器，而不会产生过多的网络流量。这里使用的方法是周期性的平均网络参数（每一或者两分钟），然后将平均之后的参数重新分布到机器上进行进一步的训练。每台机器都只能看见自己的训练数据。本身来说，这种方法并不能很好的工作。但是，我们有另外一种方法，就是正确且有效的实现了针对随机梯度下降的自然梯度，它可以允许我们的周期性平均方法工作的很好，并且极大的提高了在单个机器上的SGD收敛程度。</p>
<a id="more"></a>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>神经网络的并行训练一般是数据并行和模型并行的结合。一般的数据并行的方法是每个minibatch交换一下模型参数。这里我们介绍的并行训练框架使用了不同的数据并行方式：我们在不同的机器上有多个执行SGD的进程，每隔几分钟平均一下模型参数并且将他们重新分布到各自的机器上。这对于大规模的语音识别系统训练是非常有效的，但是在我们的例子中，只有和我们实现的有效的自然梯度随机梯度下降结合起来工作的才比较好。考虑到DNN的非收敛性，在这篇文章中我们不解释为什么参数平均可以工作的很好，或者为什么NG-SGD作用很大。这篇文章的要点在于描述我们的方法，并且从经验上说明他们工作的很好。这篇文章的重要性在于，我们展现了当增加GPU数量时，可以收获线性的加速效果，在没有平凡的数据传输的情况下。</p>
<p>在第二部分我们描述了问题的设置，就是DNN在语音识别中的应用-虽然我们的点子比这更加宽泛。在第三部分我们介绍了并行训练方法。在第四部分我们描述了在自然梯度方法背后更加一般的点子，虽然大部分技术细节都被放在了附录部分。在这篇文章中我们不给出任何证明，但是我们在第五部分讨论一些我们认为可以但是证明不了的东西。第六部分有带有/不带有自然梯度和并行的SGD收敛性的实验。我们在第七部分做总结。</p>
<p>NG-SGD有两个版本，一个是简单的版本，还有一个在线版本。技术细节分别在附录A和B。附录C有关于我们DNN实现的背景知识。</p>
<h2 id="问题设置"><a href="#问题设置" class="headerlink" title="问题设置"></a>问题设置</h2><p>在训练语音识别的DNN模型时，直接的问题就是将向量$\mathbf{x} \in \mathbf{R}^D$分类为离散的label（$y \in \mathcal{Y}$）。维度$D$常常数以百计。$\mathbf{x}$是从声学信号中提取的短时谱特性，$\mathcal{Y}$是CD-phone聚类之后绑定的HMM状态，正常情况下，5000左右是典型的。每一对$(\mathbf{x}, y)$对应于音频数据的一帧。帧长和帧移一般是25ms和100/s，$\mathbf{x}$含有几个相邻上下文的谱信息。我们最终不是只对这个$y$感兴趣，而是所有$y$的log概率$\log p(y|\mathbf{x})$，因为我们要将它作为在维特比搜索算法中的权值，用来生成最大概率的词序列。训练的目标函数是在所有训练集上的帧，给出$\mathbf{x}$时$y$出现的概率：$\sum_{i}\log(y_i|\mathbf{x}_i)$。由于我们要最小化这个目标，我们使用SGD这个方法有点轻微的用词不当，它是梯度上升。监督标记$y$由训练语料的抄本生成的HMM模型进行维特比对齐得到。</p>
<h2 id="带参数平均的SGD"><a href="#带参数平均的SGD" class="headerlink" title="带参数平均的SGD"></a>带参数平均的SGD</h2><h3 id="参数平均概览"><a href="#参数平均概览" class="headerlink" title="参数平均概览"></a>参数平均概览</h3><p>在我们的训练中参数平均十分简单。我们有$N$个机器（比如$N = 4$），每一个机器独自的在训练数据的随机子集上运行，我们允许它们的参数逐渐的发散。在每个机器训练完一定数量$K$的数据时（典型的$K = 400000$）。我们平均所有进程的参数，之后将结果重新分发（实际中，我们通过在GridEngine，或者在我们使用的任何管理系统中生成新的作业）。重复这个过程直到完成在全部数据上的若干轮训练，比如说10轮。</p>
<p>我们将训练的外部迭代定义为每个作业处理完$K$批数据的时间。那么每一轮外部迭代的次数和训练数据量和$K$有关。</p>
<p>我们发现给并行的SGD流程设置一个有效的学习率是非常有用的，因为学习率$\eta_t$被每个独立的作业使用，需要除以作业数$N$。当我们为了获得线性的加速而增加作业量$N$时，我们需要按比例的增大学习率以保证有效的学习率不变。这个概念是我们进行参数平均时，任何一个SGD作业的参数更新被稀释为$N$倍造成的。</p>
<p>我们将其设置为参数平均而不是将各个作业的参数变化相加的原因是稳定性考虑。试想这样一种情形，在参数空间中某些方向的Hessian矩阵非常大（我们的学习率也足够大），以至于SGD在执行完$K$个样本时，随机梯度下降已经到达了平衡点。假如有四个作业，那么处理完$K$个样本之后将参数变化量相加，得到的参数不再接近于平衡态，而是在相反的方向，相对于起始点三倍远的地方。显然这会导致模型发散。</p>
<h3 id="我们SGD实现的其他方面"><a href="#我们SGD实现的其他方面" class="headerlink" title="我们SGD实现的其他方面"></a>我们SGD实现的其他方面</h3><p>在这里我们提供一些关于SGD实现上的其他方面的一些细节的特性，即用来避免模型发散的学习率调度策略和强制最大参数变化量。</p>
<p>还有一些其他的和主题并不直接相关的我们放在附录C中，即基于CPU和GPU的SGD（C.1），数据随机化（C.2），一般模型平均（C.4），混合分量，子空间（C.5），输入数据的正则化（C.6），参数初始化（C.7），序列训练（C.8）以及使用i-vector的在线解码。</p>
<h4 id="学习率调度"><a href="#学习率调度" class="headerlink" title="学习率调度"></a>学习率调度</h4><p>（Senior et al., 2013）中指出，在训练DNN的声学模型时，学习率的指数衰减效果很好，我们也独立的发现了这一现象。通常在训练阶段，我们使用指数衰减将学习率调小10倍。除非特殊说明，我们这里提到的实验，学习率初始设置为0.01，到0.001停止。我们提前说明训练的论数，典型的在4到20之间（如果数据更多，轮数就少一些）。</p>
<p>需要说明的是我们这里的实验都没有独立的针对SGD和NG-SGD调整学习率（我们只是使用了以前在NG-SGD上表现比较好的值），我们在过去也做过拓展性的实验，在小数据集上，学习率是独立调整的。最终在所有的情况下，我们发现NG-SGD是有帮助的。现在在大规模数据集上不方便做这些重复了。</p>
<h4 id="最大参数变化"><a href="#最大参数变化" class="headerlink" title="最大参数变化"></a>最大参数变化</h4><p>在深度学习上SGD训练阶段，常见的问题是参数会突然变的很大，目标函数也会变成负无穷。这被称为参数发散。常见的方法是减小学习率重新训练，但是这十分的不方便。为了避免这种情况，我们更改了SGD程序，在每个minbatch上强制一个最大的参数变化量。这样的限制在训练的早期比较活跃，尤其在趋向于输出层的层中。我们在附录C.3中做了进一步说明。</p>
<h2 id="针对SGD的自然梯度"><a href="#针对SGD的自然梯度" class="headerlink" title="针对SGD的自然梯度"></a>针对SGD的自然梯度</h2><p>这节描述我们对SGD的自然梯度修正，我们通过一个对称正定矩阵，即对Fisher矩阵的逆的估计来缩放梯度。</p>
<p>从技术上讲，自然梯度是指在黎曼参数表面，沿着常规参数空间中的弯曲路径走一步。它极难计算，但是，前面的工作（Yang &amp; Amari, 1998; Roux et al., 2007）已经使用了“自然梯度”来描述像我们这样的方法，即使用一个Fisher矩阵的估计作为学习率矩阵，因此我们跟随着他们，称呼我们的方法为“自然梯度”。</p>
<h3 id="我们可以在SGD中将常量的学习率替换为一个矩阵"><a href="#我们可以在SGD中将常量的学习率替换为一个矩阵" class="headerlink" title="我们可以在SGD中将常量的学习率替换为一个矩阵"></a>我们可以在SGD中将常量的学习率替换为一个矩阵</h3><p>在SGD中，学习率常常被假设为一个常量$\eta_t$，伴随着时间减少，更新等式如下：</p>
<script type="math/tex; mode=display">\boldsymbol{\theta}_{t + 1} = \boldsymbol{\theta}_{t} + \eta_t\mathbf{g}_t</script><p>其中$\mathbf{g}_t$是目标函数在时刻$t$的梯度（从一个训练样本或者minibatch获得）。然而，将这个标量用一个对称正定矩阵替换是可能的，我们可以改写上式为：</p>
<script type="math/tex; mode=display">\boldsymbol{\theta}_{t + 1} = \boldsymbol{\theta}_{t} + \eta_t\mathbf{E}_t\mathbf{g}_t</script><p>其中$\mathbf{E}_t$是学习率的矩阵分量，为了证明方便，我们没有把$\eta_t$合并到$\mathbf{E}_t$中去。$\mathbf{E}_t$随机是可被接受的：如果我们用可以提前获知的正常数限制$\mathbf{E}_t$的特征值的上下限，那么在给出$\boldsymbol{\theta}$时的$\mathbf{g}_t$和$\mathbf{E}_t$是独立采样的，我们可以证明在某些条件被满足的情况下的收敛性，就像使用一个标量的学习率一样（Bottou, 1998, Sec. 4.2.2）。</p>
<p>总的来说，学习率矩阵不是一个当前处理的样本数据的函数，否则它可能会阻止收敛到一个局部最优解。举一个例子，对于特定类型的训练数据，较小的矩阵将通过对该数据进行加权来明确地偏差学习。</p>
<h3 id="Fisher矩阵的逆是一个合适学习率矩阵"><a href="#Fisher矩阵的逆是一个合适学习率矩阵" class="headerlink" title="Fisher矩阵的逆是一个合适学习率矩阵"></a>Fisher矩阵的逆是一个合适学习率矩阵</h3><p>在和自然梯度这个点子相关的统计学习理论中，有理由可以说明为什么我们可以将$\mathbf{E}_t$设置为Fisher矩阵的逆。比如（Murata &amp; Amari, 1999）和（Roux et al., 2007）。Fisher矩阵是在我们要学习一个分布时最直接的定义，而不是分类问题，比如我们现在处理的这个。设想$x$，这个我们要对它的分布建模的变量，它可能是离散的，连续的，$f(x;\boldsymbol{\theta})$是给出$\boldsymbol{\theta}$时$x$的可能性。Fisher信息矩阵$\mathcal{I}(\boldsymbol{\theta})$被定义为log概率对参数偏导的二阶矩。</p>
<script type="math/tex; mode=display">\frac{\partial}{\partial \boldsymbol{\theta}} \log f(x;\boldsymbol{\theta})</script><p>以上偏导在信息论中称为“score”。在某些情况下，Fisher矩阵和Hessian是相同的。很明显为什么Hessian的逆可以称为一个很好的梯度下降方向。这些条件十分严格，包括正确的模型，$\boldsymbol{\theta}$是基于可以描述正确的数据分布的值的。但是即使这些条件不适用，Fisher矩阵在某种意义上也是和Hessian相同的，也就是说，它在参数变换的情况下也随之变换，因此它的逆依旧是学习率矩阵的一个很好的选择。</p>
<p>将Fisher信息矩阵的概念推广到预测问题$p(y;x,\boldsymbol{\theta})$上也是非常容易的。假设我们已经知道了$x$的分布$q(x)$，那么$p(y, x; \boldsymbol{\theta}) = q(x)p(y;x, \boldsymbol{\theta})$。不难看出“score”就等于$\frac{\partial}{\partial \boldsymbol{\theta}} \log f(x;y, \boldsymbol{\theta})$，因为$q(x)$不依赖$\boldsymbol{\theta}$，所以没有关于$q(x)$的表达式了。在计算Fisher矩阵时计算的期望是在$x$和$y$联合分布上的期望。这个结论在（Roux et al., 2007, Section 3）中同样存在。</p>
<p>更一般的来说，对于任意的目标函数，不一定得是log概率或者log似然，我们都可以计算出一个类似于Fisher矩阵的东西，在变量变化时，它的变换方式和Hessian矩阵类似，比如，它的逆也可以是一个学习率矩阵的合理选择。</p>
<h3 id="在实际中我们需要估计Fisher矩阵"><a href="#在实际中我们需要估计Fisher矩阵" class="headerlink" title="在实际中我们需要估计Fisher矩阵"></a>在实际中我们需要估计Fisher矩阵</h3><p>对于大规模的问题，比如参数量达到百万的语音识别问题，即使一次Fisher矩阵的求逆也是不切实际的因为它的时间复杂度是$O(n^3)$的。但是处理它的分解形式还是可以的。之前也有文献在这方面。在（Roux et al., 2007）中，Fisher矩阵被分解成多个对角阵，其中每个阵使用一个低秩的矩阵估计。这个对角阵的点子在（Bastian et al., 2011）也被研究了，每一个阵对应一个权值矩阵，我们的方法也是用的类似的思想。在未发表的手稿（Yang &amp; Amari, 1997）中（有些材料说1998年发表了），作者尝试去证明在一些假设下，对于单个隐层的神经网络的Fisher矩阵是一个Kronecker积的形式。虽然我们考虑的网络形式比他们更加通用，Kronecker积同样出现在我们Fisher矩阵的分解中。</p>
<p>需要说明的是，不进行分解也是可以使用NG的，只是每一轮的时间代价会剧增，可以看一下（Pascanu &amp; Bengio, 2013）中的例子，他们使用阶段牛顿法近似Fisher矩阵的逆。</p>
<h3 id="Fisher矩阵的分解"><a href="#Fisher矩阵的分解" class="headerlink" title="Fisher矩阵的分解"></a>Fisher矩阵的分解</h3><p>我们的分解形式是这样的：对于一个有$I$个权值矩阵的神经网络，我们把Fisher矩阵划分为$I$对角阵，每一个对应一个权值矩阵。考虑Fisher矩阵第$i$个对角块，它对应的权值矩阵是$\boldsymbol{W}_i$，在这里我们假设没有单独的偏置存在。那么第$i$块Fisher矩阵可以视为两个对称正定矩阵$\boldsymbol{A}_i$，$\boldsymbol{B}_i$的Kronecker积，其中$\boldsymbol{A}_i$的维度是$\boldsymbol{W}_i$的行数，$\boldsymbol{A}_i$的维度是$\boldsymbol{W}_i$的列数。我们进一步将$\boldsymbol{A}_i$和$\boldsymbol{B}_i$分解为一个低秩的对称矩阵和单位矩阵的倍数的和，那么Fisher矩阵$\boldsymbol{F}$可以被写为：</p>
<script type="math/tex; mode=display">\boldsymbol{F} = \text{diag}(\boldsymbol{A}_1 \otimes \boldsymbol{B}_1, \boldsymbol{A}_2 \otimes \boldsymbol{B}_2, \dots, \boldsymbol{A}_I \otimes \boldsymbol{B}_I)</script><p>其中$\boldsymbol{A}_i$，$\boldsymbol{B}_i$以 $\lambda\boldsymbol{I} + \boldsymbol{X}\boldsymbol{X}^T$的形式分解。$\boldsymbol{A}_i$，$\boldsymbol{B}_i$在Kronecker积中的顺序取决于矩阵的存储形式，行主序的还是列主序。实际中我们不显式的处理Kronecker积或者向量化的权值矩阵，所以这个选择不重要。不难证明如果Fisher矩阵可以被这么分解，那么它的逆也可以以同样的形式分解。</p>
<h3 id="我们如何估计Fisher矩阵"><a href="#我们如何估计Fisher矩阵" class="headerlink" title="我们如何估计Fisher矩阵"></a>我们如何估计Fisher矩阵</h3><p>我们有两种方法估计Fisher矩阵的分解形式</p>
<ul>
<li>简单方法：我们从一个minibatch里面拿一些其他的数据来估计Fisher矩阵。这样做十分高效，细节在附录A中。</li>
<li>在线方法：我们从之前所有的minibatch中估计Fisher矩阵。时间较远的minibatch使用一个遗忘因子来减少权重。细节在附录B中。</li>
</ul>
<p>我们通常使用在线方法，因为在GPU上它跑的很快，模型学习的也很快。这可能是因为它对Fisher矩阵的估计是比较干净的。我们描述简单方法是因为它更加好懂，可以帮助我们启发在线方法。</p>
<h3 id="向量操作"><a href="#向量操作" class="headerlink" title="向量操作"></a>向量操作</h3><p>虽然我们描述Fisher矩阵是一个Kronecker积的形式，但是在我们没有显式的实现它。</p>
<p>假设我们当前一次训练一批/个数据。那么SGD按照如下方法更新第$i$个权值矩阵：</p>
<script type="math/tex; mode=display">\boldsymbol{W}_{it} = \boldsymbol{W}_{i(t-1)} + \eta_t\boldsymbol{x}_{it}\boldsymbol{y}_{it}^T</script><p>$\boldsymbol{x}_{it}$是目标函数的偏导，$\boldsymbol{y}_{it}$是权值作用的输入。这个公式最初存在BP算法中。</p>
<p>在我们的自然梯度下降算法中，这被改写成：</p>
<script type="math/tex; mode=display">\boldsymbol{W}_{it} = \boldsymbol{W}_{i(t-1)} + \eta_t\boldsymbol{A}_{it}^{-1}\boldsymbol{x}_{it}\boldsymbol{y}_{it}^T\boldsymbol{B}_{it}^{-1}</script><p>其中$\boldsymbol{A}_{it}$和$\boldsymbol{B}_{it}$是Fisher矩阵的因子。很容易表明，这相当于将参数阶乘以由A和B量形成的Fisher矩阵的倒数。</p>
<h3 id="minibatch的操作"><a href="#minibatch的操作" class="headerlink" title="minibatch的操作"></a>minibatch的操作</h3><p>如果不是一次训练一批数据，而是minibatch个数据。那么上一节中的向量$\boldsymbol{x}_{it}$和$\boldsymbol{y}_{it}$就相应的变成了矩阵$\boldsymbol{X}_{it}, \boldsymbol{Y}_{it}$，那么更新公式写为：</p>
<script type="math/tex; mode=display">\boldsymbol{W}_{it} = \boldsymbol{W}_{i(t-1)} + \eta_t\boldsymbol{X}_{it}\boldsymbol{Y}_{it}^T</script><p>注意，我们没有像有些作者一样，将梯度除以minibatch的大小，这样可以更加容易的独立的调minibatch的大小和学习率。NG的更新公式为：</p>
<script type="math/tex; mode=display">\boldsymbol{W}_{it} = \boldsymbol{W}_{i(t-1)} + \eta_t\bar{\boldsymbol{X}}_{it}\bar{\boldsymbol{Y}}_{it}^T</script><p>其中带横杠的参数表示修正过的$\boldsymbol{X}，\boldsymbol{Y}$。在在线版本中可以写为：</p>
<script type="math/tex; mode=display">
\bar{\boldsymbol{X}}_{it} = \boldsymbol{X}_{it} \boldsymbol{A}_{it}^{-1}\\
\bar{\boldsymbol{Y}}_{it} = \boldsymbol{Y}_{it} \boldsymbol{B}_{it}^{-1}</script><p>在简单方法中，由于$\boldsymbol{A},\boldsymbol{B}$是从minibatch中的其他元素估计的，所以我们不能这么写（每行单独的乘法），附录A中有高效的实现。</p>
<p>从编程的角度说，我们可以这么描述NG的接口：</p>
<ul>
<li>简单方法：给出一个minibatch$\boldsymbol{X}_{it}$，每一行是minibatch的一个元素，我们通过每个样本来估计Fisher矩阵，并乘以他们的逆，返回修正过的$\bar{\boldsymbol{X}}_{it}$</li>
<li>在线方法：给出一个minibatch$\boldsymbol{X}_{it}$和前一次的Fisher矩阵因子估计，计算$\bar{\boldsymbol{X}}_{it} = \boldsymbol{X}_{it} \boldsymbol{A}_{i(t-1)}^{-1}$，之后更新$\boldsymbol{A}_{it}$</li>
</ul>
<p>以上接口对于$\boldsymbol{Y}$和$\boldsymbol{B}$执行流程和$\boldsymbol{X}$和$\boldsymbol{A}$是一样的。对于一个minibatch，我们调用接口$2I$次：每个权值矩阵两次。</p>
<h3 id="因子调整"><a href="#因子调整" class="headerlink" title="因子调整"></a>因子调整</h3><p>在两个NG方法中，我们想阻止Fisher矩阵极大的影响整体的更新，相比于标准的SGD。对此有几点原因：</p>
<ul>
<li>在训练的早期，$\boldsymbol{x}$和$\boldsymbol{y}$的量可以非常小，甚至是0，这会导致Fisher矩阵的逆很大甚至是无穷。</li>
<li>常规的收敛防御技术要求学习率矩阵的矩阵分量应具有预先知道的常数的上下限的特征值，但是我们不确定我们使用的Fisher矩阵是否是不变的。</li>
<li>从经验的角度来看，如果使用不调整的Fisher矩阵，我们很难阻止参数发散。</li>
</ul>
<p>我们的方法是调整$\bar{\boldsymbol{X}}_{it}$和$\bar{\boldsymbol{Y}}_{it}$的量，使得它们的Frobenius范数和输入$\boldsymbol{X}_{it}$和$\boldsymbol{Y}_{it}$一样，我们会在附录中介绍它。</p>
<p>因子调整会引入证明上的微小的问题，那就是每一个样本都会影响它们自己的学习率矩阵了（通过缩放矩阵的缩放因子）。我们之前也提过，虽然使用单个样例的学习率也是允许的，但是在实际问题中这不是一个问题，因为我们基本上不适用小于100的minibatch大小。</p>
<h3 id="使用单位矩阵平滑Fisher矩阵"><a href="#使用单位矩阵平滑Fisher矩阵" class="headerlink" title="使用单位矩阵平滑Fisher矩阵"></a>使用单位矩阵平滑Fisher矩阵</h3><p>在两种方法中，我们通过在转置之前给Fisher矩阵加上一个单位矩阵的倍数来平滑它。在简单方法中，这是必要的，因为通常从minibatch中估计的Fisher矩阵都不是满秩的。在在线方法中不是必要的，因为Fisher矩阵的分解已经包含了加上单位矩阵这一操作。但是我们发现通过加上单位矩阵的倍数这一操作，比如对简单方法而言，我们可以调高SGD方法的收敛性。在两种情况下，平滑操作实现如下，如果$\boldsymbol{S} \in \boldsymbol{R}^{D \times D}$是一个从$\boldsymbol{x}$或者$\boldsymbol{y}的协方差中估计的$Fisher矩阵因子，那么我们使用$\boldsymbol{S} + \beta\boldsymbol{I}$来代替Fisher矩阵因子$\boldsymbol{A}$或者$\boldsymbol{B}$，其中</p>
<script type="math/tex; mode=display">\beta = \frac{\alpha}{D}\max(\text{tr}(\boldsymbol{S}), \epsilon)</script><p>$\epsilon = 10^{-20}$用来防止平滑的$\boldsymbol{S}$值为0。也就是说，我们通过将单位矩阵缩放$\alpha$乘以$\boldsymbol{S}$的对角元素的平均值倍来平滑Fisher矩阵。我们在调参实验中发现，在大部分情况下，$\alpha = 4$对于两种方法，甚至是$\boldsymbol{S}$中存在影响不大的噪声时是合适的，比如minibatch比较大时。我们的理解是，$\alpha$相当大时，我们在$\boldsymbol{x}$和$\boldsymbol{y}$的值协相关性比较大的方向上使用了一个比正常情况小的学习率，在其他方向上使用了一个相对稳定的学习率。</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Kaldi</tag>
        <tag>Optimization</tag>
      </tags>
  </entry>
  <entry>
    <title>在安卓上使用Kaldi进行模型开发</title>
    <url>/2017/07/20/link-kaldi-on-android/</url>
    <content><![CDATA[<p>为什么有这个想法，因为自己有过体验，当初做的第一个语音增强的demo，傻乎乎的自己实现特征提取，自己实现网络前向，于是就需要将kaldi的网络参数转写成方便自己程序读取的格式，还需要不断对比自己实现的特征结果和HTK的结果是否一致，这期间花费的时间个人觉得已经远远的超出做demo本身的意义，最主要的是，由于当初实现的代码仅仅是针对当初的需求，而一旦后期的特征配置或者网络结构发生变化，之前的工作就要重复一次，如此低效率的事情我个人是不想重复做的。</p>
<a id="more"></a>
<p>所以，最简单的方法就是，将计算逻辑交给kaldi完成，自己只需要完成控制逻辑上的编码。本身使用NDK+JNI进行开发并不是很难，无非是将kaldi的依赖和自身编译成库，和自己编写的JNI接口链接，通过Android Studio支持的cmake或者ndk构建最终的动态库就行了，但是，由于网上资料过少，链接错误又比较难查，所以还是耗费了不少时间的。</p>
<p>我的需求是提取nnet1和feat两块，所以不需要openfst以及其他无关的代码，最终提取出的工作目录如下（实际上还可以进一步精简，test文件一律删除）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">base  cudamatrix  feat  hmm  itf  matrix  nnet thread  tree  util</span><br></pre></td></tr></table></figure>
<p>所有步骤都可以从以下链接中获取</p>
<ul>
<li>谷歌官方的NDK指南 <a href="https://developer.android.com/ndk/guides/index.html" target="_blank" rel="noopener">LINK</a></li>
<li>AndroidStudio的用户手册 <a href="https://developer.android.com/studio/intro/index.html" target="_blank" rel="noopener">LINK</a></li>
<li>kaldi的交叉编译 <a href="http://jcsilva.github.io/2017/03/18/compile-kaldi-android/" target="_blank" rel="noopener">LINK</a></li>
<li>OpenBlas的编译 <a href="https://github.com/xianyi/OpenBLAS/wiki/How-to-build-OpenBLAS-for-Android" target="_blank" rel="noopener">LINK</a></li>
</ul>
<p>我踩过的坑如下：</p>
<h3 id="配置本地编译环境"><a href="#配置本地编译环境" class="headerlink" title="配置本地编译环境"></a>配置本地编译环境</h3><p>这一步之前编译OpenBlas的时候也用过，使用ndk自带的<code>make_standalone_toolchain.py</code>脚本配置编译环境，安装完毕之后，将安装目录下的bin文件夹导入环境变量。脚本比较重要的参数是<code>--api</code>和<code>--stl</code>。其中<code>--stl</code>配置NDK的运行时（gnustl/libc++/stlport），<code>--api</code>配置SDK的版本，这两个配置选项要和后续的Application.mk保持一致的，分别对应<code>APP_STL</code>和<code>APP_PLATFORM</code>。<code>--arm</code>配置编译平台，安卓手机对应<code>arm</code>或者<code>arm64</code>，对应Application.mk中<code>APP_ABI</code>的<code>armeabi/armeabi-v7a</code>和<code>arm86-v8a</code>。另外，切记，openblas和kaldi在同意一个toolchain下完成编译。</p>
<h3 id="编译clapack"><a href="#编译clapack" class="headerlink" title="编译clapack"></a>编译clapack</h3><p>这个也很简单，github上有人已经构建好了工程，简单修改Android.mk执行ndk-build就行。</p>
<h3 id="编译openblas"><a href="#编译openblas" class="headerlink" title="编译openblas"></a>编译openblas</h3><p>openblas编译基本不会出现问题，参照上面给出的链接即可。将clapack生成的blas，lapack，clapack，f2c四个库拷贝到openblas安装目录下的lib中，kaldi会自动配置到kaldi.mk中作为链接库。</p>
<h3 id="编译kaldi"><a href="#编译kaldi" class="headerlink" title="编译kaldi"></a>编译kaldi</h3><p>由于修改了原先的工程目录，所以需要修改一下Makefile和configure文件</p>
<ol>
<li>去除configure文件中关于openfst的检查脚本</li>
<li>修改Makefile中的SUBDIR(控制编译那些目录)，以及各子目录中的Makefile（ADDLIBS是本目录的依赖库，OBJFILES是要打包到静态库中的目标文件，不需要生成测试文件就将TESTFILES注释即可)</li>
<li>注释android_openblas.mk中openfst的宏定义，将宏<code>ANDROIDINC</code>修正为<code>ANDROIDINCDIR</code>（脚本的bug，因为configure中定义的是<code>ANDROIDINCDIR</code>），注意一下<code>CXXFLAGS</code>的参数，后面链接的时候要用到。</li>
<li>kaldi默认在编译android平台只能生成静态库</li>
</ol>
<h3 id="AS的配置"><a href="#AS的配置" class="headerlink" title="AS的配置"></a>AS的配置</h3><p>上述过程倒是很少出现问题，在AS中用cmake或者ndk生成动态库是主要的头疼点（一系列让人摸不着头脑的链接错误）。首先说明kaldi的编译和链接参数如下（来自android_openblas.mk）：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-DKALDI_DOUBLEPRECISION&#x3D;0 # BaseFloat为单精度 </span><br><span class="line">-DHAVE_CXXABI_H </span><br><span class="line">-DHAVE_OPENBLAS # 在cblas_wrapper.h中用到，表示blas用openblas实现</span><br><span class="line">-DANDROID_BUILD -ftree-vectorize </span><br><span class="line">-mfloat-abi&#x3D;hard -mfpu&#x3D;neon -mhard-float -D_NDK_MATH_NO_SOFTFP&#x3D;1 # openblas用到</span><br></pre></td></tr></table></figure><br>以及<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-Wl,--no-warn-mismatch </span><br><span class="line">-lm_hard # openblas用到</span><br></pre></td></tr></table></figure><br>以上参数需要在Android.mk或者CmakeLists.txt中等价的实现，cmake我没有成功过，Android.mk目前配置如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LOCAL_PATH :&#x3D; $(call my-dir)</span><br><span class="line"></span><br><span class="line"># 预构建静态库</span><br><span class="line">include $(CLEAR_VARS)</span><br><span class="line">LOCAL_MODULE :&#x3D; kaldi-prebuild</span><br><span class="line">LOCAL_SRC_FILES :&#x3D; libkaldi.a</span><br><span class="line">include $(PREBUILT_STATIC_LIBRARY)</span><br><span class="line"></span><br><span class="line">include $(CLEAR_VARS)</span><br><span class="line"></span><br><span class="line">LOCAL_MODULE    :&#x3D; kaldi</span><br><span class="line">LOCAL_SRC_FILES :&#x3D; impl.cpp</span><br><span class="line"></span><br><span class="line"># 编译选项</span><br><span class="line">LOCAL_CFLAGS +&#x3D; -DKALDI_DOUBLEPRECISION&#x3D;0 -DHAVE_CXXABI_H \</span><br><span class="line">                 -DHAVE_OPENBLAS -DANDROID_BUILD -ftree-vectorize \</span><br><span class="line">                 -mfloat-abi&#x3D;hard -mfpu&#x3D;neon -mhard-float -D_NDK_MATH_NO_SOFTFP&#x3D;1</span><br><span class="line"># 链接选项</span><br><span class="line">LOCAL_LDFLAGS +&#x3D; -Wl,--no-warn-mismatch -lm_hard</span><br><span class="line"># 链接静态库，为什么只有一个？我把各个静态库压成一个了</span><br><span class="line">LOCAL_STATIC_LIBRARIES +&#x3D; kaldi-prebuild</span><br><span class="line"># 定义头文件路径</span><br><span class="line">LOCAL_C_INCLUDES +&#x3D; $(LOCAL_PATH)&#x2F;blas $(LOCAL_PATH)</span><br><span class="line"># 动态链接log库</span><br><span class="line">LOCAL_LDLIBS +&#x3D; -llog</span><br><span class="line"></span><br><span class="line">include $(BUILD_SHARED_LIBRARY)</span><br></pre></td></tr></table></figure><br>对应的Application.mk如下，之前说明过，配置要和toolchain保持一致<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">APP_ABI :&#x3D; armeabi-v7a # 用到了openblas</span><br><span class="line">APP_STL :&#x3D; c++_static # libc++</span><br><span class="line">APP_CPPFLAGS :&#x3D; -fexceptions # 打开异常开关</span><br><span class="line">APP_PLATFORM :&#x3D; android-24 # SDK-24</span><br></pre></td></tr></table></figure></p>
<p>这期间遇到的问题如下：</p>
<h4 id="cmake的VFP问题"><a href="#cmake的VFP问题" class="headerlink" title="cmake的VFP问题"></a>cmake的VFP问题</h4><p>使用链接openblas如果不加<code>-mhard-float -D_NDK_MATH_NO_SOFTFP=1 -lm_hard</code>这些选项的话，会出现<code>*.a use VFP arguments, but output not</code>的链接错误，但是，我在CmakeLists.txt中的<code>add_definitions</code>和gradle中的<code>cppFlags</code>都尝试过添加这些选项，均没有解决该问题，只能转战ndk+Android.mk了。</p>
<h4 id="f2c-的未定义问题"><a href="#f2c-的未定义问题" class="headerlink" title="f2c_的未定义问题"></a>f2c_的未定义问题</h4><p>这个推测应该是和静态库的链接顺序有关系，Android.mk要链接静态库，须先预构建一下（我暂时不知道其他链接方法），然后将预构建好的模块进行连接（加到<code>LOCAL_STATIC_LIBRARIES</code>参数之后），有一种说法是越基本的库放的越靠后，我在<code>kaldi-base.a kaldi-matrix.a</code>和五个blas相关的库上做过各种顺序的尝试，但是始终没能解决该问题（要么是<code>f2c</code>的为定义，要么是<code>openblas</code>的未定义），最终用粗暴的方法，将这几个库打包成一个静态库解决该问题的（尽量保证openblas和clapack库是同一个toolchain构建的）</p>
<h4 id="ndk命名空间错误"><a href="#ndk命名空间错误" class="headerlink" title="ndk命名空间错误"></a>ndk命名空间错误</h4><p>这个错误是后来做了若干修正之后解决的，现在回想，可能的原因是Application.mk中的<code>APP_PLATFORM</code>和<code>APP_STL</code>和toolchain配置的<code>api/stl</code>不匹配。</p>
<p>到这里，在jni文件夹外边使用<code>ndk-build</code>已经可以直接生成静态库了，但是，如果在AS中build的话，还是会出现<code>rand_r, rand, posix_memalign</code>这些函数的未定义，目前这些问题还没有解决，我通过gradle配置ndk的构建方法替换AS自身的逻辑来跳过这个错误，在gradle中<code>android{}</code>添加配置如下：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sourceSets.main &#123;</span><br><span class="line">        jni.srcDirs &#x3D; [] # 禁用AS默认的jni目录</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">task ndkBuild(type: org.gradle.api.tasks.Exec, description: &quot;compile JNI by NDK&quot;) &#123;</span><br><span class="line">    commandLine &quot;&#x2F;Users&#x2F;wujian&#x2F;Library&#x2F;Android&#x2F;sdk&#x2F;ndk-bundle&#x2F;ndk-build&quot;,</span><br><span class="line">            &#39;NDK_PROJECT_PATH&#x3D;build&#x2F;intermediates&#x2F;ndk&#39;,</span><br><span class="line">            &#39;NDK_LIBS_OUT&#x3D;src&#x2F;main&#x2F;jniLibs&#39;,</span><br><span class="line">            &#39;APP_BUILD_SCRIPT&#x3D;src&#x2F;main&#x2F;jni&#x2F;Android.mk&#39;,</span><br><span class="line">            &#39;NDK_APPLICATION_MK&#x3D;src&#x2F;main&#x2F;jni&#x2F;Application.mk&#39;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tasks.withType(JavaCompile) &#123;</span><br><span class="line">    compileTask-&gt;compileTask.dependsOn ndkBuild</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>这种方法并不推荐，实际上个人觉得还是AS支持的ndk和cmake最佳，右击<code>app</code>，选择构建工具，link一下<code>CMakeLists.txt</code>或者<code>Android.mk</code>就行了。以后找到问题所在还是会切换过去的。</p>
<p>无非就是一个链接问题，前后折腾了五天，现在总结的话，大致也只用这么多可以被写下来的东西。不过，想到今后从模型到demo的可以省下的大把时间，还是一件值得的事情。</p>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>Kaldi</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>DTW在语音唤醒中的应用</title>
    <url>/2017/06/20/apply-dtw-in-kws/</url>
    <content><![CDATA[<p>语音唤醒任务的一种常见解决方案是通过评估连续语音中分段时间窗内的音频特征和预先置入的关键词模板之间的相似性来决定系统是否唤醒，而DTW（动态时间规整算法）能够有效的衡量两个不等长序列之间的最短距离/相似性，因此在这类解决思路下被广泛使用。这里可以采用的特征有声学特征，后验特征，embedding特征或者BN特征等等，鲁棒的特征对最终的系统表现有着积极的影响。将连续语音和关键词模板之间的距离矩阵绘制出来（关键词模板在纵轴方向），可以得到如下的结果（使用的是MFCC特征）。图中蓝色的路径为最低代价下对齐/匹配路径。在唤醒系统中，我们将当前滑动窗下的最低匹配代价作为相似性打分，调出一个合理的阈值就可以做一个简单的唤醒演示系统了（实际表现中，打分平滑，模板平均等等还是有很多trick的）。<br><a id="more"></a><br><img src="http://www.funcwj.cn/images/mfcc_distmat.png" width="600"></p>
<p>DTW算法是一种衡量两个不同长度的序列之间距离的一种算法，主要的思想是将序列元素之间通过某种规则对应起来得到等长序列，在计算这种情况下的距离。由于这种映射方式有很多种，DTW采用动态规划思想，每一次取最小距离代价的映射方案，以此获得最小的匹配距离以及对应的匹配方案。</p>
<p>定义序列$\boldsymbol{X}, \boldsymbol{Y}$，DTW算法可以找出一条匹配路径$\pi$满足：</p>
<script type="math/tex; mode=display">
D = \underset{\pi}{\text{argmin}} \sum_{(i, j) \in \pi} \text{dis}(\boldsymbol{X}_i, \boldsymbol{Y}_j) \notag</script><p>令$D_{ij}$表示子序列$\boldsymbol{X}_{0 \to i}, \boldsymbol{Y}_{0 \to j}$的最小匹配距离，由动态规划思想，可以得到如下状态转移方程：</p>
<script type="math/tex; mode=display">
D_{ij} = \text{dis}(\boldsymbol{X}_i, \boldsymbol{Y}_j) + \min\{D_{(i - 1)j}, D_{i(j - 1)}, D_{(i - 1)(j - 1)}\} \notag</script><p>由此，可以在$O(n^2)$的时间复杂度内得到两个序列的最小匹配距离。该距离越小，表示序列相似度越高。在KWS任务中，$\boldsymbol{X}_i,\boldsymbol{Y}_j$表示的是声学特征或者因素后验，定义距离度量如下：</p>
<script type="math/tex; mode=display">
\begin{align}
 \cos(i, j) &= 1 - \frac{\boldsymbol{X}_i^T \boldsymbol{Y}_j}{|\boldsymbol{X}_i| \cdot |\boldsymbol{Y}_j|} \notag \\
 \log(i, j) &= -\log(\boldsymbol{X}_i^T \boldsymbol{Y}_j) \notag
\end{align}</script><p>一般而言，对于声学特征采用余弦距离，对于后验特征采用内积度量。</p>
<p>以上是基本的DTW算法，对于KWS任务，最终的目标是从句子$\boldsymbol{U} = \{\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_U\}$中获取模板$\boldsymbol{T} = \{\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_T\}$可能出现的位置。而在实际的系统中，$U$要远远大于$T$，所以在应用中还是需要对DTW算法进行改进的。目前常见的方法是分段动态时间规整（SDTW）和分段局部正则（SLN-DTW）算法。</p>
<p>分段动态时间规整算法简单的理解（实际上论文中的表述不是这样）为通过设置一个滑动窗（窗长为$W$，窗移为$S$），在每一个滑动窗内，用标准DTW计算和模板的最小匹配距离。该方法计算复杂度较高（每$S$帧就要进行一次$O(n^2)$的计算），而且性能表现和窗长$W$以及窗移$S$相关。</p>
<p>分段局部正则（SLN-DTW）算法修改了标准DTW中的初始化方法，并且引入了平均距离作为距离度量方式，默认每一帧均可以作为最优匹配的起始点，这样无需通过句子切分得到匹配起点，也无需重新计算距离矩阵，极大的降低了算法 的计算复杂度。定义累积步长$S$， $\Theta = {(i - 1, j - 1), (i, j - 1), (i - 1, j)}$，初始化$D_{0j} = \text{dis}(\boldsymbol{T}_0, \boldsymbol{U}_j)$，$S_{0j} = 1$，则状态转移方程修正为：</p>
<script type="math/tex; mode=display">
\begin{align}
D_{ij} &= \text{dis}(\boldsymbol{T}_i, \boldsymbol{U}_j) + D_{uv} \notag \\
S_{ij} &= 1 + S_{uv} \notag
\end{align}</script><p>其中</p>
<script type="math/tex; mode=display">
(u, v) = \underset{(u, v) \in \Theta}{\text{argmin}} \frac{D_{uv} + \text{dis}(\boldsymbol{T}_i, \boldsymbol{U}_j)}{S_{uv} + 1}</script><p>在关键词只出现一次的情况下，回溯位置$j = \underset{j}{\text{argmin}}\{D_{Tj}, 0 \leqslant j \leqslant U\}$处的得到的最优路径作为最优匹配路径。</p>
<p>在实验中，SLN-DTW效率和准确性上要优于前者。</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>KWS</tag>
        <tag>DTW</tag>
      </tags>
  </entry>
  <entry>
    <title>LDA线性判别分析</title>
    <url>/2017/06/15/kaldi-lda/</url>
    <content><![CDATA[<p>LDA（线性判别分析，又称为Fisher线性判别）是对标记数据的一种常见的降维算法。kaldi在对原始特征的常见处理中，就包括了应用LDA变换这一操作（但是一般不降维，比较奇怪）。本文主要讲解LDA的数学原理和在kaldi中的具体实现。<br><a id="more"></a></p>
<h3 id="坐标变换"><a href="#坐标变换" class="headerlink" title="坐标变换"></a>坐标变换</h3><p>首先，对于坐标变换这个任务，变换之后的坐标可以理解为点在新的空间基向量方向上的投影。</p>
<p>对于变换空间的一组基向量 $\overrightarrow{\boldsymbol{w}} = \{\boldsymbol v_1, \boldsymbol v_2, \cdots, \boldsymbol v_n\}$和原空间的点 $\boldsymbol{x} = \{x_1, x_2, \cdots, x_n\}^T$，变换之后的坐标 $\boldsymbol y$表示为：</p>
<script type="math/tex; mode=display">
\boldsymbol y =  \boldsymbol{w}^T \cdot \boldsymbol x</script><h3 id="LDA"><a href="#LDA" class="headerlink" title="LDA"></a>LDA</h3><p>LDA的期望是，将高维度的数据通过某种变换/降维（投影到低维度），使得类间方差最大，类内方差最小，也就是要让同一类数据尽可能的接近，不同类数据尽可能的分开。所以，如果定义要优化的目标函数，那么，表征不同数据接近程度的离散矩阵和表征同类数据类内离散程度的离散矩阵应该被分别放置在分母和分子位置，最终取使得优化目标最大的变换矩阵即可。</p>
<p>定义原始数据维度为$D$，数据集标注为$C$类，对于类$P_i$，类内离散程度$\boldsymbol{S}_w$用类内方差$\boldsymbol{V}_i$之和表示：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{S}_w & = \frac{1}{C}\sum_{i = 1}^C \boldsymbol{V}_i
= \frac{1}{C}\sum_{i = 1}^C \frac{1}{N_i}\sum_{\boldsymbol{x} \in P_i}(\boldsymbol{x} - \boldsymbol{\mu}_i)(\boldsymbol{x} - \boldsymbol{\mu}_i)^T \\
& = \frac{1}{C}\sum_{i = 1}^C E[\boldsymbol{X}_i^2] - E[\boldsymbol{X}_i]^2
\end{aligned}</script><p>类间方差$\boldsymbol{S}_b$用各类中心点$\boldsymbol{\mu}_i$相对整体样本的中心点$\boldsymbol{\mu}$计算得到的协方差$\boldsymbol{V}_i^r$之和表示：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol{S}_b & = \frac{1}{C}\sum_{i = 1}^C \boldsymbol{V}_i^r
= \frac{1}{C}\sum_{i = 1}^C (\boldsymbol{\mu}_i - \boldsymbol{\mu})(\boldsymbol{\mu}_i - \boldsymbol{\mu})^T \\
& = E[\boldsymbol{\mu}_c^2] - E[\boldsymbol{X}]^2
\end{aligned}</script><p>由以上两式，可以得到优化的目标函数：</p>
<script type="math/tex; mode=display">
J(\boldsymbol{W}) = \frac{\boldsymbol{W}^T\boldsymbol{S}_b\boldsymbol{W}}{\boldsymbol{W}^T\boldsymbol{S}_w\boldsymbol{W}}</script><h3 id="kaldi中的LDA变换"><a href="#kaldi中的LDA变换" class="headerlink" title="kaldi中的LDA变换"></a>kaldi中的LDA变换</h3><p>kaldi中经常对提取的声学特征做LDA变换，也是首先收集统计量，之后做LDA变换，输出变换矩阵。<br>统计量累计<code>lda-acc</code>接受GMM模型，声学特征和后验，输出统计量（主要是以下三个变量的值）。从GMM模型中可以知道pdf_class的个数，也就是数据集合的总的类别，记为$C$，特征维度记为$D$。那么统计量的维度以及存储的信息如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// C X 1 每一类的累计后验</span></span><br><span class="line">Vector&lt;<span class="keyword">double</span>&gt; zero_acc_;</span><br><span class="line"><span class="comment">// C X D 每一类的累计特征</span></span><br><span class="line">Matrix&lt;<span class="keyword">double</span>&gt; first_acc_;</span><br><span class="line"><span class="comment">// D X D 对称矩阵，存下三角 所有类的累计加权特征的平方</span></span><br><span class="line">SpMatrix&lt;<span class="keyword">double</span>&gt; total_second_acc_;</span><br></pre></td></tr></table></figure><br>具体求解变换矩阵的过程没有找到对应的理论依据，根据代码，过程如下：<br>定义全局方差（将所有数据视为一个整体）：</p>
<script type="math/tex; mode=display">
\boldsymbol{S}_t = E[\boldsymbol{X}^2] - E[\boldsymbol{X}]^2</script><p>之后按照如下的过程求解：</p>
<ol>
<li>$\boldsymbol{S}_w = \boldsymbol{S}_t - \boldsymbol{S}_b = \boldsymbol{L}\boldsymbol{L}^T$（乔列斯基分解）</li>
<li>$\boldsymbol{L}^{-1}\boldsymbol{S}_b = \boldsymbol{U}\boldsymbol{D}\boldsymbol{V}^T$（SVD分解）</li>
<li>$\boldsymbol{W} = \boldsymbol{U}\boldsymbol{L}^{-1}$（投影变换）</li>
</ol>
<p>补充：<br>后来在看ivector的时候发现上面的第一步做的应该是WCCN（Within-Class Covariance Normalization）。对于类内方差$\boldsymbol{W}$，WCCN定义变换：</p>
<script type="math/tex; mode=display">\phi(\boldsymbol{w}) = \boldsymbol{L}^T\boldsymbol{w}</script><p>其中$\boldsymbol{W}^{-1} = \boldsymbol{L}\boldsymbol{L}^T$，即$L$通过对$\boldsymbol{W}^{-1}$的乔列斯基分解得到。令：</p>
<script type="math/tex; mode=display">
\boldsymbol{S}_w = \boldsymbol{L}\boldsymbol{L}^T</script><p>则$\boldsymbol{S}_w^{-1} = (\boldsymbol{L}^T)^{-1}\boldsymbol{L}^{-1} = (\boldsymbol{L}^{-1})^T\boldsymbol{L}^{-1}$，所以：</p>
<script type="math/tex; mode=display">\phi(\boldsymbol{S}_b) = \boldsymbol{L}^{-1}\boldsymbol{S}_b</script>]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Kaldi</tag>
        <tag>LDA</tag>
      </tags>
  </entry>
  <entry>
    <title>编辑距离</title>
    <url>/2017/06/14/edit-distance/</url>
    <content><![CDATA[<p>编辑距离指在有限编辑条件下（增加，删除，替换），将一个字符串变换成另一个字符串所需的最小操作次数。语音中用到编辑距离的地方还是蛮多的，比如对CTC的预测进行评估的时候，就可以采用编辑距离。<br><a id="more"></a></p>
<p>一开始接触这个问题还是比较难和动态规划结合起来的，但是指明DP之后，转移方程还是很好写出来的，定义$D_{i, j}$为子串$A_{0 \to i}$和$B_{0 \to j}$的编辑距离，显然，状态$(i, j)$可以退化为三个状态：$(i - 1, j - 1), (i - 1, j), (i, j - 1)$，下面就是指出三个子状态和目标状态的关系。</p>
<ul>
<li>若$A[i] = B[j]$，则$D_{i, j} = D_{i - 1, j - 1}$，如果不相等，替换其中一个使它们相等，引入一步操作。</li>
<li>删除$A[i]$或者$B[j]$，引入一步操作。</li>
</ul>
<p>反过来考虑，子状态转移到目标状态的话，删除逻辑改为增加逻辑即可。程序的话，习惯记忆化搜索，自上而下的逻辑。边界条件：$D_{0, i} = D_{i, 0} = i$，代码逻辑如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">EditDist</span><span class="params">(<span class="keyword">char</span> *a, <span class="keyword">char</span> *b, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (i + j &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span> (i == <span class="number">0</span> || j == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> dis[i][j] = (i == <span class="number">0</span> ? j: i);</span><br><span class="line">    <span class="keyword">if</span> (dis[i][j] &gt;= <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> dis[i][j];</span><br><span class="line">    <span class="keyword">if</span> (a[i] == b[j])</span><br><span class="line">        <span class="keyword">return</span> dis[i][j] = EditDist(a, b, i - <span class="number">1</span>, j - <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> dis[i][j] = <span class="built_in">min</span>(</span><br><span class="line">                    EditDist(a, b, i - <span class="number">1</span>, j - <span class="number">1</span>),</span><br><span class="line">                    EditDist(a, b, i, j - <span class="number">1</span>),</span><br><span class="line">                    EditDist(a, b, i - <span class="number">1</span>, j)</span><br><span class="line">                ) + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>WER</tag>
      </tags>
  </entry>
  <entry>
    <title>关于Attention机制</title>
    <url>/2017/06/12/about-attention-model/</url>
    <content><![CDATA[<p>语音识别这块目前常见的端到端的方法除了CTC之外，就是attention（注意力）机制了。attention不同于CTC有着比较明确的数学定义和模式，它描述的应该是心理学现象中人注意力的某个特性，比如人的视觉上的注意力短期内只能集中在某一个区域中，而没有涵盖全部的视野范围。具体到语音识别任务（相比于图像和机器翻译领域，应用的算是比较晚的了）上，从字面意思看不出应该如何使用它。不过目前常见的使用方式和机器翻译类似，还是在encoder-decoder框架中使用。这种结合的思想是，定义一种描述注意力的方式，使得decoder可以尽量关注“有用”部分的信息，而不是全部的编码信息或者历史信息。<br><a id="more"></a></p>
<h3 id="RNN-Encoder-Decoder"><a href="#RNN-Encoder-Decoder" class="headerlink" title="RNN Encoder-Decoder"></a>RNN Encoder-Decoder</h3><p>许多机器学习任务都可以看成是一种不等长序列之间的转换任务，比如机器翻译（句子到句子），语音识别（特征序列到句子）等等。编码解码框架是一种解决变长序列映射问题的思路。核心思想是将待转换序列编码成一个特征向量，再通过解码将其转换成目标序列。</p>
<p>许多论文在介绍RNN-Encoder-Decoder的时候都是直接给出公式，没有过多的介绍，后来意外的在找GRU的原始论文的时候，发现GRU是Cho在提出RNN-Encoder-Decoder的时候，顺带对LSTM做的一个改动，鉴于论文一开始提到了</p>
<blockquote>
<p>In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN).</p>
</blockquote>
<p>我这里将其视为RNN-Encoder-Decoder的原始论文，其中第二部分详细介绍了Cho提出的所谓编码解码框架。</p>
<p>定义RNN的隐层状态为$\mathbf{h}$，输入序列$\mathbf{x} = \{x_1, x_2, \cdots, x_T\}$，对于普通的RNN，在$t$时刻，$\mathbf{h}$的更新由下式产生：</p>
<script type="math/tex; mode=display">\mathbf{h}_t = f(\mathbf{h}_{t - 1}, x_t)</script><p>由于RNN对过去信息具有一定的记忆功能，在$t$时刻网络的输出可以视为其在历史信息下的条件概率，即$p(x_t | x_1, x_2, \cdots, x_{t - 1})$。累计每个时刻下的条件概率可以得到序列$\mathbf{x}$出现的概率：</p>
<script type="math/tex; mode=display">p(\mathbf{x}) = \prod_{t = 1}^Tp(x_t | x_1, x_2, \cdots, x_{t - 1})</script><p>所谓的编解码方案是通过两个RNN网络，学习概率$p(\mathbf{y}|\mathbf{x})$（$\mathbf{x},\mathbf{y}$不等长）的分布，其中一个（编码器）学习将变长序列表示成定长序列，另一个（解码器）学习将此定长序列生成边长序列。</p>
<p>两者协调工作如下：编码器读入序列$\mathbf{x}$，处理完之后，隐层状态视为$\mathbf{c}$，解码器和编码器不同，解码器的隐层状态和预测输出均依赖于$\mathbf{c}$和前一时刻预测的输出$y_{t-1}$，表示如下：</p>
<script type="math/tex; mode=display">
\mathbf{h}_t = f(\mathbf{h}_{t - 1}, y_{t - 1}, \mathbf{c}) \\
p(y_t | y_1, y_2, \cdots, y_{t - 1}, \mathbf{c}) = g(\mathbf{h}_t, y_{t - 1}, \mathbf{c})</script><p>从这里可以看出，$\mathbf{c}$在解码器中是一成不变的，变化的只是$\mathbf{h}_t$和$y_t$，那么attention机制常见的应用点就集中在$\mathbf{c}$上。注意$\mathbf{h}_t$和$y_t$的生成顺序。</p>
<h3 id="Attention机制"><a href="#Attention机制" class="headerlink" title="Attention机制"></a>Attention机制</h3><p>以上描述的encoder-decoder在后续论文中基本都会提到，大部分情况下讲attention都会提到机器翻译领域的一篇文章（Neural Machine Translation by Jointly Learning to Align and Translate），包括那张经典的配图，如下<br><img src="http://www.funcwj.cn/images/attention-nmt.png" width="250"></p>
<p>图中的解码器的$s$和上一部分解码器中定义的$\mathbf{h}$相同。在不引入attention机制的情况下，$s$和$y$的更新如下（$\to$表示更新）：</p>
<script type="math/tex; mode=display">
\begin{align}
c, s_{t - 1}, y_{t - 1} &\to s_t \notag \\
c, s_t, y_{t - 1} &\to y_t \notag
\end{align}</script><p>引入attention之后，修正每一次的$c$为$c_t$，得到</p>
<script type="math/tex; mode=display">
\begin{align}
c_t, s_{t - 1}, y_{t - 1} &\to s_t \notag \\
c_t, s_t, y_{t - 1} &\to y_t \notag
\end{align}</script><p>这篇论文中用图中$\oplus$节点表示$c_t$，计算流程如下：</p>
<script type="math/tex; mode=display">
c_t = \sum_{t' = 1}^Ta_{tt'}h_{t'} \\
a_{tt'} = \text{softmax}(e_{tt'}) \\
e_{tt'} = a(s_{t - 1}, h_{t'})</script><p>$a$这里是一个对齐模型（align model），其中$a_{tt’}$（$a_{tt’}$和$e_{tt’}$的意义一样）表示在时刻$t$，解码器中隐层状态$h_{t’}$对上一时刻预测输出$y_{t - 1}$的重要程度，越重要在$c_t$中占比越大。训练阶段，$a$需要和编解码器一块训练，在这篇论文中，$a$使用的是一个一层的前向网络。</p>
<h3 id="attention在语音识别中的应用"><a href="#attention在语音识别中的应用" class="headerlink" title="attention在语音识别中的应用"></a>attention在语音识别中的应用</h3><p>Cho在“Attention-Based Models for Speech Recognition”中提出了一种ARSG（attention-based recurrent sequence generator）的结构来生成序列。文中给出的计算示意图如下：<br><img src="http://www.funcwj.cn/images/cho-attention-for-asr.png" width="400"></p>
<p>论文中将$c_t$重新称为glimpse，即$g_t$，定义的计算流程如图，貌似这里$y_t$和$s_t$的生成顺序变化了。</p>
<script type="math/tex; mode=display">
\begin{align}
\alpha_{t - 1}, s_{t - 1}, h &\to \alpha_t \notag \\
\alpha_t, h &\to g_t \notag \\
s_{t - 1}, g_t &\to y_t \notag \\
s_{t - 1}, g_t, y_t &\to s_t \notag
\end{align}</script><p>论文“End-to-End Attention-based Large Vocabulary Speech Recognition”也是在ARSG上做的改进，文中解释attention配图如下，基本和NMT那篇的逻辑一致。</p>
<script type="math/tex; mode=display">
\begin{align}
\alpha_{t - 1}, s_{t - 1}, h &\to \alpha_t \notag \\
\alpha_t, h &\to c_t \notag \\
s_{t - 1}, c_t, y_{t - 1} &\to s_t \notag \\
s_t, c_t, y_{t - 1} &\to y_t \notag
\end{align}</script><p><img src="http://www.funcwj.cn/images/attention-lvsr.png" width="400"></p>
<p>以上是对attention的一个大致学习，后续待补……</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>RNN</tag>
        <tag>Attention</tag>
        <tag>E2E</tag>
      </tags>
  </entry>
  <entry>
    <title>Kaldi中的决策树</title>
    <url>/2017/06/10/kaldi-decision-tree/</url>
    <content><![CDATA[<p>三音素状态绑定这部分通过以下四个步骤完成，分别对应<code>acc-tree-stats</code>，<code>cluster-phones</code>，<code>compile-question</code>，<code>build-tree</code>：</p>
<ol>
<li>统计量累计</li>
<li>音素聚类</li>
<li>问题集生成</li>
<li>决策树构建</li>
</ol>
<a id="more"></a>
<h2 id="统计量累计"><a href="#统计量累计" class="headerlink" title="统计量累计"></a>统计量累计</h2><p>累计统计量在<code>acc-tree-stats.cc</code>中的<code>AccumulateTreeStats</code>函数中完成，接受一个transition model，特征序列和对应的对齐信息，输出统计量表示。</p>
<p>统计量的结构表示：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 如果EventKeyType表示position信息，那么EventValueType表示该位置上的phone_id</span></span><br><span class="line"><span class="comment">// 如果EventKeyType为kPdfClass，那么EventValueType为对应的pdf_class</span></span><br><span class="line"><span class="comment">// pair&lt;EventKeyType, EventValueType&gt;组合为一个vector表示成一个EventType</span></span><br><span class="line"><span class="comment">// 一般单因素，1+1，三因素，3+1</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::pair&lt;EventKeyType, EventValueType&gt; &gt; EventType;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">map</span>&lt;EventType, GaussClusterable*&gt; tree_stats;</span><br></pre></td></tr></table></figure><br>统计量的具体信息在<code>GaussClusterable</code>里面，里面维护的是特征计数，特征向量和其平方和：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="comment">// n</span></span><br><span class="line"><span class="keyword">double</span> count_;</span><br><span class="line"><span class="comment">// stats_(0) =&gt; X1 + X2 + ... + Xn</span></span><br><span class="line"><span class="comment">// stats_(1) =&gt; X1^2 + X2^2 + ... + Xn^2</span></span><br><span class="line">Matrix&lt;<span class="keyword">double</span>&gt; stats_;</span><br></pre></td></tr></table></figure><br>在后续聚类操作的时候，用到了一个<code>Objf</code>函数计算似然值，函数逻辑是：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function">BaseFloat <span class="title">GaussClusterable::Objf</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">size_t</span> dim = stats_.NumCols();</span><br><span class="line">    <span class="function">Vector&lt;<span class="keyword">double</span>&gt; <span class="title">vars</span><span class="params">(dim)</span></span>;</span><br><span class="line">    <span class="keyword">double</span> objf_per_frame = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> d = <span class="number">0</span>; d &lt; dim; d++) &#123;</span><br><span class="line">        <span class="comment">// default var_floor_ = 0.01</span></span><br><span class="line">        double mean(stats_(0, d) / count_), var = stats_(1, d) / count_ - mean * mean, </span><br><span class="line">        floored_var = <span class="built_in">std</span>::<span class="built_in">max</span>(var, var_floor_);</span><br><span class="line">        vars(d) = floored_var;</span><br><span class="line">        objf_per_frame += <span class="number">-0.5</span> * var / floored_var;</span><br><span class="line">    &#125;</span><br><span class="line">    objf_per_frame += <span class="number">-0.5</span> * (vars.SumLog() + M_LOG_2PI * dim);</span><br><span class="line">    <span class="keyword">return</span> objf_per_frame * count_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>和推出来的似然函数保持一致：</p>
<script type="math/tex; mode=display">
L(S) = \sum_t\left[\log \mathcal{N}(o_t;\mu(S), \Sigma(S))\sum_{s \in S}\gamma_s^t\right] \\
= -\frac{1}{2}\left(D\log 2\pi + \log|\Sigma| + D \right)\sum_t \sum_{s \in S} \gamma_s^t</script><p>对$\gamma_s^t$的理解：</p>
<ol>
<li>为什么似然函数用上式表示</li>
<li>$t$时刻的观测是否来自状态$s$，那么$\gamma^t$最多是一个one-hot的向量</li>
<li>$t$时刻的观测是否来自状态$s$的概率</li>
</ol>
<p>该过程通过如下几步进行。</p>
<ul>
<li>把对齐信息按照音素划分，一行tid对应一个音素，存在<code>std::vector&lt;std::vector&lt;int32&gt; &gt;</code>里面。<br>注意一下，原始的对齐信息默认应该是进行过重新排序的，就是将自环放在出环之后。</li>
</ul>
<p>比如对于Transition Model如下（部分）：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Transition-state 1: phone &#x3D; SIL hmm-state &#x3D; 0 pdf &#x3D; 0</span><br><span class="line"> Transition-id &#x3D; 1 p &#x3D; 0.952097 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 2 p &#x3D; 0.01 [0 -&gt; 1]</span><br><span class="line"> Transition-id &#x3D; 3 p &#x3D; 0.01 [0 -&gt; 2]</span><br><span class="line"> Transition-id &#x3D; 4 p &#x3D; 0.0279074 [0 -&gt; 3]</span><br><span class="line">Transition-state 2: phone &#x3D; SIL hmm-state &#x3D; 1 pdf &#x3D; 1</span><br><span class="line"> Transition-id &#x3D; 5 p &#x3D; 0.921613 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 6 p &#x3D; 0.0531309 [1 -&gt; 2]</span><br><span class="line"> Transition-id &#x3D; 7 p &#x3D; 0.01 [1 -&gt; 3]</span><br><span class="line"> Transition-id &#x3D; 8 p &#x3D; 0.0152566 [1 -&gt; 4]</span><br><span class="line">Transition-state 3: phone &#x3D; SIL hmm-state &#x3D; 2 pdf &#x3D; 2</span><br><span class="line"> Transition-id &#x3D; 9 p &#x3D; 0.0146723 [2 -&gt; 1]</span><br><span class="line"> Transition-id &#x3D; 10 p &#x3D; 0.96533 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 11 p &#x3D; 0.01 [2 -&gt; 3]</span><br><span class="line"> Transition-id &#x3D; 12 p &#x3D; 0.01 [2 -&gt; 4]</span><br><span class="line">Transition-state 4: phone &#x3D; SIL hmm-state &#x3D; 3 pdf &#x3D; 3</span><br><span class="line"> Transition-id &#x3D; 13 p &#x3D; 0.01 [3 -&gt; 1]</span><br><span class="line"> Transition-id &#x3D; 14 p &#x3D; 0.01 [3 -&gt; 2]</span><br><span class="line"> Transition-id &#x3D; 15 p &#x3D; 0.928052 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 16 p &#x3D; 0.0519551 [3 -&gt; 4]</span><br><span class="line">Transition-state 5: phone &#x3D; SIL hmm-state &#x3D; 4 pdf &#x3D; 4</span><br><span class="line"> Transition-id &#x3D; 17 p &#x3D; 0.957834 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 18 p &#x3D; 0.0421665 [4 -&gt; 5]</span><br><span class="line">...</span><br><span class="line">Transition-state 9: phone &#x3D; ONE hmm-state &#x3D; 0 pdf &#x3D; 8</span><br><span class="line"> Transition-id &#x3D; 25 p &#x3D; 0.865902 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 26 p &#x3D; 0.134098 [0 -&gt; 1]</span><br><span class="line">Transition-state 10: phone &#x3D; ONE hmm-state &#x3D; 1 pdf &#x3D; 9</span><br><span class="line"> Transition-id &#x3D; 27 p &#x3D; 0.921862 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 28 p &#x3D; 0.078138 [1 -&gt; 2]</span><br><span class="line">Transition-state 11: phone &#x3D; ONE hmm-state &#x3D; 2 pdf &#x3D; 10</span><br><span class="line"> Transition-id &#x3D; 29 p &#x3D; 0.936872 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 30 p &#x3D; 0.0631278 [2 -&gt; 3]</span><br><span class="line">...</span><br><span class="line">Transition-state 24: phone &#x3D; SIX hmm-state &#x3D; 0 pdf &#x3D; 23</span><br><span class="line"> Transition-id &#x3D; 55 p &#x3D; 0.90631 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 56 p &#x3D; 0.0936895 [0 -&gt; 1]</span><br><span class="line">Transition-state 25: phone &#x3D; SIX hmm-state &#x3D; 1 pdf &#x3D; 24</span><br><span class="line"> Transition-id &#x3D; 57 p &#x3D; 0.783409 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 58 p &#x3D; 0.216591 [1 -&gt; 2]</span><br><span class="line">Transition-state 26: phone &#x3D; SIX hmm-state &#x3D; 2 pdf &#x3D; 25</span><br><span class="line"> Transition-id &#x3D; 59 p &#x3D; 0.931359 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 60 p &#x3D; 0.0686414 [2 -&gt; 3]</span><br><span class="line">Transition-state 27: phone &#x3D; SEVEN hmm-state &#x3D; 0 pdf &#x3D; 26</span><br><span class="line"> Transition-id &#x3D; 61 p &#x3D; 0.916657 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 62 p &#x3D; 0.0833432 [0 -&gt; 1]</span><br><span class="line">Transition-state 28: phone &#x3D; SEVEN hmm-state &#x3D; 1 pdf &#x3D; 27</span><br><span class="line"> Transition-id &#x3D; 63 p &#x3D; 0.886809 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 64 p &#x3D; 0.113191 [1 -&gt; 2]</span><br><span class="line">Transition-state 29: phone &#x3D; SEVEN hmm-state &#x3D; 2 pdf &#x3D; 28</span><br><span class="line"> Transition-id &#x3D; 65 p &#x3D; 0.898122 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 66 p &#x3D; 0.101878 [2 -&gt; 3]</span><br><span class="line">...</span><br><span class="line">Transition-state 33: phone &#x3D; NINE hmm-state &#x3D; 0 pdf &#x3D; 32</span><br><span class="line"> Transition-id &#x3D; 73 p &#x3D; 0.842715 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 74 p &#x3D; 0.157285 [0 -&gt; 1]</span><br><span class="line">Transition-state 34: phone &#x3D; NINE hmm-state &#x3D; 1 pdf &#x3D; 33</span><br><span class="line"> Transition-id &#x3D; 75 p &#x3D; 0.78074 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 76 p &#x3D; 0.21926 [1 -&gt; 2]</span><br><span class="line">Transition-state 35: phone &#x3D; NINE hmm-state &#x3D; 2 pdf &#x3D; 34</span><br><span class="line"> Transition-id &#x3D; 77 p &#x3D; 0.902379 [self-loop]</span><br><span class="line"> Transition-id &#x3D; 78 p &#x3D; 0.0976208 [2 -&gt; 3]</span><br></pre></td></tr></table></figure><br>那么tid序列可以为<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">74 73 73 73 73 76 75 75 75 75 75 75 78 77 77 77 77 77 77 77 77 77 77 77 77 77 77 62 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 64 63 63 63 63 63 63 63 63 63 63 63 63 63 63 66 65 65 26 28 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 30 4 1 1 1 1 1 16 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 18 56 58 57 57 60 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 26 25 25 25 28 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 30 29 29</span><br></pre></td></tr></table></figure></p>
<p>按照音素划分之后，得到：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">11 &#x3D;&gt; [74 73 73 73 73 76 75 75 75 75 75 75 78 77 77 77 77 77 77 77 77 77 77 77 77 77 77 ]</span><br><span class="line">9 &#x3D;&gt; [62 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 64 63 63 63 63 63 63 63 63 63 63 63 63 63 63 66 65 65 ]</span><br><span class="line">3 &#x3D;&gt; [26 28 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 30 ]</span><br><span class="line">1 &#x3D;&gt; [4 1 1 1 1 1 16 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 18 ]</span><br><span class="line">8 &#x3D;&gt; [56 58 57 57 60 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 ]</span><br><span class="line">3 &#x3D;&gt; [26 25 25 25 28 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 30 29 29 ]</span><br></pre></td></tr></table></figure></p>
<ul>
<li>对于每一条对齐信息，获取三音素和<code>pdf_class</code>的<code>EventType</code>事件类型，并累加其对应的<code>GaussClusterable</code>统计量。比如说对于以上对齐信息，可以得到音素序列<code>11-9-3-1-8-3</code>三音素的划分和<code>EventType</code>表示如下：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0-11-9  &#x3D;&gt; (0:0  1:11 2:9)</span><br><span class="line">11-9-3  &#x3D;&gt; (0:11 1:9  2:3)</span><br><span class="line">9-3-1   &#x3D;&gt; (0:9  1:3  2:1)</span><br><span class="line">3-1-8   &#x3D;&gt; (0:3  1:1  2:8)</span><br><span class="line">1-8-3   &#x3D;&gt; (0:1  1:8  2:3)</span><br><span class="line">8-3-0   &#x3D;&gt; (0:8  1:3  2:0)</span><br></pre></td></tr></table></figure>
对于每一种三音素划分，添加<code>pdf_class</code>即状态信息，并累计统计量，比如对于三音素<code>0-11-9</code>对应的统计量累计过程如下：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tree_stats(0:0 1:11 2:9 kPdfClass:0) +&#x3D; AddStats([74 73 73 73 73])</span><br><span class="line">tree_stats(0:0 1:11 2:9 kPdfClass:1) +&#x3D; AddStats([76 75 75 75 75 75 75])</span><br><span class="line">tree_stats(0:0 1:11 2:9 kPdfClass:2) +&#x3D; AddStats([78 77 77 77 77 77 77 77 77 77 77 77 77 77 77])</span><br></pre></td></tr></table></figure>
其他三音素类推。</li>
</ul>
<p>该过程执行完毕之后，将tree_stats信息写到磁盘中，实际就是<code>EventType</code>和<code>GaussClusterable</code>信息。</p>
<h2 id="音素聚类"><a href="#音素聚类" class="headerlink" title="音素聚类"></a>音素聚类</h2><p>音素聚类在<code>cluster-phones.cc</code>中的<code>AutomaticallyObtainQuestions</code>中完成，接受统计信息和<code>set.int</code>，输出音素聚类情况，也就是所谓的问题集。</p>
<h3 id="聚类过程"><a href="#聚类过程" class="headerlink" title="聚类过程"></a>聚类过程</h3><p>音素聚类主要进行如下几步操作</p>
<ul>
<li>状态过滤<br>默认只保留中间状态（<code>pdf_class = 1</code>）的统计量，这部分代码在<code>FilterStatsByKey</code>中，操作完毕之后，<code>stats</code>转为如下形式（<code>vector</code>存储）：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">(0:0  1:11 2:9 kPdfClass:1) &#x3D;&gt; C1</span><br><span class="line">(0:11 1:9  2:3 kPdfClass:1) &#x3D;&gt; C2</span><br><span class="line">(0:9  1:3  2:1 kPdfClass:1) &#x3D;&gt; C3</span><br><span class="line">...</span><br><span class="line">(0:8  1:3  2:0 kPdfClass:1) &#x3D;&gt; C6</span><br></pre></td></tr></table></figure></li>
<li>音素划分<br>按中间位置（<code>P == 1</code>）音素对统计量进行划分，累加，划分之后的统计量以phone_id为索引，这部分代码在<code>SplitStatsByKey</code>和<code>SumStatsVec</code>中实现，完成之后，统计量转换为如下形式：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">phone_id    GaussClusterable</span><br><span class="line">    1           C4</span><br><span class="line">    3        C3 + C6</span><br><span class="line">    8           C5</span><br><span class="line">    9           C2</span><br><span class="line">    11          C1</span><br></pre></td></tr></table></figure></li>
<li><p>按音素集合累加<br>由于在set.int中，可能是多个音素共享一个HMM的，但是他们的phone_id是不同的，所以，需要把这些共享HMM的音素对应的统计量做一个合并，存到<code>std::vector&lt;Clusterable*&gt;</code>之中。完成之后，vector的长度和set.int文件的行数相同。</p>
</li>
<li><p>决策树聚类<br>这部分在函数<code>TreeCluster</code>中完成，输入按音素集合累加之后的<code>std::vector&lt;Clusterable*&gt;</code>。聚类过程使用决策树+KMeans，KMeans算法主要目的是生成获取似然提升的划分方案。内在逻辑在“TreeClusterer的聚类逻辑”中介绍，最终目的是要获取如下信息，以生成问题集（即聚类结果）：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;int32&gt; assignments;  </span><br><span class="line"><span class="comment">// assignment of phones to clusters. dim == summed_stats.size().</span></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;int32&gt; clust_assignments;  </span><br><span class="line"><span class="comment">// Parent of each cluster.  Dim == #clusters.</span></span><br><span class="line">int32 num_leaves;  </span><br><span class="line"><span class="comment">// number of leaf-level clusters. == leaf_node_.size()</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>获取问题集合<br>这部分在函数<code>ObtainSetsOfPhones</code>中实现。函数接受上面决策树聚类得到的三个统计量以及<code>phone_sets</code>（即从set.int读出来的<code>std::vector&lt;std::vector&lt;int32&gt; &gt;</code>），输出一个<code>std::vector&lt;std::vector&lt;int32&gt; &gt;</code>类型的问题集/音素聚类结果。该部分依次完成如下操作：</p>
<ol>
<li>根据<code>assignments</code>，对<code>phone_sets</code>进行重新组合，每一类（cluster）对应一组phone_id，因为决策树可能把不同行的音素集划分为同一类了。</li>
<li>根据<code>clust_assignments</code>，组合出所有非叶子节点对应的phone_id，实际上就是其子节点phone_id之和，也就是要得到决策树上每一个节点音素id集合</li>
<li>补上原始<code>phone_sets</code>内的向量（暂时不理解），去空</li>
</ol>
</li>
</ul>
<p>最后将该聚类结果输入到文本question.int中，注意，实际看到的question.int可能还加上了一部分extra_question.int，比如在hkust中就是。展示question.int如下（不是完整的，加工自hkust，把set.int中每一行用对应的行号表示）<br><img src="http://www.funcwj.cn/images/question_demo.png" width="600"></p>
<h3 id="TreeClusterer的聚类逻辑"><a href="#TreeClusterer的聚类逻辑" class="headerlink" title="TreeClusterer的聚类逻辑"></a>TreeClusterer的聚类逻辑</h3><p>聚类过程通过<code>TreeClusterer</code>完成，下面主要分析<code>TreeClusterer</code>的聚类逻辑。</p>
<p>根据决策树理论，每一次节点分裂都是需要找到最大似然提升的方案，但是由于事先的这些音素统计量并没有标记信息，即无法根据标记信息制定划分方案，所以，一般采用无监督的方法进行二分类，取其最大的似然提升方案，kaldi中用到了KMeans聚类算法给出一次划分方案。</p>
<ul>
<li><p>决策树初始化<br>初始化给决策树建立根节点，并执行一次最优划分<code>FindBestSplit</code>。决策树由一系列<code>Node</code>构成，其中维护了其自身和叶子节点的统计信息。节点信息表示如下：</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span> &#123;</span></span><br><span class="line">    <span class="keyword">bool</span> is_leaf;</span><br><span class="line">    int32 index;  <span class="comment">// index into leaf_nodes or nonleaf_nodes as applicable.</span></span><br><span class="line">    Node *parent;</span><br><span class="line">    Clusterable *node_total;  <span class="comment">// sum of all data with this node.</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Clusterable*&gt; points;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;int32&gt; point_indices; <span class="comment">// index of points</span></span><br><span class="line">        BaseFloat best_split;</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Clusterable*&gt; clusters;  <span class="comment">// [branch_factor]... if we do split.</span></span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;int32&gt; assignments;  <span class="comment">// assignments of points to clusters.</span></span><br><span class="line">    &#125; leaf;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Node*&gt; children;  <span class="comment">// vector of size branch_factor.   if non-leaf.</span></span><br><span class="line">    <span class="comment">// pointers not owned here but in vectors leaf_nodes_, nonleaf_nodes_.</span></span><br><span class="line">  &#125;;</span><br></pre></td></tr></table></figure>
<p><code>FindBestSplit</code>总是在节点的<code>points</code>数据上执行最优划分，划分结果存储在<code>clusters</code>和<code>assignments</code>中。<code>assignments</code>表示<code>point_id</code>属于哪一个<code>cluster</code>。划分成功的话，将获得的最大似然提升和节点信息放在一个优先队列中。</p>
</li>
<li><p>最优划分逻辑<br>一次KMeans分类操作定义在<code>ClusterKMeansOnce</code>中，迭代<code>cfg.num_iters</code>次返回结果（了解KMeans原理就知道为什么这么做了）。<br>一次最优节点分裂<code>FindBestSplit</code>执行一次<code>ClusterKMeans</code>，<code>ClusterKMeans</code>具体操作是执行<code>cfg.num_tries</code>次<code>ClusterKMeansOnce</code>，找到最大获得最大似然提升的方案。</p>
</li>
<li><p>聚类逻辑<br>聚类采取BFS逻辑，不断的取出获取最大似然提升的节点，扩展子节点并在其子节点进行最优划分（这部分操作定义在<code>DoSplit</code>之中，主要是将父节点的<code>leaf</code>信息转移到新建子节点之中，并对子节点执行<code>FindBestSplit</code>），直至队列为空或者叶子节点达到上界，注意，这里的上界一般设为<code>phone_sets</code>的行数，假设set.int中有48组音素，那么聚类结果一定不大于48。</p>
<p>  在函数<code>DoSplit</code>中，需要完成以下操作：</p>
<ol>
<li>根据父节点的<code>leaf.assignments</code>划分结果，初始化子节点的<code>leaf.points</code>和<code>leaf.point_indices</code></li>
<li>根据父节点的<code>leaf.clusters</code>，初始化子节点的<code>node_total</code></li>
<li>给子节点的<code>index</code>编号，左节点继承父节点编号，在<code>leaf_nodes_</code>中替换父节点，右节点赋值为<code>leaf_nodes_.size()</code>，加入<code>leaf_nodes_</code>。</li>
<li>将父节点标记为非叶子节点，<code>index</code>赋值为非叶子节点的编号<code>nonleaf_nodes_.size()</code>并加入<code>nonleaf_nodes_</code></li>
<li>清空父节点的<code>leaf</code>信息。</li>
</ol>
</li>
<li><p>生成聚类信息<br><code>num_leaves_out</code>就是叶子节点的个数，其次主要就是要获取<code>assignments</code>和<code>clust_assignments</code>两类信息。<br><code>assignments</code>是音素集合id到决策树中叶子节点id的映射关系，只需要遍历所有叶子节点，每一次将对应叶子节点的<code>point_indices</code>集合中元素下标处赋值为叶子节点id即可。<br><code>clust_assignments</code>用来维护节点之间的父子关系，长度为叶子节点和非叶子节点个数之和。由于节点<code>index</code>都是从0开始的，所以会有冲突。kaldi中把非叶子节点通过<code>clust_assignments.size() - 1 - nonleaf_index</code>映射到区间<code>[leaf_nodes_.size(), clust_assignments.size()]</code></p>
</li>
</ul>
<h2 id="问题编译"><a href="#问题编译" class="headerlink" title="问题编译"></a>问题编译</h2><p>该部分接受topo文件和question.int输出编译好的问题集，实际就是<code>Questions</code>这个类结构。定义在<code>compile-question.cc</code>中。<code>Questions</code>维护了<code>EventKeyType</code>和其对应的<code>QuestionsForKey</code>集合，其中<code>QuestionsForKey</code>表示对于特定<code>EventKeyType</code>的查询问题集。事实上，输出的问题集包含以下信息：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">EventKeyType          QuestionsForKey</span><br><span class="line">    0             PhoneQuestions(question.int)</span><br><span class="line">    1             PhoneQuestions(question.int)</span><br><span class="line">    2             PhoneQuestions(question.int)</span><br><span class="line">kPdfClass            PdfClassQuestion</span><br></pre></td></tr></table></figure><br>其中<code>pdfClassQuestion</code>根据每个HMM建模的状态数而不同：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">MaxNumPdfclasses        PdfClassQuestion</span><br><span class="line">       3                  [[0] [0 1]]</span><br><span class="line">       5          [[0] [0 1] [0 1 2] [0 1 2 3]]</span><br></pre></td></tr></table></figure></p>
<h2 id="决策树构建"><a href="#决策树构建" class="headerlink" title="决策树构建"></a>决策树构建</h2><p>未完待续……</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Tree</tag>
        <tag>Kaldi</tag>
      </tags>
  </entry>
  <entry>
    <title>加权自动机的索引构造</title>
    <url>/2017/06/08/general-indexation-of-weighted-automata/</url>
    <content><![CDATA[<p>现实任务中，我们得到的大量信息都具有很高的不确定性，比如语言识别的结果取N-best的lattice网络，其中就包括了N种可能的带权序列。在对这种不确定信息的检索不同于以往确定信息中的检索模式（显然是权值相关的）。</p>
<p>我们可以将这些不确定的序列统一的用一个加权自动机（状态节点和带权的转移边）表示，那么这个问题就可以抽象成一个对加权自动机的索引构造算法。<br><a id="more"></a></p>
<p>提前弄清楚一个概念，之前也说过，因子（factor）。可以简单的理解成子串，前缀（prefix）或者后缀（suffix）都是因子。这种索引算法可以看成是后缀自动机和因子自动机的一种泛化。加权自动机索引构造的主要思想是：</p>
<p>对于$n$个句子，每个句子$u_i$可以用一个带权自动机$A_i$表示（其实就是解码的lattice）。可以构建一个带权转换器$T$，这个转换器可以检出这些自动机集合${A_1, A_2, \dots, A_n}$所接受的所有字符的因子。比如给出一个因子$x$，转换器$T$可以给出$x$出现的自动机集合下标和在对应的自动机中出现期望（的负log）：</p>
<script type="math/tex; mode=display">T_i(x) = -\log(E_{P_i}[C_x])</script><p>其中$P_i$是$A_i$的概率分布，$C_x$是因子$x$在$u_i$中出现的次数。</p>
<p>由于是WFST框架，符号定义在WFST入门中已经说明了。索引构造的思想很简单，和后缀自动机十分类似，其中的很多优化过程直接使用WFST的标准操作就OK。主要分为两步骤，依次处理$A_i \to T_i$，最后$T = \bigcup T_i$即可。对于第一步，为自动机接受的字符的每一个后缀建立一条转移路径，路径输出是自动机的下标和对应的权值，输入就是后缀。权值通过前向-后向算法进行：</p>
<p>定义$A_i$中状态$q$的前向和后向概率是$f_i[q], b_i[q]$：</p>
<script type="math/tex; mode=display">
\begin{align}
f_i[q] = \bigoplus_{\pi \in P(I_i, q)}^{\log} \lambda_i[p[\pi]] + w[\pi] \notag \\
b_i[q] = \bigoplus_{\pi \in P(q, F_i)}^{\log} \rho_i[n[\pi]] + w[\pi] \notag \\
\end{align}</script><p>那么，因子$x$在$T_i$中出现的概率表示为：</p>
<script type="math/tex; mode=display">
T_i(x) = \bigoplus_{i[\pi] = x}^{\log} \lambda_i[p[\pi]] + w[\pi] + \rho_i[n[\pi]]</script><p>$A_i \to T_i$分为如下几步：</p>
<ol>
<li>预处理：对$A_i$进行weight-push转换为$B_i$</li>
<li>因子选择：因为$B_i$还是一个acceptor，没有输出，所以先将$B_i$中每条弧的输出初始化为$\epsilon$，之后新增初始节点$s_i$和终止节点$e_i$，为$B_i$中的每一个状态$q$增加两条弧$(s_i, \epsilon, \epsilon, d_i[q], q)$和$(q, \epsilon, i, f_i[q], e_i)$</li>
<li>优化操作，即$\epsilon$-remove，确定化和最小化</li>
</ol>
<p>$T_i$的输出信息只有下标$i$，所以将它放在终止边上就行。第三步的优化操作得到和原先等价的转换器，只是在空间复杂度更低，搜索效率更高。得到$T_i$之后，通过$T = \bigcup T_i$和进一步的确定化，得到最终整体的索引转换器。用户的查询表示可以用自动机$X$表示，查询结果$R$有下式给出：</p>
<script type="math/tex; mode=display">R = \Pi_o(X \circ T)</script><p>举个例子，在论文<a href="http://cs.nyu.edu/~mohri/pub/nfac.pdf" target="_blank" rel="noopener">General Suffix Automaton Construction Algorithm and Space Bounds</a>中实现了从String Acceptor到后缀自动机的通用构造算法，得到后缀自动机之后，将每一个状态设置为final，再执行一些简化操作就可以得到因子自动机了（acceptor），只是没有权值信息。实际上这个构造过程也可以用上面的方式进行，原文给出的例子如下：</p>
<p><img src="http://www.funcwj.cn/images/suffix_generation_egs.png" alt="suffix_generation_egs.png-54.7kB"></p>
<p>按照上面的流程，先对左边的Acceptor进行因子选择：</p>
<p><img src="http://www.funcwj.cn/images/string_select.jpg" alt="string_select.jpg-53.6kB"></p>
<p>由于加入的都是$\epsilon$边，所以因子选择实际上构建出了对输入自动机接受的字符串集合的所有因子的索引，只是不够简化而已，接下来对其进行简化操（等价操作）就可以得到最终的索引自动机。首先去除$\epsilon$边。</p>
<p><img src="http://www.funcwj.cn/images/string_rmeps.jpg" width="450"></p>
<p>上面的结果不是确定的，执行确定化操作：</p>
<p><img src="http://www.funcwj.cn/images/string_deter.jpg" width="450"></p>
<p>这个结果实际上就是将后缀自动机的每一个状态设为final之后的结果，但是还有优化空间，最小化之后得到最终的形式：</p>
<p><img src="http://www.funcwj.cn/images/string_minim.jpg" width="450"></p>
<p>查询操作可以抽象为Compose操作，比如给出$cab$子串，查询结果为$cab$，如果是$cdb$，那么查询结果为$\epsilon$，表示子串不存在。</p>
<p>以上说明没有考虑权值，加权因子索引构造的因子选择是要在$\epsilon$边上加上权值信息的，权值信息可由前向-后向算法完成。</p>
<p>最后说一下TFT，整体看来kaldi-kws的TFT时间因子转换器完全继承了这套方法的衣钵，理解这部分之后再看TFT就相对容易一些。而且这个框架在论文中也提到，具有很高的通用性。TFT的修正在于，1) 将时间间隔信息带入权值之中，以便给出关键词出现的时间区间，2) 加入了聚类标识符，索引不相交的因子。</p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>WSA</tag>
      </tags>
  </entry>
  <entry>
    <title>一个简单内存管理器的实现</title>
    <url>/2017/06/05/htk-memheap-demo/</url>
    <content><![CDATA[<p>可能是C/C++用的多一些，看代码的时候总是习惯先看内存分配和管理部分的内容，看完之后心里才觉得踏实。之前看HTK源码的时候发现HTK中实现了一个简单的内存管理器（MemHeap），当时好奇，看了一下实现思路，非常朴素。<br><a id="more"></a><br>HTK的内存管理器提供三种内存分配方法：</p>
<ul>
<li>MHEAP 主要针对固定结构的内存分配，初始化的时候确定大小</li>
<li>MSTAK 可以申请任意大小的内存</li>
<li>CHEAP 这个基本就是对malloc的简单封装，HTKBook上也不推荐使用这种</li>
</ul>
<p>我尝试实现了第一种。本身是想在移植的时候替换的，后来发现没必要就没有使用。</p>
<p>第一种的实现逻辑就是先一次性申请一大块内存区域，称为一个Block，它的大小常常是注册分配单元的整数倍。Block通过一个单向链表管理，当有申请请求到来时，找出第一个非空Block的第一个非空区域首地址返回，并标记该区域已经分配。释放的话，只需要简单的将该标记置为未分配即可。如果没有非空Block，就在链表尾部继续分配一块。因为指针本身就是无符号的地址，所以释放内存时，定位需要“释放”的空间在哪个Block里面就很简单，只要依次和当前Block的首地址比较一下地址关系即可。</p>
<p>Demo提供如下接口：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// init and free</span></span><br><span class="line"><span class="function">Segment *<span class="title">NewSegment</span><span class="params">(<span class="keyword">int</span> segLen, <span class="keyword">int</span> eleLen)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">FreeSegment</span><span class="params">(Segment *seg)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// alloc/free items</span></span><br><span class="line"><span class="function"><span class="keyword">byte</span>* <span class="title">NewItem</span><span class="params">(Segment *seg)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">FreeItem</span><span class="params">(Segment *seg, <span class="keyword">byte</span> *addr)</span></span>;</span><br></pre></td></tr></table></figure></p>
<p>其中<code>Segment</code>定义如下<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">unsigned</span> <span class="keyword">char</span> <span class="keyword">byte</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">MemHeap</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    <span class="keyword">int</span> segLen;</span><br><span class="line">    <span class="keyword">int</span> eleLen;</span><br><span class="line">    <span class="keyword">int</span> newIdx;</span><br><span class="line">    <span class="keyword">byte</span> *vis;      <span class="comment">// 采用bit标记</span></span><br><span class="line">    <span class="keyword">byte</span> *data;     <span class="comment">// 空间地址</span></span><br><span class="line">    MemHeap *next;  <span class="comment">// next指针</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><br>由于分配，释放的逻辑在上面已经说明了，代码也很简单，下面直接给出简单实现了。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Segment *<span class="title">NewSegment</span><span class="params">(<span class="keyword">int</span> segLen, <span class="keyword">int</span> eleLen)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Segment *seg = (Segment*)<span class="built_in">malloc</span>(<span class="keyword">sizeof</span>(Segment));</span><br><span class="line">    seg-&gt;segLen = segLen;</span><br><span class="line">    seg-&gt;eleLen = eleLen;</span><br><span class="line">    seg-&gt;newIdx = <span class="number">0</span>;</span><br><span class="line">    seg-&gt;vis = (<span class="keyword">byte</span>*)<span class="built_in">malloc</span>(segLen / <span class="number">8</span> + <span class="number">1</span>);</span><br><span class="line">    seg-&gt;data = (<span class="keyword">byte</span>*)<span class="built_in">malloc</span>(segLen * eleLen);</span><br><span class="line">    seg-&gt;next = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="built_in">memset</span>(seg-&gt;vis, <span class="number">0</span>, segLen / <span class="number">8</span> + <span class="number">1</span>);</span><br><span class="line">    <span class="built_in">memset</span>(seg-&gt;data, <span class="number">0</span>, segLen * eleLen);</span><br><span class="line">    <span class="keyword">return</span> seg;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">FreeSegment</span><span class="params">(Segment *seg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Segment *cur, *next;</span><br><span class="line">    <span class="keyword">for</span>(cur = seg; cur != <span class="literal">NULL</span>; cur = next)</span><br><span class="line">    &#123;</span><br><span class="line">        next = cur-&gt;next;</span><br><span class="line">        <span class="keyword">if</span>(cur-&gt;vis)</span><br><span class="line">            <span class="built_in">free</span>(cur-&gt;vis);</span><br><span class="line">        <span class="keyword">if</span>(cur-&gt;data)</span><br><span class="line">            <span class="built_in">free</span>(cur-&gt;data);</span><br><span class="line">        <span class="built_in">free</span>(cur);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">SetSegVisited</span><span class="params">(Segment *seg, <span class="keyword">int</span> pos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(pos &gt;= seg-&gt;segLen)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"SetSegVisited: Accessed out of index: %d/%d\n"</span>, pos, seg-&gt;segLen);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    seg-&gt;vis[pos &gt;&gt; <span class="number">3</span>] |= <span class="number">1</span> &lt;&lt; (<span class="number">7</span> - (pos &amp; <span class="number">7</span>));</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">SetSegUnvisited</span><span class="params">(Segment *seg, <span class="keyword">int</span> pos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(pos &gt;= seg-&gt;segLen)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"SetSegUnvisited: Accessed out of index: %d/%d\n"</span>, pos, seg-&gt;segLen);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    seg-&gt;vis[pos &gt;&gt; <span class="number">3</span>] &amp;= ~(<span class="number">1</span> &lt;&lt; (<span class="number">7</span> - (pos &amp; <span class="number">7</span>)));</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsSegVisited</span><span class="params">(Segment *seg, <span class="keyword">int</span> pos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(pos &gt;= seg-&gt;segLen)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">fprintf</span>(<span class="built_in">stderr</span>, <span class="string">"IsSegVisited: Accessed out of index: %d/%d\n"</span>, pos, seg-&gt;segLen);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">-1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> (seg-&gt;vis[pos &gt;&gt; <span class="number">3</span>] &amp; (<span class="number">1</span> &lt;&lt; (<span class="number">7</span> - (pos &amp; <span class="number">7</span>)))) != <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">IsSegUsedUp</span><span class="params">(Segment *seg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> seg-&gt;newIdx == seg-&gt;segLen;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Segment* <span class="title">GetNextSeg</span><span class="params">(Segment *seg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Segment *cur, *pre;</span><br><span class="line">    <span class="keyword">for</span>(cur = seg; cur != <span class="literal">NULL</span>; cur = cur-&gt;next)</span><br><span class="line">    &#123;</span><br><span class="line">        pre = cur;</span><br><span class="line">        <span class="keyword">if</span>(!IsSegUsedUp(cur))</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span>(cur == <span class="literal">NULL</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        pre-&gt;next = NewSegment(pre-&gt;segLen, pre-&gt;eleLen);</span><br><span class="line">        <span class="keyword">return</span> pre-&gt;next;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> cur;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">byte</span>* <span class="title">NewItem</span><span class="params">(Segment *seg)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Segment *cur = GetNextSeg(seg);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">byte</span> *p = cur-&gt;data + cur-&gt;eleLen * cur-&gt;newIdx;</span><br><span class="line">    SetSegVisited(cur, cur-&gt;newIdx);</span><br><span class="line">    <span class="comment">// update newIdx</span></span><br><span class="line">    <span class="keyword">while</span>(cur-&gt;newIdx &lt; cur-&gt;segLen)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span>(!IsSegVisited(cur, cur-&gt;newIdx))</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        cur-&gt;newIdx++;</span><br><span class="line">    &#125;</span><br><span class="line">    ShowSegUse(seg);</span><br><span class="line">    <span class="keyword">return</span> p;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Segment* <span class="title">LocateSeg</span><span class="params">(Segment *seg, <span class="keyword">byte</span> *addr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Segment *cur;</span><br><span class="line">    <span class="keyword">for</span>(cur = seg; cur != <span class="literal">NULL</span>; cur = cur-&gt;next)</span><br><span class="line">        <span class="keyword">if</span>(addr - cur-&gt;data &lt; cur-&gt;segLen * cur-&gt;eleLen)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">return</span> cur;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">FreeItem</span><span class="params">(Segment *seg, <span class="keyword">byte</span> *addr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Segment *cur = LocateSeg(seg, addr);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> pos = (addr - cur-&gt;data) / cur-&gt;eleLen;</span><br><span class="line"></span><br><span class="line">    SetSegUnvisited(cur, pos);</span><br><span class="line">    <span class="comment">// update newIdx</span></span><br><span class="line">    <span class="keyword">if</span>(pos &lt; cur-&gt;newIdx)</span><br><span class="line">        cur-&gt;newIdx = pos;</span><br><span class="line">    ShowSegUse(seg);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>我觉得这么做在某些情况下还是有较高的可用性的，比如你要（前提是用C）维护一个巨大的Hash表，二叉树，链表，有向图等这些结构的时候，在节点的分配阶段，你不需要注意太多，但是当销毁这些巨大的结构时，特别容易出现所谓的double free错误。有可能在之前动态更新结构的时候，某个节点已经被释放或者重置为<code>NULL</code>了，所以，每次释放，你可能都要无尽的重复着内存合法性的判断。当然，如果用的不是C语言，比如C++的话，我觉得完全没有必要，一方面，析构函数本身就可以处理内存释放的工作，其次就是，数据结构没必要从头自己实现了。</p>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title>Kaldi中的Transition Model</title>
    <url>/2017/06/04/kaldi-transition-model/</url>
    <content><![CDATA[<p>kaldi中的Transition Model主要维护了概率密度函数pdf，HMM拓扑类型，以及所有音素的HMM状态信息（即音素id，状态id，和对应的概率密度函数的id，单独索引的transition-id）。这篇是过去的讲解列表，弄清前面说的几个id之间的关系就行了。<br><a id="more"></a></p>
<h3 id="topo文件结构"><a href="#topo文件结构" class="headerlink" title="topo文件结构"></a>topo文件结构</h3><p><img src="http://www.funcwj.cn/images/topo.png" alt="topo.png-88.9kB"></p>
<h3 id="将topo文件读入HmmTopology"><a href="#将topo文件读入HmmTopology" class="headerlink" title="将topo文件读入HmmTopology"></a>将topo文件读入<code>HmmTopology</code></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">phones_     音素列表</span><br><span class="line">phone2idx_  该音素建模用哪一种拓扑结构【几状态】</span><br><span class="line">entries_    多少种拓扑结构【2】，每一种拓扑结构实际上由一系列状态描述</span><br></pre></td></tr></table></figure>
<h3 id="如何描述状态"><a href="#如何描述状态" class="headerlink" title="如何描述状态"></a>如何描述状态</h3><ul>
<li>发射概率: pdf，概率密度函数</li>
<li>转移概率：<code>transitions</code></li>
</ul>
<h3 id="关于pdfclass"><a href="#关于pdfclass" class="headerlink" title="关于pdfclass"></a>关于pdfclass</h3><ul>
<li><code>&lt;PdfClass&gt;</code>默认<code>forward_pdf_class</code>和<code>self_loop_pdf_class</code>相同</li>
<li>否则分开描述<code>&lt;ForwardPdfClass&gt;</code>，<code>&lt;SelfLoopPdfClass&gt;</code></li>
</ul>
<h3 id="Transition-Model的初始化条件"><a href="#Transition-Model的初始化条件" class="headerlink" title="Transition Model的初始化条件"></a>Transition Model的初始化条件</h3><ul>
<li><code>HmmTopology</code></li>
<li><code>ContextDependency</code>: 决策树，实际上，这里面维护一个<code>EventMap</code>，输入查询条件，给出查询结果</li>
</ul>
<h3 id="set-txt文件结构"><a href="#set-txt文件结构" class="headerlink" title="set.txt文件结构"></a>set.txt文件结构</h3><p><img src="http://www.funcwj.cn/images/phone-sets.png" alt="phone-sets.png-55.2kB"><br>set.txt文件中的一行表示这些因素共享一个一个pdf即GMM模型。所谓的决策树是在此基础之上，构建出索引树结构的。Transition Model初始化的时候只是针对单音素建模。所以决策树结构看起来比较简单（最后面附上两张图吧）。</p>
<h3 id="关于EventMap"><a href="#关于EventMap" class="headerlink" title="关于EventMap"></a>关于EventMap</h3><ul>
<li>SE: <code>SplitEventMap</code>：一般给出中心位置的phone-id应答【<code>key = P_</code>】</li>
<li>TE: <code>TableEventMap</code>：一般给出pdf-class应答，默认【<code>key = keyPdfClass =-1</code>】</li>
<li>CE: <code>ConstantEventMap</code>: 一对一，只给出答案</li>
<li><code>copy-tree --binary=false tree -</code> 看到的是什么: 树结构递归过程中间量的记录</li>
</ul>
<p><img src="http://www.funcwj.cn/images/copy-tree.png" alt="copy-tree.png-86.7kB"></p>
<h3 id="Transition-Model的作用"><a href="#Transition-Model的作用" class="headerlink" title="Transition Model的作用"></a>Transition Model的作用</h3><ul>
<li>维护音素建模的拓扑结构，就是<code>HmmTopology</code></li>
<li>维护了模型中所有<code>phone_id</code>，<code>state_id</code>， <code>pdf_id</code>的信息，索引称为<code>transition_state</code></li>
<li><code>transition_state</code>到first<code>transition_id</code>的映射</li>
<li><code>transition_id</code>到<code>transition_state</code>的映射</li>
<li><code>transition_id</code>到<code>pdf_id</code>的映射</li>
<li><code>transition_id</code>对应的转移概率<br>对应存储结构如下：<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line">HmmTopology topo_;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Tuple&gt; tuples_;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;int32&gt; state2id_;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;int32&gt; id2state_;</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;int32&gt; id2pdf_id_;</span><br><span class="line">Vector&lt;BaseFloat&gt; log_probs_;</span><br></pre></td></tr></table></figure>
<img src="http://www.funcwj.cn/images/transition-model-tuples.png" width="60%"></li>
</ul>
<h3 id="如何获取Tuples-phone-id，state-id，pdf-id-三元组信息"><a href="#如何获取Tuples-phone-id，state-id，pdf-id-三元组信息" class="headerlink" title="如何获取Tuples[phone-id，state-id，pdf-id]三元组信息"></a>如何获取Tuples[phone-id，state-id，pdf-id]三元组信息</h3><ul>
<li>在索引树中，可以获得【phone-id, pdf-class, pdf-id】信息</li>
<li>将上述结构按pdf-id索引，存入<code>pdf-info</code>中，这个结构的大小，就是我们要建模的pdf数目<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"># pdf_id =&gt; [phone_id, pdf_class], [phone_id, pdf_class]...</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::pair&lt;int32, int32&gt; &gt; &gt; pdf_info;</span><br></pre></td></tr></table></figure></li>
<li>从<code>topo</code>结构中，获取【phone-id, pdf-class, state-id】信息</li>
<li>将上述结构按照【phone-id, pdf-class】索引，存入<code>to_hmm_state_list</code>中<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"># phone_id pdf_class =&gt; state1 state2...</span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">map</span>&lt;<span class="built_in">std</span>::pair&lt;int32, int32&gt;, <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;int32&gt; &gt; to_hmm_state_list;</span><br></pre></td></tr></table></figure></li>
<li>merge【pdf-id: phone-id, pdf-class】和【phone-id, pdf-class: state-id】</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> pdf_id <span class="keyword">in</span> range(len(pdf_info)):</span><br><span class="line">    <span class="keyword">for</span> phone_id, pdf_class <span class="keyword">in</span> pdf_info[pdf_id]:</span><br><span class="line">        <span class="keyword">for</span> state_id <span class="keyword">in</span> to_hmm_state_list[phone-id, pdf-<span class="class"><span class="keyword">class</span>]:</span></span><br><span class="line">            tuples.append(phone_id, state_id, pdf_id)</span><br></pre></td></tr></table></figure>
<h3 id="如何获取state2id-id2state-id2pdf-id"><a href="#如何获取state2id-id2state-id2pdf-id" class="headerlink" title="如何获取state2id_,id2state_,id2pdf_id_"></a>如何获取<code>state2id_</code>,<code>id2state_</code>,<code>id2pdf_id_</code></h3><ul>
<li><code>transition_state</code>索引从1开始</li>
<li><code>transition_state</code>的总数就是<code>tuples_</code>的大小，也就是说,<code>tuples_</code>按<code>transition_state</code>索引</li>
<li>获取<code>state2id_</code><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">first_tid &#x3D; 1</span><br><span class="line">for state_id in range(1, tuples_.size + 1):</span><br><span class="line">    state2id_[state_id] &#x3D; first_tid</span><br><span class="line">    first_tid +&#x3D; num_of_tids_in_state</span><br></pre></td></tr></table></figure></li>
<li><code>state2id_</code>倒过来就是<code>id2state_</code></li>
<li><code>id2pdf_id_</code>根据tid找到<code>state_id</code>里面的<code>forward_pdf</code>或者<code>self_loop_pdf</code>就行</li>
</ul>
<h3 id="如何获取log-probs"><a href="#如何获取log-probs" class="headerlink" title="如何获取log_probs_"></a>如何获取<code>log_probs_</code></h3><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">for each tid:</span><br><span class="line">    find: first_state_id &#x3D; id2state_[tid]</span><br><span class="line">    get : pdf_class &#x3D; tid - first_state_id</span><br><span class="line">    find: cur_tuple &#x3D; tuples_[first_state_id - 1]</span><br><span class="line">    find: tpo_entry by cur_tuple.phone</span><br><span class="line">    get : log_trans_prob by tpo_entry[cur_tuple.state].transitions[pdf_class].prob</span><br></pre></td></tr></table></figure>
<h3 id="数据格式转换"><a href="#数据格式转换" class="headerlink" title="数据格式转换"></a>数据格式转换</h3><ul>
<li>查看模型transition信息<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show-transitions phones.txt final.mdl</span><br></pre></td></tr></table></figure></li>
<li>可视化tree，<code>dot</code>命令，详细查询graphviz<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># -Gsize指定大小，-T指定保存类型，可以是png, jpg, pdf等</span><br><span class="line">draw-tree phones.txt tree | dot -Gsize&#x3D;80,100 -Tpng &gt; tree.png</span><br><span class="line">draw-tree phones.txt tree | dot -Tpdf &gt; tree.pdf</span><br></pre></td></tr></table></figure></li>
<li>GMM模型转文本格式<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 输出到标准输出</span><br><span class="line">gmm-copy --binary&#x3D;false final.mdl -</span><br></pre></td></tr></table></figure></li>
<li>Tree转文本格式<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 输出到标准输出</span><br><span class="line">eg: copy-tree --binary&#x3D;false tree -</span><br></pre></td></tr></table></figure>
</li>
</ul>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>HMM</tag>
      </tags>
  </entry>
  <entry>
    <title>小结一下</title>
    <url>/2017/06/04/get-things-done/</url>
    <content><![CDATA[<p>从拿下一个腾讯云主机到今天把域名申了，零零星星两个多星期了。为了避免站点上东西太少，我从Cmd Markdown上拿了一部分东西（还是那句话，我只是在意一个markdown编辑器而已……）在markdown上记笔记，整理知识点还是相对随意的，毕竟就是自己看，能会意就行。放在云上，虽然我不会刻意去推广，但是仍然感觉会有误人子弟的潜在风险存在。<br><a id="more"></a></p>
<p>我对自身专业的认识就是，这是一个可玩性很高的领域，太多的未知意味着太多的趣味。说实话，真的从理想的角度说，我不想把自己限制在某一个角落，为了很多刻意设置的目标去打拼。小时候我总觉得research是有趣的，可是我不知道为什么我对它感兴趣。长大之后，有了一种模糊的感觉，好奇心作祟，和天生爱玩不无区别。仿佛是不经意间走入某个岔路口，后来惊奇的发现，这条路的风景比原来的有意思多了，就流连与此，无心返程了。重复那么几次之后，早已不知道自己身在何方，要去往何处，心里就只有一个念想，那就是，我要持续这种快乐。真正的痛苦在于舍不得告别。</p>
<p>从高中到大学，我一直觉得，纯粹的东西一旦带有了强烈的目的性，那么原始的趣味就不复存在了。高三我很痛苦，每天都是做过的题，学过的东西，我有想法，实现不了，想改变，无能为力啊。所以到了大学，我唯一的期望在于，能自己忙活自己的东西了。对自己的要求就是，有收获，有快乐，足以。</p>
<p>所以相比于过去的我，已经很不在意外界的评价了。我觉得我在机会触手可及的时候，没有选择去更好的学校，去追求所谓更好的资源，本身就已经是对大学四年的一个总结了。以至于我很多时候都在考虑教育这个问题，最后得出的结论就是，如果XX不能使我快乐，那么我为什么要XX？到这里就有点明白了，这个通用句式填上任意两个相关的词语，只要逻辑关系成立，就是通用的。所以，我是本质上只是一个“贪玩”的人？</p>
<p>我有时候好奇，是不是现在独生子女都有这个通病，太在意自己，以至于很少考虑外界的感受……</p>
<p>有点扯远了，以后照常的更新吧。风格上说我不是很喜欢把东西说的太细，毕竟是总结和记录，自己有个印象就行。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>checkpoint</tag>
      </tags>
  </entry>
  <entry>
    <title>Connectionist Temporal Classification</title>
    <url>/2017/06/03/ctc-conclusion/</url>
    <content><![CDATA[<p>CTC（Connectionist Temporal Classification）是为递归神经网络设计的一种输出层的损失准则。在语音领域，识别任务实际上是一种序列标记任务。比如，识别的目标就是要将观测到的帧序列映射到字符序列。传统的识别方案需要依靠因素分类器（即声学模型）得到当前观测帧的因素后验，之后借助解码网络得到最优路径从而得到字符序列。<br><a id="more"></a></p>
<p>但是，分类器并不能很好的进行序列标注任务。因为对于某一标注类别/label，分类器给出的是该类别/label出现可能的预测，这是一个沿时间轴的离散概率分布，对于连续label出现的情况，并不能直直接给出预测，而是要通过后续处理（比如解码，借助语言模型和字典等专业信息完成状态后验到最终的字符序列的映射）的方式完成对label序列概率分布的建模。其次，分类器的训练需要提前获知当前输入的标注信息。但是在实际任务中，比如因素状态分类器，通常无法直接从音频抄本中获知当前帧所对应的状态序列，所以，要借助已有的声学模型来获取，这一过程称为在识别任务中称为强制对齐（Force Alignment）。显然，声学模型，或者说分类器的表现效果十分依赖对齐的结果。</p>
<p>CTC允许RNN网络输出直接对label的标注序列进行预测，比如音素，字，词等等。所以，CTC具有以下优势：</p>
<ol>
<li><p>CTC损失函数的计算只依赖于对于输入的序列标注信息，对于音频而言，就是抄本，而不需要获得每一次输入的状态标注，比如每一帧对应的因素状态这样的信息。如此，舍去了传统识别框架中的对齐操作，也避免了由于对齐效果差对模型训练造成的负面影响。</p>
</li>
<li><p>CTC层的输出直接给出的是标注序列的出现概率。比如标记的是关键词序列$K = {c_1, c_2, c_3}$，那么，网络可以直接给出对$K$的概率预测，而不需要借助后续处理。因此，相比于分类器的“窗型”输出，CTC的输出呈现尖峰效应，如下图所示（BLSTM+CTC的数字序列预测）。</p>
</li>
</ol>
<p><img src="http://www.funcwj.cn/images/ctc_pick.png" width="60%"></p>
<p>假设CTC层输出可以将输入映射到label集合$A$，并在集合$A$之外定义一个空label符号$\epsilon$，令$A’ = A \cup {\epsilon}$。$\epsilon$符号表示当前输入不产生任何输出。对于一个长度为$T$的观测序列$\boldsymbol{x}$，CTC输出一条在集合$A’$上的序列$\pi$。假设每一时刻网络的输出概率都是独立的，那么可以得到序列$\pi$在给定长度为$T$的观测$\boldsymbol{x}$下的条件概率：</p>
<script type="math/tex; mode=display">
p(\pi | \boldsymbol{x}) = \prod_{t = 1}^{T} y_{\pi_t}^t</script><p>其中$y_{\pi_t}^t$表示在$t$时刻路径$\pi$对应的label出现的概率。考虑到最终要得到的是在集合$A$上的序列$\boldsymbol{l}$，所以还需要将$A’$上的序列$\pi$对应到$\boldsymbol{l}$上（训练阶段的抄本）。假设$A = {x, y}$，网络给出的路径$\pi$可能为${xx{\epsilon}xy{\epsilon}y, x{\epsilon}yy, x{\epsilon}{\epsilon}y}$，它们都可以对应到$A$上的一条序列$\boldsymbol{l} = xy$。若借助$\mathcal{F}: \pi \to \boldsymbol{l}$来表示这种多到一的映射关系，那么序列$\boldsymbol{l}$在给定观测$\boldsymbol{x}$下的条件概率为：</p>
<script type="math/tex; mode=display">
\begin{align}
    p(\boldsymbol{l} | \boldsymbol{x}) = \sum_{\pi \in \mathcal{F'}(\boldsymbol{l})} p(\pi | \boldsymbol{x}) \tag{1}
\end{align}</script><p>CTC的设计原理就是要通过最大化$\boldsymbol{l}$在观测序列$\boldsymbol{x}$下的条件概率，从而达到优化网络的目的。在识别任务中，$\boldsymbol{l}$为音频对应的抄本，$\boldsymbol{x}$为音频对应的特征。CTC通过映射$\mathcal{F}$成功解决了在序列标注问题中，输入输出维度不一致的问题（抄本序列长度往往低于音频长度）。</p>
<p>定义$\boldsymbol{l}$的长度为$U$，下标为$u$的label $\boldsymbol{l}_u$，那么$p(\boldsymbol{l} | \boldsymbol{x})$计算的是在时刻$T$到达$\boldsymbol{l}_U$的所有可能路径$\pi$在给定观测$\boldsymbol{x}$下的条件概率之和。这个问题如果直接求解，枚举满足条件的$\pi$，计算复杂度很高。可以根据动态规划原理，定义子问题$\alpha_t( u)$（在时刻$t$到达$\boldsymbol{l}_u$的可能路径条件概率之和）和$\beta_t(u)$（从时刻$t$和$\boldsymbol{l}_u$开始到达$\boldsymbol{l}_U$的可能路径条件概率之和）间接求解。他们分别被称为前向，后向概率。</p>
<p>令$F_t(u)$和$B_t(u)$为前向，后向概率计算中的可能路径集合，那么，前向，后向概率由下式计算得到：</p>
<script type="math/tex; mode=display">
\begin{align}
    \alpha_t(u) &= \sum_{\pi \in F_t(u)} \prod_{i = 1}^{t} y_{\pi_t}^t \notag \\
    \beta_t(u) &= \sum_{\pi \in B_t(u)} \prod_{i = t}^{T} y_{\pi_t}^t \notag
\end{align}</script><p>据此，可以计算出$(1)$式，令：</p>
<script type="math/tex; mode=display">
    \theta_t(u) = \alpha_t(u)\beta_t(u) = \sum_{\pi_t = \boldsymbol{l}_u, \mathcal{F}(\pi) = \boldsymbol{l}} \prod_{i = 1}^{T} y_{\pi_t}^t = \sum_{\pi_t = \boldsymbol{l}_u, \mathcal{F}(\pi) = \boldsymbol{l}} p(\pi | \boldsymbol{x}) \notag</script><p>那么</p>
<script type="math/tex; mode=display">
p(\boldsymbol{l} | \boldsymbol{x}) = \sum_{u = 1}^{|\boldsymbol{l}|} \theta_t(u)</script><p>实际在CTC的输出层是有空label $\epsilon$的，$\epsilon$被安插在每俩个相邻非空label之间。label序列$\boldsymbol{l}$被拓展为$\boldsymbol{l}’(U’ = 2U + 1)$。如果将前向，后向算法的搜索空间表示出来的话，如下图所示。<br><img src="http://www.funcwj.cn/images/ctc_feed.png" width="50%"></p>
<p>在状态$(t, u)$（即在时刻$t$，当前label为$\boldsymbol{l}’_u$），对于前向概率，有如下转移情况：</p>
<ol>
<li><p>如果当前label为空，那么$(t, u)$可以由状态$(t - 1, u)$和$(t - 1, u - 1)$得到。</p>
</li>
<li><p>如果当前label非空，那么$(t, u)$可以由状态$(t - 1, u)$，$(t - 1, u - 1)$和$(t - 1, u - 2)$得到。</p>
</li>
</ol>
<p>转移方程表示为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \alpha_t(u)=
    \begin{cases}
    [\alpha_{t-1}(u-1)+\alpha_{t-1}(u)]y_{\boldsymbol{l}'_u}^t,  & \boldsymbol{l}'_u=\epsilon \text{ or } \boldsymbol{l'}_u=\boldsymbol{l}'_{u-2} \\
    [\alpha_{t-1}(u-2)+\alpha_{t-1}(u-1)+\alpha_{t-1}(u)]y_{\boldsymbol{l}'_u}^t, & \text{otherwise}
    \end{cases} \notag
\end{equation}</script><p>类似的，对于后向概率转移方程为：</p>
<script type="math/tex; mode=display">
\begin{equation}
    \beta_t(u)=
    \begin{cases}
    [\beta_{t+1}(u+1)+\beta_{t+1}(u)]y_{\boldsymbol{l}'_u}^t,  & \boldsymbol{l}'_u=\epsilon \text{ or } \boldsymbol{l}'_u=\boldsymbol{l}'_{u+2} \\
    [\beta_{t+1}(u+2)+\beta_{t+1}(u+1)+\beta_{t+1}(u)]y_{\boldsymbol{l}'_u}^t, & \text{otherwise}
    \end{cases} \notag
\end{equation}</script><p>CTC层的损失函数通过似然函数表示，对于单个输入和标记label序列$(\boldsymbol{x}, \boldsymbol{l})$，似然函数为$\mathcal{L}(\boldsymbol{x}, \boldsymbol{l}) = -\ln p(\boldsymbol{l} | \boldsymbol{x})$，依次对CTC输出层的每个输出单元$y_s^t$求导（$1 \leqslant s \leqslant U + 1$）：</p>
<script type="math/tex; mode=display">
\begin{align}
    \frac{\partial \mathcal{L}(\boldsymbol{x}, \boldsymbol{l})}{y_s^t} = -\frac{\partial \ln p(\boldsymbol{l} | \boldsymbol{x})}{y_s^t} &= -\frac{1}{\ln p(\boldsymbol{l} | \boldsymbol{x})} \frac{\partial p(\boldsymbol{l} | \boldsymbol{x})}{y_s^t} \notag \\
    &= -\frac{1}{\ln p(\boldsymbol{l} | \boldsymbol{x})} \sum_{u = 1}^{|\boldsymbol{l}'|} \frac{\partial \theta_t(u)}{y_s^t} \notag \\
    &= -\frac{1}{\ln p(\boldsymbol{l} | \boldsymbol{x}) y_s^t} \sum_{u \in S(\boldsymbol{l}', s)} \theta_t(u) \notag
\end{align}</script><p>其中$S(\boldsymbol{l’}, s) = {u: \boldsymbol{l’}_u = s}$。得到损失函数对输出层的导数之后，就可以按照RNN中梯度传递规则，对CTC层之前的RNN网络进行训练了。</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>E2E</tag>
        <tag>CTC</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Kaidi谱特征的语音重构</title>
    <url>/2017/06/01/kaldi-based-reconstruction/</url>
    <content><![CDATA[<p>第一次是拿C写的，提谱特征，过增强网络，之后取噪声相位，重构音频，弄了一个星期，后来发现，其实可以不必这么麻烦的。用kaldi得到的增强特征，做一个逆的CMVN，之后拿Python处理一下特征还原就行了。<br><a id="more"></a></p>
<p>总结一下，语音重构主要是还原频域特征到时域上，使用原始音频的相位信息，流程如下</p>
<ol>
<li>获取一帧的谱特征</li>
<li>获取原始音频中对应帧的相位<br> a. 分帧<br> b. Remove DC<br> c. 预加重<br> d. 加窗<br> e. RFFT，获取相位，返回</li>
<li>对谱特征，取exp，开方得到幅度谱，这里只使用[1: 257]的值，不使用能量</li>
<li>幅度谱和相位点乘，RFFT，取前400维得到一帧数据</li>
<li>加窗</li>
<li>进行OverlapAdd, 实际上就是帧移相加</li>
<li>所有帧处理完之后，加一个低通滤波器</li>
<li>将采样值的范围恢复到原始音频的范围内</li>
</ol>
<p>代码如下，理清特征处理过程思路就很清晰了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""transform spectrogram to waveform"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> wave</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> kaldi_io</span><br><span class="line"><span class="keyword">import</span> wave_io</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> len(sys.argv) != <span class="number">4</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"format error: %s [spectrum] [origin-wave] [reconst-wave]"</span> % sys.argv[<span class="number">0</span>]</span><br><span class="line">    sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">WAVE_WARPPER = wave_io.WaveWrapper(sys.argv[<span class="number">2</span>])</span><br><span class="line">WAVE_RECONST = wave.open(sys.argv[<span class="number">3</span>], <span class="string">"wb"</span>)</span><br><span class="line"></span><br><span class="line">WND_SIZE = WAVE_WARPPER.get_wnd_size()</span><br><span class="line">WND_RATE = WAVE_WARPPER.get_wnd_rate()</span><br><span class="line"></span><br><span class="line">REAL_IFFT = np.fft.irfft</span><br><span class="line"></span><br><span class="line">HAM_WND = np.hamming(WND_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> open(sys.argv[<span class="number">1</span>], <span class="string">"rb"</span>) <span class="keyword">as</span> ark:</span><br><span class="line">    SPECT_ENHANCE = kaldi_io.next_mat_ark(ark)</span><br><span class="line">    SPECT_ROWS, SPECT_COLS = SPECT_ENHANCE.shape</span><br><span class="line">    <span class="keyword">assert</span> WAVE_WARPPER.get_frames_num() == SPECT_ROWS</span><br><span class="line">    INDEX = <span class="number">0</span></span><br><span class="line">    SPECT = np.zeros(SPECT_COLS)</span><br><span class="line">    RECONST_POOL = np.zeros((SPECT_ROWS - <span class="number">1</span>) * WND_RATE + WND_SIZE)</span><br><span class="line">    <span class="keyword">for</span> phase <span class="keyword">in</span> WAVE_WARPPER.next_frame_phase():</span><br><span class="line">        <span class="comment"># exclude energy</span></span><br><span class="line">        SPECT[<span class="number">1</span>: ] = np.sqrt(np.exp(SPECT_ENHANCE[INDEX][<span class="number">1</span>: ]))</span><br><span class="line">        RECONST_POOL[INDEX * WND_RATE: INDEX * WND_RATE + WND_SIZE] += \</span><br><span class="line">                    REAL_IFFT(SPECT * phase)[: WND_SIZE] * HAM_WND</span><br><span class="line">        INDEX += <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">1</span>, RECONST_POOL.size):</span><br><span class="line">        RECONST_POOL[x] += <span class="number">0.97</span> * RECONST_POOL[x - <span class="number">1</span>]</span><br><span class="line">    RECONST_POOL = RECONST_POOL / np.max(RECONST_POOL) * WAVE_WARPPER.get_upper_bound()</span><br><span class="line"></span><br><span class="line">    WAVE_RECONST.setnchannels(<span class="number">1</span>)</span><br><span class="line">    WAVE_RECONST.setnframes(RECONST_POOL.size)</span><br><span class="line">    WAVE_RECONST.setsampwidth(<span class="number">2</span>)</span><br><span class="line">    WAVE_RECONST.setframerate(WAVE_WARPPER.get_sample_rate())</span><br><span class="line">    WAVE_RECONST.writeframes(np.array(RECONST_POOL, dtype=np.int16).tostring())</span><br><span class="line">    WAVE_RECONST.close()</span><br></pre></td></tr></table></figure>
<p>当年python画风好奇怪，顺便补充一下谱特征的正向处理过程，我拿python写的结果和kaldi做了一下对比，在不加随机高斯量的时候，误差还是很小的。</p>
<p>kaldi中默认的普特征提取流程如下</p>
<ol>
<li>分帧【加一个随机高斯量，可以通过options去掉，默认为真】</li>
<li>Remove DC, 也就是减去帧的均值，移除直流分量</li>
<li>计算原始能量，放在第一维上</li>
<li>预加重</li>
<li>加窗，这里加的是指定类型的窗</li>
<li>RFFT, 取[1, 256]区间，注意，这里是能量log谱，不是幅度log谱</li>
<li>返回一帧的谱特征，继续</li>
</ol>
<p>Demo代码如下</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"></span><br><span class="line"><span class="string">"""compute spectrogram according to kaldi"""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> wave</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> len(sys.argv) != <span class="number">2</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"format error: %s [wave-in]"</span> % sys.argv[<span class="number">0</span>]</span><br><span class="line">    sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">SRC_WAVE = wave.open(sys.argv[<span class="number">1</span>], <span class="string">"rb"</span>)</span><br><span class="line">SRC_SAMPLE_RATE, TOT_SAMPLE = SRC_WAVE.getparams()[<span class="number">2</span>: <span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">WND_SIZE = int(SRC_SAMPLE_RATE * <span class="number">0.001</span> * <span class="number">25</span>)</span><br><span class="line">WND_OFFSET = int(SRC_SAMPLE_RATE * <span class="number">0.001</span> * <span class="number">10</span>)</span><br><span class="line">WAVE_DATA = np.fromstring(SRC_WAVE.readframes(TOT_SAMPLE), np.int16)</span><br><span class="line"></span><br><span class="line">FRAME_NUM = (WAVE_DATA.size - WND_SIZE) / WND_OFFSET + <span class="number">1</span></span><br><span class="line"><span class="comment"># FRAME_VEC = np.zeros(WND_SIZE)</span></span><br><span class="line"></span><br><span class="line">SPECT_LEN = <span class="number">257</span></span><br><span class="line">SPECT_VEC = np.zeros(SPECT_LEN)</span><br><span class="line"></span><br><span class="line">HAMMING = np.hamming(WND_SIZE)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> FRAME_NUM</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> range(FRAME_NUM):</span><br><span class="line">    BASE_PNT = index * WND_OFFSET</span><br><span class="line">    <span class="comment"># get frame</span></span><br><span class="line">    FRAME_VEC = np.array(WAVE_DATA[BASE_PNT: BASE_PNT + WND_SIZE], dtype=np.float)</span><br><span class="line">    <span class="comment"># dither...</span></span><br><span class="line">    <span class="comment"># remove dc mean</span></span><br><span class="line">    FRAME_VEC -= (np.sum(FRAME_VEC) / WND_SIZE)</span><br><span class="line">    <span class="comment"># calculate log energy</span></span><br><span class="line">    energy = math.log(np.sum(FRAME_VEC ** <span class="number">2</span>))</span><br><span class="line">    <span class="comment"># preemphasize</span></span><br><span class="line">    FRAME_VEC[<span class="number">1</span>: ] -= <span class="number">0.97</span> * FRAME_VEC[: <span class="number">-1</span>]</span><br><span class="line">    FRAME_VEC[<span class="number">0</span>] -= <span class="number">0.97</span> * FRAME_VEC[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># buffer</span></span><br><span class="line">    DFT_VALUE = np.zeros((SPECT_LEN - <span class="number">1</span>) * <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># hamming</span></span><br><span class="line">    DFT_VALUE[: WND_SIZE] = FRAME_VEC * HAMMING</span><br><span class="line">    <span class="comment"># power log</span></span><br><span class="line">    SPECT_VEC[<span class="number">0</span>] = energy</span><br><span class="line">    SPECT_VEC[<span class="number">1</span>: ] = np.log(np.abs(np.fft.rfft(DFT_VALUE)[<span class="number">1</span>: ]) ** <span class="number">2</span>)</span><br><span class="line">    <span class="comment"># print SPECT_VEC</span></span><br><span class="line">    <span class="comment"># print np.log(np.abs(np.fft.rfft(DFT_VALUE)) ** 2)</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Speech Enhancement</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>STFT</tag>
      </tags>
  </entry>
  <entry>
    <title>伸展树</title>
    <url>/2017/06/01/splay-tree/</url>
    <content><![CDATA[<p>伸展树是一种二叉平衡树，普通搜索树在构造序列不是很理想的情况下，访问复杂度会退化。相比于较高级的一点平衡树，伸展树实现上还是比较简单的，只有左旋和右旋两个操作。这种数据结构的优化思路是利用数据访问的局部性，将上次访问的数据节点旋转到根节点，而不破坏平衡树的结构。<br><a id="more"></a></p>
<p>我自己实现的时候，核心操作只有左旋和右旋（所谓的Zig/Zag）。这两个操作是对称的，所以一个函数就可以搞定。为了方便操作，每个节点维护一个表示自己是左/右子节点的标记<code>index_</code>。节点表示如下（为方便访问，类中无私有变量）<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SplayNode</span> &#123;</span></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    SplayNode(<span class="keyword">int</span> data, <span class="keyword">int</span> index, SplayNode *p): data_(data), index_(index), parent_(p) &#123;</span><br><span class="line">        child_.resize(<span class="number">2</span>, <span class="literal">NULL</span>);</span><br><span class="line">    &#125;;</span><br><span class="line">    SplayNode *parent_;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;SplayNode*&gt; child_;</span><br><span class="line">    <span class="keyword">int</span> data_;</span><br><span class="line">    <span class="keyword">int</span> index_;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>对于一个节点，它的左旋或者右旋涉及他的孩子，父亲和祖父节点，注意，统一考虑的话，实际上孩子节点和祖父节点都是可以不存在的，所以代码里面添加了一些存在性判断。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ZigOrZag</span><span class="params">(SplayNode *vis)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> index = vis-&gt;index_ != <span class="number">0</span>;</span><br><span class="line">    SplayNode *g = vis-&gt;parent_-&gt;parent_;</span><br><span class="line">    SplayNode *f = vis-&gt;parent_;</span><br><span class="line">    SplayNode *c = vis-&gt;child_[<span class="number">1</span> - index];</span><br><span class="line"></span><br><span class="line">    f-&gt;child_[index] = c;</span><br><span class="line">    <span class="keyword">if</span> (c != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        c-&gt;parent_ = f;</span><br><span class="line">        c-&gt;index_ = index;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    f-&gt;parent_ = vis;</span><br><span class="line">    vis-&gt;child_[<span class="number">1</span> - index] = f;</span><br><span class="line"></span><br><span class="line">    vis-&gt;parent_ = g;</span><br><span class="line">    <span class="keyword">if</span> (g != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        g-&gt;child_[f-&gt;index_] = vis;</span><br><span class="line">        vis-&gt;index_ = f-&gt;index_;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这么写的目的是双旋操作可以用以上单旋操作来表示。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">DualZigOrZag</span><span class="params">(SplayNode *vis)</span> </span>&#123;</span><br><span class="line">    ZigOrZag(vis-&gt;parent_);</span><br><span class="line">    ZigOrZag(vis);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">CrossZigOrZag</span><span class="params">(SplayNode *vis)</span> </span>&#123;</span><br><span class="line">    ZigOrZag(vis);</span><br><span class="line">    ZigOrZag(vis);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于一个访问节点<code>vis</code>而言，伸展树的伸展操作就是要使该节点转到根节点的位置。一次旋转不够就多次旋转，直至成为根节点。旋转方式就是网上双旋加单旋，主要取决于祖父，父亲和该节点的位置关系。代码如下：<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Splay</span><span class="params">(SplayNode *vis)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (vis-&gt;parent_ != <span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (vis-&gt;parent_-&gt;parent_ == <span class="literal">NULL</span>)</span><br><span class="line">            ZigOrZag(vis);</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (vis-&gt;index_ == vis-&gt;parent_-&gt;index_)</span><br><span class="line">                DualZigOrZag(vis);</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                CrossZigOrZag(vis);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>为了可视化，最终将树BFS成dot语言格式，可以绘制出来。<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">BFS</span><span class="params">(SplayNode *root)</span> </span>&#123;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">queue</span>&lt;SplayNode*&gt; Q;</span><br><span class="line">    Q.push(root);</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"digraph Splay &#123;"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"\tnode [shape = record, height = .1]"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">while</span> (!Q.empty()) &#123;</span><br><span class="line">        SplayNode *p = Q.front();</span><br><span class="line">        Q.pop();</span><br><span class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"\t"</span> &lt;&lt; p-&gt;data_ &lt;&lt; <span class="string">"[label = \"&lt;F0&gt; |&lt;F1&gt; "</span> &lt;&lt; p-&gt;data_ &lt;&lt; <span class="string">"|&lt;F2&gt; \"]\n"</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++) &#123;</span><br><span class="line">            <span class="built_in">std</span>::<span class="built_in">string</span> node = i == <span class="number">0</span> ? <span class="string">"F0"</span>: <span class="string">"F2"</span>;</span><br><span class="line">            <span class="keyword">if</span> (p-&gt;child_[i]) &#123;</span><br><span class="line">                <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"\t\""</span> &lt;&lt; p-&gt;data_ &lt;&lt; <span class="string">"\":"</span> &lt;&lt; node &lt;&lt; <span class="string">" -&gt; "</span></span><br><span class="line">                          <span class="string">"\""</span> &lt;&lt; p-&gt;child_[i]-&gt;data_ &lt;&lt;<span class="string">"\":F1;"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">                Q.push(p-&gt;child_[i]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"&#125;"</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>以<code>5, 4, 1, 2, 3, 8, 7, 6, 9</code>为例，原二叉搜索树如下：<br><img src="http://www.funcwj.cn/images/splay_input.jpg" alt="splay_input.jpg-15.2kB"></p>
<p>在这棵树上对节点的伸展结果如下：</p>
<p>节点4<br><img src="http://www.funcwj.cn/images/visit_node4.jpg" alt="visit_node4.jpg-15.2kB"></p>
<p>节点1<br><img src="http://www.funcwj.cn/images/visit_node1.jpg" alt="visit_node1.jpg-15.4kB"></p>
<p>节点7<br><img src="http://www.funcwj.cn/images/visit_node7.jpg" alt="visit_node7.jpg-15.8kB"></p>
<p>节点6<br><img src="http://www.funcwj.cn/images/visit_node6.jpg" alt="visit_node6.jpg-15.6kB"></p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>C/C++</tag>
        <tag>Tree</tag>
      </tags>
  </entry>
  <entry>
    <title>STC/MLLT</title>
    <url>/2017/05/29/stc-mllt/</url>
    <content><![CDATA[<p>GMM的传统建模中，为了避免建模单元参数过多，默认只存储协方差矩阵的对角形式。实际上这里做了一个隐性的假设，就是数据各个维度之间是不相关的，显然，这一点并不成立，但是如果对于每一个GMM建模单元都采取协方差矩阵表示方差的话，模型的整体参数量会急剧增大，所以，对于这一问题，一般有以下两种方式解决：</p>
<ul>
<li>特征方案，通过去相关算法，使得数据分布更适合用对角矩阵建模，比如DCT和LDA算法</li>
<li>模型方案，根据生成观测的不同状态，使用不同的变换算法</li>
</ul>
<p>Semi-Tied方法属于第二种，是基于state-specific rotation提出的一种通过在状态之间共享变换矩阵，解决该问题的方式。</p>
<a id="more"></a>
<h3 id="State-Specific-Rotation"><a href="#State-Specific-Rotation" class="headerlink" title="State-Specific Rotation"></a>State-Specific Rotation</h3><p>State-Specific Rotation用来对特征矩阵中的相关性建模，顺序如下</p>
<ol>
<li>对于每一个状态，有一个协方差矩阵，对它进行特征值分解</li>
<li>对齐之后，关联到这个状态的特征使用特征向量去相关</li>
<li>对该状态的多个高斯分量的对角协方差矩阵进行训练</li>
</ol>
<p>注：特征值分解【spectral decomposition】（线性代数学过）<br>对于一个状态$s$，它的协方差矩阵 $\Sigma_{full}^s$ 通过下式计算：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\Sigma_{full}^s & = \frac{\sum_t\gamma_t^s(o_t - \mu^s)(o_t - \mu^s)^T}{\sum_t\gamma_t^s} \\
\gamma_t^s & = p(q_t^s|M, O_T)
\end{aligned}</script><p>其中$\mu^s$表示对齐到该状态的数据均值，$\gamma<em>t^s$表示在$t$时刻，来自状态$s$的概率，$\Sigma</em>{full}^s$分解如下</p>
<script type="math/tex; mode=display">
\Sigma_{full}^s = U^s\Lambda^sU^{sT}</script><p>其中，$U^s$是特征向量组成的特征矩阵，$\Lambda^s$是对角矩阵</p>
<p>在训练阶段，对于每一帧观测特征$o_t$，将它关联到状态$s$，做如下变换得到状态相关的观测$o_t^s$：</p>
<script type="math/tex; mode=display">o_t^s = U^{sT}o_t</script><p>在一个状态内，对于每一个分量$m$，均值$\mu^{sm}$和方差$\Sigma_{diag}^m$更新如下：</p>
<script type="math/tex; mode=display">
\mu^{sm} = \frac{\sum_t \gamma_t^m o_t^s}{\sum_t \gamma_t^m} \Sigma_{diag}^m = \frac{\sum_t \gamma_t^m(o_t^s - \mu^{sm})(o_t^s - \mu^{sm})^T}{\sum_t \gamma_t^m}</script><p>而每一个分量对应的协方差矩阵$\Sigma^m$定义为：</p>
<script type="math/tex; mode=display">
\Sigma^m = U^s\Sigma_{diag}^mU^{sT}</script><p>识别阶段，每一个状态下特定分量的似然为</p>
<script type="math/tex; mode=display">
L(o_t; \mu^m, \Sigma^m, U^s) = \mathcal N(o_t^s;\mu^{sm}, \Sigma_{diag}^m)</script><p>有一点不明白，说这种方式不能用标准的ML算法更新，也和多分量模型无关，有一些解决的方法，暂时没有看懂……</p>
<h3 id="Semi-Tied-Covariance-Matrices"><a href="#Semi-Tied-Covariance-Matrices" class="headerlink" title="Semi-Tied Covariance Matrices"></a>Semi-Tied Covariance Matrices</h3><p>Semi-Tied理解为，对于识别器中的每一个分量，我们不使用不同的协方差矩阵，换句话说，它的协方差矩阵有两个量组成</p>
<ol>
<li>一个分量相关的对角协方差矩阵$\Sigma_{diag}^m$</li>
<li>Semi-Tied的非对角矩阵$H^r$</li>
</ol>
<p>那么，识别器中每一个GMM中每一个分量的协方差矩阵可以表示为：</p>
<script type="math/tex; mode=display">
\Sigma^m = H^r\Sigma_{diag}^mH^{rT}</script><p>由上式，令$A^r = (H^r)^{-1}$：</p>
<script type="math/tex; mode=display">
\Sigma_{diag}^m = (H^r)^{-1}\Sigma^m(H^{rT})^{-1} = A^r\Sigma^mA^{rT}</script><p>其中$H^r$可以被多个分量共享，从这里看，STC这种模型也就是比传统的GMM模型多了一个分量间可共享的矩阵$H^r$，使用EM算法更新，需要更新每个分量中的一下几个量：</p>
<script type="math/tex; mode=display">
(c^m, \mu^m, \Sigma_{diag}^m, H^r)</script><p>使用EM算法对以上参数进行估计，定义$Q$函数$Q(\hat{M}, M)$（$\hat{}$表示新模型）：</p>
<script type="math/tex; mode=display">
\begin{aligned}
Q(\hat{M}, M) & = \sum_Z \log P(X,Z|\hat{M})P(Z|X, M) \\
              & = \sum_{t, \; m \in M^r}\gamma_t^m \left\{ \log \left(|\hat{\Sigma}^m|^{-1}\right) - (o_t - \hat{\mu}^m)^T(\hat{\Sigma}^{m})^{-1}(o_t - \hat{\mu}^m) \right\}
\end{aligned}</script><p>上式中去除了一些优化无关的常量和系数，结合$\Sigma^m$的定义，上式展开为</p>
<script type="math/tex; mode=display">
Q(\hat{M},M) = \sum_{t,\; m \in M^r} \gamma_t^m\left\{\log \left(\frac{|\hat
{A}^r|^2}{|\hat{\Sigma}_{diag}^m| } \right) - (o_t - \hat{\mu}^m)^T\left(\hat{A}^{tT}(\hat{\Sigma}_{diag}^{m})^{-1}\hat{A}^{r}\right)(o_t - \hat{\mu}^m) \right\}</script><p>这里做一个化简，原理在“状态绑定之决策树似然公式”中证明过：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\sum_{t,\; m \in M^r} & \gamma_t^m\left[(o_t - \hat{\mu}^m)^T\left(\hat{A}^{rT}(\hat{\Sigma}_{diag}^{m})^{-1}\hat{A}^{r}\right)(o_t - \hat{\mu}^m)\right] \\
& = \sum_{t,\; m \in M^r} \gamma_t^m \cdot \text{tr}\left[\left(\hat{A}^{rT}(\hat{\Sigma}_{diag}^{m})^{-1}\hat{A}^{r}\right)(o_t - \hat{\mu}^m)(o_t - \hat{\mu}^m)^T\right] \\
& = \text{tr}\left[ \sum_{t,\; m \in M^r} \gamma_t^m \left(\hat{A}^{rT}(\hat{\Sigma}_{diag}^{m})^{-1}\hat{A}^{r}\right)(o_t - \hat{\mu}^m)(o_t - \hat{\mu}^m)^T\right] \\
& = \text{tr}\left[ \sum_{m \in M^r} \left(\hat{A}^{rT}(\hat{\Sigma}_{diag}^{m})^{-1}\hat{A}^{r}\right)\sum_{t}\gamma_t^m(o_t - \hat{\mu}^m)(o_t - \hat{\mu}^m)^T\right]
\end{aligned}</script><p>由</p>
<script type="math/tex; mode=display">
\frac{\sum_{t}\gamma_t^m(o_t - \mu^m)(o_t - \mu^m)^T}{\sum_t \gamma_t^m} = \Sigma^m = \left(A^{rT}(\Sigma_{diag}^{m})^{-1}A^{r}\right)^{-1}</script><p>得：</p>
<script type="math/tex; mode=display">
\text{tr}\left[ \sum_{m \in M^r} \left(\hat{A}^{rT}(\hat{\Sigma}_{diag}^{m})^{-1}\hat{A}^{r}\right)\sum_{t}\gamma_t^m(o_t - \hat{\mu}^m)(o_t - \hat{\mu}^m)^T\right] = \text{tr}\left[ \sum_{t,\;m \in M^r} \gamma_t^m I \right] = n\sum_{t,\;m \in M^r} \gamma_t^m</script><p>于是，$Q(M, \hat{M})$可写成：</p>
<script type="math/tex; mode=display">
Q(\hat{M}, M) = \sum_{t,\; m \in M^r} \gamma_t^m\left\{\log \frac{|\hat{A}^r|^2}{|\hat{\Sigma}_{diag}^m| } \right\} - n\sum_{t,\;m \in M^r} \gamma_t^m</script><p>在M步，更新的均值，方差如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\hat{\mu}^m & = \frac{\sum_t \gamma_t^m o_t}{\sum_t \gamma_t^m} \\
\hat{\Sigma}^m & = \frac{\sum_t \gamma_t^m(o_t - \hat{\mu}^m)(o_t - \hat{\mu}^m)^T}{\sum_t \gamma_t^m} \\
\hat{\Sigma}_{diag}^m & = \text{diag}\left( \hat{A}^r\hat{\Sigma}^m\hat{A}^{rT} \right)
\end{aligned}</script>]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>GMM</tag>
      </tags>
  </entry>
  <entry>
    <title>后缀自动机之DAWG构造</title>
    <url>/2017/05/28/dawg-const/</url>
    <content><![CDATA[<p>最近需要参考一下文本检索的思路，所以看了一下后缀自动机并做了实现。<br><a id="more"></a></p>
<p>定义：$\text{tail}(w)$表示词$w$中出现不止一次的最长后缀，比如 $\text{tail}(abcbc) = bc, \text{tail}(aaa) = aa, \text{tail}(aab) = \epsilon$。</p>
<p>定义： 当满足如下条件时，$y$被称为$w$中的新左上下文的第一次出现。</p>
<ol>
<li>$w = w_1yw_2$</li>
<li>$y$在$w_1y$中至少出现两次，而且除了最后一次之外，都必须和一个特定的前缀同时出现<br>比如$w = abcbc$中第二次出现的$bc$就是在新左上下文的第一次出现。</li>
</ol>
<p>那么：</p>
<ol>
<li>$wa$可以代表等价关系$\equiv_{wa}$上的一个等价类，它包含所有出现在$wa$子词集合中而不在$w$字词集合中的元素。</li>
<li>对于$w$的一个子词$x$，如果$x$表示等价关系$\equiv_w$上的一个等价类，那么它表示$\equiv_{wa}$上的一个等价类。这俩个类中的成员在一下情况下是不同的（意思是如果不满足这两个条件那么这两个集合是相同的）：$x \equiv_{w} \text{tail}(wa)$并且$\text{tail}(wa)$是在新的左上下文的第一次出现。在这种情况下，等价类$[x]_w$可以被划分为两类：词长超过$\text{tail}(wa)$保留在$[x]_{wa}$中，其他的划分进一个新类$[\text{tail}(wa)]_{wa}$，用$\text{tail}(wa)$表示。</li>
<li>在等价关系$\equiv_{wa}$上，除了1，2之外，再没有其他等价类。</li>
</ol>
<p>说明：上述表示有点抽象，举个例子，比如从$abcb \to abcbc$，拓展前后的划分表示如下：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">划分元素</th>
<th style="text-align:center">end-set</th>
<th style="text-align:center">代表元素 $x$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">a</td>
<td style="text-align:center">1</td>
<td style="text-align:center">a</td>
</tr>
<tr>
<td style="text-align:center">ab</td>
<td style="text-align:center">2</td>
<td style="text-align:center">ab</td>
</tr>
<tr>
<td style="text-align:center">c, bc, abc</td>
<td style="text-align:center">3</td>
<td style="text-align:center">abc</td>
</tr>
<tr>
<td style="text-align:center">cb,bcb,abcb</td>
<td style="text-align:center">4</td>
<td style="text-align:center">abcb</td>
</tr>
<tr>
<td style="text-align:center">b</td>
<td style="text-align:center">2,4</td>
<td style="text-align:center">b</td>
</tr>
</tbody>
</table>
</div>
<p>拓展后：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">划分元素</th>
<th style="text-align:center">end-set</th>
<th style="text-align:center">代表元素 $x$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">a</td>
<td style="text-align:center">1</td>
<td style="text-align:center">a</td>
</tr>
<tr>
<td style="text-align:center">ab</td>
<td style="text-align:center">2</td>
<td style="text-align:center">ab</td>
</tr>
<tr>
<td style="text-align:center">abc</td>
<td style="text-align:center">3</td>
<td style="text-align:center">abc</td>
</tr>
<tr>
<td style="text-align:center">cb,bcb,abcb</td>
<td style="text-align:center">4</td>
<td style="text-align:center">abcb</td>
</tr>
<tr>
<td style="text-align:center">abcbc,bcbc,cbc</td>
<td style="text-align:center">5</td>
<td style="text-align:center">abcbc</td>
</tr>
<tr>
<td style="text-align:center">b</td>
<td style="text-align:center">2,4</td>
<td style="text-align:center">b</td>
</tr>
<tr>
<td style="text-align:center">c,bc</td>
<td style="text-align:center">3,5</td>
<td style="text-align:center">bc</td>
</tr>
</tbody>
</table>
</div>
<ol>
<li>新增的等价类$[abcbc]_{wa}$包含了只在$abcbc$中出现的子串（相比拓展前多了${cbc, bcbc, abcbc}$三个子串）</li>
<li>拓展前的等价类$[abc]_w$在拓展后的串中分裂成了两个划分，分别是$[bc]_{wa}$和$[abc]_{wa}$。令$x = abc$，那么拓展前，有$abc \equiv_{w} bc$（因为$abc$和$bc$在划分$[abc]_w$中），拓展后，$\text{tail}(abcbc) = bc$而且$bc$在$abcbc$中满足新的左上下文的第一次出现。所以要对$[x]_w$，即$[abc]_w$进行分裂。分裂规则是：词长超过$bc$即2的${abc}$被划分进$[abc]_wa$中，其他的被划分进新的划分$[bc]_{wa}$中。其他不满足分裂条件的$x = {a, b, ab}$保持不变，$[x]_w = [x]_{wa}$。</li>
</ol>
<p>上述过程定义了$D_w \to D_{wa}$的拓展过程，构造后缀自动机的思路是，首先一个字符一个字符的完成$D_W$的构造，之后再完成从$D_W \to M_W$的转换。</p>
<p>定义：</p>
<ol>
<li>在$D_w$中，每个转移边要么是首要的，要么是次要的。</li>
<li>如果$xa = y$，那么从$x$代表的等价类到$y$代表的等价类的转移边就是首要的，否则就是次要的。</li>
<li>每个状态（除了初始状态）都有一个后缀指针，记录它在$T(w)$中的父节点。</li>
<li>如果$x$表示一个等价类，那么用$SC(x)$表示从$x$开始的后缀链。它是一条从$x$到$T(w)$根节点的路径。</li>
</ol>
<p>那么</p>
<ol>
<li>在等价关系$\equiv_{w}$上可以表示等价类的任何子串$x$，$SC(x)$都将$x$的后缀划分成了$|SC(x)|$类。</li>
<li>如果$w \ne \epsilon$，那么$D_w$宿节点的后缀节点指向$[\text{tail}(w)]_w$</li>
<li>回溯从$D_w$的宿节点到源节点的后缀指针过程中，遇到的第一个含有$a$的转移的等价类肯定有一个到$[\text{tail}((wa))]_w$的$a$转移。如果没有遇到$a$转移，那么$a$只在$wa$中出现一次，因此$\text{tail}(wa) = \epsilon$。</li>
<li>令$\text{tail}(wa) = xa$，那么$x$表示$\equiv_w$上的一个等价类，而且当且仅当从$[x]_w$到$[xa]_{w}$存在次要边的时候，$\text{tail}(wa)$是在左上下文的第一次出现。</li>
</ol>
<p>设计以上定义的目的是：</p>
<ol>
<li>在$D_w \to D_{wa}$过程中，后缀指针可以定义具体哪一个等价类需要分裂。</li>
<li>通过次要转移的存在可以确认该等价类是否需要被分裂。</li>
</ol>
<p>下面给出$abc \to abcb \to abcbc$的拓展过程：</p>
<p><img src="http://www.funcwj.cn/images/dawg_expand.jpg" width=500></p>
<p>上图中蓝色线条表示后缀指针，虚线表示次要边，实线表示首要边，宿节点默认为上一次拓展操作中添加的节点。<br>算法核心在于拓展节点和分裂节点两步，对于每一个新增字符$a$，拓展节点时，操作如下：</p>
<ol>
<li>新建一个节点$s$，建立一条从宿节点$e$到$s$的首要边，label为$a$。</li>
<li>确定新建节点的后缀节点。从宿节点开始，沿着后缀节点一路回溯（经过的节点称为回溯节点），直到到达源节点（$0$号节点)或者后缀节点被确定时停止，分为以下三种情况处理：<br>2.1 回溯节点没有label为$a$的边，那么新建一条到$s$的次要边<br>2.2 回溯节点有一条label为$a$的首要边，那么$s$的后缀节点就是这条边的指向<br>2.3 回溯节点有一条label为$a$的次要边，那么对这条边上的父子节点执行分类操作，分裂的新状态就是$s$的后缀节点</li>
<li>如果回溯完成，后缀节点还没确定，就设为源节点</li>
<li>$s$成为新的宿节点</li>
</ol>
<script type="math/tex; mode=display">
\begin{align}
&\text{expand}(a): \\
&\quad \quad e \xrightarrow{a}_{1} s \\
&\quad \quad \text{suffix}[s] = \epsilon\\
&\quad \quad p = \; e\\
&\quad \quad \text{while} \; p \ne 0 \; \text{then} \\
&\quad \quad \quad \quad p = \text{suffix}[p] \\
&\quad \quad \quad \quad a \notin \text{label}(p \to *, * \in \deg(p)) \; \Rightarrow p \xrightarrow{a}_{2} s \\
&\quad \quad \quad \quad p \xrightarrow{a}_1 q \Rightarrow \text{suffix}[s] = q \\
&\quad \quad \quad \quad p \xrightarrow{a}_2 q \Rightarrow \text{suffix}[s] = \text{split}(p, q) \\
&\quad \quad \text{suffix}[s] = \epsilon \Rightarrow \text{suffix}[s] = 0\\
&\quad \quad  e = \; s
\end{align}</script><p>分裂操作如下，对于父子节点$p, s$：</p>
<ol>
<li>新建一个子状态$c$</li>
<li>将$p \to s$的次要边，更改为$p \to c$的首要边</li>
<li>对于$s$所连接的节点，建立$c$到他们的次要边，label为$a$</li>
<li>$c$的后缀节点更改为$s$的后缀节点，$s$的后缀节点更改为$c$</li>
<li>从父节点$p$开始回溯，直到到达源节点。如果回溯节点存在和$s$的次要边，将它改为到$c$的次要边，继续回溯，否则停止回溯。</li>
</ol>
<script type="math/tex; mode=display">
\begin{align}
&\text{split}(p, s): \\
&\quad  \quad  p \xrightarrow{a}_2 s \Rightarrow p \xrightarrow{a}_1 c \\
&\quad  \quad  c \xrightarrow{a}_2 * \quad \text{for} \; * \in \deg(s) \\
&\quad  \quad  \text{suffix}[c] = \text{suffix}[s] \\
&\quad  \quad  \text{suffix}[s] = c\\
&\quad  \quad  \text{while} \; p \ne 0 \; \text{then} \\
&\quad  \quad  \quad  \quad p = \text{suffix}[p] \\
&\quad  \quad  \quad  \quad p \xrightarrow{a}_2 s \Rightarrow p \xrightarrow{a}_2 c \quad \text{or break}\\
&\quad  \quad  \text{return} \; c
\end{align}</script><p>以上图作为分析</p>
<script type="math/tex; mode=display">
\begin{align}
abc \to abcb:& \quad  0 \xrightarrow{b}_{2} 2 \Rightarrow \text{suffix}[4] = 5 =  \text{split}(0, 2) \notag \\
abcb \to abcbc:& \quad  5 \xrightarrow{c}_{2} 3 \Rightarrow \text{suffix}[6] = 7 =  \text{split}(5, 3) \notag
\end{align}</script><p>对于$\text{split}(0, 2)$：</p>
<script type="math/tex; mode=display">
0 \xrightarrow{b}_{2} 2 \Rightarrow 0 \xrightarrow{b}_{1} 5 \\
2 \xrightarrow{c}_1 3 \Rightarrow 5 \xrightarrow{c}_2 3 \\
\text{suffix}[5] = \text{suffix}[2] = 0 \\
\text{suffix}[2] = 5</script><p>对于$\text{split}(5, 3)$：</p>
<script type="math/tex; mode=display">
5 \xrightarrow{c}_{2} 3 \Rightarrow 5 \xrightarrow{c}_{1} 7 \\
3 \xrightarrow{b}_1 4 \Rightarrow 7 \xrightarrow{c}_2 4 \\
\text{suffix}[7] = \text{suffix}[3] = 0 \\
\text{suffix}[3] = 7 \\
0 \xrightarrow{c}_{2} 3 \Rightarrow 0 \xrightarrow{c}_{2} 7</script><p>以上仅仅是完成了$D_w$的在线构造，但是$D_w$还有简化的空间，后续还有相应的算法完成$D_w \to M_w$的转换，代码照着伪代码的思路写就行了，相比理论而言，简洁很多。</p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>DAWG</tag>
      </tags>
  </entry>
  <entry>
    <title>WFST核心算法</title>
    <url>/2017/05/28/wfst-kernel/</url>
    <content><![CDATA[<p>论文参考经典之作“Speech Recognition With Weighted Finite-State Transducers”，网上随便就能搜到。</p>
<a id="more"></a>
<h3 id="符号化："><a href="#符号化：" class="headerlink" title="符号化："></a>符号化：</h3><p>在半环$\mathbb K(\oplus, \otimes, 0, 1)$之上定义一个WFST</p>
<script type="math/tex; mode=display">def \quad T=(\mathcal A, \mathcal B, Q, I, F, E, \lambda, \rho)</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{align}
\mathcal A:& \text有限的输入字母表 \notag \\
\mathcal B:& \text有限的输入字母表 \notag \\
Q:& \text有限的状态集合 \notag \\
I,F:& \text始末状态 \ I,F \subseteq \ Q \notag \\
E:& 转移集合 \notag \\
\lambda:& 初始状态权值 \notag \\
\rho:& 结束状态权值 \notag \\
\end{align}</script><p>对于$e \in E$</p>
<script type="math/tex; mode=display">
\begin{align}
p[e]:& \text起始状态 \notag \\
n[e]:& \text终止状态 \notag \\
i[e]:& \text输入标签 \notag \\
o[e]:& \text输出标签 \notag \\
w[e]:& \text转移权值 \notag
\end{align}</script><p>对于多次转移形成的一个路径$\pi=e_1 \dots e_k$满足：</p>
<script type="math/tex; mode=display">n[e_i]=p[r_{i+1}]\ i=2,\dots ,k</script><p>将$p,n,w$这些函数应用到path上,令</p>
<script type="math/tex; mode=display">
n[\pi]=n[e_k] \\
p[\pi]=p[e_1] \\
w[\pi]=w[e_1] \otimes \dots \otimes w[e_k]</script><p>若存在路径集合$R$，那么</p>
<script type="math/tex; mode=display">w[R]=\bigoplus_{\pi \in R}w[\pi]</script><p>另做如下定义：</p>
<script type="math/tex; mode=display">
P(q,q'): \ q \to q'\ 的路径集合 \\
P(q,x,y,q'): \ q \to q',x \in \mathcal A, y \in \mathcal B \ 的路径集合 \\
P(q,x,q'): \ q \to q' \ input = x\ 的路径集合</script><p>上述定义拓展至$R,R’ \subseteq Q$</p>
<script type="math/tex; mode=display">
P(R,R')=\bigcup_{q \in R,\ q' \in R'}P(q,q')  \\
P(R,x,y,R')=\bigcup_{q \in R,\ q' \in R'}P(q,x,y,q')  \\
P(R,x,R')=\bigcup_{q \in R,\ q' \in R'}P(q,x,q')</script><p>定义一个transducer $T$在$input/output=(x,y)$时</p>
<script type="math/tex; mode=display">T(x,y)=\bigoplus_{\pi \in P(I,x,y,F)}\ \lambda[p[\pi]]\otimes w[\pi] \otimes \rho[n[\pi]]</script><p>同理</p>
<script type="math/tex; mode=display">T(x)=\bigoplus_{\pi \in P(I,x,F)}\ \lambda[p[\pi]]\otimes w[\pi] \otimes \rho[n[\pi]]</script><h3 id="Composition操作"><a href="#Composition操作" class="headerlink" title="Composition操作"></a>Composition操作</h3><p>定义$T_1$，$T_2$的Composition操作如下：</p>
<script type="math/tex; mode=display">T_1\circ T_2=\bigoplus_{z \in \mathcal B^*}T_1(x,z)\otimes T_2(z,y)</script><p>示例，详细操作见OpenFST<br><img src="http://www.funcwj.cn/images/composition-example.png" width="600"></p>
<p>操作的伪代码如下：</p>
<p><img src="http://www.funcwj.cn/images/composition.png" width="500"></p>
<p>算法设置一个队列，初始化两个操作数的$I$集合的笛卡尔积插入队列，之后进行BFS逻辑的流程。每一次迭代过程如下($e$表示一个状态节点的所有输出转移路径)</p>
<ol>
<li>从队列中取出一个state pair($p_1, p_2$)，这是一对状态节点，第一次pop时必然在$I$集合的笛卡尔集合中</li>
<li>依次比较每个状态节点的输出的转移路径($e_1, e_2$)，若满足$o[e_1] = i[e_2]$又不存在于队列中，加入队列</li>
<li>输出半群中加入一条新的转移路径，从$(p_1, p_2)$到$(n[e_1], n[e_2])$，路径标志为$(o[e_1], i[e_2], w[e_1] \otimes w[e_2])$</li>
</ol>
<p>根据上述流程，输出半群的过程也是BFS逻辑的，一次操作可以扩展完节点$(p_1, p_2)$的所有后继。</p>
<h3 id="Determination操作"><a href="#Determination操作" class="headerlink" title="Determination操作"></a>Determination操作</h3><p>对于一个FST中任意的状态$q$，如果从他出发的边没有着相同的输入，那么就可以说这个FST是deterministic的<br>定义若干符号表示如下</p>
<script type="math/tex; mode=display">
\begin{align}
p &: \text{带权子状态集合} \notag \\
Q[p] &: p\text{中的状态集合} \notag \\
E\left[Q[p]\right] &: p\text{中的状态集合的出弧集合} \notag \\
i[E\left[Q[p]\right]] &: p\text{中的状态集合的出弧集合的输入集合} \notag \\
\end{align}</script><p>算法如下<br><img src="http://www.funcwj.cn/images/Determinization.png" width="600"></p>
<p>注意，确定化之后的状态本身是未确定化之前的状态集合和权值的pair</p>
<ul>
<li>算法采用BFS逻辑，将带权子状态集合$q$放在队列中依次处理，初始化该集合状态为所有initial状态，权值为1</li>
<li>对于每次拿到的$q$，在对应的$i[E\left[Q[p]\right]]$中的每一种输入，做如下操作</li>
</ul>
<blockquote>
<ol>
<li>拿到有该类输入的出弧累计权值最小的一个权值作为新建出弧的权值$w’$</li>
<li>把这些出弧的目标状态和相应累计权值减去$w’$的集合，作为新建状态$q’$</li>
<li>新建$E[q, x, w’, p’]$</li>
<li>若新建状态$q’$为新，加入BFS队列中待处理</li>
</ol>
</blockquote>
<h3 id="RemoveEps操作"><a href="#RemoveEps操作" class="headerlink" title="RemoveEps操作"></a>RemoveEps操作</h3><p>RemoveEps去除FST中输入为$\varepsilon$的边，得到的FST和原FST等价，算法分为两步执行</p>
<ul>
<li>对于每一个状态$p$，计算$\varepsilon$闭包，结果定义为<script type="math/tex; mode=display">C(p) = \{(q, w): q \in \varepsilon(p), \; d[p, q] = w \in \mathbb{K} - \overline 0\}</script></li>
<li>对于每一个状态$p$，移除$\varepsilon$边，添加若干拓展边，这部分伪代码如下</li>
</ul>
<p><img src="http://www.funcwj.cn/images/remove-eps.png" width="600"></p>
<p>在该算法中，有三个状态比较重要</p>
<ul>
<li>当前正在处理的状态$p$</li>
<li>可以通过$p$的$\varepsilon$闭包到达的状态$q$</li>
<li>可以通过状态$p$到达的后继状态$r$</li>
</ul>
<p>若$q$是终止节点，那么$p$肯定也是终止节点</p>
<p>举个栗子：<br><img src="http://www.funcwj.cn/images/remove-eps-egs.png" width="700"></p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Decoder</tag>
        <tag>WFST</tag>
      </tags>
  </entry>
  <entry>
    <title>状态绑定之决策树似然公式</title>
    <url>/2017/05/28/decision-tree-loglike/</url>
    <content><![CDATA[<p>对于一般决策树而言，每一次的最优划分，是要找到一个标准，使得在这种标准之下进行的划分获取的信息增益最大，这里的信息增益一般表示划分之后信息熵的增量。在ASR中，决策树的划分标准是获取最大似然提升，在GMM模型中，对于一个状态集合$S$，其似然表示为：<br><a id="more"></a></p>
<script type="math/tex; mode=display">
\begin{aligned}
L(S) & = \sum_t\sum_{s \in S}\log \mathcal{N}(o_t;\mu(S), \Sigma(S))\gamma_s^t \\
& = \sum_t\left[\log \mathcal{N}(o_t;\mu(S), \Sigma(S))\sum_{s \in S}\gamma_s^t\right]
\end{aligned}</script><p>其中</p>
<script type="math/tex; mode=display">
\begin{aligned}
\log \mathcal{N}(o_t;\mu(S), \Sigma(S)) & = \log \frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\exp\left(\frac{-(o_t - \mu(S))\Sigma^{-1}(o_t - \mu(S))^T}{2}\right) \\
& = -\frac{1}{2}\left[D\log 2\pi + \log|\Sigma| + (o_t - \mu(S))\Sigma^{-1}(o_t - \mu(S))^T \right]
\end{aligned}</script><p>方差的定义为</p>
<script type="math/tex; mode=display">
\begin{aligned}
\Sigma &= \frac{\sum_t \left\{(\sum_{s \in S}\gamma_s^t) (o_t - \mu(S))(o_t - \mu(S))^T )\right\} }{\sum_t \sum_{s \in S} \gamma_s^t} \\
& = \frac{\sum_t \left\{\gamma^t(o_t - \mu(S))(o_t - \mu(S))^T )\right\} }{\sum_t \gamma^t}
\end{aligned}</script><p>对于$\gamma_s^t$，有如下两种理解：</p>
<ol>
<li>时刻t的state occupancy，由于一个时刻只能由一个状态生成，所以值为${0, 1}$</li>
<li>时刻t的观测由状态s生成的概率</li>
</ol>
<p>为了计算出$L(S)$，需要得到$\Sigma^{-1}$，由上式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\sum_t \gamma^t \cdot I & = \sum_t \left\{\gamma^t(o_t - \mu(S))(o_t - \mu(S))^T )\right\} \Sigma^{-1} \\
& = \sum_t \left(\gamma^t(o_t - \mu(S))\left[(o_t - \mu(S))^T \Sigma^{-1}\right]\right) \\
& = \sum_t \gamma^t A_t^{D \times 1}B_t^{1 \times D}
\end{aligned}</script><p>其中$A_t^{D \times 1} = o_t - \mu(S), B_t^{1 \times D} = (o_t - \mu(S))^T \Sigma^{-1}$</p>
<p>由$B_t^{1 \times D}A_t^{D \times 1} = \text{tri}(A_t^{D \times 1}B_t^{1 \times D})$：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\sum_t\left(\gamma^tB_t^{1 \times D}A_t^{D \times 1}\right) & = \text{tr}\left\{\sum_t \gamma^t A_t^{D \times 1}B_t^{1 \times D}\right\} \\
& = \text{tr}\sum_t \gamma^t \cdot I = D\sum_t \gamma^t  \\ 
& = \sum_t (o_t - \mu(S))^T \Sigma^{-1}(o_t - \mu(S))\gamma^t
\end{aligned}</script><p>带回$L(S)$：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L(S) & = \sum_t\left[\log \mathcal{N}(o_t;\mu(S), \Sigma(S))\sum_{s \in S}\gamma_s^t\right] \\
& = \sum_t\left\{-\frac{1}{2}\left[D\log 2\pi + \log|\Sigma| + (o_t - \mu(S))\Sigma^{-1}(o_t - \mu(S))^T \right]\gamma^t\right\} \\
& = -\frac{1}{2}\left(D\log 2\pi + \log|\Sigma|\right) \sum_t \gamma^t - \frac{1}{2}D \sum_t \gamma^t\\
& = -\frac{1}{2}\left(D\log 2\pi + \log|\Sigma| + D \right)\sum_t \sum_{s \in S} \gamma_s^t
\end{aligned}</script><p>得证</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Tree</tag>
        <tag>Kaldi</tag>
      </tags>
  </entry>
  <entry>
    <title>swig处理C指针参数传递</title>
    <url>/2017/05/28/swig-for-cptr/</url>
    <content><![CDATA[<p>用Python调用C模块容易发生的就是参数类型不一致的问题，比如，C函数接收传入指针，python端怎么办？这里使用swig作为一种备选方案，处理方式不一定明智简洁，旨在说明可行性。<br><a id="more"></a></p>
<ul>
<li>方案一：自我定义空间分配，释放，访问，修改等函数，用swig封装</li>
<li>方案二：使用swig内置carrays.i，这里用FFT举个栗子</li>
</ul>
<p>使用方法，直接在.i文件中声明carrays.i</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># fft.i</span></span><br><span class="line">%module fft</span><br><span class="line">%&#123;</span><br><span class="line"><span class="comment">#define SWIG_FILE_WITH_INIT</span></span><br><span class="line"><span class="comment">#include "fft.h"</span></span><br><span class="line">%&#125;</span><br><span class="line"></span><br><span class="line">%include <span class="string">"fft.h"</span></span><br><span class="line">%include <span class="string">"carrays.i"</span></span><br><span class="line">%array_functions(float, floatArray);</span><br></pre></td></tr></table></figure>
<p>其中<code>array_functions(type, name)</code>会创建一下四个函数</p>
<figure class="highlight"><table><tr><td class="code"><pre><span class="line">type *new_name(int nelements)   # 申请内存</span><br><span class="line">type *delete_name(type *ary)    # 释放内存</span><br><span class="line">type name_getitem(type *ary, int index)     # 访问</span><br><span class="line">void name_setitem(type *ary, int index, type value) # 赋值</span><br></pre></td></tr></table></figure>
<p>定义<code>setup.py</code>如下，也可以手动编译动态库</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;env python</span><br><span class="line">from distutils.core import setup, Extension</span><br><span class="line"></span><br><span class="line">example_module &#x3D; Extension(&#39;_fft&#39;,</span><br><span class="line">    sources&#x3D;[&#39;fft.cpp&#39;, &#39;fft_wrap.cxx&#39;,], )</span><br><span class="line"></span><br><span class="line">setup (name &#x3D; &#39;fft&#39;,</span><br><span class="line">       version &#x3D; &#39;0.1&#39;,</span><br><span class="line">       author      &#x3D; &quot;wujian&quot;,</span><br><span class="line">       description &#x3D; &quot;&quot;&quot;FFT implement by C&quot;&quot;&quot;,</span><br><span class="line">       ext_modules &#x3D; [example_module],</span><br><span class="line">       py_modules &#x3D; [&quot;fft&quot;],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>执行(<code>--inplace</code>使得生成的动态库在当前目录下)</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">swig -python -c++ fft.i</span><br><span class="line">python setup.py build_ext --inplace</span><br></pre></td></tr></table></figure>
<p>编写测试文件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> fft</span><br><span class="line"></span><br><span class="line">R = fft.new_floatArray(<span class="number">16</span>)</span><br><span class="line">I = fft.new_floatArray(<span class="number">16</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">16</span>):</span><br><span class="line">    fft.floatArray_setitem(R, i, <span class="number">0</span>)</span><br><span class="line">    fft.floatArray_setitem(I, i, <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">4</span>):</span><br><span class="line">    fft.floatArray_setitem(R, i, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">fft.ComplexFFT(R, I, <span class="number">16</span>, <span class="number">0</span>)</span><br><span class="line">fft.ComplexFFT(R, I, <span class="number">16</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">16</span>):</span><br><span class="line">    <span class="keyword">print</span> <span class="string">"[%10f %10f]"</span> %(fft.floatArray_getitem(R, i), fft.floatArray_getitem(I, i))</span><br><span class="line"></span><br><span class="line">fft.delete_floatArray(R)</span><br><span class="line">fft.delete_floatArray(I)</span><br></pre></td></tr></table></figure>
<p>测试结果</p>
<pre><code>[  1.000000  -0.000000]
[  1.000000  -0.000000]
[  1.000000   0.000000]
[  1.000000  -0.000000]
[  0.000000   0.000000]
[ -0.000000   0.000000]
[  0.000000   0.000000]
[ -0.000000   0.000000]
           ...
</code></pre><p>附FFT源码实现</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// FFT.h</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">float</span> PI = <span class="number">3.14159265</span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ComplexFFT</span><span class="params">(<span class="keyword">float</span> *R, <span class="keyword">float</span> *I, <span class="keyword">int</span> N, <span class="keyword">int</span> invert)</span></span>;</span><br></pre></td></tr></table></figure>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"fft.h"</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ComplexFFT</span><span class="params">(<span class="keyword">float</span> *R, <span class="keyword">float</span> *I, <span class="keyword">int</span> N, <span class="keyword">int</span> invert)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n, nn, i, j, m, cnt, inc, k;</span><br><span class="line">    <span class="keyword">float</span> tmpR, tmpI, WR, WI, Ri, Ii, Rj, Ij;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 原版本R[0]是数组大小，从R[1]开始是数据区域</span></span><br><span class="line">    R--, I--;</span><br><span class="line">    </span><br><span class="line">    n = N, nn = n &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(j = <span class="number">0</span>, i = <span class="number">0</span>; i &lt; n - <span class="number">1</span>; i++)   </span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="keyword">if</span>(i &lt; j)</span><br><span class="line">        &#123;  </span><br><span class="line">            tmpR = R[j + <span class="number">1</span>], tmpI = I[j + <span class="number">1</span>];</span><br><span class="line">            R[j + <span class="number">1</span>] = R[i + <span class="number">1</span>], I[j + <span class="number">1</span>] = I[i + <span class="number">1</span>];</span><br><span class="line">            R[i + <span class="number">1</span>] = tmpR, I[i + <span class="number">1</span>] = tmpI;</span><br><span class="line">        &#125;</span><br><span class="line">        m = n &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(j &gt;= m)</span><br><span class="line">        &#123;</span><br><span class="line">            j = j - m;</span><br><span class="line">            m = m &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        &#125; </span><br><span class="line">        j = j + m;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    m = <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// 1, 2, 4 级</span></span><br><span class="line">    <span class="keyword">while</span>(m &lt; n)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">            m = 1: [1, 2], [3, 4], [5, 6], [7, 8] 4</span></span><br><span class="line"><span class="comment">            m = 2: [1, 3], [2, 4], [5, 7], [6, 8] 2</span></span><br><span class="line"><span class="comment">            m = 4: [1, 5], [2, 6], [3, 7], [4, 8] 1</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//printf("M = %d\n", m);</span></span><br><span class="line">        cnt = <span class="number">0</span>, inc = n / (m &lt;&lt; <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// inc: 4 2 1</span></span><br><span class="line">        <span class="comment">// m  : 1 2 4</span></span><br><span class="line">        <span class="comment">// W递增inc</span></span><br><span class="line">        <span class="keyword">while</span>(cnt &lt; inc)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// m = 1: 1 3 5 7</span></span><br><span class="line">            <span class="comment">// m = 2: 1 5</span></span><br><span class="line">            <span class="comment">// m = 4: 1</span></span><br><span class="line">            i = cnt * m * <span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">            <span class="comment">// W[0, n]: inc</span></span><br><span class="line">            <span class="comment">// 计算m次 迭代inc次</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> t = <span class="number">0</span>; t &lt; m; t++, i++)</span><br><span class="line">            &#123;</span><br><span class="line">                j = i + m;</span><br><span class="line">                k = t * inc;</span><br><span class="line">                <span class="comment">// printf("[%3d, %3d] W[%3d, %3d]\n", i, j, k, nn);</span></span><br><span class="line">                k == <span class="number">0</span> ? WR = <span class="number">1.0</span>, WI = <span class="number">0.0</span>: WR = <span class="built_in">cos</span>(PI * k / nn), WI = -<span class="built_in">sin</span>(PI * k / nn);</span><br><span class="line">                <span class="keyword">if</span>(invert) WI = - WI;</span><br><span class="line">                <span class="comment">//(R[i], I[i]) = (Ri, Ii) + W * (Rj, Ij)</span></span><br><span class="line">                <span class="comment">//(R[j], I[j]) = (Ri, Ii) - W * (Rj, Ij)</span></span><br><span class="line">                Rj = R[j], Ij = I[j], Ri = R[i], Ii = I[i];</span><br><span class="line">                R[i] = Ri + WR * Rj - WI * Ij, I[i] = Ii + WR * Ij + WI * Rj;</span><br><span class="line">                R[j] = Ri - WR * Rj + WI * Ij, I[j] = Ii - WR * Ij - WI * Rj;</span><br><span class="line">            &#125;</span><br><span class="line">            cnt++;</span><br><span class="line">        &#125;</span><br><span class="line">        m = m &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (invert)</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">            R[i] = R[i] / n, I[i] = I[i] / n;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>Python绘制语谱图</title>
    <url>/2017/05/28/python-spectrum/</url>
    <content><![CDATA[<p>Linux上没装matlab，没有audition，开源的audacity程序没法看语谱(找到看的方法了……)，所以当时就简单写了一个，勉强能看。</p>
<a id="more"></a>
<p>基本原理是STFT，短时傅里叶变换，下面的程序思想和STFT类似，但是不完全一致，只是绘制了每一帧的幅度谱，效果看着还可以，语谱绘制使用matplotlib的<code>imshow</code>函数，直接传入矩阵即可，但是注意，该函数绘制的时候按列绘制，我在存储每一帧的结果是按行存储的，所以需要转置。</p>
<p>另外，之前还做了预加重，毕竟不是提取特征，不需要，细节看代码（当初的写的有点不规范啊）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> scipy.io.wavfile <span class="keyword">as</span> wav</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> len(sys.argv) != <span class="number">2</span>:</span><br><span class="line">    print(<span class="string">"Format error: &lt;src wave&gt;"</span>)</span><br><span class="line">    sys.exit()</span><br><span class="line"></span><br><span class="line">wavpath = sys.argv[<span class="number">1</span>]</span><br><span class="line"><span class="comment"># samples 返回类型是 numpy.ndarray</span></span><br><span class="line"><span class="comment"># 用这个模块读取wav scipy.io.wavfile，之前用的是python的wave模块</span></span><br><span class="line">rate, samples =  wav.read(wavpath)</span><br><span class="line"></span><br><span class="line">m = re.match(<span class="string">'(.*)/(.*)'</span>, wavpath)</span><br><span class="line"></span><br><span class="line">wavname = m.group(<span class="number">2</span>)</span><br><span class="line"><span class="keyword">print</span> <span class="string">"process %s..."</span> % wavname</span><br><span class="line"><span class="comment"># 转成浮点值</span></span><br><span class="line">wave = np.array(samples, dtype = <span class="string">"float"</span>)</span><br><span class="line"></span><br><span class="line">frame_off = <span class="number">160</span></span><br><span class="line">frame_len = <span class="number">400</span></span><br><span class="line">spect_len = <span class="number">512</span></span><br><span class="line"></span><br><span class="line">frame_num = (wave.size - frame_len) / frame_off + <span class="number">1</span></span><br><span class="line"><span class="comment"># 生成汉明窗</span></span><br><span class="line">hamwindow = np.hamming(frame_len)</span><br><span class="line">spect = np.zeros((frame_num, spect_len / <span class="number">2</span> + <span class="number">1</span>))</span><br><span class="line">z = np.zeros(spect_len - frame_len)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> idx <span class="keyword">in</span> range(frame_num):</span><br><span class="line">    base = idx * frame_off</span><br><span class="line">    frame = wave[base: base + frame_len]            <span class="comment"># 分帧</span></span><br><span class="line">    frame = np.append(frame * hamwindow, z)         <span class="comment"># 加窗</span></span><br><span class="line">    spect[idx:] = np.log10(np.abs(np.fft.rfft(frame))) <span class="comment"># FFT，返回幅度谱</span></span><br><span class="line"></span><br><span class="line">plt.title(wavname)</span><br><span class="line">plt.imshow(np.transpose(spect), origin=<span class="string">"lower"</span>, cmap = <span class="string">"jet"</span>, aspect = <span class="string">"auto"</span>, interpolation = <span class="string">"none"</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>给出一个绘制结果</p>
<p><img src="http://www.funcwj.cn/images/stft_demo.png" alt="stft_demo.png-221kB"></p>
<p>完善：还可以为横纵坐标加上单位（时间和频率），时间信息如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">xlocs &#x3D; np.linspace(0, frame_num - 1, 5)</span><br><span class="line">frame_dur &#x3D; 1 &#x2F; float(rate) * frame_off</span><br><span class="line">plt.xticks(xlocs, [&quot;%.02f&quot; % l for l in (xlocs * frame_dur)])</span><br><span class="line">plt.xlabel(&quot;time (s)&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="http://www.funcwj.cn/images/time_stft_demo.png" alt="time_stft_demo.png-211.7kB"></p>
<p>频率信息待完善…</p>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>Python</tag>
        <tag>Spectrogram</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu上安装pyfst</title>
    <url>/2017/05/28/pyfst-on-ubuntu/</url>
    <content><![CDATA[<p>pyfst是对openfst的python API封装，学习fst过程中，实现代价相对较低，安装的时候只要先装openfst，再<code>pip install pyfst</code>就OK了，但是，问题就出在这俩步上<br><a id="more"></a></p>
<h3 id="openfst版本问题"><a href="#openfst版本问题" class="headerlink" title="openfst版本问题"></a>openfst版本问题</h3><p>我装的时候，openfst已经发布到1.6.1版本了，kaldi里面装的也是，所以安装pyfst的时候，我指定的是1.6.1版本的位置，结果编译的时候就各种问题，后来想到可能是版本问题，装了一个常见的1.3.4，直接ok<br>注意，openfst默认configure的时候，不会编译动态库和静态库，通过<code>--enable-shared</code>和<code>--enable-static</code>让其编译的时候，编译库</p>
<h3 id="pyfst通过pip安装"><a href="#pyfst通过pip安装" class="headerlink" title="pyfst通过pip安装"></a>pyfst通过pip安装</h3><p>因为openfst安装不在系统目录之下，所以需要给pip提供头文件和链接库的索引位置，命令为<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo pip install --global-option='build_ext' \</span><br><span class="line">    --global-option='-I/home/wujian/Document/git/openfst-1.3.4/include/' \</span><br><span class="line">    --global-option='-L/home/wujian/Document/git/openfst-1.3.4/lib' pyfst</span><br></pre></td></tr></table></figure><br>注意的是，<code>-I/L</code>和后面的路径之间不能存在空格，否则一样找不到头文件<br>这样的问题在Mac上也出现过，解决思路同上，版本用1.4.3的话还是有问题，<code>&lt;tri/unorder_map&gt;</code>找不到，所以改成1.4.0版本就ok，但是最新版本还是不行。</p>
<h3 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h3><p>在Mac上<code>pip</code>安装pyaudio的时候，执行：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">brew install portaudio</span><br><span class="line">sudo pip install pyaudio</span><br></pre></td></tr></table></figure></p>
<p>也会出现找不到<code>portaudio.h</code>头文件的错误（可是这个头文件就在<code>/usr/local/include</code>下面……），最终的解决方法也是类似的：<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">sudo pip install --global-option='build_ext' \</span><br><span class="line">    --global-option='-I/usr/local/include' \</span><br><span class="line">    --global-option='-L/usr/local/lib' pyaudio</span><br></pre></td></tr></table></figure></p>
<p>PS: 之前以为是portaudio的问题，官网下了一个手动编译安装，但是缺少一个<code>pa_mac_core.h</code>头文件，所以卸了用<code>brew</code>了。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Problem</tag>
      </tags>
  </entry>
  <entry>
    <title>本地交叉编译Android执行文件</title>
    <url>/2017/05/28/x-compile-on-android/</url>
    <content><![CDATA[<p>用NDK很久了，玩一玩交叉编译，其实使用<code>ndk-build</code>和<code>Android.mk</code>，<code>Application.mk</code>文件也可以做这件事，但是因为NDK自带了toolchain的脚本，配置很方便，简单的编译可以依赖cmd了。<br><a id="more"></a></p>
<p>真机总是没有权限，<code>adb push</code>不上去，只能玩虚拟机了。<br>问题有点多，一个简单的info程序，有几个卡点。</p>
<ul>
<li><p>直接<code>adb push</code>的话，可能会报<code>read-only</code>的error，可以<code>adb remount</code>一下</p>
</li>
<li><p>push上去之后，默认权限中是没有x的，<code>chmod</code>一下</p>
</li>
<li><p>PIE错误如下</p>
</li>
</ul>
<p><img src="http://www.funcwj.cn/images/cross-complier-error.png" width="600"></p>
<p>之前的编译命令为<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">i686-linux-android-gcc main.cc -o mac_x86</span><br></pre></td></tr></table></figure></p>
<p>根据提示改为<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">i686-linux-android-gcc main.cc -fPIC -pie -o mac_x86</span><br></pre></td></tr></table></figure><br>可以正常执行了，如下。<br><img src="http://www.funcwj.cn/images/cross-complier-success.png" width="300"></p>
<p>注：<code>adb pull</code>可以取回android上的文件</p>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title>JNI下C读写大小端和权限问题</title>
    <url>/2017/05/28/jni-write-permission/</url>
    <content><![CDATA[<p>最近搞项目期间需要频繁的操作数据文件，之前都是用C进行操作，转到java的时候出现了一点小问题：<br>在Android平台上进行wave的特征重构，重构的wave文件希望使用C直接输入，因为这部分代码在PC上已经验证通过了。Android的话，Application的Context本身提供了<code>openFileInput</code>和<code>openFileOutput</code>，用于创建，写入存在目录<code>/data/data/package_name/files/</code>里面的文件。所以如果希望java能够读取C的输出文件的话，C在JNI部分的输出目录也应该是上面这个。<br><a id="more"></a></p>
<p>经过测试，C端的创建，写入均没有问题，java部分的读取也没有报错，只是第一次读取就失败。问题最终抽象成java读取二进制文件的问题。C端使用如下代码生成一个二进制文件<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (short i = <span class="number">0</span>; i &lt; <span class="number">400</span>; ++i)</span><br><span class="line">      fwrite(&amp;i, <span class="keyword">sizeof</span>(short), <span class="number">1</span>, wav);</span><br></pre></td></tr></table></figure></p>
<p>java上原先打算使用DataInputStream来操作的，毕竟他拥有一系列读取各种类型数据的函数，但是上例中使用<code>readShort()</code>并不成功。<br>什么情况下成功呢？如果使用<code>DataOutputStream</code>，写出来的文件可以被上述方式正确读取，而且也是二进制格式，于是我认为该方法可以普遍适用于二进制文件的读取。<br>后来也是受到了java读取wave文件的启发，先读取整块<code>byte</code>的buffer，之后转成相应的数据类型，如下：<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">wavWriter.read(wav);</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; wav.length / <span class="number">2</span>; i++) &#123;</span><br><span class="line">    <span class="keyword">short</span> s0 = (<span class="keyword">short</span>) (wav[<span class="number">2</span> * i] &amp; <span class="number">0xff</span>);</span><br><span class="line">    <span class="keyword">short</span> s1 = (<span class="keyword">short</span>) ((wav[<span class="number">2</span> * i + <span class="number">1</span>] &amp; <span class="number">0xff</span>) &lt;&lt; <span class="number">8</span>);</span><br><span class="line">    dat[i] = (<span class="keyword">short</span>) (s1 | s0);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>莫非这是传说中的大端小端问题？C直接读Java写的二进制文件也有问题，以short为例，转换代码如下，其实和上面是互逆的。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; FRAME_LEN; ++i)</span><br><span class="line">&#123;</span><br><span class="line">    short s0 = val[i * <span class="number">2</span>] &amp; <span class="number">0xff</span>；</span><br><span class="line">    short s1 = val[i * <span class="number">2</span> + <span class="number">1</span>] &amp; <span class="number">0xff</span>;</span><br><span class="line">    wav[i] =  (s0 &lt;&lt; <span class="number">8</span>) | s1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>总而言之，四个关系中，交叉读取文件是需要进行格式转换的，java中的低位是C中的高位。如果java想直接读取C的二进制文件，在写C的时候，提前做好格式转换也是可以的，比如：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">short s0 = data[i] &amp; <span class="number">0x00ff</span>;</span><br><span class="line">short s1 = data[i] &amp; <span class="number">0xff00</span>;</span><br><span class="line">s0 = (s0 &lt;&lt; <span class="number">8</span>);</span><br><span class="line">s1 = (s1 &gt;&gt; <span class="number">8</span>);</span><br><span class="line">data[i] = (s0 | s1);</span><br></pre></td></tr></table></figure></p>
<p>另外，如果将文件写在应用的私有包目录之下，应用访问没用问题，但是想<code>pull</code>出来的时候，提示没有权限，所以想换个公有的目录访问。</p>
<p>现在的手机内部存储空间已经能满足大部分用户的需求了，所以少有支持外插SD卡的了，故基本认为存储空间为internal space，我想在<code>/sdcard/</code>目录下操作文件， <code>errno</code>依旧是<code>permission denied</code>。</p>
<p>但是其实<code>adb shell</code>进该目录之下，依旧可以创建删除文件。最终很奇怪，赋予了SD卡读写的权限之后<br><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">uses-permission</span> <span class="attr">android:name</span>=<span class="string">"android.permission.WRITE_EXTERNAL_STORAGE"</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">uses-permission</span> <span class="attr">android:name</span>=<span class="string">"android.permission.READ_EXTERNAL_STORAGE"</span> /&gt;</span></span><br></pre></td></tr></table></figure><br>问题解决。<br>补充：后来发现在某些6.0的机器上的权限需要添加动态申请<br><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> REQUEST_EXTERNAL_STORAGE = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> String[] PERMISSIONS_STORAGE = &#123;</span><br><span class="line">        Manifest.permission.READ_EXTERNAL_STORAGE,</span><br><span class="line">        Manifest.permission.WRITE_EXTERNAL_STORAGE,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">int</span> permission = ActivityCompat.checkSelfPermission(<span class="keyword">this</span>, </span><br><span class="line">        Manifest.permission.WRITE_EXTERNAL_STORAGE);</span><br><span class="line"><span class="keyword">if</span> (permission != PackageManager.PERMISSION_GRANTED) &#123;</span><br><span class="line">    ActivityCompat.requestPermissions(<span class="keyword">this</span>, PERMISSIONS_STORAGE, REQUEST_EXTERNAL_STORAGE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>JNI</tag>
      </tags>
  </entry>
  <entry>
    <title>JNI在AS下的初步配置</title>
    <url>/2017/05/28/jni-config/</url>
    <content><![CDATA[<p>安装ndk之类的东西就不用说了。<br><a id="more"></a></p>
<h3 id="local-properties文件"><a href="#local-properties文件" class="headerlink" title="local.properties文件"></a>local.properties文件</h3><p>设置ndk和sdk的目录<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ndk.dir&#x3D;&#x2F;Users&#x2F;wujian&#x2F;Library&#x2F;Android&#x2F;sdk&#x2F;ndk-bundle</span><br><span class="line">sdk.dir&#x3D;&#x2F;Users&#x2F;wujian&#x2F;Library&#x2F;Android&#x2F;sdk</span><br></pre></td></tr></table></figure></p>
<h3 id="gradle-properties文件"><a href="#gradle-properties文件" class="headerlink" title="gradle.properties文件"></a>gradle.properties文件</h3><p>设置启动ndk<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">android.useDeprecatedNdk&#x3D;true</span><br></pre></td></tr></table></figure></p>
<h3 id="build-gradle文件"><a href="#build-gradle文件" class="headerlink" title="build.gradle文件"></a>build.gradle文件</h3><p>设置ndk part的一些配置参数，最基本的下面三个即可，moduleName在java文件中需要用到，这个只的最后编译的静态链接库的名称，这里面有很多可以配置的情况，最基本的需求的话，保证这些就可以跑起来了。<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ndk &#123;</span><br><span class="line">    moduleName &quot;WriteLib&quot;</span><br><span class="line">    ldLibs &quot;log&quot;, &quot;z&quot;, &quot;m&quot;</span><br><span class="line">    abiFilters &quot;armeabi&quot;, &quot;armeabi-v7a&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="java文件"><a href="#java文件" class="headerlink" title="java文件"></a>java文件</h3><p>基本是要定义一个utility的类，用来做java调用C的接口，注意要加载编译好的库，否则运行的时候是找不到实现的。</p>
<h3 id="c-c-文件"><a href="#c-c-文件" class="headerlink" title="c/c++文件"></a>c/c++文件</h3><p>这部分比较简单，使用<code>javah</code>命令生成一个头文件，实现函数接口即可。<br>注意，一般来说AS的IDE会高亮C部分的语法的，但是有时候可能会失效，如果不是配置的原因的话，重启一次。<br>正确的画风是这样的，配色美美哒！</p>
<p><img src="http://www.funcwj.cn/images/AS_highlight_C.png" width="600"></p>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>JNI</tag>
      </tags>
  </entry>
  <entry>
    <title>OpenBlas优化效果测试</title>
    <url>/2017/05/28/openblas-test/</url>
    <content><![CDATA[<p>我目前测试三个版本编译的OpenBlas效果，分别是32位单线程，64位单线程，32位多线程<br>测试为300次网络前向耗时，网络结构为[360, 1024, 1024, 1024, 1024, 1024, 4375]。<br><a id="more"></a></p>
<h3 id="代码样例"><a href="#代码样例" class="headerlink" title="代码样例"></a>代码样例</h3><p>基准代码<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TransRes_stdc</span><span class="params">(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, <span class="keyword">int</span> npre, <span class="keyword">int</span> npos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	FLOATS tmp = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; npos; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		tmp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; npre; j++)</span><br><span class="line">			tmp += x[j] * w[i * npre + j];</span><br><span class="line">		y[i] = tmp + b[i];</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>OpenMP优化<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TransRes_stdc</span><span class="params">(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, <span class="keyword">int</span> npre, <span class="keyword">int</span> npos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	FLOATS tmp = <span class="number">0</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; npos; i++)</span><br><span class="line">	&#123;</span><br><span class="line">		tmp = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; npre; j++)</span><br><span class="line">			tmp += x[j] * w[i * npre + j];</span><br><span class="line">		y[i] = tmp + b[i];</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>OpenBlas内积优化<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TransRes_blas</span><span class="params">(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, <span class="keyword">int</span> npre, <span class="keyword">int</span> npos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    FLOATS tmp = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; npos; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        tmp = cblas_sdot(npre, x, <span class="number">1</span>, w + i * npre, <span class="number">1</span>);</span><br><span class="line">        y[i] = tmp + b[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>OpenBlas内积+OpenMP优化<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TransRes_blas</span><span class="params">(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, <span class="keyword">int</span> npre, <span class="keyword">int</span> npos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    FLOATS tmp = <span class="number">0</span>;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> omp parallel for</span></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; npos; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        tmp = cblas_sdot(npre, x, <span class="number">1</span>, w + i * npre, <span class="number">1</span>);</span><br><span class="line">        y[i] = tmp + b[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>OpenBlas矩阵优化<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">TransRes_blas</span><span class="params">(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, <span class="keyword">int</span> npre, <span class="keyword">int</span> npos)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    cblas_scopy(npos, b, <span class="number">1</span>, y, <span class="number">1</span>);</span><br><span class="line">    cblas_sgemv(CblasRowMajor, CblasNoTrans, npos, npre, <span class="number">1</span>, w, npre, x, <span class="number">1</span>, <span class="number">1</span>, y, <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h3><ul>
<li>32位多线程</li>
</ul>
<ol>
<li>基准值：6400ms</li>
<li>内积优化：3900ms</li>
<li>OpenMP优化：4000ms</li>
<li>OpenMP+OpenBlas内积优化：1950ms *</li>
<li>OpenMP矩阵优化：1950 - 2100ms</li>
</ol>
<ul>
<li>32位单线程</li>
</ul>
<ol>
<li>基准值：6400ms</li>
<li>内积优化：3800ms</li>
<li>OpenMP优化：3800ms</li>
<li>OpenMP+OpenBlas内积优化：1800ms-2000ms不稳定</li>
<li>OpenMP矩阵优化：2500ms</li>
</ol>
<ul>
<li>64位单线程</li>
</ul>
<ol>
<li>基准值： 6400ms</li>
<li>内积优化：7800ms</li>
<li>OpenMP+OpenBlas内积优化：4200ms</li>
<li>OpenMP矩阵优化：3200ms</li>
</ol>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Android</tag>
        <tag>OpenBlas</tag>
      </tags>
  </entry>
  <entry>
    <title>使用OpenBlas优化</title>
    <url>/2017/05/28/use-openblas/</url>
    <content><![CDATA[<p>当时是需要对一个终端耗时任务做矩阵加速，我选了OpenBlas开源方案，事实证明在ARM平台上能用的开源的方案中，OpenBlas做的算相当可以的了。以后有时间还想自己实现一下矩阵乘法的加速。做优化这个过程还是很吸引人的。</p>
<a id="more"></a>

<h3 id="编译准备"><a href="#编译准备" class="headerlink" title="编译准备"></a>编译准备</h3><p>原理还是一样，首先在本地配置安卓的交叉编译环境，编译出OpenBlas的静态库，用于JNI链接。github上有详细的教程，包括我后来的一个编译错误也是在上面找到了解决方案。详见 <a href="https://github.com/xianyi/OpenBLAS/wiki/How-to-build-OpenBLAS-for-Android" target="_blank" rel="noopener">How to build OpenBLAS for Android</a></p>
<p>注意教程上建议在做交叉编译之前先构建一个标准工具链，其实就是交叉编译的环境，第一次我图省事只配置了<code>arm-linux-androideabi-gcc</code>的环境变量，<code>make</code>的时候就会出现找不到头文件的错误。</p>
<p>NDK已经提供了一个脚本做这件事情，在路径<code>/Users/wujian/Library/Android/sdk/ndk-bundle/build/tools</code>下有一个<code>make_standalone_toolchain.py</code>脚本，通过执行命令</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">make_standalone_toolchain.py --arch arm --api 21 --install-dir &#x2F;dst&#x2F;path&#x2F;</span><br></pre></td></tr></table></figure>
<p>之后我们对这个文件夹配置环境变量即可。</p>
<h3 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h3><p>不需要Fortran，针对ARMv7</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">make TARGET&#x3D;ARMV7 HOSTCC&#x3D;gcc CC&#x3D;arm-linux-androideabi-gcc NOFORTRAN&#x3D;1 &gt; make.log</span><br></pre></td></tr></table></figure>
<p>编译时间不长，几分钟吧，编译完会提示安装，执行</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">make PREFIX&#x3D;&#x2F;dst&#x2F;path install</span><br></pre></td></tr></table></figure>
<p>最终安装目录下存在头文件和静态库，这个就是我们最终需要的。<br><img src="http://www.funcwj.cn/images/android-openblas.png" width="400"></p>
<h3 id="AS中使用JNI链接"><a href="#AS中使用JNI链接" class="headerlink" title="AS中使用JNI链接"></a>AS中使用JNI链接</h3><p>这里有个很恶心的问题，目前我没有找到gradle中如何配置链接静态库的方法，只能借助Android.mk文件，但是由于AS默认是执行gradle的编译过程，所以需要在build.gradle中禁用JNI(否则他还是那么一套规程)，之后手动配置build的过程。<br>禁用AS默认的JNI目录：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sourceSets.main &#123;</span><br><span class="line">    jni.srcDirs &#x3D; []</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>配置编译规则</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">task ndkBuild(type: org.gradle.api.tasks.Exec, description: &quot;compile JNI by NDK&quot;) &#123;</span><br><span class="line">    commandLine &quot;&#x2F;Users&#x2F;wujian&#x2F;Library&#x2F;Android&#x2F;sdk&#x2F;ndk-bundle&#x2F;ndk-build&quot;,</span><br><span class="line">            &#39;NDK_PROJECT_PATH&#x3D;build&#x2F;intermediates&#x2F;ndk&#39;,</span><br><span class="line">            &#39;NDK_LIBS_OUT&#x3D;src&#x2F;main&#x2F;jniLibs&#39;,</span><br><span class="line">            &#39;APP_BUILD_SCRIPT&#x3D;src&#x2F;main&#x2F;jni&#x2F;Android.mk&#39;,</span><br><span class="line">            &#39;NDK_APPLICATION_MK&#x3D;src&#x2F;main&#x2F;jni&#x2F;Application.mk&#39;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">tasks.withType(JavaCompile) &#123;</span><br><span class="line">    compileTask-&gt;compileTask.dependsOn ndkBuild</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时在JNI目录下加入Android.mk和Application.mk文件，如下，具体含义之后再解释，这里先说明配置过程。Android.mk中详细说明了OpenBlas静态库的连接过程。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">LOCAL_PATH :&#x3D; $(call my-dir)</span><br><span class="line"></span><br><span class="line">include $(CLEAR_VARS)</span><br><span class="line">LOCAL_MODULE :&#x3D; blas</span><br><span class="line">LOCAL_SRC_FILES :&#x3D; libopenblas_armv7p-r0.2.20.dev.a</span><br><span class="line">include $(PREBUILT_STATIC_LIBRARY)</span><br><span class="line"></span><br><span class="line">include $(CLEAR_VARS)</span><br><span class="line"></span><br><span class="line">LOCAL_MODULE    :&#x3D; math</span><br><span class="line">LOCAL_SRC_FILES :&#x3D; impl.cpp</span><br><span class="line"></span><br><span class="line">ifeq ($(TARGET_ARCH_ABI),armeabi-v7a)</span><br><span class="line">    LOCAL_CFLAGS +&#x3D; -mhard-float -D_NDK_MATH_NO_SOFTFP&#x3D;1</span><br><span class="line">    LOCAL_LDFLAGS +&#x3D; -Wl,--no-warn-mismatch -lm_hard</span><br><span class="line">	LOCAL_STATIC_LIBRARIES :&#x3D; blas</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">LOCAL_CFLAGS +&#x3D; -DUSE_JNI</span><br><span class="line">LOCAL_CFLAGS +&#x3D; -DPFFFT_SIMD_DISABLE</span><br><span class="line">LOCAL_LDLIBS +&#x3D; -llog</span><br><span class="line"></span><br><span class="line">include $(BUILD_SHARED_LIBRARY)</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">APP_ABI :&#x3D; armeabi-v7a</span><br><span class="line">APP_PLATFORM :&#x3D; android-19</span><br></pre></td></tr></table></figure>
<p>再把OpenBlas的头文件加入JNI目录下，include使用即可，接下来就可以make了。</p>
<h3 id="后续问题"><a href="#后续问题" class="headerlink" title="后续问题"></a>后续问题</h3><p>我两次做静态链接时都出现了如下问题，第一次是使用NENO库：<br><img src="http://www.funcwj.cn/images/openblas-error.png" width="400"></p>
<p>后来在网上查了许久，是编译选项和ABI的问题，这在<a href="https://github.com/xianyi/OpenBLAS/wiki/How-to-build-OpenBLAS-for-Android" target="_blank" rel="noopener">How to build OpenBLAS for Android</a>最后一部分也说明了。我采取的是第二种方案，因为这里是使用Android.mk来配置编译规则的。</p>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Android</tag>
        <tag>JNI</tag>
        <tag>OpenBlas</tag>
      </tags>
  </entry>
  <entry>
    <title>CMake使用外部链接库</title>
    <url>/2017/05/28/cmake-use-lib/</url>
    <content><![CDATA[<p>在Linux下不想每次写Makefile自然就想到替代工具了。由于Clion支持的是cmake，所以我也就粉了它。<br><a id="more"></a></p>
<p>C/C++工程使用外部链接库时需要指定头文件和库的所在目录（<code>-I -L</code>），同时编译选项加上对应的库名，对应在cmake中CMakeLists.txt文件即使用如下的三个命令<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">include_directories: -I</span><br><span class="line">link_directories: -L</span><br><span class="line">target_link_libraries: -lXXX</span><br></pre></td></tr></table></figure></p>
<p>举个例子<br>编译<code>main.cc</code>时需要使用neno库，库和头文件分别在目录<code>inc</code>和<code>lib</code>之下<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">|-- Ne10</span><br><span class="line">|   |-- CMakeLists.txt</span><br><span class="line">|   |-- GNUlinux_config.cmake</span><br><span class="line">|   |-- LICENSE</span><br><span class="line">|   |-- README.md</span><br><span class="line">|   |-- android</span><br><span class="line">|   |-- build</span><br><span class="line">|   |-- cmake</span><br><span class="line">|   |-- common</span><br><span class="line">|   |-- contributing.md</span><br><span class="line">|   |-- doc</span><br><span class="line">|   |-- inc</span><br><span class="line">|   |-- ios</span><br><span class="line">|   |-- lib</span><br><span class="line">|   |-- modules</span><br><span class="line">|   |-- samples</span><br><span class="line">|   |-- test</span><br><span class="line">|   |-- tools</span><br><span class="line">|-- bench</span><br><span class="line">|   |-- CMakeLists.txt</span><br><span class="line">|   |-- main.cc</span><br></pre></td></tr></table></figure><br><code>g++ -I ../Ne10/inc/ -L ../Ne10/lib/ main.cc -o demo -lNE10</code>对应的 cmake文件如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 2.6)</span><br><span class="line"></span><br><span class="line">project(NENO_benchmark)</span><br><span class="line"></span><br><span class="line">set(NENO_PREFIX ~&#x2F;Ne10)</span><br><span class="line">include_directories($&#123;NENO_PREFIX&#125;&#x2F;inc)</span><br><span class="line">link_directories($&#123;NENO_PREFIX&#125;&#x2F;lib)</span><br><span class="line"></span><br><span class="line">add_executable(demo main.cc)</span><br><span class="line">target_link_libraries(demo libNE10.a)</span><br></pre></td></tr></table></figure>
<p>validate ok~</p>
<p>补充一发，KALDI中的option_parser测试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 3.5)</span><br><span class="line"></span><br><span class="line">set(KALDI_DIR ~&#x2F;Document&#x2F;git&#x2F;kaldi)</span><br><span class="line">set(TARGET test-options-parse)</span><br><span class="line">set(SRC test-options.cc)</span><br><span class="line">include_directories($&#123;KALDI_DIR&#125;&#x2F;src $&#123;KALDI_DIR&#125;&#x2F;tools&#x2F;openfst&#x2F;include)</span><br><span class="line">link_directories($&#123;KALDI_DIR&#125;&#x2F;src&#x2F;lib)</span><br><span class="line"></span><br><span class="line">add_definitions(-O3 -g -std&#x3D;c++11)</span><br><span class="line"></span><br><span class="line">add_executable($&#123;TARGET&#125; $&#123;SRC&#125;)</span><br><span class="line">target_link_libraries($&#123;TARGET&#125; kaldi-util kaldi-base)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>CMake</tag>
      </tags>
  </entry>
  <entry>
    <title>Grub手动引导Ubuntu启动</title>
    <url>/2017/05/28/grub-start/</url>
    <content><![CDATA[<p>原先的Ubuntu不小心整崩溃了，在windows下删掉分区，重新安装之后总是找不到boot loader，出现Grub引导界面，如下<br><a id="more"></a></p>
<p><img src="http://www.funcwj.cn/images/grub2.0-error.jpg" width="500"></p>
<p>第一次见真的挺方的……</p>
<p>解决方案，手动引导，只需要熟悉几个命令即可</p>
<p>首先要知道/boot和/区安装在具体哪个分区，使用ls可以知道当前磁盘的分区情况，或者直接TAB</p>
<p>执行如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">linux (hd0, gptX)&#x2F;vmlinuz-*** root&#x3D;&#x2F;dev&#x2F;sdaX</span><br><span class="line">initrd (hd0, gptX)&#x2F;initrd-***.img</span><br><span class="line">boot</span><br></pre></td></tr></table></figure>
<p>其中<code>root=</code>指明/挂载在的那个分区，<code>(hd0, gptX)</code>表示/boot所在的分区，后来发现下面的命令也可以<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set root&#x3D;(hd0, gptX)</span><br><span class="line">set prefix&#x3D;(hd0, gptX)&#x2F;grub</span><br><span class="line">normal</span><br></pre></td></tr></table></figure><br>选硬盘和分区时，如果文件系统被识别，那么用TAB键会自动补全的，所以完全可以找到/root的所在分区的，grub目录就在root目录之下。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Problem</tag>
      </tags>
  </entry>
  <entry>
    <title>RedHat下GCC升级安装的若干问题</title>
    <url>/2017/05/28/gcc-update/</url>
    <content><![CDATA[<p>大三玩SC的时候，手动升级了好几次GCC，还有Glibc的库（升级失误，整废一个节点），遇到问题在此做个备注。<br><a id="more"></a></p>
<p>其实流程跟装普通软件没有什么区别，装之前先完成依赖安装，主要就是下面第一个列表中的三个，装完导一下环境变量。</p>
<ul>
<li>gmp, mpc, mpfc的安装</li>
</ul>
<p>正常安装在家目录下面之后，环境变量要导入对应的<code>C_INCLUDE_PATH</code>和<code>LD_LIBRARY_PATH</code>，否则安装GCC时<code>configure</code>check不到对应的头文件或者库</p>
<ul>
<li>GCC编译时，出现<code>error: Unable to find a suitable type for HOST_WIDE_INT</code></li>
</ul>
<p>这个貌似是宏定义冲突导致的，重置相关的环境变量，如下</p>
<pre><code>unset LIBRARY_PATH CPATH C_INCLUDE_PATH PKG_CONFIG_PATH CPLUS_INCLUDE_PATH INCLUDE
</code></pre><p>这个问题出现的很奇怪……此处备忘</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Problem</tag>
      </tags>
  </entry>
  <entry>
    <title>Boost.Python和Boost.Numpy的使用</title>
    <url>/2017/05/28/boost-python/</url>
    <content><![CDATA[<p>习惯上python之后，我很自然的就想到怎么和C++代码结合的问题了，毕竟核心计算模块不敢用python做，之前用过swig，但是感觉不够灵活，方便。后来找到了boost库，开始上手会遇到一些乱七八糟的问题，但是做完了回头看看，还是蛮方便的，起码相对于swig来说。<br><a id="more"></a></p>
<p>需求其实是要在树莓派上做个KWS模型，提特征和网络前向的代码不想再重新写了（虽然之前已经实现过了），所以突发奇想，基于kaldi给python写一个wrapper调用就行了。</p>
<h3 id="Boost库的安装"><a href="#Boost库的安装" class="headerlink" title="Boost库的安装"></a>Boost库的安装</h3><p>分为俩类，一类不需要编译成库文件，包含头文件即可使用，另外一类是需要编译安装库文件的，使用的时候加上链接，Boost.Python就属于后一类，安装完成Boost.python之后，默认会编译numpy库，所以可以直接使用boost.numpy</p>
<h3 id="Boost-Python和Numpy的使用"><a href="#Boost-Python和Numpy的使用" class="headerlink" title="Boost Python和Numpy的使用"></a>Boost Python和Numpy的使用</h3><ul>
<li>boost python一般用来封装C++的API给python调用，一般编译成特定的lib，使用python的时候，直接import就行了</li>
<li>boost numpy一般给C++提供直接处理传，返回入numpy矩阵的功能</li>
</ul>
<h3 id="Boost-Python-Numpy初步使用"><a href="#Boost-Python-Numpy初步使用" class="headerlink" title="Boost Python/Numpy初步使用"></a>Boost Python/Numpy初步使用</h3><ul>
<li>Boost Python<br>正常定义C++类和成员函数，使用<code>BOOST_PYTHON_MODULE</code>定义模块名和对应的函数导出名就行了，详见<a href="http://www.boost.org/doc/libs/1_64_0/libs/python/doc/html/index.html" target="_blank" rel="noopener">boost.python</a></li>
<li>Boost Numpy<br>这个主要是一系列API掌握就行了，详见<a href="http://www.boost.org/doc/libs/1_64_0/libs/python/doc/html/numpy/index.html" target="_blank" rel="noopener">boost.python(Numpy)</a></li>
</ul>
<h3 id="使用boost封装kaldi-nnet1的网络前向"><a href="#使用boost封装kaldi-nnet1的网络前向" class="headerlink" title="使用boost封装kaldi nnet1的网络前向"></a>使用boost封装kaldi nnet1的网络前向</h3><p>一个简单的使用例子，基本操作都在里面<br><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;boost/python.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;boost/python/numpy.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"nnet/nnet-nnet.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"nnet/nnet-loss.h"</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> kaldi;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> kaldi::nnet1;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 命名空间</span></span><br><span class="line"><span class="keyword">namespace</span> py = boost::python;</span><br><span class="line"><span class="keyword">namespace</span> np = boost::python::numpy;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NnetWrapper</span> &#123;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    NnetWrapper(<span class="built_in">std</span>::<span class="built_in">string</span> nnet_mdl = <span class="string">"final.nnet"</span>);</span><br><span class="line">    <span class="comment">// 传入，返回numpy类型</span></span><br><span class="line">    <span class="function">np::ndarray <span class="title">Predict</span><span class="params">(np::ndarray &amp;<span class="built_in">vector</span>)</span></span>;</span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    Nnet nnet_;</span><br><span class="line">    <span class="comment">// keep memory not free</span></span><br><span class="line">    CuMatrix&lt;BaseFloat&gt; nnet_out;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">NnetWrapper::NnetWrapper(<span class="built_in">std</span>::<span class="built_in">string</span> nnet_mdl) &#123;</span><br><span class="line">    nnet_.Read(nnet_mdl);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">np::ndarray <span class="title">NnetWrapper::Predict</span><span class="params">(np::ndarray &amp;<span class="built_in">vector</span>)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> cols, rows;</span><br><span class="line">    <span class="comment">// 获取内建dtype</span></span><br><span class="line">    KALDI_ASSERT(<span class="built_in">vector</span>.get_dtype() == np::dtype::get_builtin&lt;<span class="keyword">float</span>&gt;());</span><br><span class="line">    <span class="comment">// 获取维度</span></span><br><span class="line">    KALDI_ASSERT(<span class="built_in">vector</span>.get_nd() &lt;= <span class="number">2</span>);</span><br><span class="line"></span><br><span class="line">    cols = <span class="built_in">vector</span>.shape(<span class="built_in">vector</span>.get_nd() - <span class="number">1</span>);</span><br><span class="line">    KALDI_ASSERT(cols == nnet_.InputDim());</span><br><span class="line"></span><br><span class="line">    rows = <span class="built_in">vector</span>.get_nd() == <span class="number">1</span> ? <span class="number">1</span>: <span class="built_in">vector</span>.shape(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">// 获取数据指针</span></span><br><span class="line">    <span class="function">CuSubMatrix&lt;BaseFloat&gt; <span class="title">nnet_in</span><span class="params">(<span class="keyword">reinterpret_cast</span>&lt;BaseFloat*&gt;(<span class="built_in">vector</span>.get_data()),</span></span></span><br><span class="line"><span class="function"><span class="params">                                   rows, cols, <span class="built_in">vector</span>.strides(<span class="number">0</span>) / <span class="keyword">sizeof</span>(BaseFloat))</span></span>;</span><br><span class="line"></span><br><span class="line">    nnet_.Feedforward(nnet_in, &amp;nnet_out);</span><br><span class="line">    <span class="comment">// 有已知数据，建立ndarray类型变量，传参如下：</span></span><br><span class="line">    <span class="comment">// data_addr, dtype, shape, stride, obj</span></span><br><span class="line">    <span class="keyword">return</span> np::from_data(nnet_out.Data(), np::dtype::get_builtin&lt;<span class="keyword">float</span>&gt;(),</span><br><span class="line">                         py::make_tuple(rows, nnet_out.NumCols()),</span><br><span class="line">                         py::make_tuple(nnet_out.Stride() * <span class="keyword">sizeof</span>(BaseFloat), <span class="keyword">sizeof</span>(BaseFloat)),</span><br><span class="line">                         py::object());</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BOOST_PYTHON_MODULE(pynnet1) &#123;</span><br><span class="line">    <span class="keyword">using</span> <span class="keyword">namespace</span> boost::python;</span><br><span class="line">    <span class="comment">// 初始化numpy模块</span></span><br><span class="line">    np::initialize();</span><br><span class="line">    <span class="comment">// 导出构造函数为init, 可选参数输入，和预测函数Predict为predict</span></span><br><span class="line">    class_&lt;NnetWrapper&gt;(<span class="string">"nnet1"</span>, init&lt;optional&lt;<span class="built_in">std</span>::<span class="built_in">string</span>&gt; &gt;())</span><br><span class="line">            .def(<span class="string">"predict"</span>, &amp;NnetWrapper::Predict);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="Cmake编译，基于python2-7"><a href="#Cmake编译，基于python2-7" class="headerlink" title="Cmake编译，基于python2.7"></a>Cmake编译，基于python2.7</h3><p>给python调用肯定编译成库，注意</p>
<ul>
<li>如果不用numpy，只需要额外链接<code>python2.7</code>和<code>boost_python</code>俩个库</li>
<li>使用numpy的话，链接<code>boost_numpy</code><br>boost库默认安装在<code>/usr/local/lib</code>之下，头文件在<code>/usr/local/include/boost</code>里面，编译时需要指定这些目录<br>Cmake完整如下</li>
</ul>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">cmake_minimum_required(VERSION 3.5)</span><br><span class="line">project(PyNnet1)</span><br><span class="line"></span><br><span class="line"><span class="built_in">set</span>(CMAKE_CXX_STANDARD 11)</span><br><span class="line"><span class="built_in">set</span>(TARGET pynnet1)</span><br><span class="line"><span class="built_in">set</span>(KALDI_DIR ../../../Document/git/kaldi)</span><br><span class="line"><span class="built_in">set</span>(BOOST_LIB /usr/<span class="built_in">local</span>/lib)</span><br><span class="line"><span class="built_in">set</span>(PYTHON_INC /usr/include/python2.7)</span><br><span class="line"><span class="comment"># -I</span></span><br><span class="line">include_directories(<span class="variable">$&#123;PYTHON_INC&#125;</span> <span class="variable">$&#123;KALDI_DIR&#125;</span>/tools/openfst/include <span class="variable">$&#123;KALDI_DIR&#125;</span>/tools/CLAPACK <span class="variable">$&#123;KALDI_DIR&#125;</span>/src)</span><br><span class="line"><span class="comment"># -L</span></span><br><span class="line">link_directories(<span class="variable">$&#123;KALDI_DIR&#125;</span>/src/lib <span class="variable">$&#123;BOOST_LIB&#125;</span>)</span><br><span class="line"></span><br><span class="line">add_definitions(-O3 -g -std=c++11 -DHAVE_CLAPACK)</span><br><span class="line"><span class="built_in">set</span>(SOURCE_FILES nnet-wrapper.cpp)</span><br><span class="line"></span><br><span class="line">add_library(<span class="variable">$&#123;TARGET&#125;</span> SHARED <span class="variable">$&#123;SOURCE_FILES&#125;</span>)</span><br><span class="line"><span class="comment"># 默认生成格式为libXXX.so，现在不需要前缀</span></span><br><span class="line">set_target_properties(<span class="variable">$&#123;TARGET&#125;</span> PROPERTIES PREFIX <span class="string">""</span>)</span><br><span class="line">target_link_libraries(<span class="variable">$&#123;TARGET&#125;</span> python2.7 boost_numpy boost_python pthread kaldi-base kaldi-cudamatrix kaldi-nnet)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>EM算法对GMM模型进行参数估计</title>
    <url>/2017/05/28/gmm-trainning/</url>
    <content><![CDATA[<p>之前学习的EM算法很抽象，以GMM模型为例，看看EM算法如何通过期望-最大化的迭代过程，进行参数的有效估计的。</p>
<a id="more"></a>
<h3 id="高斯混合模型"><a href="#高斯混合模型" class="headerlink" title="高斯混合模型"></a>高斯混合模型</h3><p>对于一个一元变量的高斯分布的概率密度函数(pdf)定义为</p>
<script type="math/tex; mode=display">
\begin{aligned}
P(x) & = \frac{1}{\sqrt{2\pi\mu}}e^{-(\frac{x - \mu}{\sigma})^2 / 2} \notag \\
&= \mathcal N(x;\mu, \sigma)\notag
\end{aligned}</script><p>拓展到多元高斯分布</p>
<script type="math/tex; mode=display">
\begin{aligned}
P(\boldsymbol x) & = \frac{1}{(2\pi)^{D/2}|\boldsymbol \varSigma|^{1/2}}e^{(\boldsymbol x - \boldsymbol \mu)^T\boldsymbol \varSigma^{-1} (\boldsymbol x - \boldsymbol \mu)} \notag \\
&= \mathcal N(\boldsymbol x;\boldsymbol \mu, \boldsymbol \varSigma)\notag
\end{aligned}</script><p>再拓展到高斯混合分布：</p>
<script type="math/tex; mode=display">
P(\boldsymbol x) = \sum_{m = 1}^Mc_m\mathcal N(\boldsymbol x;\boldsymbol \mu_m, \boldsymbol \varSigma_m)</script><p>其中$m$为高斯数</p>
<h3 id="GMM的参数估计"><a href="#GMM的参数估计" class="headerlink" title="GMM的参数估计"></a>GMM的参数估计</h3><h4 id="确定隐变量"><a href="#确定隐变量" class="headerlink" title="确定隐变量"></a>确定隐变量</h4><p>对于GMM生成的数据，我们并不知道他来自哪一个分布，反映数据来源这部分信息是未知的，定义$h_i^m$表示第$i$个数据是否来自于第$m$个高斯分量</p>
<p>定义：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\boldsymbol \Theta & = (c_1, c_2, \cdots, c_M; \boldsymbol \mu_1, \boldsymbol \mu_2, \cdots, \boldsymbol \mu_M;\boldsymbol \varSigma_1, \boldsymbol \varSigma_2, \cdots, \boldsymbol \varSigma_M) \\
\boldsymbol Y & = (\boldsymbol y_1, \boldsymbol y_2, \cdots, \boldsymbol y_N) \\
\boldsymbol H & = 
\begin{pmatrix}
h_1^1 & h_1^2 & \cdots & h_1^M  \\
h_2^1 & h_2^2 & \cdots & h_2^M  \\
\vdots & \vdots & \ddots & \vdots \\  
h_N^1 & h_N^2 & \cdots & h_N^M  \\
\end{pmatrix} \\
\end{aligned}</script><p>则，完全数据的似然函数为</p>
<script type="math/tex; mode=display">
\begin{aligned}
P(\boldsymbol Y, \boldsymbol H|\boldsymbol \Theta) & = \prod_{n = 1}^NP(\boldsymbol y_n, \boldsymbol H_n|\boldsymbol \Theta) \notag \\
& = \prod_{n = 1}^N\prod_{m = 1}^M \left[c_m \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)\right]^{h_n^m} \notag
\end{aligned}</script><h4 id="确定-Q-函数"><a href="#确定-Q-函数" class="headerlink" title="确定$Q$函数"></a>确定$Q$函数</h4><p>在E步，我们要确定$Q$函数，根据$Q$函数定义</p>
<script type="math/tex; mode=display">Q(\Theta, \Theta^t) = E_H[\log P(H,Y|\Theta) | Y, \Theta^t]</script><script type="math/tex; mode=display">
\begin{aligned}
\log P(\boldsymbol Y, \boldsymbol H|\boldsymbol \Theta) & = \sum_{n = 1}^N\sum_{m = 1}^M h_n^m \left\{\log c_m + \log \left[ \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)\right]\right\} \notag \\
\end{aligned}</script><p>可以得到</p>
<script type="math/tex; mode=display">
Q(\Theta, \Theta^t) = \sum_{m = 1}^M \sum_{n = 1}^N\left\{E_{h_n^m} \cdot \log c_m + E_{h_n^m} \cdot \log
\left[ \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)\right]\right\}</script><p>其中，$E_{h_n^m}$是隐变量在完全数据下的期望</p>
<script type="math/tex; mode=display">
\begin{aligned}
E_{h_n^m} & = E(h_n^m|Y_n, \Theta^t) = P(h_n^m = 1 | Y_n, \Theta^t) \\
& = \frac{c_m \cdot \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)}{\sum_{m = 1}^{m = M} \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)}
\end{aligned}</script><h4 id="期望最大化"><a href="#期望最大化" class="headerlink" title="期望最大化"></a>期望最大化</h4><p>得到$E_{h_n^m}$之后，对$Q$函数求偏导，可以得到混合高斯模型中参量的更新公式</p>
<ul>
<li><p>$c_m$</p>
<script type="math/tex; mode=display">
c_m^{t + 1} = \frac{\sum_{n = 1}^NE_{h_n^m}}{N}</script></li>
<li><p>$\boldsymbol \mu_m^{t + 1}$</p>
<script type="math/tex; mode=display">
\boldsymbol \mu_m^{t + 1} = \frac{\sum_{n = 1}^NE_{h_n^m} \cdot Y_n}{\sum_{n = 1}^NE_{h_n^m}}</script></li>
<li><p>$\boldsymbol \varSigma_m^{t + 1}$</p>
<script type="math/tex; mode=display">
\boldsymbol \varSigma_m^{t + 1} = \frac{\sum_{n = 1}^N E_{h_n^m} \cdot (Y_n - \boldsymbol \mu_n)^2}{\sum_{n = 1}^NE_{h_n^m}}</script></li>
</ul>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>EM</tag>
        <tag>GMM</tag>
      </tags>
  </entry>
  <entry>
    <title>EM算法</title>
    <url>/2017/05/28/em-algorithm/</url>
    <content><![CDATA[<p>EM算法优化的目标是观测数据对参数$\theta$的对数似然函数，如果不存在隐变量的话，可以直接用最大似然法估计，在隐变量存在的情况下，使用EM算法进行迭代估计。本篇是当时学李航的统计学习方法写下的笔记，可能有理解不正确的地方。<br><a id="more"></a></p>
<p>EM算法重要之处在于传统的语音识别框架中，HMM和GMM的参数学习是靠EM完成的。</p>
<p>在$MLE$（最大似然估计）中，最大化目标函数</p>
<script type="math/tex; mode=display">P(Y|\Theta) \tag{1}</script><p>的参数估计，可以通过下式得到</p>
<script type="math/tex; mode=display">
\begin{align}
\Theta_{MLE} & = \underset{\Theta}{\arg \max}L(\Theta) \notag \\
& = \underset{\Theta}{\arg \max}\prod_YP(Y|\Theta) \tag{2}
\end{align}</script><p>但是在观测不全面的情况下，比如只观测到了训练数据$Y$，为了优化$(1)$中的目标，还需要知道一些隐变量$X$，否则无法进行全面的估计。对于完全数据$(X, Y)$</p>
<script type="math/tex; mode=display">P(X,Y|\Theta) = P(X|Y,\Theta) \cdot P(Y|\Theta) \tag{3}</script><p>上面已经提到，我们的目标是优化$(1)$，则</p>
<script type="math/tex; mode=display">\log P(Y|\Theta) = \log P(X,Y|\Theta) - \log P(X|Y,\Theta) \tag{4}</script><p>如果我们现在已知分布参数$\Theta^t$，用它计算$P(Y|\Theta)$在$X$上条件分布的期望</p>
<script type="math/tex; mode=display">
\log P(Y|\Theta) = \sum_x \log P(Y|\Theta) \cdot P(X|Y,\Theta^t) \\
= Q(\Theta, \Theta^t) - H(\Theta, \Theta^t)</script><p>令</p>
<script type="math/tex; mode=display">
Q(\Theta,\Theta^t) = \sum_x \log P(X,Y|\Theta) \cdot P(X|Y,\Theta^t) \\
H(\Theta,\Theta^t) = \sum_x \log P(X|Y,\Theta) \cdot P(X|Y,\Theta^t)</script><h3 id="EM算法的收敛性"><a href="#EM算法的收敛性" class="headerlink" title="EM算法的收敛性"></a>EM算法的收敛性</h3><p>EM算法找出</p>
<script type="math/tex; mode=display">\Theta^{t + 1} = \underset{\Theta}{argmax}Q(\Theta, \Theta^t) \tag{8}</script><p>进行下一轮迭代，收敛性需证明：</p>
<script type="math/tex; mode=display">logP(Y|\Theta^{t + 1}) - \log P(Y|\Theta^t) \ge 0 \tag{9}</script><p>由$(8)$，已知：</p>
<script type="math/tex; mode=display">Q(\Theta^{t + 1}, \Theta^t) - Q(\Theta^{t}, \Theta^t) \ge 0 \tag{10}</script><p>只需</p>
<script type="math/tex; mode=display">H(\Theta^{t + 1}, \Theta^t) - H(\Theta^{t}, \Theta^t) \le 0 \tag{11}</script><p>证明:</p>
<script type="math/tex; mode=display">
\begin{align}
(11) &= \sum_x \log\frac{P(X|Y,\Theta^{t + 1})}{P(X|Y,\Theta^{t})} \cdot P(X|Y,\Theta^t) \notag \\
& \le \log\sum_x\frac{P(X|Y,\Theta^{t + 1})}{P(X|Y,\Theta^{t})}P(X|Y,\Theta^t) \notag \\
& = \log\sum_xP(X|Y,\Theta^{t + 1}) = 0 \notag \\
\end{align}</script><p>证明过程使用了Jesson不等式</p>
<h3 id="Q-函数"><a href="#Q-函数" class="headerlink" title="$Q$函数"></a>$Q$函数</h3><p>$Q$函数是完全数据的对数似然函数关于在观测数据$Y$和已知参数$\Theta^t$对未观测数据$X$的条件分布$P(X|Y,\Theta^t)$的期望，定义如下：</p>
<script type="math/tex; mode=display">Q(\Theta, \Theta^t) = E_X\left[\log P(X,Y|\Theta) | Y, \Theta^t\right]</script><p>对$Q$函数展开，写成</p>
<script type="math/tex; mode=display">Q(\Theta, \Theta^t) = \sum_X \log P(X,Y|\Theta)P(X|Y,\Theta^t)</script><p>对于$P(X|Y,\Theta^t)$，理解成隐变量在模型参数$\Theta^t$和观测$Y$下的概率。</p>
<p>推到这里还是比较抽象，下面继续就EM算法在HMM，GMM中的应用做相关说明，这个应该就比较具象了。</p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>EM</tag>
      </tags>
  </entry>
  <entry>
    <title>Kaldi中的GMM模型</title>
    <url>/2017/05/28/kaldi-gmm/</url>
    <content><![CDATA[<p>这部分主要记录的是GMM在kaldi中的实现。<br><a id="more"></a></p>
<p>Kaldi中关于高斯混合模型的表示，更新，主要用到下面这四个类，之间的关系如下：</p>
<p><img src="http://www.funcwj.cn/images/kaldi-gmm.png", width="400"></p>
<p>具体表述为：</p>
<ol>
<li><code>DiagGMM</code>表示一个GMM模型，<code>AmDiagGMM</code>存储了一个GMM声学模型中的所有GMM，也就是pdf</li>
<li><code>AccumDiagGmm</code>用来对一个GMM模型进行参数更新，<code>AccumAmDiagGmm</code>中存储了一个<code>AccumDiagGmm</code>向量，可以对整个声学模型进行更新</li>
</ol>
<p>下面一个一个说明</p>
<h3 id="DiagGMM"><a href="#DiagGMM" class="headerlink" title="DiagGMM"></a>DiagGMM</h3><p>对于一个GMM模型，pdf可以表示为</p>
<script type="math/tex; mode=display">
\prod_{m = 0}^Mc_m\mathcal{N}(\boldsymbol{x}, \boldsymbol{\mu}_m, \boldsymbol{\varSigma}_m) = \prod_{m=0}^M \frac{c_m}{(2\pi)^{D/2}|\boldsymbol{\varSigma}_m|^{1/2}}e^\frac{(\boldsymbol{x}-\boldsymbol{\mu}_m)^T\boldsymbol{\varSigma}_m^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_m)}{2}</script><p>对其中一个GMM分量，我们取log可以得到：</p>
<script type="math/tex; mode=display">
\log{c_m} - \frac{1}{2}(D\log{2\pi}+\log{\boldsymbol{|\varSigma}_m|}) + \frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_m)^T\boldsymbol{\varSigma}_m^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_m)</script><p>对于原先的指数部分，展开：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\exp & = \frac{1}{2}(\boldsymbol{x}^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{x} - \boldsymbol{x}^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{\mu}_m - \boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{x} + \boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{\mu}_m) \\
& = \frac{1}{2}\boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{\mu}_m + \frac{1}{2}\boldsymbol{x}^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{x} - \boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{x}
\end{aligned}</script><p>DiagGMM中<code>gconst_</code>，<code>weights_</code>，<code>inv_vars_</code>，<code>means_invvars_</code>依次存放的值如下：</p>
<script type="math/tex; mode=display">
\log{c_m} - \frac{1}{2}(D\log{2\pi}+\log{\boldsymbol{|\varSigma}_m|}-\boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{\mu}_m) \\
c_m \\
\boldsymbol{\varSigma}_m^{-1} \\
\boldsymbol{\mu}_m^T \boldsymbol{\varSigma}_m^{-1}</script><p>在给定$\boldsymbol{x}$时，计算一个分量的loglikelihood由下式给出</p>
<script type="math/tex; mode=display">
- \text{gconst_} + \text{means_invvars_} \cdot \boldsymbol{x} - \frac{1}{2} \cdot \text{inv_vars_} \cdot \boldsymbol{x}^2</script><p>由此看来，DiagGMM的作用就是表示一个最基本的GMM模型，给出一个观测，可以给出一个各个GMM分量观测概率(比如在函数LogLikelihoods的作用，可以得到一个观测的后验向量)。对于这单个GMM模型的更新，需要记录EM算法中的一些过程量，这个依靠AccumDiagGmm完成。</p>
<h3 id="AccumDiagGmm"><a href="#AccumDiagGmm" class="headerlink" title="AccumDiagGmm"></a>AccumDiagGmm</h3><p>结合EM算法，要更新GMM模型中的$(c_m, \mu_m, \varSigma_m)$，必须首先得到隐变量在完全数据下的期望$E_{H_n^m}$：</p>
<script type="math/tex; mode=display">
E_{H_n^m} = \frac{c_m \cdot \mathcal{N(\boldsymbol{x}_n;\boldsymbol{\mu}_m, \boldsymbol{\varSigma}_m})}{\sum_{m = 0}^M\mathcal{N(\boldsymbol{x}_n;\boldsymbol{\mu}_m, \boldsymbol{\varSigma}_m})}
= \frac{P_m(\boldsymbol{x}_n;\boldsymbol{\mu}_m, \boldsymbol{\varSigma}_m)}{P(\boldsymbol{x}_n;\boldsymbol{\mu}, \boldsymbol{\varSigma})}</script><p>${P_m} \to {P_m / P}$的映射由函数<code>ApplySoftMax</code>完成，该函数如下</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span>&lt;<span class="keyword">typename</span> Real&gt;</span><br><span class="line">Real VectorBase&lt;Real&gt;::ApplySoftMax() &#123;</span><br><span class="line">  Real <span class="built_in">max</span> = <span class="keyword">this</span>-&gt;Max(), sum = <span class="number">0.0</span>;</span><br><span class="line">  <span class="keyword">for</span> (MatrixIndexT i = <span class="number">0</span>; i &lt; dim_; i++) &#123;</span><br><span class="line">    sum += (data_[i] = Exp(data_[i] - <span class="built_in">max</span>));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">this</span>-&gt;Scale(<span class="number">1.0</span> / sum);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">max</span> + Log(sum);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这个函数的功能如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\{P_m\} & \leftarrow \{e^{P_m - P_{max}}\} \\
\text{sum} & \leftarrow \sum_{m = 0}^MP_m=\frac{1}{e^{P_{max}}}\sum_{m = 0}^Me^{P_m} \\
\{P_m\} & \leftarrow \{\frac{P_m}{\text{sum}}\} = \{\frac{e^{P_{max}}}{\sum_{m = 0}^Me^{P_m}} \cdot \frac{e^{P_m}}{e^{P_{max}}}\} = \{\frac{e^{P_m}}{\sum_{m = 0}^Me^{P_m}}\} \\
\text{return} & \; \log\sum_{m = 0}^Me^{P_m}
\end{aligned}</script><p>由于实际参与运算的${P_m}$实际上都是取过log的，所以，<code>ApplySoftMax</code>完成了${P_m} \to {P_m / P}$映射功能，表示如下：</p>
<script type="math/tex; mode=display">
\{\log P_m\} \xrightarrow{\text{softmax}} \{E_{H_n^m}\}</script><p>下面把AccumDiagGmm中的三个变量和EM算法中的更新参数结合起来<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Vector&lt;double&gt; occupancy_;</span><br><span class="line">Matrix&lt;double&gt; mean_accumulator_;</span><br><span class="line">Matrix&lt;double&gt; variance_accumulator_;</span><br></pre></td></tr></table></figure><br>以上三个变量的对应关系如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathcal{O}_m & = \sum_{n = 0}^NE_{H_n^m} \\
\mathcal{M}_m(M \times D) & = \sum_{n = 0}^NE_{H_n^m} \cdot X_n \\
\mathcal{V}_m(M \times D) & = \sum_{n = 0}^NE_{H_n^m} \cdot X_n \cdot X_n
\end{aligned}</script><p>以上过程量$\mathcal{O}, \mathcal{M}, \mathcal{V} $在<code>gmm-acc-stats-ali</code>中完成积累，在<code>gmm-est</code>中完成更新。<br>结合EM算法中更新公式，可以得到：</p>
<script type="math/tex; mode=display">
\begin{aligned}
c_m & = \frac{\mathcal{O}_m}{\sum_{m = 0}^M \mathcal{O}_m} \\
\boldsymbol{\mu}_m & = \frac{\mathcal{M}_m}{\sum_{m = 0}^M \mathcal{O}_m} \\
\boldsymbol{\varSigma}_m & = \frac{\mathcal{V}_m}{\sum_{m = 0}^M \mathcal{O}_m} - \boldsymbol{\mu}_m^2
\end{aligned}</script><p>kaldi中这部分还进行了GMM高斯数的自动调整，即merge和split操作。</p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>Kaldi</tag>
        <tag>GMM</tag>
      </tags>
  </entry>
  <entry>
    <title>RealFFT算法实现</title>
    <url>/2017/05/28/realfft-2/</url>
    <content><![CDATA[<p>FFT最后一步，解释RealFFT的算法原理。<br>RealFFT输入，对于实序列$x_n(0 \le n \le N - 1)$，以$(x_{2n }, x_{2n + 1})$的形式输入，输出为实序列FFT变换结果的前$N / 2$个点。<br><a id="more"></a></p>
<p>比如，以长为16的序列${1, 1, 1, 1, 0, \ldots 0 }$输入<code>ComplexFFT</code>和<code>RealFFT</code>，结果输出分别为<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[  4.000000,   0.000000] </span><br><span class="line">[  3.013670,   2.013670] </span><br><span class="line">[  1.000000,   2.414214] </span><br><span class="line">[ -0.248303,   1.248303] </span><br><span class="line">[  0.000000,   0.000000] </span><br><span class="line">[  0.834089,  -0.165911] </span><br><span class="line">[  1.000000,   0.414214] </span><br><span class="line">[  0.400544,   0.599456] </span><br><span class="line">[  0.000000,   0.000000] </span><br><span class="line">[  0.400544,  -0.599456] </span><br><span class="line">[  1.000000,  -0.414214] </span><br><span class="line">[  0.834089,   0.165911] </span><br><span class="line">[  0.000000,   0.000000] </span><br><span class="line">[ -0.248303,  -1.248303] </span><br><span class="line">[  1.000000,  -2.414214] </span><br><span class="line">[  3.013670,  -2.013670] </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;</span><br><span class="line">[  4.000000,   0.000000]</span><br><span class="line">[  3.013670,   2.013670]</span><br><span class="line">[  1.000000,   2.414214]</span><br><span class="line">[ -0.248303,   1.248303]</span><br><span class="line">[  0.000000,   0.000000]</span><br><span class="line">[  0.834089,  -0.165911]</span><br><span class="line">[  1.000000,   0.414214]</span><br><span class="line">[  0.400544,   0.599456]</span><br></pre></td></tr></table></figure><br>观察可以发现，利用序列的共轭对称性可以补全一些其余的点（有一个点无法补全，即对称中心点）<br>下面说明算法流程</p>
<script type="math/tex; mode=display">
\begin{aligned}
X_k  & = \sum_{n = 0}^{N - 1}x_nW_N^{kn} \\
 & = \sum_{n = 0}^{N / 2 - 1}x_{2n}W_N^{2nk} + x_{2n + 1}W_N^{(2n + 1)k} \\
 & = \sum_{n = 0}^{N / 2 - 1}x_{2n}W_{N/2}^{nk} +  W_N^k\sum_{n = 0}^{N / 2 - 1}x_{2n + 1}W_{N/2}^{nk} \\
 & = F_k + W_N^kG_k
\end{aligned}</script><p>共轭对称证明：</p>
<script type="math/tex; mode=display">
\begin{aligned}
X_{n-k}^*  & = F_{n-k}^* + W_N^{*n-k}G_{n-k}^* \\
& = F_k + W_N^{*-k}G_k = F_k + W_N^kG_k = X_k
\end{aligned}</script><p>之前的$F_k, G_k$已经计算完毕，只需要在上次程序的基础之上计算</p>
<script type="math/tex; mode=display">F_k + W_N^kG_k</script><p>即可。</p>
<p>实现如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">ComplexFFT(R, I, <span class="number">0</span>);</span><br><span class="line"><span class="keyword">float</span> FR, FI, GR, GI, YR, YI, CYR, CYI, XR, XI, cosr, sinr;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> r = <span class="number">1</span>; r &lt;= MAX_LEN; r++)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">if</span>(r == <span class="number">1</span>)</span><br><span class="line">		FR = R[r], FI = <span class="number">0.0</span>, GR = I[r], GI = <span class="number">0.0</span>;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	&#123;</span><br><span class="line">		YR  = R[r], YI = I[r];</span><br><span class="line">		CYR = R[MAX_LEN + <span class="number">2</span> - r], CYI = -I[MAX_LEN + <span class="number">2</span> - r];</span><br><span class="line">		FR  = (YR + CYR) / <span class="number">2</span>, FI = (YI + CYI) / <span class="number">2</span>;</span><br><span class="line">		GR  = (YI - CYI) / <span class="number">2</span>, GI = (CYR - YR) / <span class="number">2</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	cosr = <span class="built_in">cos</span>((r - <span class="number">1</span>) * PI / MAX_LEN);</span><br><span class="line">	sinr = <span class="built_in">sin</span>((r - <span class="number">1</span>) * PI / MAX_LEN);</span><br><span class="line">	XR = FR + cosr * GR - sinr * GI;</span><br><span class="line">	XI = FI + cosr * GI + sinr * GR;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"[%12f, %12f]\n"</span>, XR, XI);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>结果经过验证无误。</p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>C/C++</tag>
        <tag>FFT</tag>
      </tags>
  </entry>
  <entry>
    <title>RealFFT算法铺垫</title>
    <url>/2017/05/27/realfft-1/</url>
    <content><![CDATA[<p>继续FFT，上回已经手写FFT了，但是也遗留了一个问题，实际应用中FFT处理的都是实信号，但是为了使用我上回写的<code>ComplexFFT</code>函数，需要给其虚部补0，这一操作不仅浪费空间，而且计算耗时啊。RealFFT算法就是处理实信号的快速算法。<br><a id="more"></a></p>
<p>同时，搞信号的重构也让我对实FFT的对称性加深了认识，确实是有用的……</p>
<p>实信号DFT的对称性:</p>
<script type="math/tex; mode=display">
\begin{aligned}
W_N^k & =e^{-2kj\pi/N} \\
X_k  & = \sum_{n = 0}^{N-1}x_nW_N^{nk}
\end{aligned}</script><p>注意这里$x_n$是实数</p>
<script type="math/tex; mode=display">
\begin{aligned}
X_{N - r} & = \sum_{n = 0}^{N-1}x_nW_N^{(N - r)k} \\
 & = \sum_{n = 0}^{N-1}x_nW_N^{-rk}W_N^{Nk} \\
 & =  \sum_{n = 0}^{N-1}x_nW_N^{-rk} = \sum_{n = 0}^{N-1}[x_nW_N^{rk}]^* = X_r^*
\end{aligned}</script><p>反之：</p>
<script type="math/tex; mode=display">
X_{N - r}^* = X_r \quad (1 \le r\le N-1)</script><p>在$0$这点：</p>
<script type="math/tex; mode=display">
X_0 = \sum_{n = 0}^{N-1}x_n</script><p>直观一点，看个例子，使用<code>ComplexFFT</code>函数，输入<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ 0.000078,    0.000000] &#x3D;&gt; [  67.890442,    0.000000]</span><br><span class="line">[ 1.315378,    0.000000] &#x3D;&gt; [ -13.852791,    1.756794]</span><br><span class="line">[ 7.556053,    0.000000] &#x3D;&gt; [   0.532240,  -14.502794]</span><br><span class="line">[ 4.586502,    0.000000] &#x3D;&gt; [ -10.848876,    0.947389]</span><br><span class="line">[ 5.327672,    0.000000] &#x3D;&gt; [   8.034233,    8.668694]</span><br><span class="line">[ 2.189592,    0.000000] &#x3D;&gt; [  -8.089980,   12.082935]</span><br><span class="line">[ 0.470446,    0.000000] &#x3D;&gt; [ -14.220805,    6.269228]</span><br><span class="line">[ 6.788647,    0.000000] &#x3D;&gt; [   5.620103,    0.964417]</span><br><span class="line">[ 6.792964,    0.000000] &#x3D;&gt; [  -2.237431,    0.000000]</span><br><span class="line">[ 9.346930,    0.000000] &#x3D;&gt; [   5.620103,   -0.964417]</span><br><span class="line">[ 3.835021,    0.000000] &#x3D;&gt; [ -14.220805,   -6.269228]</span><br><span class="line">[ 5.194164,    0.000000] &#x3D;&gt; [  -8.089980,  -12.082935]</span><br><span class="line">[ 8.309653,    0.000000] &#x3D;&gt; [   8.034233,   -8.668694]</span><br><span class="line">[ 0.345721,    0.000000] &#x3D;&gt; [ -10.848876,   -0.947389]</span><br><span class="line">[ 0.534616,    0.000000] &#x3D;&gt; [   0.532240,   14.502794]</span><br><span class="line">[ 5.297002,    0.000000] &#x3D;&gt; [ -13.852791,   -1.756794]</span><br></pre></td></tr></table></figure><br>注意，这种对称性不包括直流分量的。<br>使用对称性还可以做许多优化，包括RealFFT。<br>这里的铺垫是指：使用一次FFT计算的结果，得到实部，虚部序列的FFT结果，以下面这个为例子:<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[ 0.000078,    1.315378] &#x3D;&gt; [  76.081299,   78.423798]</span><br><span class="line">[ 7.556053,    4.586502] &#x3D;&gt; [  -7.566336,   10.051374]</span><br><span class="line">[ 5.327672,    2.189592] &#x3D;&gt; [  -2.170276,  -19.456476]</span><br><span class="line">[ 0.470446,    6.788647] &#x3D;&gt; [  -1.338717,    1.404751]</span><br><span class="line">[ 6.792964,    9.346930] &#x3D;&gt; [ -12.029690,   -0.553211]</span><br><span class="line">[ 3.835021,    5.194164] &#x3D;&gt; [  -1.947378,    5.299602]</span><br><span class="line">[ 8.309653,    0.345721] &#x3D;&gt; [ -19.588976,  -11.740066]</span><br><span class="line">[ 0.534616,    5.297002] &#x3D;&gt; [ -16.009092,    3.573137]</span><br><span class="line">[ 6.711493,    0.076982] &#x3D;&gt; [  11.795471,  -13.576748]</span><br><span class="line">[ 3.834157,    0.668422] &#x3D;&gt; [ -17.982683,   -8.924475]</span><br><span class="line">[ 4.174860,    6.867727] &#x3D;&gt; [ -11.516462,   -1.057013]</span><br><span class="line">[ 5.889766,    9.304365] &#x3D;&gt; [ -32.044506,  -12.575722]</span><br><span class="line">[ 8.461669,    5.269288] &#x3D;&gt; [  12.017742,   -0.259529]</span><br><span class="line">[ 0.919649,    6.539190] &#x3D;&gt; [  16.961304,    5.201901]</span><br><span class="line">[ 4.159994,    7.011906] &#x3D;&gt; [  -0.896533,  -20.641878]</span><br><span class="line">[ 9.103209,    7.621980] &#x3D;&gt; [   6.236089,    5.876601]</span><br></pre></td></tr></table></figure><br>根据一个虚数序列$(X, Y)$得到的$(R, I)$，我们是可以得到$(X,0)$和$(Y,0)$的FFT结果的。<br>推导如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
X_k & = \sum_{n = 0}^{N-1}x_nW_N^{nk}  = \sum_{n = 0}^{N-1}(f_n+jg_n)W_N^{nk} \\
 & = \sum_{n = 0}^{N-1}f_nW_N^{nk}+ j\sum_{n = 0}^{N-1}g_nW_N^{nk} = F_k + jG_k
\end{aligned}</script><p>又$f_n,g_n$是实数序列，满足</p>
<script type="math/tex; mode=display">
\begin{aligned}
F_{N - k}^* & = F_k \\
G_{N - k}^* & = G_k
\end{aligned}</script><p>那么</p>
<script type="math/tex; mode=display">
X_{N - k}^* = F_{N - k}^* - jG_{N - k}^* = F_k - jG_k</script><p>要想从$X_k$中恢复出$F_k$和$G_k$，可以通过下式：</p>
<script type="math/tex; mode=display">
\begin{aligned}
F_k & = \frac{1}{2}( X_{N - k}^* + X_k) \\
G_k & = \frac{j}{2}(X_{N - k}^* - X_k) \; 1 \le k \le N - 1
\end{aligned}</script><p>当$k = 0$时：</p>
<script type="math/tex; mode=display">
X_0 = F_0 + jG_0 = \sum_{n = 0}^{N-1}f_n + j\sum_{n = 0}^{N-1}g_n</script><p>所以：</p>
<script type="math/tex; mode=display">
\begin{aligned}
F_0 & = R(X_0) \\
G_0 & = I(X_0)
\end{aligned}</script><p>代码实现<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">ComplexFFT(R, I, <span class="number">0</span>);	</span><br><span class="line"><span class="keyword">float</span> FrR, FrI, GrR, GrI, YrR, YrI, CyrR, CyrI;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> r = <span class="number">1</span>; r &lt;= MAX_LEN; r++)</span><br><span class="line">&#123;</span><br><span class="line">	<span class="keyword">if</span>(r == <span class="number">1</span>)</span><br><span class="line">		FrR = R[r], FrI = <span class="number">0.0</span>, GrR = I[r], GrI = <span class="number">0.0</span>;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">	&#123;</span><br><span class="line">		YrR  = R[r], YrI = I[r];</span><br><span class="line">		CyrR = R[MAX_LEN + <span class="number">2</span> - r], CyrI = -I[MAX_LEN + <span class="number">2</span> - r];</span><br><span class="line">		FrR  = (YrR + CyrR) / <span class="number">2</span>, FrI = (YrI + CyrI) / <span class="number">2</span>;</span><br><span class="line">		GrR  = (YrI - CyrI) / <span class="number">2</span>, GrI = (-YrR + CyrR) / <span class="number">2</span>;</span><br><span class="line">	&#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"[%12f, %12f]\t[%12f, %12f]\n"</span>, FrR, FrI, GrR, GrI);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>程序输出<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[   76.081299,     0.000000]	[   78.423798,     0.000000]</span><br><span class="line">[   -0.665123,     2.087387]	[    7.963987,     6.901212]</span><br><span class="line">[   -1.533404,     0.592701]	[  -20.049177,     0.636872]</span><br><span class="line">[    7.811293,    -1.898575]	[    3.303326,     9.150011]</span><br><span class="line">[   -0.005974,    -0.146841]	[   -0.406370,    12.023716]</span><br><span class="line">[  -16.995941,     8.937662]	[   -3.638060,   -15.048564]</span><br><span class="line">[  -15.552719,    -5.341527]	[   -6.398539,     4.036257]</span><br><span class="line">[  -16.995888,     6.248806]	[   -2.675669,    -0.986795]</span><br><span class="line">[   11.795471,     0.000000]	[  -13.576748,     0.000000]</span><br><span class="line">[  -16.995888,    -6.248806]	[   -2.675669,     0.986795]</span><br><span class="line">[  -15.552719,     5.341527]	[   -6.398539,    -4.036257]</span><br><span class="line">[  -16.995941,    -8.937662]	[   -3.638060,    15.048564]</span><br><span class="line">[   -0.005974,     0.146841]	[   -0.406370,   -12.023716]</span><br><span class="line">[    7.811293,     1.898575]	[    3.303326,    -9.150011]</span><br><span class="line">[   -1.533404,    -0.592701]	[  -20.049177,    -0.636872]</span><br><span class="line">[   -0.665123,    -2.087387]	[    7.963987,    -6.901212]</span><br></pre></td></tr></table></figure><br>和以$(X,0)$和$(Y,0)$作为输入时的结果做对比<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[    76.081299,    0.000000]    [   78.423798,    0.000000]</span><br><span class="line">[    -0.665124,    2.087387]    [    7.963987,    6.901213]</span><br><span class="line">[    -1.533404,    0.592701]    [  -20.049177,    0.636871]</span><br><span class="line">[     7.811293,   -1.898576]    [    3.303326,    9.150011]</span><br><span class="line">[    -0.005974,   -0.146841]    [   -0.406370,   12.023716]</span><br><span class="line">[   -16.995941,    8.937661]    [   -3.638060,  -15.048563]</span><br><span class="line">[   -15.552718,   -5.341526]    [   -6.398538,    4.036257]</span><br><span class="line">[   -16.995888,    6.248806]    [   -2.675670,   -0.986795]</span><br><span class="line">[    11.795471,    0.000000]    [  -13.576748,    0.000000]</span><br><span class="line">[   -16.995888,   -6.248806]    [   -2.675670,    0.986795]</span><br><span class="line">[   -15.552718,    5.341526]    [   -6.398538,   -4.036257]</span><br><span class="line">[   -16.995941,   -8.937661]    [   -3.638060,   15.048563]</span><br><span class="line">[    -0.005974,    0.146841]    [   -0.406370,  -12.023716]</span><br><span class="line">[     7.811293,    1.898576]    [    3.303326,   -9.150011]</span><br><span class="line">[    -1.533404,   -0.592701]    [  -20.049177,   -0.636871]</span><br><span class="line">[    -0.665124,   -2.087387]    [    7.963987,   -6.901213]</span><br></pre></td></tr></table></figure><br>基本无误。<br>熟悉了这部分，下面就可以正式啃RealFFT了。</p>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Code</tag>
        <tag>C/C++</tag>
        <tag>FFT</tag>
      </tags>
  </entry>
  <entry>
    <title>FFT实现</title>
    <url>/2017/05/27/write-fft/</url>
    <content><![CDATA[<p>前端时间搞前端处理，遇到RealFFT算法，挺感兴趣的，网上资料太少，就自己实现了一遍。<br>考虑大部分情况下，FFT输入都是实信号，所以一般的实现方法，都是在虚部补0之后，转成虚信号，进行变换，RealFFT就是快速处理实信号的一类算法，这个以后再谈。先是最基本的实现。<br><a id="more"></a></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ComplexFFT</span><span class="params">(<span class="keyword">float</span> *R, <span class="keyword">float</span> *I, <span class="keyword">int</span> invert)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n, nn, i, j, m, cnt, inc, k;</span><br><span class="line">    <span class="keyword">float</span> tmpR, tmpI, WR, WI, Ri, Ii, Rj, Ij, dR, dI;</span><br><span class="line"></span><br><span class="line">    n = R[<span class="number">0</span>], nn = n &gt;&gt; <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span>(j = <span class="number">0</span>, i = <span class="number">0</span>; i &lt; n - <span class="number">1</span>; i++)   </span><br><span class="line">    &#123;  </span><br><span class="line">        <span class="keyword">if</span>(i &lt; j)</span><br><span class="line">        &#123;  </span><br><span class="line">            tmpR = R[j + <span class="number">1</span>], tmpI = I[j + <span class="number">1</span>];</span><br><span class="line">            R[j + <span class="number">1</span>] = R[i + <span class="number">1</span>], I[j + <span class="number">1</span>] = I[i + <span class="number">1</span>];</span><br><span class="line">            R[i + <span class="number">1</span>] = tmpR, I[i + <span class="number">1</span>] = tmpI;</span><br><span class="line">        &#125;</span><br><span class="line">        m = n &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(j &gt;= m)</span><br><span class="line">        &#123;</span><br><span class="line">            j = j - m;</span><br><span class="line">            m = m &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        &#125; </span><br><span class="line">        j = j + m;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    m = <span class="number">1</span>;</span><br><span class="line">    <span class="comment">// 1, 2, 4 级</span></span><br><span class="line">    <span class="keyword">while</span>(m &lt; n)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">            m = 1: [1, 2], [3, 4], [5, 6], [7, 8] 4</span></span><br><span class="line"><span class="comment">            m = 2: [1, 3], [2, 4], [5, 7], [6, 8] 2</span></span><br><span class="line"><span class="comment">            m = 4: [1, 5], [2, 6], [3, 7], [4, 8] 1</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="comment">//printf("M = %d\n", m);</span></span><br><span class="line">        cnt = <span class="number">0</span>, inc = n / (m &lt;&lt; <span class="number">1</span>);</span><br><span class="line">        <span class="comment">// inc: 4 2 1</span></span><br><span class="line">        <span class="comment">// m  : 1 2 4</span></span><br><span class="line">        <span class="comment">// W递增inc</span></span><br><span class="line">        <span class="keyword">while</span>(cnt &lt; inc)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="comment">// m = 1: 1 3 5 7</span></span><br><span class="line">            <span class="comment">// m = 2: 1 5</span></span><br><span class="line">            <span class="comment">// m = 4: 1</span></span><br><span class="line">            i = cnt * m * <span class="number">2</span> + <span class="number">1</span>;</span><br><span class="line">            <span class="comment">// W[0, n]: inc</span></span><br><span class="line">            <span class="comment">// 计算m次 迭代inc次</span></span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> t = <span class="number">0</span>; t &lt; m; t++, i++)</span><br><span class="line">            &#123;</span><br><span class="line">                j = i + m;</span><br><span class="line">                k = t * inc;</span><br><span class="line">                <span class="comment">// printf("[%3d, %3d] W[%3d, %3d]\n", i, j, k, nn);</span></span><br><span class="line">                k == <span class="number">0</span> ? WR = <span class="number">1.0</span>, WI = <span class="number">0.0</span>: WR = <span class="built_in">cos</span>(PI * k / nn), WI = <span class="built_in">sin</span>(PI * k / nn);</span><br><span class="line">                <span class="keyword">if</span>(invert) WI = - WI;</span><br><span class="line">                <span class="comment">//(R[i], I[i]) = (Ri, Ii) + W * (Rj, Ij)</span></span><br><span class="line">                <span class="comment">//(R[j], I[j]) = (Ri, Ii) - W * (Rj, Ij)</span></span><br><span class="line">                Rj = R[j], Ij = I[j], Ri = R[i], Ii = I[i];</span><br><span class="line">                R[i] = Ri + WR * Rj - WI * Ij, I[i] = Ii + WR * Ij + WI * Rj;</span><br><span class="line">                R[j] = Ri - WR * Rj + WI * Ij, I[j] = Ii - WR * Ij - WI * Rj;</span><br><span class="line">            &#125;</span><br><span class="line">            cnt++;</span><br><span class="line">        &#125;</span><br><span class="line">        m = m &lt;&lt; <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (invert)</span><br><span class="line">        <span class="keyword">for</span> (i = <span class="number">1</span>; i &lt;= n; i++)</span><br><span class="line">            R[i] = R[i] / n, I[i] = I[i] / n;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>用的是最基本的基于时间抽取的算法，写的时候参照下图：<br><img src="http://www.funcwj.cn/images/FFT.png" width="500">下面对一个窗函数进行16点采样，测试结果如下，一次是输入数据，正变换和逆变换的结果。<br><img src="http://www.funcwj.cn/images/FFT_res.png" width="200"><br>最后顺便用C++也写了一下，用了一下虚数库。</p>
<figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;complex&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">float</span> PI = <span class="number">3.14159265</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">FFT</span><span class="params">(<span class="built_in">vector</span>&lt; <span class="built_in">complex</span>&lt;<span class="keyword">float</span>&gt; &gt; &amp;sig, <span class="keyword">bool</span> invert)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> N = sig.<span class="built_in">size</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>, j = <span class="number">0</span>; i &lt; N - <span class="number">1</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span>(i &lt; j) &#123;</span><br><span class="line">            swap(sig[i], sig[j]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> k = N &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span>(j &gt;= k) &#123;</span><br><span class="line">            j -= k;</span><br><span class="line">            k = k &gt;&gt; <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        j += k;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="built_in">vector</span>&lt; <span class="built_in">complex</span>&lt;<span class="keyword">float</span>&gt; &gt; <span class="title">W</span><span class="params">(N / <span class="number">2</span>)</span></span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; W.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">        W[i] = polar(<span class="number">1.0f</span>, <span class="number">-2</span> * PI * i / N);</span><br><span class="line">        <span class="keyword">if</span> (invert) W[i] = conj(W[i]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> m = <span class="number">1</span>; m &lt; N; m = m &lt;&lt; <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> n = <span class="number">0</span>; n &lt; N; n += (m &lt;&lt; <span class="number">1</span>)) &#123;</span><br><span class="line">            <span class="keyword">int</span> k = <span class="number">0</span>;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = n; j &lt; n + m; j++, k += N / (m &lt;&lt; <span class="number">1</span>)) &#123;</span><br><span class="line">                <span class="built_in">complex</span>&lt;<span class="keyword">float</span>&gt; A = sig[j], B = sig[j + m];</span><br><span class="line">                sig[j] = A + W[k] * B, sig[j + m] = A - W[k] * B;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (invert) &#123;</span><br><span class="line">        for_each(sig.<span class="built_in">begin</span>(), sig.<span class="built_in">end</span>(), [=] (<span class="built_in">complex</span>&lt;<span class="keyword">float</span>&gt; &amp;s) &#123;s /= N;&#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">vector</span>&lt; <span class="built_in">complex</span>&lt;<span class="keyword">float</span>&gt; &gt; signal = &#123;<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>&#125;;</span><br><span class="line"></span><br><span class="line">    FFT(signal, <span class="number">0</span>);</span><br><span class="line">    FFT(signal, <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    for_each(signal.<span class="built_in">begin</span>(), signal.<span class="built_in">end</span>(), [](<span class="built_in">complex</span>&lt;<span class="keyword">float</span>&gt; s) &#123;<span class="built_in">cout</span> &lt;&lt; <span class="built_in">abs</span>(s) &lt;&lt; <span class="built_in">endl</span>;&#125;);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>FFT</tag>
      </tags>
  </entry>
  <entry>
    <title>一系列简单区间DP问题</title>
    <url>/2017/05/25/think-about-interval-dp/</url>
    <content><![CDATA[<p>和矩阵连乘类似的套路，举几个问题作为例子。<br><a id="more"></a></p>
<h3 id="矩阵连乘问题"><a href="#矩阵连乘问题" class="headerlink" title="矩阵连乘问题"></a>矩阵连乘问题</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*=======================================</span></span><br><span class="line"><span class="comment">矩阵连乘问题</span></span><br><span class="line"><span class="comment">dp(i, j) = min( dp(i, k) + dp(k + 1, j) + S);</span></span><br><span class="line"><span class="comment">i &lt; k &lt; j;</span></span><br><span class="line"><span class="comment">dp(i, i) = 0;</span></span><br><span class="line"><span class="comment">========================================*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> flush(arr, i) memset(arr, i, sizeof(arr))</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> int64;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_ITEM = <span class="number">128</span>;</span><br><span class="line"><span class="comment">//const int oo = 0x7fffffff;</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> oo = <span class="number">0x3f3f3f3f</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> dp[MAX_ITEM][MAX_ITEM];</span><br><span class="line"><span class="keyword">int</span> w[MAX_ITEM], pos[MAX_ITEM][MAX_ITEM];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">DP</span><span class="params">(<span class="keyword">int</span> l, <span class="keyword">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(l == r)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(dp[l][r])</span><br><span class="line">        <span class="keyword">return</span> dp[l][r];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> ans = oo, tmp = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = l; i &lt; r; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        tmp = DP(l, i) + DP(i + <span class="number">1</span>, r) + w[l - <span class="number">1</span>] * w[i] * w[r];</span><br><span class="line">        <span class="keyword">if</span>(ans &gt; tmp)</span><br><span class="line">        &#123;</span><br><span class="line">            ans = tmp;</span><br><span class="line">            pos[l][r] = i;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> dp[l][r] = ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">display</span><span class="params">(<span class="keyword">int</span> l, <span class="keyword">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(l == r)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"A%d"</span>, l);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"("</span>);</span><br><span class="line">    <span class="built_in">display</span>(l, pos[l][r]);</span><br><span class="line">    <span class="built_in">display</span>(pos[l][r] + <span class="number">1</span>, r);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">")"</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    freopen(<span class="string">"0-data.txt"</span>, <span class="string">"r"</span>, <span class="built_in">stdin</span>);</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;n) != EOF)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">flush</span>(dp, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">flush</span>(pos, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt;= n; i++)</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">"%d"</span>, w + i);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, DP(<span class="number">1</span>, n));</span><br><span class="line">        <span class="built_in">display</span>(<span class="number">1</span>, n);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="最优三角剖分"><a href="#最优三角剖分" class="headerlink" title="最优三角剖分"></a>最优三角剖分</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*=======================================</span></span><br><span class="line"><span class="comment">最优三角剖分</span></span><br><span class="line"><span class="comment">dp[i][j] = min(dp[i][x] + dp[x][j] + w(i, x, j));</span></span><br><span class="line"><span class="comment">i &lt;= x &lt;= j</span></span><br><span class="line"><span class="comment">边界条件 dp[i][i + 1] == 0</span></span><br><span class="line"><span class="comment">========================================*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> flush(arr, i) memset(arr, i, sizeof(arr))</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> int64;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_ITEM = <span class="number">110</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> oo = <span class="number">0x7fffffff</span>;</span><br><span class="line"><span class="comment">//const int oo = 0x3f3f3f3f;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> dp[MAX_ITEM][MAX_ITEM], wei[MAX_ITEM][MAX_ITEM];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">GetWeight</span><span class="params">(<span class="keyword">int</span> from, <span class="keyword">int</span> mid, <span class="keyword">int</span> to)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> wei[from][mid] + wei[from][to] + wei[mid][to];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">DP</span><span class="params">(<span class="keyword">int</span> from, <span class="keyword">int</span> to)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(to - from == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">if</span>(dp[from][to])</span><br><span class="line">        <span class="keyword">return</span> dp[from][to];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> ans = oo;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = from + <span class="number">1</span>; i &lt; to; i++)</span><br><span class="line">        ans = <span class="built_in">min</span>(ans, DP(from, i) + DP(i, to) + GetWeight(from, i, to));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[from][to] = ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    freopen(<span class="string">"0-data.txt"</span>, <span class="string">"r"</span>, <span class="built_in">stdin</span>);</span><br><span class="line">    <span class="keyword">int</span> n;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;n) != EOF)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++)</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; n; j++)</span><br><span class="line">                <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;wei[i][j]);</span><br><span class="line">        <span class="built_in">flush</span>(dp, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, DP(<span class="number">0</span>, n - <span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="最大m子段和"><a href="#最大m子段和" class="headerlink" title="最大m子段和"></a>最大m子段和</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*=======================================</span></span><br><span class="line"><span class="comment">最大m子段和</span></span><br><span class="line"><span class="comment">9 3</span></span><br><span class="line"><span class="comment">9 8 7 6 5 4 3 2 1</span></span><br><span class="line"><span class="comment">17</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">dp[k][p]表示前k个元素划分为p个子段最大值的最小值</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">dp[k][p] = min&#123;dp[k][p], max&#123;dp[x][p - 1] + sum[x + 1][k]&#125;&#125;</span></span><br><span class="line"><span class="comment">p - 1 &lt;= x &lt;= k - 1</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">========================================*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> flush(arr, i) memset(arr, i, sizeof(arr))</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> int64;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_ITEM = <span class="number">110</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> oo = <span class="number">0x7fffffff</span>;</span><br><span class="line"><span class="comment">//const int oo = 0x3f3f3f3f;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> dp[MAX_ITEM][MAX_ITEM];</span><br><span class="line"><span class="keyword">int</span> sum[MAX_ITEM];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">DP</span><span class="params">(<span class="keyword">int</span> k, <span class="keyword">int</span> p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(p == <span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> dp[k][p] = sum[k];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(dp[k][p])</span><br><span class="line">        <span class="keyword">return</span> dp[k][p];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> tmp = <span class="number">0</span>;</span><br><span class="line">    dp[k][p] = oo;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = p - <span class="number">1</span>; i &lt;= k - <span class="number">1</span>; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        tmp = <span class="built_in">max</span>(DP(i, p - <span class="number">1</span>), sum[k] - sum[i]);</span><br><span class="line">        dp[k][p] = <span class="built_in">min</span>(dp[k][p], tmp);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dp[k][p];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len, p;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">"%d%d"</span>, &amp;len, &amp;p) != EOF)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">flush</span>(sum, <span class="number">0</span>);</span><br><span class="line">        <span class="built_in">flush</span>(dp, <span class="number">0</span>);</span><br><span class="line">        <span class="keyword">int</span> tmp;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= len; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;tmp);</span><br><span class="line">            sum[i] = sum[i - <span class="number">1</span>] + tmp;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, DP(len, p));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="石子合并问题"><a href="#石子合并问题" class="headerlink" title="石子合并问题"></a>石子合并问题</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*=======================================</span></span><br><span class="line"><span class="comment">石子合并问题</span></span><br><span class="line"><span class="comment">自底向上，求步长为k的时候，步长为k - 1问题的解已知</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">dp[i][j]表示i -&gt; j的最优解 得分最多/最少</span></span><br><span class="line"><span class="comment">要加上合并的石子总数作为最优值</span></span><br><span class="line"><span class="comment">dp[i][j] = max(dp[i][j], dp[i][k] + dp[k + 1][j] + sum[i][j]);</span></span><br><span class="line"><span class="comment">========================================*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> flush(arr, i) memset(arr, i, sizeof(arr))</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> int64;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_ITEM = <span class="number">110</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> oo = <span class="number">0x7fffffff</span>;</span><br><span class="line"><span class="comment">//const int oo = 0x3f3f3f3f;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> dp[MAX_ITEM][MAX_ITEM];</span><br><span class="line"><span class="keyword">int</span> sum[MAX_ITEM];</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;len) != EOF)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= len; i++) <span class="built_in">scanf</span>(<span class="string">"%d"</span>, sum + i);</span><br><span class="line">        sum[<span class="number">0</span>] = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= len; i++)</span><br><span class="line">            sum[i] += sum[i - <span class="number">1</span>];</span><br><span class="line">        <span class="built_in">flush</span>(dp, <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> sp = <span class="number">1</span>; sp &lt;= len; sp++)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i + sp &lt;= len; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                <span class="keyword">int</span> j = i + sp;</span><br><span class="line">                <span class="keyword">for</span>(<span class="keyword">int</span> k = i; k &lt; j; k++)</span><br><span class="line">                    dp[i][j] = <span class="built_in">max</span>(dp[i][j], dp[i][k] + dp[k + <span class="number">1</span>][j] + sum[j] - sum[i - <span class="number">1</span>]);</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">"dp[%d][%d] = %d\n"</span>, i, j, dp[i][j]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, dp[<span class="number">1</span>][len]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="最大的算式"><a href="#最大的算式" class="headerlink" title="最大的算式"></a>最大的算式</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*=======================================</span></span><br><span class="line"><span class="comment">最大的算式</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">dp[k][p] = max(dp[p - 1 ... k - 1][p - 1] * sum[k][p])</span></span><br><span class="line"><span class="comment">表示前i部分插入p个乘号获取的最大值</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">========================================*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> flush(arr, i) memset(arr, i, sizeof(arr))</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> int64;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_ITEM = <span class="number">110</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> oo = <span class="number">0x7fffffff</span>;</span><br><span class="line"><span class="comment">//const int oo = 0x3f3f3f3f;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> dp[MAX_ITEM][MAX_ITEM], sum[MAX_ITEM][MAX_ITEM];</span><br><span class="line"><span class="keyword">int</span> num[MAX_ITEM];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">getSum</span><span class="params">(<span class="keyword">int</span> len)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">flush</span>(sum, <span class="number">0</span>);</span><br><span class="line">    <span class="built_in">flush</span>(dp, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= len; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        sum[i][i] = num[i];</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = i + <span class="number">1</span>; j &lt;= len; j++)</span><br><span class="line">            sum[i][j] = sum[i][j - <span class="number">1</span>] + num[j];</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    for(int i = 1; i &lt;= len; i++)</span></span><br><span class="line"><span class="comment">        for(int j = i; j &lt;= len; j++)</span></span><br><span class="line"><span class="comment">            j == len ? printf("%d\n", sum[i][j]) : printf("%d ", sum[i][j]);</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">DP</span><span class="params">(<span class="keyword">int</span> k, <span class="keyword">int</span> p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(p == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        dp[k][p] = sum[<span class="number">1</span>][k];</span><br><span class="line">        <span class="keyword">return</span> dp[k][p];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(dp[k][p])</span><br><span class="line">        <span class="keyword">return</span> dp[k][p];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> ans = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = p - <span class="number">1</span>; i &lt;= k - <span class="number">1</span>; i++)</span><br><span class="line">        ans = <span class="built_in">max</span>(ans, DP(i, p - <span class="number">1</span>) * sum[i + <span class="number">1</span>][k]);</span><br><span class="line"></span><br><span class="line">    dp[k][p] = ans;</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len, p;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">"%d%d"</span>, &amp;len, &amp;p) != EOF)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= len; i++) <span class="built_in">scanf</span>(<span class="string">"%d"</span>, num + i);</span><br><span class="line">        getSum(len);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, DP(len, p));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="最大K乘积问题"><a href="#最大K乘积问题" class="headerlink" title="最大K乘积问题"></a>最大K乘积问题</h3><figure class="highlight c++"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stack&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;queue&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;math.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;time.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*=======================================</span></span><br><span class="line"><span class="comment">最大k乘积问题</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">dp[k][p] = max(dp[p - 1 ... k - 1][p - 1] * num[k][p])</span></span><br><span class="line"><span class="comment">表示前i项分为j部分的最大乘积</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">========================================*/</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> flush(arr, i) memset(arr, i, sizeof(arr))</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> int64;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> MAX_ITEM = <span class="number">110</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> oo = <span class="number">0x7fffffff</span>;</span><br><span class="line"><span class="comment">//const int oo = 0x3f3f3f3f;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> dp[MAX_ITEM][MAX_ITEM], num[MAX_ITEM][MAX_ITEM];</span><br><span class="line"><span class="keyword">char</span> in[MAX_ITEM];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getNum</span><span class="params">(<span class="keyword">char</span> *in)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> len = <span class="built_in">strlen</span>(in);</span><br><span class="line">    <span class="built_in">flush</span>(num, <span class="number">0</span>), <span class="built_in">flush</span>(dp, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= len; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> mul = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> j = i; j &lt;= len; j++)</span><br><span class="line">        &#123;</span><br><span class="line">            mul = mul * <span class="number">10</span> + in[j - <span class="number">1</span>] - <span class="string">'0'</span>;</span><br><span class="line">            num[i][j] = mul;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">    for(int i = 1; i &lt;= len; i++)</span></span><br><span class="line"><span class="comment">        for(int j = i; j &lt;= len; j++)</span></span><br><span class="line"><span class="comment">            j != len ? printf("%d ", num[i][j]) : printf("%d\n", num[i][j]);</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//前k个分为p部分</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">DP</span><span class="params">(<span class="keyword">int</span> k, <span class="keyword">int</span> p)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(p == <span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        dp[k][p] = num[<span class="number">1</span>][k];</span><br><span class="line">        <span class="keyword">return</span> num[<span class="number">1</span>][k];</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(dp[k][p])</span><br><span class="line">        <span class="keyword">return</span> dp[k][p];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span> ans = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = p - <span class="number">1</span>; i &lt;= k - <span class="number">1</span>; i++)</span><br><span class="line">        ans = <span class="built_in">max</span>(ans, DP(i, p - <span class="number">1</span>) * num[i + <span class="number">1</span>][k]);</span><br><span class="line"></span><br><span class="line">    dp[k][p] = ans;</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> p;</span><br><span class="line">    <span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">"%s"</span>, in) != EOF)</span><br><span class="line">    &#123;</span><br><span class="line">        getNum(in);</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">"%d"</span>, &amp;p);</span><br><span class="line">        <span class="keyword">int</span> len = <span class="built_in">strlen</span>(in);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>, DP(len, p));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>DP</tag>
      </tags>
  </entry>
  <entry>
    <title>遇见Ubuntu</title>
    <url>/2017/05/25/meeting-ubuntu/</url>
    <content><![CDATA[<p>从认识Ubuntu到如今大概不到四年的时间。我记得第一次接触的时候，是在某君的宿舍，一个mentohust命令，将我拉进了Linux的世界。<br><a id="more"></a></p>
<p>第一个Ubuntu也是他帮我弄上的，从那之后的几个星期里，我几乎日夜不断的倒腾它，查配置，弄教程，软件装了卸，卸了装，单纯觉得有趣和神奇，每一次的终端操作，都伴随着紧张，期待与激动。后来因为AMD的显卡驱动问题，跑Ubuntu风扇转的不停，掉电太快，就直接在虚拟机上弄了。</p>
<p>一年前，正式转入Ubuntu工作环境。在台式机上，我个人没有什么娱乐需求，甚至连视频都不会看，最多刷刷新闻，听听歌曲。自从解决了QQ问题之后（DeepinQQ + wine，还是很美观的），从实际需求来看，Ubuntu完全满足我的条件了。</p>
<p>目前在乎如下装置：</p>
<ul>
<li>默认terminal，Ubuntu Mono字体好看，好像也只有在它自己的终端下显示的才优美，换在Mac上都不行……</li>
<li>zsh，主题，插件很丰富，省的自己改bashrc了</li>
<li>JetBrains的Idea，Clion，AS，主题一律monikai，内建终端很方便，编辑器字体首选ubuntu家族的mono，和终端效果相似，其次Droids Sans。</li>
<li>VSCode，之前的Sublime输入不了中文，还有就是，前者免费。</li>
<li>Cmd Markdown，三大平台同步，只喜欢写Markdown，图方便。</li>
<li>Chrome，必备Adlock(Plus)，其他随意了</li>
<li>vimplus，airline要正常的话，从github上装个字体布丁，终端设置改一下就ok，高亮，补全美的不行</li>
</ul>
<p>其他的细节的东西还有很多，记得再补充吧，对于桌面，下个unity-tweak-tools把主题改成Flatabulous，图标ultra-flat-icons，最重要的，桌面不要放文件夹!</p>
<p>网易云音乐起到这么个作用，干活的时候听听歌，貌似年末了，统计一下自己工作了多长时间&gt;_&lt;。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>HTK解码器部分代码走读</title>
    <url>/2017/05/24/HTK-decoder-analysis/</url>
    <content><![CDATA[<p>本篇主要解析Token Passing算法实现的核心过程，主要是四个步奏，配合代码理解如下，最后一部分是词网络拓展，个人感觉复杂度大于解码过程，所以放在最后交代。</p>
<a id="more"></a>
<h2 id="1-StartRecognition"><a href="#1-StartRecognition" class="headerlink" title="1. StartRecognition"></a>1. StartRecognition</h2><p>这部分需要做一些<code>pri</code>和<code>vri</code>的初始化工作，这两个值在前期的<code>InitVRecInfo</code>函数中已经做了更全面的初始化，之后对<code>pri-&gt;net-&gt;initial</code>附着一个实例，往后的解码过程实际上是一个bfs的过程，而<code>AttachInst</code>函数实际上是给<code>pri-&gt;link</code>这个双向链表加了初始的节点。之后的过程大体上是：</p>
<ul>
<li>从链表中取节点进行节点内token算分，节点间token传递</li>
<li>不断从链表中剪枝，即拿掉不满足某种阈值条件的节点</li>
</ul>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">pri-&gt;net-&gt;<span class="keyword">final</span>.inst=pri-&gt;net-&gt;initial.inst=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// store previous calculate resultes</span></span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>,pre=pri-&gt;psi-&gt;sPre+<span class="number">1</span>;i&lt;=pri-&gt;psi-&gt;nsp;i++,pre++) pre-&gt;id=<span class="number">-1</span>;</span><br><span class="line"><span class="keyword">for</span>(i=<span class="number">1</span>,pre=pri-&gt;psi-&gt;mPre+<span class="number">1</span>;i&lt;=pri-&gt;psi-&gt;nmp;i++,pre++) pre-&gt;id=<span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">tact: total active number</span></span><br><span class="line"><span class="comment">frame: current process frame id</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line">pri-&gt;tact=pri-&gt;nact=pri-&gt;frame=<span class="number">0</span>;</span><br><span class="line"><span class="comment">// attach a instance to the network entrance</span></span><br><span class="line">AttachInst(&amp;pri-&gt;net-&gt;initial);</span><br></pre></td></tr></table></figure>
<h3 id="节点含义"><a href="#节点含义" class="headerlink" title="节点含义"></a>节点含义</h3><p>需要搞清楚几个节点的含义，我的理解如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// n_hmm = 2: HMM 模型节点</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> node_hmm(node) ((node)-&gt;type &amp; n_hmm)</span></span><br><span class="line"><span class="comment">// n_word = 4: 词节点</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> node_word(node) ((node)-&gt;type == n_word)</span></span><br><span class="line"><span class="comment">// n_tr0 = 4: 一类特殊的点，貌似可以从start直接调到fin状态</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> node_tr0(node) ((node)-&gt;type &amp; n_tr0)</span></span><br><span class="line"><span class="comment">// n_wd0 = 1: 最后一个发音节点，如果是5状态的话，就是3节点</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> node_wd0(node) ((node)-&gt;type &amp; n_wd0)</span></span><br></pre></td></tr></table></figure></p>
<p><img src="http://www.funcwj.cn/images/nodetype.png", width="300"></p>
<p>最重要的是词节点和模型节点【对音素HMM建模】，token passing算法实现时的多数操作集中在对俩类节点的操作。</p>
<h3 id="AttachInst"><a href="#AttachInst" class="headerlink" title="AttachInst"></a>AttachInst</h3><p>关于<code>AttachInst</code>函数，很重要的一个作用是对<code>pri-&gt;head</code>这个双向链表加入了初始节点：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"> TokenSet *cur;</span><br><span class="line"> NetInst *inst;</span><br><span class="line"> <span class="keyword">int</span> i,n;</span><br><span class="line"> </span><br><span class="line"> inst=(NetInst*) New(&amp;pri-&gt;instHeap,<span class="number">0</span>);</span><br><span class="line"> </span><br><span class="line"> <span class="comment">// node-&gt;info.hmm-&gt;numState include entry and exit nodes</span></span><br><span class="line"> <span class="comment">// represent the HMM nodes</span></span><br><span class="line"> <span class="keyword">if</span> (node_hmm(node))</span><br><span class="line">     n=node-&gt;info.hmm-&gt;numStates<span class="number">-1</span>;</span><br><span class="line"> <span class="keyword">else</span></span><br><span class="line">     n=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// position of the instance in the network</span></span><br><span class="line">inst-&gt;node=node;</span><br><span class="line"><span class="comment">// tokenset in HMM non-exit status</span></span><br><span class="line">inst-&gt;state=(TokenSet*) New(pri-&gt;stHeap+pri-&gt;psi-&gt;stHeapIdx[n],<span class="number">0</span>);</span><br><span class="line"><span class="comment">// tokenset in HMM exit status</span></span><br><span class="line">inst-&gt;<span class="built_in">exit</span>=(TokenSet*) New(pri-&gt;stHeap+pri-&gt;psi-&gt;stHeapIdx[<span class="number">1</span>],<span class="number">0</span>);</span><br><span class="line"><span class="comment">// const Token null_token=&#123;LZERO, 0.0, NULL, NULL&#125;</span></span><br><span class="line"><span class="comment">// 是要传递的token,初始化为空</span></span><br><span class="line">inst-&gt;<span class="built_in">exit</span>-&gt;tok=null_token;</span><br><span class="line"></span><br><span class="line"><span class="comment">// handle exit nodes</span></span><br><span class="line"><span class="comment">// pri-&gt;nToks: maximum tokens to propagate</span></span><br><span class="line"><span class="comment">// could be ignored：这一步不求N-best可以忽略</span></span><br><span class="line"><span class="keyword">if</span> (pri-&gt;nToks&gt;<span class="number">1</span>) &#123;</span><br><span class="line">     <span class="comment">// set: sorted tokens</span></span><br><span class="line">     inst-&gt;<span class="built_in">exit</span>-&gt;<span class="built_in">set</span>=(RelToken*) New(&amp;pri-&gt;rTokHeap,<span class="number">0</span>);</span><br><span class="line">     <span class="comment">// n: 0 == 1-best keep only one answer</span></span><br><span class="line">     <span class="comment">// 1 &gt;== N-best: keep N best answers</span></span><br><span class="line">     inst-&gt;<span class="built_in">exit</span>-&gt;n=<span class="number">1</span>;</span><br><span class="line">     inst-&gt;<span class="built_in">exit</span>-&gt;<span class="built_in">set</span>[<span class="number">0</span>]=rmax;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">     <span class="comment">// only need to transfer one token：表示1-best</span></span><br><span class="line">     inst-&gt;<span class="built_in">exit</span>-&gt;n=<span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// initial each status nodes, same as exit node</span></span><br><span class="line"><span class="comment">// 1 2 3 4</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">1</span>,cur=inst-&gt;state;i&lt;=n;i++,cur++) &#123;</span><br><span class="line">     cur-&gt;tok=null_token;</span><br><span class="line">     <span class="keyword">if</span> (pri-&gt;nToks&gt;<span class="number">1</span>) &#123;</span><br><span class="line">         cur-&gt;<span class="built_in">set</span>=(RelToken*) New(&amp;pri-&gt;rTokHeap,<span class="number">0</span>);</span><br><span class="line">         cur-&gt;n=<span class="number">1</span>;</span><br><span class="line">         cur-&gt;<span class="built_in">set</span>[<span class="number">0</span>]=rmax;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="keyword">else</span> &#123;</span><br><span class="line">         cur-&gt;n=<span class="number">0</span>;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// #define LZERO  (-1.0E10)  ~log(0)</span></span><br><span class="line"><span class="comment">// to prune the likelihood</span></span><br><span class="line"><span class="comment">// keep the max likelihood of the status：状态的最大可能值</span></span><br><span class="line">inst-&gt;<span class="built_in">max</span>=LZERO;</span><br><span class="line"></span><br><span class="line"><span class="comment">// instance: double link</span></span><br><span class="line"><span class="comment">// pri-&gt;tail newest pri-&gt;head oldest</span></span><br><span class="line"><span class="comment">// append new instance to the pri：拓展网络【实际是链表】</span></span><br><span class="line"><span class="comment">// pri-&gt;link will be accessed out of this function</span></span><br><span class="line">inst-&gt;link=&amp;pri-&gt;tail;</span><br><span class="line">inst-&gt;knil=pri-&gt;tail.knil;</span><br><span class="line"></span><br><span class="line">inst-&gt;link-&gt;knil=inst;</span><br><span class="line">inst-&gt;knil-&gt;link=inst;</span><br><span class="line"></span><br><span class="line"><span class="comment">// attach instance to a node</span></span><br><span class="line">node-&gt;inst=inst;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Exit token reaches word node in t=0</span></span><br><span class="line"><span class="comment">// the last phone node</span></span><br><span class="line"><span class="keyword">if</span> (node_wd0(node))</span><br><span class="line">     <span class="comment">// inst-&gt;wdlk: Max likelihood of t=0 path to word end node</span></span><br><span class="line">     inst-&gt;wdlk=LikeToWord(inst-&gt;node);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">     inst-&gt;wdlk=LZERO;</span><br><span class="line"></span><br><span class="line"><span class="comment">// num of active nodes</span></span><br><span class="line">pri-&gt;nact++;</span><br><span class="line"></span><br><span class="line"><span class="comment">/*  New node needs any currently alive following insts moved */</span></span><br><span class="line"><span class="comment">/*  to be more recent than it to ensure tokens propagated in */</span></span><br><span class="line"><span class="comment">/*  correct order. */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// out of order</span></span><br><span class="line">inst-&gt;ooo=TRUE;   <span class="comment">/* Need keep list in propagation order */</span></span><br><span class="line"><span class="comment">// move node and it's subsequence into the pri-&gt;link</span></span><br><span class="line">ReOrderList(node);</span><br></pre></td></tr></table></figure></p>
<h3 id="ReOrderList"><a href="#ReOrderList" class="headerlink" title="ReOrderList"></a>ReOrderList</h3><p><code>ReOrderList</code>是一个DFS逻辑，将该节点的后续节点加入<code>pri-&gt;head</code>这个链表，注意，<code>node-&gt;nlinks</code>可能是1和n，如果是模型节点的话，只能为1，词节点则可能为n。这个函数作用应该是保证节点间token传递的顺序，代码逻辑如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">NetLink *dest;</span><br><span class="line"><span class="keyword">int</span> i;</span><br><span class="line"></span><br><span class="line"><span class="comment">// if ordered return</span></span><br><span class="line"><span class="keyword">if</span> (node-&gt;inst!=<span class="literal">NULL</span>?!node-&gt;inst-&gt;ooo:TRUE) <span class="keyword">return</span>;</span><br><span class="line"><span class="comment">// modify flag</span></span><br><span class="line">node-&gt;inst-&gt;ooo=FALSE;</span><br><span class="line"></span><br><span class="line"><span class="comment">// node-&gt;links: connected nodes</span></span><br><span class="line"><span class="comment">// node-&gt;nlinks: num of connected nodes 1 or n[word nodes]</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>,dest=node-&gt;links;i&lt;node-&gt;nlinks;i++,dest++) &#123;</span><br><span class="line">    <span class="comment">// Entry token reaches exit in t = 0</span></span><br><span class="line">    <span class="keyword">if</span> (!node_tr0(dest-&gt;node)) <span class="keyword">break</span>;</span><br><span class="line">    <span class="comment">// if not NULL, many be added to the list again</span></span><br><span class="line">    <span class="keyword">if</span> (dest-&gt;node-&gt;inst!=<span class="literal">NULL</span>) </span><br><span class="line">        <span class="comment">// append to pti-&gt;tail</span></span><br><span class="line">        MoveToRecent(dest-&gt;node-&gt;inst);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// DFS</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>,dest=node-&gt;links;i&lt;node-&gt;nlinks;i++,dest++) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!node_tr0(dest-&gt;node)) <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">if</span> (dest-&gt;node-&gt;inst!=<span class="literal">NULL</span>)</span><br><span class="line">        ReOrderList(dest-&gt;node);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><code>ReOrderList</code>将存在的节点后继加入解码网络，之后继续对每一个存在节点进行DFS逻辑的搜索。</p>
<h3 id="net-gt-initial的初始化"><a href="#net-gt-initial的初始化" class="headerlink" title="net-&gt;initial的初始化"></a>net-&gt;initial的初始化</h3><p><code>net-&gt;initial</code>这个node是在<code>ExpandWordNet</code>函数中<code>AddInitialFinal</code>实现的，用于初始化表征解码网络的入口和出口<code>initial</code>和<code>final</code>，初始化<code>initial</code>节点如下【实际上该节点的后继是网络根节点的发音实例】：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"> PronHolder *pInst;</span><br><span class="line"> NetNode *node;</span><br><span class="line"> LNode *thisLNode;</span><br><span class="line"> <span class="keyword">int</span> ninitial = <span class="number">0</span>;</span><br><span class="line"> <span class="keyword">int</span> i,type;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// for num of nodes</span></span><br><span class="line"> <span class="comment">// a node is a word</span></span><br><span class="line"> <span class="keyword">for</span> (i=<span class="number">0</span>; i &lt; wnet-&gt;nn; i++)</span><br><span class="line">     <span class="comment">// find root node</span></span><br><span class="line">     <span class="keyword">if</span> (wnet-&gt;lnodes[i].pred == <span class="literal">NULL</span>) </span><br><span class="line">         <span class="comment">// each word may has multiple prons</span></span><br><span class="line">         <span class="keyword">for</span> (pInst=(PronHolder*)wnet-&gt;lnodes[i].sublat; pInst!=<span class="literal">NULL</span>;pInst=pInst-&gt;next)</span><br><span class="line">             ninitial++;</span><br><span class="line">     <span class="comment">// ninitial: get how many prons</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">// network init nodes</span></span><br><span class="line"> net-&gt;initial.type = n_word;</span><br><span class="line"> net-&gt;initial.tag = <span class="literal">NULL</span>;</span><br><span class="line"> net-&gt;initial.info.pron = <span class="literal">NULL</span>;</span><br><span class="line"> net-&gt;initial.nlinks = <span class="number">0</span>;</span><br><span class="line"> net-&gt;initial.links = </span><br><span class="line"> (NetLink *)New(net-&gt;heap,ninitial*<span class="keyword">sizeof</span>(NetLink));</span><br><span class="line"></span><br><span class="line"> <span class="keyword">for</span> (i=<span class="number">0</span>,thisLNode=wnet-&gt;lnodes; i&lt;wnet-&gt;nn; i++,thisLNode++) &#123;</span><br><span class="line">     <span class="comment">// find root: initial nodes</span></span><br><span class="line">     <span class="keyword">if</span> (thisLNode-&gt;pred != <span class="literal">NULL</span>) <span class="keyword">continue</span>;</span><br><span class="line">     <span class="comment">// node's pron</span></span><br><span class="line">     <span class="keyword">for</span> (pInst=(PronHolder*)thisLNode-&gt;sublat;pInst!=<span class="literal">NULL</span>;pInst=pInst-&gt;next) &#123;</span><br><span class="line">         <span class="comment">// Chain of initial models</span></span><br><span class="line">         <span class="comment">// 指向每一个发音的starts节点</span></span><br><span class="line">         <span class="keyword">if</span> (xc==<span class="number">0</span>) node=pInst-&gt;starts;</span><br><span class="line">         <span class="keyword">else</span> <span class="keyword">if</span> (pInst-&gt;nphones!=<span class="number">0</span>) node=pInst-&gt;lc[<span class="number">0</span>];</span><br><span class="line">         <span class="keyword">else</span> node=FindWordNode(<span class="literal">NULL</span>,pInst-&gt;pron,pInst,n_word);</span><br><span class="line">         <span class="comment">// modify nlinks and point links to the node</span></span><br><span class="line">         net-&gt;initial.links[net-&gt;initial.nlinks].node = node;</span><br><span class="line">         net-&gt;initial.links[net-&gt;initial.nlinks++].like = <span class="number">0.0</span>;</span><br><span class="line">     &#125;</span><br><span class="line"> &#125;</span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure><br>实际上Lattice和Network之间是有一定的关系的，Lattice是最上层词网络拓扑，<code>Lnode</code>表征词节点，<code>LArc</code>表征词词之间的链接，每一个<code>LNode</code>可能会有多个发音，每一个发音建立一个<code>PronHolder</code>，这也是个链表结构，可以通过<code>next</code>寻访到下一个发音，其中有关模型节点的是下面三个结构体：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">NetNode *starts; <span class="comment">/* Chain of initial models */</span></span><br><span class="line">NetNode *ends;   <span class="comment">/* Chain of final models */</span></span><br><span class="line"><span class="comment">// point to status node, each node present a single phone model</span></span><br><span class="line">NetNode *chain;  <span class="comment">/* Chain of other nodes in word */</span></span><br></pre></td></tr></table></figure><br>这三个结构和加入<code>pri-&gt;head</code>的实际上是同样的节点。都是模型节点。</p>
<p>执行完<code>AttachInst</code>之后，继续对该节点实例进行初始化，同时加入<code>pri-&gt;head</code>链表。接下来就可以进行token的传递算法了，那里面主要就是对该链表中的<code>Netnode</code>进行反复的节点内外的算分，传递和节点的剪枝，添加。<code>AttachInst</code>剩下的代码如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// init initial node's instance</span></span><br><span class="line">inst=pri-&gt;net-&gt;initial.inst;</span><br><span class="line">inst-&gt;state-&gt;tok.like=inst-&gt;<span class="built_in">max</span>=<span class="number">0.0</span>;</span><br><span class="line">inst-&gt;state-&gt;tok.lm=<span class="number">0.0</span>;</span><br><span class="line">inst-&gt;state-&gt;tok.path=<span class="literal">NULL</span>;</span><br><span class="line">inst-&gt;state-&gt;n=((pri-&gt;nToks&gt;<span class="number">1</span>)?<span class="number">1</span>:<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">vri-&gt;genMaxNode=vri-&gt;wordMaxNode=<span class="literal">NULL</span>;</span><br><span class="line">vri-&gt;genMaxTok=vri-&gt;wordMaxTok=null_token;</span><br><span class="line"></span><br><span class="line"><span class="comment">// #define LSMALL (-0.5E10)   log values &lt; LSMALL are set to LZERO</span></span><br><span class="line">pri-&gt;wordThresh=pri-&gt;genThresh=pri-&gt;nThresh=LSMALL;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Most likely node/word node in the network</span></span><br><span class="line">pri-&gt;genMaxNode=pri-&gt;wordMaxNode=<span class="literal">NULL</span>;</span><br><span class="line">pri-&gt;genMaxTok=pri-&gt;wordMaxTok=null_token;</span><br><span class="line"></span><br><span class="line"><span class="comment">// init pri-&gt;head in AttachInst(&amp;pri-&gt;net-&gt;initial)</span></span><br><span class="line"><span class="keyword">for</span> (inst=pri-&gt;head.link;inst!=<span class="literal">NULL</span> &amp;&amp; inst-&gt;node!=<span class="literal">NULL</span>;inst=next)</span><br><span class="line">    <span class="comment">// inst-&gt;max: likelihood for pruning of instance</span></span><br><span class="line">    <span class="comment">// cutoff</span></span><br><span class="line">    <span class="keyword">if</span> (inst-&gt;<span class="built_in">max</span>&lt;pri-&gt;genThresh) &#123;</span><br><span class="line">        next=inst-&gt;link;</span><br><span class="line">        DetachInst(inst-&gt;node);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        pri-&gt;nxtInst=inst;</span><br><span class="line">        <span class="comment">// call SetEntryState and new instance, append to the pri-&gt;head</span></span><br><span class="line">        StepInst2(inst-&gt;node);</span><br><span class="line">        next=pri-&gt;nxtInst-&gt;link;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="2-ProcessObservation"><a href="#2-ProcessObservation" class="headerlink" title="2. ProcessObservation"></a>2. ProcessObservation</h2><p>该函数传入<code>Observation</code>，一帧一帧的处理观测序列<br>首先进行必要的赋初值之后，根据链表中的活跃节点数目进行一个全局剪枝，因为是一帧一帧的处理，所以token只会向后传递一层。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ProcessObservation</span><span class="params">(VRecInfo *vri,Observation *obs,<span class="keyword">int</span> id, AdaptXForm *xform)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    NetInst *inst,*next;</span><br><span class="line">    <span class="keyword">int</span> j;</span><br><span class="line">    <span class="keyword">float</span> thresh;</span><br><span class="line">    <span class="comment">// get private info</span></span><br><span class="line">    pri=vri-&gt;pri;</span><br><span class="line">    inXForm = xform; </span><br><span class="line">    <span class="comment">/* sepcifies the transform to use for this observation */</span></span><br><span class="line">    pri-&gt;psi-&gt;sBuf[<span class="number">1</span>].n=((pri-&gt;nToks&gt;<span class="number">1</span>)?<span class="number">1</span>:<span class="number">0</span>); </span><br><span class="line">    <span class="comment">/* Needed every observation */</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// Current frame number</span></span><br><span class="line">    pri-&gt;frame++;</span><br><span class="line">    <span class="comment">// Current Observation </span></span><br><span class="line">    pri-&gt;obs=obs;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (id&lt;<span class="number">0</span>) pri-&gt;id=(pri-&gt;prid&lt;&lt;<span class="number">20</span>)+pri-&gt;frame;</span><br><span class="line">    <span class="keyword">else</span> pri-&gt;id=id;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Max model pruning is done initially in a separate pass */</span></span><br><span class="line">    <span class="comment">// vri-&gt;maxBeam: Maximum model instance beam </span></span><br><span class="line">    <span class="comment">// pri-&gt;nact: num of active nodes in dual links</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (vri-&gt;maxBeam&gt;<span class="number">0</span> &amp;&amp; pri-&gt;nact&gt;vri-&gt;maxBeam) &#123;</span><br><span class="line">        <span class="comment">// qsn: quick sort num</span></span><br><span class="line">        <span class="keyword">if</span> (pri-&gt;nact&gt;pri-&gt;qsn) &#123;</span><br><span class="line">            <span class="keyword">if</span> (pri-&gt;qsn&gt;<span class="number">0</span>)</span><br><span class="line">                Dispose(&amp;vri-&gt;heap,pri-&gt;qsa);</span><br><span class="line">            pri-&gt;qsn=(pri-&gt;nact*<span class="number">3</span>)/<span class="number">2</span>;</span><br><span class="line">            pri-&gt;qsa=(LogFloat*) New(&amp;vri-&gt;heap,pri-&gt;qsn*<span class="keyword">sizeof</span>(LogFloat));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// qsa: quick sort array</span></span><br><span class="line">        <span class="comment">// inst-&gt;max: Likelihood for pruning of instance</span></span><br><span class="line">        <span class="keyword">for</span> (inst=pri-&gt;head.link,j=<span class="number">0</span>;inst!=<span class="literal">NULL</span>;inst=inst-&gt;link,j++)</span><br><span class="line">            pri-&gt;qsa[j]=inst-&gt;<span class="built_in">max</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// num of nodes in dual links more than maxBeam: cutoff</span></span><br><span class="line">        <span class="keyword">if</span> (j&gt;=vri-&gt;maxBeam) &#123;</span><br><span class="line">            qcksrtM(pri-&gt;qsa,<span class="number">0</span>,j<span class="number">-1</span>,vri-&gt;maxBeam);</span><br><span class="line">            thresh=pri-&gt;qsa[vri-&gt;maxBeam];</span><br><span class="line"></span><br><span class="line">            <span class="comment">// start cutoff for the first time</span></span><br><span class="line">            <span class="keyword">if</span> (thresh&gt;LSMALL) </span><br><span class="line">                <span class="keyword">for</span> (inst=pri-&gt;head.link;inst-&gt;link!=<span class="literal">NULL</span>;inst=next) &#123;</span><br><span class="line">                    next=inst-&gt;link;</span><br><span class="line">                    <span class="keyword">if</span> (inst-&gt;<span class="built_in">max</span>&lt;thresh) </span><br><span class="line">                    DetachInst(inst-&gt;node);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">// ...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="节点内传递"><a href="#节点内传递" class="headerlink" title="节点内传递"></a>节点内传递</h3><p>之后就进行第一个token传递计算，在节点内部，执行完毕，更新maxToken和maxNode<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pri-&gt;genMaxTok: Most likely token</span></span><br><span class="line"><span class="comment">// pri-&gt;wordMaxTok: Most likely word end token</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// update in StepInst1 in StepHMM1</span></span><br><span class="line">pri-&gt;genMaxTok=pri-&gt;wordMaxTok=null_token;</span><br><span class="line">pri-&gt;genMaxNode=pri-&gt;wordMaxNode=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// nodes represent phones</span></span><br><span class="line"><span class="keyword">for</span> (inst=pri-&gt;head.link,j=<span class="number">0</span>;inst!=<span class="literal">NULL</span>;inst=inst-&gt;link,j++)</span><br><span class="line">    <span class="keyword">if</span> (inst-&gt;node)</span><br><span class="line">        <span class="comment">// stepHMM1 stepInst1</span></span><br><span class="line">        <span class="comment">// calcu aij + bj(Ot) for each status in the node</span></span><br><span class="line">        StepInst1(inst-&gt;node);</span><br><span class="line"><span class="comment">//...</span></span><br></pre></td></tr></table></figure></p>
<h3 id="StepInst1"><a href="#StepInst1" class="headerlink" title="StepInst1"></a>StepInst1</h3><p><code>StepInst1</code>做了一个分类，主要针对HMM模型节点：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">StepInst1</span><span class="params">(NetNode *node)</span> </span></span><br><span class="line"><span class="function"><span class="comment">/* First pass of token propagation (Internal) */</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// model node</span></span><br><span class="line">    <span class="keyword">if</span> (node_hmm(node))</span><br><span class="line">    <span class="comment">// inside a single node</span></span><br><span class="line">    <span class="comment">// calcu max possibility on each status j[1 &lt; j &lt; N] inside a node</span></span><br><span class="line">        StepHMM1(node);   </span><br><span class="line">        <span class="comment">/* Advance tokens within HMM instance t =&gt; t-1 */</span></span><br><span class="line">        <span class="comment">/* Entry tokens valid for t-1, do states 2..N */</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        StepWord1(node);</span><br><span class="line">    node-&gt;inst-&gt;pxd=FALSE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><code>StepHMM1</code>计算在该节点内部token的传递，在状态节点之间的实现如下，对应的模型应该如图：<br><img src="http://www.funcwj.cn/images/stephmm1.png", width="300"></p>
<h3 id="StepHMM1"><a href="#StepHMM1" class="headerlink" title="StepHMM1"></a>StepHMM1</h3><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">StepHMM1</span><span class="params">(NetNode *node)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    inst=node-&gt;inst;</span><br><span class="line">    <span class="built_in">max</span>=null_token;</span><br><span class="line">   </span><br><span class="line">    hmm=node-&gt;info.hmm; </span><br><span class="line">    N=hmm-&gt;numStates;</span><br><span class="line">    <span class="comment">// transition matrix (logs)</span></span><br><span class="line">    trP=hmm-&gt;transP;</span><br><span class="line">    seIndex=pri-&gt;psi-&gt;seIndexes[hmm-&gt;tIdx];</span><br><span class="line">   </span><br><span class="line">    <span class="comment">// pri-&gt;psi-&gt;sBuf: Buffer Array[2..N-1] of tokset for StepHMM1_N</span></span><br><span class="line">    <span class="comment">// pri-&gt;psi-&gt;sBuf: public and each node use it, tmp var and copy back to current nodes</span></span><br><span class="line">    <span class="comment">// res: tmp buffer, previous calculate results</span></span><br><span class="line">    <span class="comment">// 2, 3, 4</span></span><br><span class="line">    <span class="comment">// Emitting states first</span></span><br><span class="line">    <span class="keyword">for</span> (j=<span class="number">2</span>,res=pri-&gt;psi-&gt;sBuf+<span class="number">2</span>;j&lt;N;j++,res++) &#123;</span><br><span class="line">        <span class="comment">// res: tokenset of status j</span></span><br><span class="line">        i=seIndex[j][<span class="number">0</span>]; </span><br><span class="line">        endi=seIndex[j][<span class="number">3</span>];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// tokenset of status i</span></span><br><span class="line">        <span class="comment">// from i to endi</span></span><br><span class="line">        <span class="comment">// 这里为什么要减一有点奇怪</span></span><br><span class="line">        cur=inst-&gt;state+i<span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// res &lt;= cur</span></span><br><span class="line">        res-&gt;tok=cur-&gt;tok; res-&gt;n=cur-&gt;n;</span><br><span class="line">        <span class="keyword">for</span> (k=<span class="number">0</span>;k&lt;cur-&gt;n;k++) </span><br><span class="line">            res-&gt;<span class="built_in">set</span>[k]=cur-&gt;<span class="built_in">set</span>[k];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// from status i skip to status j</span></span><br><span class="line">        <span class="comment">// init res to get maximum</span></span><br><span class="line">        <span class="comment">// tok.like: likelihood of the token</span></span><br><span class="line">        res-&gt;tok.like+=trP[i][j];</span><br><span class="line"></span><br><span class="line">        <span class="comment">// following except res</span></span><br><span class="line">        <span class="comment">// status + i =&gt; status + endi;</span></span><br><span class="line">        <span class="keyword">for</span> (i++,cur++;i&lt;=endi;i++,cur++) &#123;</span><br><span class="line">            cmp.tok=cur-&gt;tok;</span><br><span class="line">            <span class="comment">// aij</span></span><br><span class="line">            cmp.tok.like+=trP[i][j];</span><br><span class="line">            <span class="comment">// res keep max: status j</span></span><br><span class="line">            <span class="comment">// keep best one</span></span><br><span class="line">            <span class="keyword">if</span> (res-&gt;n==<span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (cmp.tok.like &gt; res-&gt;tok.like)</span><br><span class="line">                res-&gt;tok=cmp.tok;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// don't consider</span></span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                TokSetMerge(res,&amp;cmp.tok,cur);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// pri-&gt;genThresh: Cutoff from global beam</span></span><br><span class="line">        <span class="keyword">if</span> (res-&gt;tok.like&gt;pri-&gt;genThresh) &#123; </span><br><span class="line">            <span class="comment">// State pruning</span></span><br><span class="line">            <span class="comment">// calcu bj(Ot)</span></span><br><span class="line">            outp=cPOutP(pri-&gt;psi,pri-&gt;obs,hmm-&gt;svec[j].info,pri-&gt;id);</span><br><span class="line">            res-&gt;tok.like+=outp;</span><br><span class="line">         </span><br><span class="line">            <span class="comment">// update max status token</span></span><br><span class="line">            <span class="comment">// max: max aij + bj(Ot)</span></span><br><span class="line">            <span class="keyword">if</span> (res-&gt;tok.like&gt;<span class="built_in">max</span>.like)</span><br><span class="line">                <span class="built_in">max</span>=res-&gt;tok;</span><br><span class="line">        &#125; </span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            res-&gt;tok=null_token;</span><br><span class="line">            res-&gt;n=((pri-&gt;nToks&gt;<span class="number">1</span>)?<span class="number">1</span>:<span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/* Null entry state ready for external propagation */</span></span><br><span class="line">    <span class="comment">/* And copy tokens from buffer to instance */</span></span><br><span class="line">    <span class="comment">// copy back</span></span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">1</span>,res=pri-&gt;psi-&gt;sBuf+<span class="number">1</span>,cur=inst-&gt;state; i&lt;N; i++,res++,cur++) &#123;</span><br><span class="line">        cur-&gt;n=res-&gt;n; cur-&gt;tok=res-&gt;tok; </span><br><span class="line">        <span class="keyword">for</span> (k=<span class="number">0</span>;k&lt;res-&gt;n;k++) </span><br><span class="line">            cur-&gt;<span class="built_in">set</span>[k]=res-&gt;<span class="built_in">set</span>[k];</span><br><span class="line">   &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/* Set up pruning limits */</span></span><br><span class="line">    <span class="comment">// max: max token in a single node: aij + bj(Ot)</span></span><br><span class="line">    <span class="comment">// update genMaxTok and genMaxNode</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">max</span>.like&gt;pri-&gt;genMaxTok.like) &#123;</span><br><span class="line">        pri-&gt;genMaxTok=<span class="built_in">max</span>;</span><br><span class="line">        pri-&gt;genMaxNode=node;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// max status likelihood in a single phone node</span></span><br><span class="line">    inst-&gt;<span class="built_in">max</span>=<span class="built_in">max</span>.like;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用图例可以表示为：<br><img src="http://www.funcwj.cn/images/token-inside.png", width="300"></p>
<p>对于exit节点单独处理，处理逻辑和上面处理status节点类似，最后更新了exit节点的token值</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Exit state (ignoring tee trP) </span></span><br><span class="line"><span class="comment">// process exit status, don't need tmp var</span></span><br><span class="line"></span><br><span class="line">i=seIndex[N][<span class="number">0</span>]; </span><br><span class="line">endi=seIndex[N][<span class="number">5</span>];</span><br><span class="line">   </span><br><span class="line"><span class="comment">// res pointed to the exit node</span></span><br><span class="line">res=inst-&gt;<span class="built_in">exit</span>;</span><br><span class="line">cur=inst-&gt;state+i<span class="number">-1</span>;</span><br><span class="line"></span><br><span class="line">res-&gt;n=cur-&gt;n; </span><br><span class="line">res-&gt;tok=cur-&gt;tok; </span><br><span class="line"><span class="keyword">for</span> (k=<span class="number">0</span>;k&lt;cur-&gt;n;k++) res-&gt;<span class="built_in">set</span>[k]=cur-&gt;<span class="built_in">set</span>[k];</span><br><span class="line"></span><br><span class="line">res-&gt;tok.like+=trP[i][N];</span><br><span class="line"><span class="comment">// update exit nodes</span></span><br><span class="line"><span class="keyword">for</span> (i++,cur++;i&lt;=endi;i++,cur++) &#123;</span><br><span class="line">    cmp.tok=cur-&gt;tok; </span><br><span class="line">    cmp.tok.like+=trP[i][N];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get maximum token from i -&gt; endi</span></span><br><span class="line">    <span class="keyword">if</span> (res-&gt;n==<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (cmp.tok.like &gt; res-&gt;tok.like) </span><br><span class="line">            res-&gt;tok=cmp.tok;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        TokSetMerge(res,&amp;cmp.tok,cur);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (res-&gt;tok.like&gt;LSMALL) &#123;</span><br><span class="line">    <span class="comment">// inst-&gt;wdlk: Max likelihood of t=0 path to word end node</span></span><br><span class="line">    tok.like=res-&gt;tok.like+inst-&gt;wdlk;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// update pri-&gt;wordMaxTok.like</span></span><br><span class="line">    <span class="keyword">if</span> (tok.like &gt; pri-&gt;wordMaxTok.like) &#123;</span><br><span class="line">        pri-&gt;wordMaxTok=tok;</span><br><span class="line">        pri-&gt;wordMaxNode=node;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    inst-&gt;<span class="built_in">exit</span>-&gt;tok=null_token;</span><br><span class="line">    inst-&gt;<span class="built_in">exit</span>-&gt;n=((pri-&gt;nToks&gt;<span class="number">1</span>)?<span class="number">1</span>:<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上是<code>StepHMM1</code>函数，它实现的是计算一个节点内部2，3，4，exit音素节点在当前观测序列下最大的可能值。在此期间更新的值有如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">inst-&gt;<span class="built_in">max</span>: 当前节点上实例中每个状态节点的最大like值</span><br><span class="line">pri-&gt;wordMaxNode: 最可能的此节点值</span><br></pre></td></tr></table></figure><br><code>path</code>和<code>align</code>分别对应词级别间的回溯路径和状态级别的回溯路径，只有前者是必要的。上述代码中<code>align</code>这部分已经删除。而<code>path</code>信息则在节点间传递时维护。</p>
<h3 id="节点间传递"><a href="#节点间传递" class="headerlink" title="节点间传递"></a>节点间传递</h3><p><code>ProcessObservation</code>函数下面的部分进行节点之间的token传递，实现如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// #define LSMALL (-0.5E10) log values &lt; LSMALL are set to LZERO</span></span><br><span class="line"><span class="comment">// update in StepHMM1</span></span><br><span class="line"><span class="comment">// vri-&gt;wordBeam: Separte word end beam width</span></span><br><span class="line"><span class="comment">// pri-&gt;wordThresh: Cutoff for word end propagation</span></span><br><span class="line"><span class="comment">// after StepHMM1, use results to update some global beam</span></span><br><span class="line"></span><br><span class="line">pri-&gt;wordThresh=pri-&gt;wordMaxTok.like-vri-&gt;wordBeam;</span><br><span class="line"><span class="keyword">if</span> (pri-&gt;wordThresh&lt;LSMALL) pri-&gt;wordThresh=LSMALL;</span><br><span class="line"></span><br><span class="line"><span class="comment">// pri-&gt;genMaxTok.like update in StepHMM1</span></span><br><span class="line"><span class="comment">// vri-&gt;genBeam: Global beam width</span></span><br><span class="line"><span class="comment">// pri-&gt;genThresh: Cutoff from global beam</span></span><br><span class="line">pri-&gt;genThresh=pri-&gt;genMaxTok.like-vri-&gt;genBeam;</span><br><span class="line"><span class="keyword">if</span> (pri-&gt;genThresh&lt;LSMALL) pri-&gt;genThresh=LSMALL;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (pri-&gt;nToks&gt;<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="comment">// vri-&gt;nBeam: Beam width for non-best tokens</span></span><br><span class="line">    pri-&gt;nThresh=pri-&gt;genMaxTok.like-vri-&gt;nBeam;</span><br><span class="line">    <span class="keyword">if</span> (pri-&gt;nThresh&lt;LSMALL/<span class="number">2</span>) pri-&gt;nThresh=LSMALL/<span class="number">2</span>;</span><br><span class="line">&#125;</span><br><span class="line">   </span><br><span class="line"><span class="comment">/* Pass 2 Performs external token propagation and pruning */</span></span><br><span class="line"><span class="keyword">for</span> (inst=pri-&gt;head.link,j=<span class="number">0</span>;inst!=<span class="literal">NULL</span> &amp;&amp; inst-&gt;node!=<span class="literal">NULL</span>;inst=next,j++)</span><br><span class="line">    <span class="keyword">if</span> (inst-&gt;<span class="built_in">max</span>&lt;pri-&gt;genThresh) &#123;</span><br><span class="line">        next=inst-&gt;link;</span><br><span class="line">        <span class="comment">// remove from inst list</span></span><br><span class="line">        DetachInst(inst-&gt;node);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> &#123;</span><br><span class="line">        pri-&gt;nxtInst=inst;</span><br><span class="line">        <span class="comment">// call SetEntryState</span></span><br><span class="line">        <span class="comment">// add new instance to pri-&gt;tail and reorder it</span></span><br><span class="line">        StepInst2(inst-&gt;node);</span><br><span class="line">        next=pri-&gt;nxtInst-&gt;link;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line"><span class="comment">// npth: Current number of path records</span></span><br><span class="line"><span class="comment">// cpth: Number of path records after last collection</span></span><br><span class="line"><span class="comment">// nalign: Current number of align records</span></span><br><span class="line"><span class="comment">// caligh: Number of align records after last collection</span></span><br><span class="line"><span class="comment">// wait for the time to collect path</span></span><br><span class="line"><span class="keyword">if</span> ((pri-&gt;npth-pri-&gt;cpth) &gt; vri-&gt;pCollThresh || </span><br><span class="line">    (pri-&gt;nalign-pri-&gt;calign) &gt; vri-&gt;aCollThresh)</span><br><span class="line">    CollectPaths();</span><br><span class="line">    </span><br><span class="line"><span class="comment">// pri-&gt;tact: total active nodes</span></span><br><span class="line">pri-&gt;tact+=pri-&gt;nact;</span><br><span class="line"></span><br><span class="line"><span class="comment">// update</span></span><br><span class="line">vri-&gt;frame=pri-&gt;frame;</span><br><span class="line">vri-&gt;nact=pri-&gt;nact;</span><br><span class="line">vri-&gt;genMaxNode=pri-&gt;genMaxNode;</span><br><span class="line">vri-&gt;wordMaxNode=pri-&gt;wordMaxNode;</span><br><span class="line">vri-&gt;genMaxTok=pri-&gt;genMaxTok;</span><br><span class="line">vri-&gt;wordMaxTok=pri-&gt;wordMaxTok;</span><br></pre></td></tr></table></figure></p>
<h3 id="StepInst2"><a href="#StepInst2" class="headerlink" title="StepInst2"></a>StepInst2</h3><p><code>StepInst2</code>是对<code>pri-&gt;head</code>链表进行扩展的部分，类似BFS的逻辑在这里实现,还实现了节点之间的token传递<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Second pass of token propagation (External) */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">StepInst2</span><span class="params">(NetNode *node)</span> </span></span><br><span class="line"><span class="function"><span class="comment">/* Must be able to survive doing this twice !! */</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Token tok;</span><br><span class="line">    TokenSet xtok;</span><br><span class="line">    RelToken rtoks[MAX_TOKS];</span><br><span class="line">    NetLink *dest;</span><br><span class="line">    LogFloat lm;</span><br><span class="line">    <span class="keyword">int</span> i,k;</span><br><span class="line">    <span class="comment">// == 4</span></span><br><span class="line">    <span class="comment">// word end node</span></span><br><span class="line">    <span class="keyword">if</span> (node_word(node))</span><br><span class="line">        <span class="comment">// P(O) = argmax P(O|W) + LMSF * logP(W) + N * logWIP</span></span><br><span class="line">        <span class="comment">// add path</span></span><br><span class="line">        <span class="comment">// inst-&gt;exit-&gt;tok.like</span></span><br><span class="line">        <span class="comment">// calcu LMSF * logP(W) + N * logWIP and create path</span></span><br><span class="line">        <span class="comment">// 为当前节点的exit节点建立索引path，该path的prev指向该节点start的索引path，而这个start节点的索引path实际上在SetEntryState被初始化为上一个节点的exit状态的索引path</span></span><br><span class="line">        StepWord2(node);</span><br><span class="line">        <span class="comment">/* Merge tokens and update traceback */</span></span><br><span class="line">    <span class="comment">// &amp; 4</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (node_tr0(node) <span class="comment">/* &amp;&amp; node_hmm(node) */</span></span><br><span class="line">        <span class="comment">// calcu exit status node: 这是个十分特殊的节点</span></span><br><span class="line">        StepHMM2(node);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// xtok: node-&gt;inst-&gt;exit</span></span><br><span class="line">    <span class="comment">// xtok init by node-&gt;inst-&gt;exit</span></span><br><span class="line">    <span class="comment">// hmm nodes</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// get exit node's token</span></span><br><span class="line">    <span class="comment">// 当前音素节点中exit节点的token信息被记录下来了，不管节点类型</span></span><br><span class="line">    <span class="comment">// token里面有path和分数信息</span></span><br><span class="line">    tok=node-&gt;inst-&gt;<span class="built_in">exit</span>-&gt;tok;</span><br><span class="line">    xtok.tok=tok;</span><br><span class="line">    xtok.n=node-&gt;inst-&gt;<span class="built_in">exit</span>-&gt;n;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// new RelToken sets</span></span><br><span class="line">    xtok.<span class="built_in">set</span>=rtoks;</span><br><span class="line">    <span class="keyword">for</span> (k=<span class="number">0</span>;k&lt;xtok.n;k++)</span><br><span class="line">        xtok.<span class="built_in">set</span>[k]=node-&gt;inst-&gt;<span class="built_in">exit</span>-&gt;<span class="built_in">set</span>[k];</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (node_word(node))</span><br><span class="line">        <span class="keyword">if</span> (tok.like&lt;pri-&gt;wordThresh)</span><br><span class="line">            tok=null_token;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ok</span></span><br><span class="line">    <span class="comment">// tok: exit node</span></span><br><span class="line">    <span class="keyword">if</span> (tok.like&gt;pri-&gt;genThresh) &#123;</span><br><span class="line">        <span class="comment">// connected nodes</span></span><br><span class="line">        <span class="comment">// words node has many：词节点有多个后继</span></span><br><span class="line">        <span class="comment">// hmm has only one：模型节点只有一个，符合常识，如果是模型节点，则相当于把token传递给了之后的那个节点，下一次可以被寻访到</span></span><br><span class="line">        <span class="comment">// pass token to next nodes[model nodes]</span></span><br><span class="line">        <span class="keyword">for</span>(i=<span class="number">0</span>,dest=node-&gt;links;i&lt;node-&gt;nlinks;i++,dest++) &#123;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// transition likelihood</span></span><br><span class="line">            lm=dest-&gt;like;</span><br><span class="line">            <span class="comment">// pri-&gt;scale: LM (Net probs) scale factor</span></span><br><span class="line">            xtok.tok.like=tok.like+lm*pri-&gt;scale;</span><br><span class="line">            <span class="comment">// tok.lm: LM likelihood of token</span></span><br><span class="line">            xtok.tok.lm=tok.lm+lm;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> (k=<span class="number">0</span>;k&lt;xtok.n;k++)</span><br><span class="line">                xtok.<span class="built_in">set</span>[k].lm=node-&gt;inst-&gt;<span class="built_in">exit</span>-&gt;<span class="built_in">set</span>[k].lm+lm;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// pri-&gt;genThresh: Cutoff from global beam</span></span><br><span class="line">            <span class="keyword">if</span> (xtok.tok.like&gt;pri-&gt;genThresh) &#123;</span><br><span class="line">                <span class="comment">// call AttachInst(node)</span></span><br><span class="line">                <span class="comment">// expand network</span></span><br><span class="line">                <span class="comment">// pass exit token to dest-&gt;nodes =&gt; xtok</span></span><br><span class="line">                SetEntryState(dest-&gt;nodes, &amp;xtok);</span><br><span class="line">                <span class="comment">/* Transfer set of tokens to node, activating when necessary */</span></span><br><span class="line">                <span class="comment">/* choosing N most likely after adding transition likelihood */</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    node-&gt;inst-&gt;pxd=TRUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="StepWord2"><a href="#StepWord2" class="headerlink" title="StepWord2"></a>StepWord2</h3><p><code>StepWord2</code>处理词节点，用新建的<code>path</code>更新<code>inst-&gt;exit-&gt;tok.path</code>，它的<code>prev</code>记录为<code>inst-&gt;state-&gt;tok.path</code>，这个值被前一个节点的<code>inst-&gt;exit-&gt;tok.path</code>初始化，在<code>StepWord2</code>中<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">NetInst *inst;</span><br><span class="line">Path *newpth,*oldpth;</span><br><span class="line">RelToken *cur;</span><br><span class="line">NxtPath *rth;</span><br><span class="line"><span class="keyword">int</span> i,k;</span><br><span class="line"></span><br><span class="line">inst=node-&gt;inst;</span><br><span class="line"></span><br><span class="line"><span class="comment">// info.pron == NULL ?</span></span><br><span class="line"><span class="keyword">if</span> (node-&gt;info.pron==<span class="literal">NULL</span> &amp;&amp; node-&gt;tag==<span class="literal">NULL</span>) &#123;</span><br><span class="line">    inst-&gt;<span class="built_in">exit</span>-&gt;tok=inst-&gt;state-&gt;tok;</span><br><span class="line">    inst-&gt;<span class="built_in">exit</span>-&gt;n=inst-&gt;state-&gt;n;</span><br><span class="line">    <span class="keyword">for</span> (k=<span class="number">0</span>;k&lt;inst-&gt;<span class="built_in">exit</span>-&gt;n;k++)</span><br><span class="line">        inst-&gt;<span class="built_in">exit</span>-&gt;<span class="built_in">set</span>[k]=inst-&gt;state-&gt;<span class="built_in">set</span>[k];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    inst-&gt;<span class="built_in">exit</span>-&gt;tok=inst-&gt;state-&gt;tok;</span><br><span class="line">    <span class="keyword">if</span> (node-&gt;info.pron!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="comment">// pri-&gt;wordpen: word penity</span></span><br><span class="line">        inst-&gt;<span class="built_in">exit</span>-&gt;tok.like+=pri-&gt;wordpen;</span><br><span class="line">        <span class="comment">// node-&gt;info.pron-&gt;prob: Log probability of pronunciation</span></span><br><span class="line">        <span class="comment">// pri-&gt;pscale: LM (Net probs) scale factor</span></span><br><span class="line">        inst-&gt;<span class="built_in">exit</span>-&gt;tok.like+=node-&gt;info.pron-&gt;prob * pri-&gt;pscale;</span><br><span class="line">        <span class="comment">// P(O) = argmax P(O|W) + LMSF * logP(W) + N * logWIP</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// append new path to pNoRef</span></span><br><span class="line">    <span class="comment">// path-&gt;chain = NULL</span></span><br><span class="line">    <span class="comment">// path-&gt;used = FALSE</span></span><br><span class="line">    <span class="comment">// new path only in word node and pass the path info in StepInst2 when extend pri-&gt;head</span></span><br><span class="line">    newpth=NewNRefPath();</span><br><span class="line">    <span class="comment">// point to the node</span></span><br><span class="line">    newpth-&gt;node=node;</span><br><span class="line">    <span class="comment">// ref times == 0</span></span><br><span class="line">    newpth-&gt;usage=<span class="number">0</span>;</span><br><span class="line">    newpth-&gt;frame=pri-&gt;frame;</span><br><span class="line">    newpth-&gt;like=inst-&gt;<span class="built_in">exit</span>-&gt;tok.like;</span><br><span class="line">    newpth-&gt;lm=inst-&gt;<span class="built_in">exit</span>-&gt;tok.lm;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// not run here</span></span><br><span class="line">    <span class="keyword">if</span> ((newpth-&gt;align=inst-&gt;<span class="built_in">exit</span>-&gt;tok.align)!=<span class="literal">NULL</span>)</span><br><span class="line">        <span class="comment">// MoveAlignYesRef(align)</span></span><br><span class="line">        RefAlign(newpth-&gt;align);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// assign to exit node and newpath could pass to next nodes by exit-&gt;token</span></span><br><span class="line">    inst-&gt;<span class="built_in">exit</span>-&gt;tok.path=newpth;</span><br><span class="line">    inst-&gt;<span class="built_in">exit</span>-&gt;tok.lm=<span class="number">0.0</span>;</span><br><span class="line">    inst-&gt;<span class="built_in">exit</span>-&gt;tok.align=<span class="literal">NULL</span>;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// assign position: in SetEntryState</span></span><br><span class="line">    <span class="comment">// inst-&gt;state: start status</span></span><br><span class="line">    oldpth=inst-&gt;state-&gt;tok.path;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// oldpth != NULL</span></span><br><span class="line">    <span class="keyword">if</span> ((newpth-&gt;prev=oldpth)!=<span class="literal">NULL</span>)</span><br><span class="line">        <span class="comment">// if usage == 0 MovePathYesRef(path) =&gt; append pYesRef</span></span><br><span class="line">        <span class="comment">// and then usage++</span></span><br><span class="line">        RefPath(oldpth);</span><br></pre></td></tr></table></figure><br>搞清楚<code>path</code>相关的一些问题，些直接关系到解码最后一步的搜索。<br>首先，只有在进行token的外部传递，即处理词节点时才会新建<code>path</code>变量，记录回溯路径，函数<code>NewNRefPath</code>仅仅在<code>StepInst2 =&gt; StepWord2</code>用到。<code>StepWord2</code>函数执行完毕之后，紧接着在<code>StepInst2</code>后半部分执行<code>SetEntryState</code>，<code>path</code>信息伴随着<code>xtok</code>进入了下一个新的节点。</p>
<h3 id="SetEntryState"><a href="#SetEntryState" class="headerlink" title="SetEntryState"></a>SetEntryState</h3><p><code>SetEntryState</code>为当前节点附上一个实例，同时传入上一个词的token，如此token即可在网络中传递了，token中包含上一个节点的路径和分值。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// attach instance to the connected nodes</span></span><br><span class="line"><span class="comment">// SetEntryState(dest-&gt;node,&amp;xtok)</span></span><br><span class="line"><span class="comment">// node: connected next node</span></span><br><span class="line"><span class="comment">// src: contains token and path info： 记录前一个节点的token</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">SetEntryState</span><span class="params">(NetNode *node,TokenSet *src)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    NetInst *inst;</span><br><span class="line">    TokenSet *res;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (node-&gt;inst==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="comment">// append to pri-&gt;tail</span></span><br><span class="line">        <span class="comment">// call ReOrderList(node)</span></span><br><span class="line">        AttachInst(node);</span><br><span class="line"></span><br><span class="line">    inst=node-&gt;inst;</span><br><span class="line">    res=inst-&gt;state;</span><br><span class="line">   </span><br><span class="line">    <span class="comment">// update instance's token</span></span><br><span class="line">    <span class="keyword">if</span> (res-&gt;n==<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// path info assigned: inst-&gt;state-&gt;tok.path</span></span><br><span class="line">        <span class="keyword">if</span> (src-&gt;tok.like &gt; res-&gt;tok.like)</span><br><span class="line">            res-&gt;tok=src-&gt;tok;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        TokSetMerge(res,&amp;src-&gt;tok,src);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// inst-&gt;max: Likelihood for pruning of instance</span></span><br><span class="line">    <span class="keyword">if</span> (res-&gt;tok.like&gt;inst-&gt;<span class="built_in">max</span>)</span><br><span class="line">        inst-&gt;<span class="built_in">max</span>=res-&gt;tok.like;</span><br><span class="line">    <span class="keyword">if</span> (node-&gt;type==n_word &amp;&amp; (pri-&gt;wordMaxNode==<span class="literal">NULL</span> || </span><br><span class="line">                              pri-&gt;wordMaxNode-&gt;inst==<span class="literal">NULL</span> || </span><br><span class="line">                              res-&gt;tok.like &gt;     pri-&gt;wordMaxNode-&gt;inst-&gt;<span class="built_in">max</span>))</span><br><span class="line">        <span class="comment">// Most likely word end node in network</span></span><br><span class="line">        pri-&gt;wordMaxNode=node;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>现在<code>path</code>可以由下图表示逻辑<br><img src="http://www.funcwj.cn/images/path.png", width="300"></p>
<h3 id="CollectPaths"><a href="#CollectPaths" class="headerlink" title="CollectPaths"></a>CollectPaths</h3><p>最后一步，定时整理之前维护的<code>path</code>信息，实现在<code>CollectPaths</code>之中，有些执行的部分已经删除，这一部分还有些疑惑。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">CollectPaths</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    NetInst *inst;</span><br><span class="line">    TokenSet *cur;</span><br><span class="line">    <span class="keyword">int</span> i,k,n;</span><br><span class="line">    Path *path,*plink;</span><br><span class="line">    Align *align,*alink;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// for each status in each inst in the pri-&gt;head</span></span><br><span class="line">    <span class="comment">// modify path-&gt;used: in current inst link</span></span><br><span class="line">    <span class="keyword">for</span> (inst=pri-&gt;head.link;inst!=<span class="literal">NULL</span>;inst=inst-&gt;link)</span><br><span class="line">        <span class="keyword">if</span> (inst-&gt;node!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="comment">// only model nodes have multiple status</span></span><br><span class="line">            <span class="keyword">if</span> (node_hmm(inst-&gt;node)) </span><br><span class="line">                n=inst-&gt;node-&gt;info.hmm-&gt;numStates<span class="number">-1</span>;</span><br><span class="line">            <span class="keyword">else</span></span><br><span class="line">                n=<span class="number">1</span>;</span><br><span class="line">            <span class="comment">// n: status num</span></span><br><span class="line">            <span class="comment">// each status</span></span><br><span class="line">            <span class="keyword">for</span> (i=<span class="number">1</span>,cur=inst-&gt;state;i&lt;=n;i++,cur++) &#123;</span><br><span class="line">                path=cur-&gt;tok.path;</span><br><span class="line">                <span class="comment">// path-&gt;used: Reference to struct by current inst</span></span><br><span class="line">                <span class="comment">// not refered in order to avoid duplicate</span></span><br><span class="line">                <span class="keyword">if</span> (path &amp;&amp; !path-&gt;used) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (path-&gt;usage!=<span class="number">0</span>) MovePathYesRef(path);</span><br><span class="line">                        path-&gt;used=TRUE;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// exit node</span></span><br><span class="line">            path=inst-&gt;<span class="built_in">exit</span>-&gt;tok.path;</span><br><span class="line">            <span class="keyword">if</span> (path &amp;&amp; !path-&gt;used) &#123;</span><br><span class="line">                <span class="keyword">if</span> (path-&gt;usage!=<span class="number">0</span>) MovePathYesRef(path);</span><br><span class="line">                path-&gt;used=TRUE;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// if no refer, could be deleted</span></span><br><span class="line">    <span class="keyword">for</span> (path=pri-&gt;pNoRef.link;path-&gt;link!=<span class="literal">NULL</span>;path=plink) &#123;</span><br><span class="line">        <span class="comment">// not in pri-&gt;head</span></span><br><span class="line">        <span class="keyword">if</span> (!path-&gt;used) &#123;</span><br><span class="line">            <span class="comment">// not run here</span></span><br><span class="line">            <span class="keyword">if</span> (path-&gt;align!=<span class="literal">NULL</span>)</span><br><span class="line">                DeRefAlign(path-&gt;align);</span><br><span class="line">            <span class="comment">// minus path-&gt;prev-&gt;prev-&gt;usage</span></span><br><span class="line">            <span class="comment">// if == 0 add path-&gt;prev-&gt;prev to pNoRef</span></span><br><span class="line">            DeRefPathPrev(path);</span><br><span class="line">            plink=path-&gt;link;</span><br><span class="line">            <span class="comment">// delete path</span></span><br><span class="line">            UnlinkPath(path);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// in pri-&gt;head</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            path-&gt;used=FALSE;</span><br><span class="line">            plink=path-&gt;link;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (path=pri-&gt;pYesRef.link;path-&gt;link!=<span class="literal">NULL</span>;path=path-&gt;link) &#123;</span><br><span class="line">        <span class="keyword">if</span> (!path-&gt;used) <span class="keyword">break</span>;</span><br><span class="line">        path-&gt;used=FALSE;</span><br><span class="line">    &#125;</span><br><span class="line">    pri-&gt;cpth=pri-&gt;npth;</span><br><span class="line">    pri-&gt;calign=pri-&gt;nalign;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>以上部分是处理观察序列的主要步骤。</p>
<h2 id="3-CompleteRecognition"><a href="#3-CompleteRecognition" class="headerlink" title="3. CompleteRecognition"></a>3. CompleteRecognition</h2><p>这部分主要是返回一个Lattice【执行下面这段代码】，同时重置<code>pri</code>这个结构体，为之后的transcript做准备。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">CreateLattice(heap,pri-&gt;net-&gt;<span class="keyword">final</span>.inst-&gt;<span class="built_in">exit</span>,vri-&gt;frameDur)；</span><br></pre></td></tr></table></figure><br>该函数实现如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> Lattice *<span class="title">CreateLattice</span><span class="params">(MemHeap *heap,TokenSet *res,HTime framedur)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">   Lattice *lat;</span><br><span class="line">   RelToken *cur;</span><br><span class="line">   Path path;</span><br><span class="line">   WordPron pron;</span><br><span class="line">   NxtPath rth[MAX_TOKS];</span><br><span class="line">   <span class="keyword">int</span> nn,nl,ln,i;</span><br><span class="line">   NetNode node;</span><br><span class="line"></span><br><span class="line">   pron.<span class="keyword">word</span>=<span class="literal">NULL</span>;pron.pnum=<span class="number">0</span>;pron.next=<span class="literal">NULL</span>;</span><br><span class="line">   pron.outSym=<span class="literal">NULL</span>;pron.phones=<span class="literal">NULL</span>;pron.nphones=<span class="number">0</span>;</span><br><span class="line">   pron.prob=<span class="number">0.0</span>;</span><br><span class="line">   </span><br><span class="line">   path.like=res-&gt;tok.like;</span><br><span class="line">   path.lm=res-&gt;tok.lm;</span><br><span class="line">   path.usage=<span class="number">0</span>;</span><br><span class="line">   path.align=res-&gt;tok.align;</span><br><span class="line">   path.node=&amp;node;</span><br><span class="line">   path.node-&gt;tag=<span class="literal">NULL</span>;</span><br><span class="line">   path.node-&gt;info.pron=&amp;pron;</span><br><span class="line">   path.frame=pri-&gt;frame;</span><br><span class="line">   path.prev=res-&gt;tok.path;</span><br><span class="line">   path.chain=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">   <span class="comment">// nn: num of nodes</span></span><br><span class="line">   <span class="comment">// nl: num of arcs</span></span><br><span class="line">   nn=<span class="number">1</span>;nl=<span class="number">0</span>;ln=<span class="number">0</span>;</span><br><span class="line">   <span class="comment">// dfs</span></span><br><span class="line">   <span class="comment">// modify usage, coding nn, nl</span></span><br><span class="line">   MarkPaths(&amp;path,&amp;nn,&amp;nl);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// single lattice</span></span><br><span class="line">   <span class="comment">// lat-&gt;lnodes = new LNode(nn)</span></span><br><span class="line">   lat=NewLattice(heap,nn,nl);</span><br><span class="line">   lat-&gt;voc=pri-&gt;net-&gt;vocab;</span><br><span class="line">   lat-&gt;lmscale=pri-&gt;scale;</span><br><span class="line">   lat-&gt;wdpenalty=pri-&gt;wordpen;</span><br><span class="line">   lat-&gt;prscale=pri-&gt;pscale;</span><br><span class="line">   lat-&gt;framedur=framedur;</span><br><span class="line"> </span><br><span class="line">   <span class="comment">// Time of word boundary at node</span></span><br><span class="line">   <span class="comment">// Word represented by arc</span></span><br><span class="line">   <span class="comment">// lnodes: Array of lattice nodes</span></span><br><span class="line"></span><br><span class="line">   lat-&gt;lnodes[<span class="number">0</span>].time=<span class="number">0.0</span>; lat-&gt;lnodes[<span class="number">0</span>].<span class="keyword">word</span>=<span class="literal">NULL</span>;</span><br><span class="line">   lat-&gt;lnodes[<span class="number">0</span>].tag=<span class="literal">NULL</span>;</span><br><span class="line">   lat-&gt;lnodes[<span class="number">0</span>].score=<span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">   LatFromPaths(&amp;path,&amp;ln,lat);</span><br><span class="line">   <span class="keyword">return</span>(lat);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br><code>MarkPaths</code>函数主要用来在回溯的过程中给<code>path</code>的<code>usage</code>编号，这将会在之后的执行中用到。该函数执行完毕之后，得出的nn和nl为node个数和弧的个数<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Number/count nodes (in path-&gt;usage field) and count links */</span></span><br><span class="line"><span class="comment">// nn = 1, nl = 0;</span></span><br><span class="line"><span class="comment">// modify usage</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">MarkPaths</span><span class="params">(Path *path,<span class="keyword">int</span> *nn,<span class="keyword">int</span> *nl)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    NxtPath *pth;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// path-&gt;usage: Times struct ref'd (by next path)</span></span><br><span class="line">    <span class="keyword">if</span> (path-&gt;usage&gt;=<span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// minus</span></span><br><span class="line">        path-&gt;usage=-(*nn)++;</span><br><span class="line">        (*nl)++;</span><br><span class="line">        <span class="keyword">if</span> (path-&gt;prev) MarkPaths(path-&gt;prev,nn,nl);</span><br><span class="line">        <span class="comment">// may not run</span></span><br><span class="line">        <span class="keyword">for</span> (pth=path-&gt;chain;pth!=<span class="literal">NULL</span>;pth=pth-&gt;chain) &#123;</span><br><span class="line">            (*nl)++;</span><br><span class="line">            <span class="keyword">if</span> (pth-&gt;prev) MarkPaths(pth-&gt;prev,nn,nl);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><br>最主要的函数是<code>LatFromPaths</code>，它将<code>path</code>信息整合到<code>Lattice</code>之中，为最后的<code>TranscriptionFromLattice</code>做准备。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// ln = 0;</span></span><br><span class="line"><span class="comment">// fill lattice from path info</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">LatFromPaths</span><span class="params">(Path *path,<span class="keyword">int</span> *ln,Lattice *lat)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    LNode *ne,*ns;</span><br><span class="line">    LArc *la;</span><br><span class="line">    <span class="comment">// point</span></span><br><span class="line">    Word nullwordId;</span><br><span class="line">    NxtPath tmp,*pth;</span><br><span class="line">    Align *align,*al,*pr;</span><br><span class="line">    MLink ml;</span><br><span class="line">    LabId labid,splabid,labpr = <span class="literal">NULL</span>;</span><br><span class="line">    <span class="keyword">char</span> buf[<span class="number">80</span>];</span><br><span class="line">    <span class="keyword">int</span> i,frame;</span><br><span class="line">    <span class="keyword">double</span> prlk,dur,like,wp;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get id of NULL word</span></span><br><span class="line">    nullwordId = GetWord(lat-&gt;voc,GetLabId(<span class="string">"!NULL"</span>,FALSE),FALSE);</span><br><span class="line">    <span class="comment">// SP: "sp"</span></span><br><span class="line">    splabid = GetLabId(SP,FALSE);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// tmp &lt;= path</span></span><br><span class="line">    <span class="comment">// path-&gt;prev: Previous word record</span></span><br><span class="line">    tmp.prev=path-&gt;prev;</span><br><span class="line">    tmp.like=path-&gt;like;</span><br><span class="line">    <span class="comment">// path-&gt;chain: Next of NBest Paths</span></span><br><span class="line">    tmp.chain=path-&gt;chain;</span><br><span class="line">    tmp.lm=path-&gt;lm;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ne: LNode end</span></span><br><span class="line">    <span class="comment">// why substract?</span></span><br><span class="line">    <span class="comment">// path-&gt;usage lower than zero</span></span><br><span class="line">    <span class="comment">// assign ne and init ne</span></span><br><span class="line">    ne=lat-&gt;lnodes-path-&gt;usage;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// path-&gt;frame: Time (frame) of boundary (end of word)</span></span><br><span class="line">    <span class="comment">// lat-&gt;framedur: Frame duration in 100ns units</span></span><br><span class="line">    <span class="comment">// ne-&gt;time: Time of word boundary at node</span></span><br><span class="line">    ne-&gt;time=path-&gt;frame*lat-&gt;framedur;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// path-&gt;node: Word level traceback info</span></span><br><span class="line">    <span class="keyword">if</span> (path-&gt;node-&gt;info.pron != <span class="literal">NULL</span>)</span><br><span class="line">        ne-&gt;<span class="keyword">word</span>=path-&gt;node-&gt;info.pron-&gt;<span class="keyword">word</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        ne-&gt;<span class="keyword">word</span>=nullwordId;</span><br><span class="line"></span><br><span class="line">    ne-&gt;tag=path-&gt;node-&gt;tag;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ne-&gt;v: Pronunciation variant number</span></span><br><span class="line">    <span class="keyword">if</span> (path-&gt;node-&gt;info.pron != <span class="literal">NULL</span>)</span><br><span class="line">        ne-&gt;v=path-&gt;node-&gt;info.pron-&gt;pnum;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        ne-&gt;v=<span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    ne-&gt;score=path-&gt;like;</span><br><span class="line"></span><br><span class="line">    align=path-&gt;align;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// pth-&gt;chain: Next of NBest Paths</span></span><br><span class="line">    <span class="comment">// ln == 0;</span></span><br><span class="line">    <span class="keyword">for</span>(pth=&amp;tmp;pth!=<span class="literal">NULL</span>;pth=pth-&gt;chain) &#123;</span><br><span class="line">        <span class="comment">// arcs </span></span><br><span class="line">        <span class="comment">// ln inited by 0</span></span><br><span class="line">        <span class="comment">// modify lat-&gt;larcs</span></span><br><span class="line">        <span class="comment">// ln++ after get la</span></span><br><span class="line">        la=lat-&gt;larcs+(*ln)++;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// ns: node start</span></span><br><span class="line">        <span class="keyword">if</span> (pth-&gt;prev) &#123;</span><br><span class="line">            ns=lat-&gt;lnodes-pth-&gt;prev-&gt;usage,prlk=pth-&gt;prev-&gt;like;</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            ns=lat-&gt;lnodes, prlk=<span class="number">0.0</span>;</span><br><span class="line">        &#125;</span><br><span class="line">          <span class="comment">// la-&gt;start: Node at start of word: pointer</span></span><br><span class="line">        la-&gt;start=ns;la-&gt;<span class="built_in">end</span>=ne;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// wp: word penalty</span></span><br><span class="line">        <span class="keyword">if</span> (ne-&gt;<span class="keyword">word</span>==<span class="literal">NULL</span> || ne-&gt;<span class="keyword">word</span>==nullwordId) </span><br><span class="line">        <span class="comment">/* no word or NULL node */</span></span><br><span class="line">            wp=<span class="number">0.0</span>;                 <span class="comment">/* No penalty for current word */</span></span><br><span class="line">        <span class="keyword">else</span> </span><br><span class="line">            wp=pri-&gt;wordpen;        <span class="comment">/* Inc penalty for current word */</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// la-&gt;aclike: Acoustic likelihood of word</span></span><br><span class="line">        la-&gt;aclike=pth-&gt;like-prlk-pth-&gt;lm*pri-&gt;scale-wp;</span><br><span class="line">        <span class="comment">// la-&gt;prlike: Pronunciation likelihood of arc</span></span><br><span class="line">        <span class="keyword">if</span> (path-&gt;node-&gt;info.pron != <span class="literal">NULL</span>) &#123;</span><br><span class="line">            la-&gt;aclike-=path-&gt;node-&gt;info.pron-&gt;prob*pri-&gt;pscale;</span><br><span class="line">            la-&gt;prlike=path-&gt;node-&gt;info.pron-&gt;prob;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span></span><br><span class="line">            la-&gt;prlike=<span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Language model likelihood of word</span></span><br><span class="line">        la-&gt;lmlike=pth-&gt;lm;</span><br><span class="line">        <span class="comment">// Field used for pruning/sorting</span></span><br><span class="line">        la-&gt;score=pth-&gt;like;</span><br><span class="line">        <span class="comment">// la-&gt;farc: Next arc following start node</span></span><br><span class="line">        <span class="comment">// la-&gt;parc: Next arc preceding end node</span></span><br><span class="line">        <span class="comment">// ns-&gt;foll: Linked list of arcs following node</span></span><br><span class="line">        <span class="comment">// ne-&gt;pred: Linked list of arcs preceding node</span></span><br><span class="line">        la-&gt;farc=ns-&gt;foll;la-&gt;parc=ne-&gt;pred;</span><br><span class="line">      </span><br><span class="line">        ns-&gt;foll=ne-&gt;pred=la;</span><br><span class="line">      </span><br><span class="line">        <span class="comment">// forword search</span></span><br><span class="line">        <span class="keyword">if</span> (pth-&gt;prev!=<span class="literal">NULL</span> &amp;&amp; ns-&gt;<span class="keyword">word</span>==<span class="literal">NULL</span>)</span><br><span class="line">            LatFromPaths(pth-&gt;prev,ln,lat);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="4-TranscriptionFromLattice"><a href="#4-TranscriptionFromLattice" class="headerlink" title="4. TranscriptionFromLattice"></a>4. TranscriptionFromLattice</h2><p>这里通过一个A*搜索算法，在上一步骤填充的<code>Lattice</code>拓扑网络中搜索出来一个最优解或者多个，这里只讨论最优解。<br>先看搜索前的处理部分:<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// get best N ans, suppose N = 1</span></span><br><span class="line">ans=(NBestEntry**) New(&amp;gstack,<span class="keyword">sizeof</span>(NBestEntry*)*N);ans--;</span><br><span class="line"></span><br><span class="line"><span class="comment">// through num of nodes</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>,ln=lat-&gt;lnodes;i&lt;lat-&gt;nn;i++,ln++) &#123;</span><br><span class="line">    <span class="comment">// ln-&gt;foll: following arcs of the nodes</span></span><br><span class="line">    <span class="comment">// leaf node?</span></span><br><span class="line">    <span class="keyword">if</span> (ln-&gt;foll==<span class="literal">NULL</span>)</span><br><span class="line">        ln-&gt;score=<span class="number">0.0</span>;</span><br><span class="line">    <span class="comment">// ~log(0): -oo</span></span><br><span class="line">    <span class="keyword">else</span> </span><br><span class="line">        ln-&gt;score=LZERO;</span><br><span class="line">    <span class="comment">// sorted order init all by -1</span></span><br><span class="line">    ln-&gt;n=<span class="number">-1</span>;</span><br><span class="line">&#125;</span><br><span class="line">n=<span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>,ln=lat-&gt;lnodes;i&lt;lat-&gt;nn;i++,ln++)</span><br><span class="line">    <span class="comment">// not ordered: 没有被排序过</span></span><br><span class="line">    <span class="keyword">if</span> (ln-&gt;n==<span class="number">-1</span>)</span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">        // nn = 0; num of nodes</span></span><br><span class="line"><span class="comment">        static void MarkBack(LNode *ln,int *nn)</span></span><br><span class="line"><span class="comment">        &#123;</span></span><br><span class="line"><span class="comment">            LArc *la;</span></span><br><span class="line"><span class="comment">            // modify flag</span></span><br><span class="line"><span class="comment">            ln-&gt;n=-2;</span></span><br><span class="line"><span class="comment">            // node ln's previous linked nodes</span></span><br><span class="line"><span class="comment">            for (la=ln-&gt;pred;la!=NULL;la=la-&gt;parc)</span></span><br><span class="line"><span class="comment">                // == 1: new node</span></span><br><span class="line"><span class="comment">                if (la-&gt;start-&gt;n==-1) </span></span><br><span class="line"><span class="comment">                     MarkBack(la-&gt;start,nn);</span></span><br><span class="line"><span class="comment">            ln-&gt;n=(*nn)++;</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">        */</span></span><br><span class="line">        MarkBack(ln,&amp;n);</span><br><span class="line"></span><br><span class="line"><span class="comment">// n: num of nodes</span></span><br><span class="line"><span class="comment">// ln-&gt;n: id of nodes by DFS</span></span><br><span class="line">order=(<span class="keyword">int</span>*) New(&amp;gstack, <span class="keyword">sizeof</span>(<span class="keyword">int</span>)*lat-&gt;nn);</span><br><span class="line"></span><br><span class="line"><span class="comment">// id in the net mapped to the position in the lnodes</span></span><br><span class="line"><span class="comment">// id =&gt; pos</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>,ln=lat-&gt;lnodes;i&lt;lat-&gt;nn;i++,ln++)</span><br><span class="line">    order[ln-&gt;n]=i;</span><br><span class="line"></span><br><span class="line"><span class="comment">// backtrack order</span></span><br><span class="line"><span class="comment">// 注意每个节点的score来源</span></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">        5</span></span><br><span class="line"><span class="comment">       / \</span></span><br><span class="line"><span class="comment">      1   4</span></span><br><span class="line"><span class="comment">     /   / \</span></span><br><span class="line"><span class="comment">    0   2   3</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">for</span> (i=lat-&gt;nn<span class="number">-1</span>;i&gt;<span class="number">0</span>;i--) &#123;</span><br><span class="line">    <span class="comment">// get the node of position of i in the net</span></span><br><span class="line">    ln=lat-&gt;lnodes+order[i];</span><br><span class="line">    <span class="comment">// get max la-&gt;start-&gt;score</span></span><br><span class="line">    <span class="comment">// arcs from node: 从该节点出发的弧？</span></span><br><span class="line">    <span class="keyword">for</span> (la=ln-&gt;pred;la!=<span class="literal">NULL</span>;la=la-&gt;parc) &#123;</span><br><span class="line">        <span class="comment">// LArcTotLike: kinds of factor, like, scalar multiplx together in a arcs</span></span><br><span class="line">        score=ln-&gt;score+LArcTotLike(lat,la);</span><br><span class="line">        <span class="comment">// update la-&gt;start-&gt;score</span></span><br><span class="line">        <span class="keyword">if</span> (score&gt;la-&gt;start-&gt;score) </span><br><span class="line">            la-&gt;start-&gt;score=score;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">Dispose(&amp;gstack,order);</span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure><br>之后使用AStar算法搜索出一个最优解，维护一个递增队列，不断的取出头节点，push满足条件的后继到这个队列之中，直至队列为空。这里的队列由双向链表实现，根据<code>score</code>排序。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// init head and tail</span></span><br><span class="line"><span class="comment">// 搜索队列 small =&gt; great</span></span><br><span class="line">head.link=&amp;tail;head.knil=<span class="literal">NULL</span>;</span><br><span class="line">tail.link=<span class="literal">NULL</span>;tail.knil=&amp;head;</span><br><span class="line">tail.score=head.score=LZERO;</span><br><span class="line"></span><br><span class="line"><span class="comment">// all the node in the lattice</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>,ln=lat-&gt;lnodes;i&lt;lat-&gt;nn;i++,ln++) &#123;</span><br><span class="line">    <span class="comment">// find root</span></span><br><span class="line">    <span class="keyword">if</span> (ln-&gt;pred!=<span class="literal">NULL</span>) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// arcs after/pointed to node</span></span><br><span class="line">    <span class="keyword">for</span> (la=ln-&gt;foll;la!=<span class="literal">NULL</span>;la=la-&gt;farc) &#123;</span><br><span class="line">        like=LArcTotLike(lat,la);</span><br><span class="line">        score=like+la-&gt;<span class="built_in">end</span>-&gt;score;</span><br><span class="line">        <span class="keyword">if</span> (score&lt;LSMALL) <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// new entity</span></span><br><span class="line">        newNBE=(NBestEntry*) New(&amp;gstack,<span class="keyword">sizeof</span>(NBestEntry));</span><br><span class="line">        newNBE-&gt;score=score;</span><br><span class="line">        newNBE-&gt;like=like;</span><br><span class="line">        newNBE-&gt;lnode=la-&gt;<span class="built_in">end</span>;</span><br><span class="line">        newNBE-&gt;larc=la;</span><br><span class="line">        newNBE-&gt;prev=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// score: from small to large</span></span><br><span class="line">        <span class="keyword">for</span> (pos=head.link;score&lt;pos-&gt;score;pos=pos-&gt;link);</span><br><span class="line">        <span class="comment">// insert into OPEN link</span></span><br><span class="line">        newNBE-&gt;knil=pos-&gt;knil;newNBE-&gt;link=pos;</span><br><span class="line">        newNBE-&gt;knil-&gt;link=newNBE-&gt;link-&gt;knil=newNBE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;    </span><br><span class="line"></span><br><span class="line"><span class="comment">// from small to large</span></span><br><span class="line"><span class="comment">// equal to while(1)</span></span><br><span class="line"><span class="keyword">for</span> (n=<span class="number">0</span>,best=head.link;n&lt;N &amp;&amp; best!=&amp;tail;best=head.link) &#123;</span><br><span class="line">    <span class="comment">// search until linklist is empty</span></span><br><span class="line">    <span class="keyword">if</span> (head.link==&amp;tail) <span class="keyword">break</span>;</span><br><span class="line">    <span class="comment">// delete from linklist</span></span><br><span class="line">    best=head.link;</span><br><span class="line">    best-&gt;link-&gt;knil=best-&gt;knil;</span><br><span class="line">    best-&gt;knil-&gt;link=best-&gt;link;</span><br><span class="line">    nent--;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (best-&gt;lnode-&gt;foll!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">        nexp++;</span><br><span class="line">        <span class="keyword">for</span> (la=best-&gt;lnode-&gt;foll;la!=<span class="literal">NULL</span>;la=la-&gt;farc) &#123;</span><br><span class="line">            <span class="comment">// like: like on arcs</span></span><br><span class="line">            like=best-&gt;like+LArcTotLike(lat,la);</span><br><span class="line">            <span class="comment">// like plus nodes score</span></span><br><span class="line">            score=like+la-&gt;<span class="built_in">end</span>-&gt;score;</span><br><span class="line">            <span class="keyword">if</span> (score&lt;LSMALL) <span class="keyword">continue</span>;</span><br><span class="line">            newNBE=(NBestEntry*) New(&amp;gstack,<span class="keyword">sizeof</span>(NBestEntry));</span><br><span class="line"></span><br><span class="line">            newNBE-&gt;score=score;</span><br><span class="line">            newNBE-&gt;like=like;</span><br><span class="line">            newNBE-&gt;lnode=la-&gt;<span class="built_in">end</span>;</span><br><span class="line">            newNBE-&gt;larc=la;</span><br><span class="line">            newNBE-&gt;prev=best;</span><br><span class="line">            <span class="comment">// add to the linklist</span></span><br><span class="line">            <span class="keyword">for</span> (pos=head.link;score&lt;pos-&gt;score;pos=pos-&gt;link);</span><br><span class="line">            newNBE-&gt;knil=pos-&gt;knil;newNBE-&gt;link=pos;</span><br><span class="line">            newNBE-&gt;knil-&gt;link=newNBE-&gt;link-&gt;knil=newNBE;</span><br><span class="line">            nent++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// must be different from previous</span></span><br><span class="line">    <span class="comment">// one time get an ans</span></span><br><span class="line">    <span class="comment">// first time n == 0;</span></span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        <span class="keyword">if</span> (WordMatch(best,ans[i])) &#123;</span><br><span class="line">            best=<span class="literal">NULL</span>;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="keyword">if</span> (best!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">        ans[++n]=best;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="5-补充：ExpandWordNet"><a href="#5-补充：ExpandWordNet" class="headerlink" title="5. 补充：ExpandWordNet"></a>5. 补充：ExpandWordNet</h2><p>该函数返回一个<code>Network</code>结构体，用于后续的解码过程，做的是词网络拓展。调用如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// wdNet: Lattice</span></span><br><span class="line">net = ExpandWordNet(&amp;netHeap,wdNet,&amp;vocab,&amp;hset);</span><br></pre></td></tr></table></figure><br><code>Lattice</code>通过词网络文件读入内存组织为该结构体：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">wdNet = ReadLattice(nf,&amp;netHeap,&amp;vocab,TRUE,FALSE)</span><br></pre></td></tr></table></figure><br>先说<code>ReadLattice</code>函数：是通过调用<code>ReadOneLattice</code>来返回<code>Lattice</code>的：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="function">Lattice *<span class="title">ReadLattice</span><span class="params">(FILE *file, MemHeap *heap, Vocab *voc, </span></span></span><br><span class="line"><span class="function"><span class="params">                     Boolean shortArc, Boolean add2Dict)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Lattice *lat,*<span class="built_in">list</span>,*fLat;</span><br><span class="line">    Source source;</span><br><span class="line"> </span><br><span class="line">    AttachSource(file,&amp;source);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>((lat=ReadOneLattice(&amp;source,heap,voc,shortArc,add2Dict))==<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// has other lattice</span></span><br><span class="line">    <span class="keyword">if</span> (lat-&gt;subLatId!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="comment">/* Need to preserve first lattice to return */</span></span><br><span class="line">        <span class="comment">// fLat: first Lattice</span></span><br><span class="line">        fLat=lat; lat = (Lattice *) New(heap,<span class="keyword">sizeof</span>(Lattice)); *lat=*fLat;</span><br><span class="line">        <span class="comment">// fLat keep previous one</span></span><br><span class="line">        <span class="comment">// lat init as previous one</span></span><br><span class="line">        <span class="keyword">do</span> &#123;</span><br><span class="line">            <span class="comment">/* Add SUBLAT to hash table for later lookup */</span></span><br><span class="line">            <span class="comment">// add lat into the hash table named subLatId</span></span><br><span class="line">            GetSubLat(lat-&gt;subLatId,lat);</span><br><span class="line">            <span class="keyword">if</span>((lat=ReadOneLattice(&amp;source,heap,voc,shortArc,add2Dict))==<span class="literal">NULL</span>) &#123;</span><br><span class="line">                Dispose(heap, fLat); <span class="comment">/*fLat points to 1st thing on heap*/</span></span><br><span class="line">                <span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">while</span>(lat-&gt;subLatId!=<span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Clear hash table */</span></span><br><span class="line">        GetSubLat(<span class="literal">NULL</span>,<span class="literal">NULL</span>); </span><br><span class="line">        <span class="comment">/* Set all chain fields to NULL */</span></span><br><span class="line">        lat-&gt;chain=<span class="literal">NULL</span>; </span><br><span class="line">        SubLatList(lat,<span class="literal">NULL</span>,<span class="number">1</span>);</span><br><span class="line">        <span class="comment">/* Set chain fields to make linked list */</span></span><br><span class="line">        lat-&gt;chain=lat; </span><br><span class="line">        <span class="built_in">list</span>=SubLatList(lat,lat,<span class="number">1</span>);</span><br><span class="line">        <span class="comment">/* Disconnect loop */</span></span><br><span class="line">        <span class="built_in">list</span>-&gt;chain=<span class="literal">NULL</span>;</span><br><span class="line">        <span class="comment">/* Copy last to first Lattices to ensure lat is first thing on stack */</span></span><br><span class="line">        *fLat=*lat; lat=fLat;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span>(lat);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这个函数的简单逻辑应该是如果有多个词网络文件，多次读取否则只读一次。<br><img src="http://www.funcwj.cn/images/node.png", width="200"></p>
<p><code>ReadOneLattice</code>函数是对词网络文件的信息包装到<code>Lattice</code>结构中，包含节点，弧的信息和链接关系以及一些权值，系数的初始化。节点和弧的定义分别为<code>LNode</code>和<code>LArc</code>。他们之间的关系如上下图所示：<br><img src="http://www.funcwj.cn/images/arc.png", width="200"></p>
<p>函数对<code>Lattice</code>的初始化如下：<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">la-&gt;start=lat-&gt;lnodes+s;</span><br><span class="line">la-&gt;<span class="built_in">end</span>=lat-&gt;lnodes+e;</span><br><span class="line">la-&gt;lmlike=lmlike;</span><br><span class="line"></span><br><span class="line">la-&gt;farc=la-&gt;start-&gt;foll;</span><br><span class="line">la-&gt;parc=la-&gt;<span class="built_in">end</span>-&gt;pred;</span><br><span class="line">la-&gt;start-&gt;foll=la;</span><br><span class="line">la-&gt;<span class="built_in">end</span>-&gt;pred=la;</span><br></pre></td></tr></table></figure><br>下面就进行词网络拓展部分了，这部分主要是根据文件的配置信息决定如何做音素级别的拓展，因为之前的<code>Lattice</code>只是最上层的词网络，节点表示词，边表示转换关系，还没有发音和HMM模型，这些信息都是在最终解码之前需要的，所以网络需要一步一步的充实。</p>
<h3 id="InitPronHolders"><a href="#InitPronHolders" class="headerlink" title="InitPronHolders"></a>InitPronHolders</h3><p>首先为了引入发音信息，引入一个<code>PronHolder</code>的结构体，做一个初始化。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* First create context arrays and pronunciation instances */</span></span><br><span class="line"><span class="comment">// frcSil: global string</span></span><br><span class="line"><span class="comment">// net: new network</span></span><br><span class="line"><span class="keyword">int</span> nNull = InitPronHolders(net,lat,hci,voc,&amp;holderHeap,frcSil);</span><br></pre></td></tr></table></figure><br>首先需要对<code>!NULL</code>做处理，如果是真的空节点，创建一个空的发音实例，否则不做此操作。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"> <span class="comment">/* Reset hash table prior to processing lattice */</span></span><br><span class="line"> <span class="comment">// wnHashTab: NetNode</span></span><br><span class="line"> <span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;WNHASHSIZE; i++)</span><br><span class="line">     wnHashTab[i]=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line"> <span class="comment">/* Determine if we have a real !NULL word */</span></span><br><span class="line"> <span class="comment">// nullWord: Word for output when word==NULL</span></span><br><span class="line"></span><br><span class="line"> net-&gt;nullWord = GetWord(voc,GetLabId(<span class="string">"!NULL"</span>, TRUE),TRUE);</span><br><span class="line"> <span class="comment">// next: Next pronunciation of word</span></span><br><span class="line"> <span class="comment">// a word can have kinds of pronunciations</span></span><br><span class="line"> <span class="keyword">for</span> (thisPron=net-&gt;nullWord-&gt;pron;thisPron!=<span class="literal">NULL</span>;thisPron=thisPron-&gt;next)</span><br><span class="line">     <span class="comment">// not real NULL word</span></span><br><span class="line">     <span class="keyword">if</span> (thisPron-&gt;nphones!=<span class="number">0</span>) &#123;</span><br><span class="line">         net-&gt;nullWord=<span class="literal">NULL</span>;</span><br><span class="line">         <span class="keyword">break</span>;</span><br><span class="line">     &#125;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// nullword without pron</span></span><br><span class="line"> <span class="comment">// real !NULL word</span></span><br><span class="line"> <span class="keyword">if</span> (net-&gt;nullWord!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">     <span class="keyword">if</span> (net-&gt;nullWord-&gt;pron==<span class="literal">NULL</span>)</span><br><span class="line">         <span class="comment">//  add a pron to a given word</span></span><br><span class="line">         NewPron(voc,net-&gt;nullWord,<span class="number">0</span>,<span class="literal">NULL</span>,net-&gt;nullWord-&gt;wordName,<span class="number">1.0</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> <span class="comment">// frcSil: Automagically add these sil models to the end of words</span></span><br><span class="line"> <span class="comment">// confusion: 这部分搞不懂</span></span><br><span class="line"> <span class="keyword">if</span> (frcSil!=<span class="literal">NULL</span> &amp;&amp; <span class="built_in">strlen</span>(frcSil)&gt;<span class="number">0</span>) &#123;</span><br><span class="line">     <span class="keyword">for</span>(nSil=nAdd=<span class="number">0</span>,ptr=frcSil;ptr!=<span class="literal">NULL</span>;ptr=nxt) &#123;</span><br><span class="line">         <span class="comment">// finish</span></span><br><span class="line">         <span class="keyword">if</span> ((nxt=ParseString(ptr,name))==<span class="literal">NULL</span>) <span class="keyword">break</span>;</span><br><span class="line">         <span class="keyword">if</span> (name[<span class="number">0</span>]==<span class="string">'+'</span> || name[<span class="number">0</span>]==<span class="string">'-'</span>) st=name[<span class="number">0</span>],p=name+<span class="number">1</span>;</span><br><span class="line">         <span class="keyword">else</span> st=<span class="number">0</span>,p=name;</span><br><span class="line">         <span class="keyword">if</span> (<span class="built_in">strlen</span>(p)==<span class="number">0</span>) labid=<span class="literal">NULL</span>;</span><br><span class="line">         <span class="keyword">else</span> labid=GetLabId(p,TRUE);</span><br><span class="line">         <span class="keyword">if</span> (st==<span class="string">'+'</span> || st==<span class="number">0</span>) addPhones[++nAdd]=labid;</span><br><span class="line">         <span class="keyword">if</span> (st==<span class="string">'-'</span> || st==<span class="number">0</span>) silPhones[++nSil]=labid;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">   nSil=nAdd=<span class="number">0</span>;</span><br></pre></td></tr></table></figure><br>接下来初始化节点的剪枝信息，有些地方可能不被执行<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// num of nodes</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;lat-&gt;nn; i++) &#123;</span><br><span class="line">    <span class="keyword">float</span> fct;</span><br><span class="line">    LArc *la;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// current node</span></span><br><span class="line">    thisLNode = lat-&gt;lnodes+i;</span><br><span class="line">    fct = <span class="number">0.0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// factor lm likelihoods throughout words</span></span><br><span class="line">    <span class="comment">// default: false， may not run</span></span><br><span class="line">    <span class="keyword">if</span> (factorLM &amp;&amp; thisLNode-&gt;pred!=<span class="literal">NULL</span>)</span><br><span class="line">        <span class="keyword">for</span> (la=thisLNode-&gt;pred,fct=LZERO;la!=<span class="literal">NULL</span>;la=la-&gt;parc) </span><br><span class="line">            <span class="keyword">if</span> (la-&gt;lmlike&gt;fct) fct=la-&gt;lmlike;</span><br><span class="line">    <span class="comment">// max item in arcs which pointed to itself</span></span><br><span class="line">    <span class="comment">// Field used for pruning</span></span><br><span class="line">    thisLNode-&gt;score = fct;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// factorLM: factor lm likelihoods throughout words</span></span><br><span class="line"><span class="keyword">if</span> (factorLM)</span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;lat-&gt;na; i++) &#123;</span><br><span class="line">    LArc *la;</span><br><span class="line">    <span class="comment">// current arcs</span></span><br><span class="line">    la=NumbLArc(lat,i);</span><br><span class="line">    la-&gt;lmlike-=la-&gt;<span class="built_in">end</span>-&gt;score;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ...</span></span><br></pre></td></tr></table></figure><br>下面是最重要的部分，为<code>Lattice</code>中的每个节点创建发音实例，一个词的发音可以有多个。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"> <span class="comment">/* Create instance for each pronunciation in lattice */</span></span><br><span class="line"> <span class="keyword">for</span> (i=<span class="number">0</span>,nNull=<span class="number">0</span>,t=<span class="number">0</span>; i &lt; lat-&gt;nn; i++) &#123;</span><br><span class="line">     <span class="comment">// current node in lattice</span></span><br><span class="line">     thisLNode = lat-&gt;lnodes+i;</span><br><span class="line">     <span class="comment">// the word that the word represent</span></span><br><span class="line">     <span class="comment">// init in ReadOneLattice by GetWordId</span></span><br><span class="line">     thisWord = thisLNode-&gt;<span class="keyword">word</span>;</span><br><span class="line">     <span class="comment">// replace by NULL word</span></span><br><span class="line">     <span class="keyword">if</span> (thisWord==<span class="literal">NULL</span>) thisWord=voc-&gt;nullWord;</span><br><span class="line">     thisLNode-&gt;sublat=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">     <span class="comment">// nAdd: get from frcSil, may be 0</span></span><br><span class="line">     pii=(PInstInfo *) New(&amp;gstack,(thisWord-&gt;nprons+<span class="number">1</span>)*(nAdd+<span class="number">1</span>)*<span class="keyword">sizeof</span>(PInstInfo));</span><br><span class="line">     pii--;</span><br><span class="line">     <span class="comment">/* Scan current pronunciations and make modified ones */</span></span><br><span class="line">     <span class="comment">// thisWord-&gt;pron init in ReadOneLattice</span></span><br><span class="line">     <span class="comment">// for each pron in a single word</span></span><br><span class="line">   <span class="keyword">for</span> (j=<span class="number">1</span>,thisPron=thisWord-&gt;pron,npii=<span class="number">0</span>; thisPron!=<span class="literal">NULL</span>; j++,thisPron=thisPron-&gt;next) &#123;</span><br><span class="line">     <span class="keyword">if</span> (thisPron-&gt;nphones==<span class="number">0</span>) n=<span class="number">0</span>;</span><br><span class="line">     <span class="keyword">else</span></span><br><span class="line">         <span class="comment">// for each phones</span></span><br><span class="line">         <span class="comment">// n inited by thisPron-&gt;nphones</span></span><br><span class="line">         <span class="keyword">for</span> (k=<span class="number">1</span>,n=thisPron-&gt;nphones;k&lt;=nSil;k++) </span><br><span class="line">             <span class="comment">// each phone end with sil?</span></span><br><span class="line">             <span class="keyword">if</span> (thisPron-&gt;phones[thisPron-&gt;nphones<span class="number">-1</span>]==silPhones[k]) &#123;</span><br><span class="line">                 <span class="comment">/* Strip it */</span></span><br><span class="line">                 n--;<span class="keyword">break</span>;</span><br><span class="line">            &#125;</span><br><span class="line">         <span class="comment">// n: non-sil phones</span></span><br><span class="line">      <span class="keyword">if</span> (thisPron-&gt;nphones==<span class="number">0</span> || nAdd==<span class="number">0</span> || n==<span class="number">0</span>) &#123;</span><br><span class="line">         <span class="comment">/* Just need one pronunciation */</span></span><br><span class="line">         <span class="comment">// !NULL one</span></span><br><span class="line">         <span class="keyword">if</span> (thisPron-&gt;nphones==<span class="number">0</span>) &#123;</span><br><span class="line">            nNull++;</span><br><span class="line">         &#125;</span><br><span class="line">         <span class="keyword">if</span> (n==<span class="number">0</span>) </span><br><span class="line">            n=thisPron-&gt;nphones;</span><br><span class="line">         pii[++npii].pron=thisPron; pii[npii].silId=<span class="number">-1</span>;</span><br><span class="line">         pii[npii].n=n;pii[npii].t=n;</span><br><span class="line">         pii[npii].phones=thisPron-&gt;phones;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="comment">// sil phones</span></span><br><span class="line">      <span class="keyword">else</span> &#123;</span><br><span class="line">         <span class="comment">/* Make one instance per silence label */</span></span><br><span class="line">         <span class="keyword">for</span> (k=<span class="number">1</span>;k&lt;=nAdd;k++) &#123;</span><br><span class="line">            pii[++npii].pron=thisPron; </span><br><span class="line">            pii[npii].silId=k;</span><br><span class="line">            pii[npii].n=pii[npii].t=n;</span><br><span class="line">            <span class="comment">// after modify</span></span><br><span class="line">            <span class="keyword">if</span> (addPhones[k]!=<span class="literal">NULL</span>) </span><br><span class="line">               pii[npii].t++;</span><br><span class="line">            pii[npii].phones=(LabId *) New(heap,<span class="keyword">sizeof</span>(LabId)*pii[npii].t);</span><br><span class="line">            <span class="comment">// copy phones</span></span><br><span class="line">            <span class="keyword">for</span>(l=<span class="number">0</span>;l&lt;pii[npii].n;l++) </span><br><span class="line">               pii[npii].phones[l]=pii[npii].pron-&gt;phones[l];</span><br><span class="line">            <span class="comment">// add sil</span></span><br><span class="line">            <span class="keyword">if</span> (addPhones[k]!=<span class="literal">NULL</span>) </span><br><span class="line">               pii[npii].phones[pii[npii].n]=addPhones[k];</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   <span class="comment">/* Scan new pronunciations and remove duplicates */</span></span><br><span class="line">   <span class="comment">// npii: all the phones in a word</span></span><br><span class="line">   <span class="comment">// default: true</span></span><br><span class="line">   </span><br><span class="line">   <span class="keyword">if</span> (remDupPron)</span><br><span class="line">      <span class="comment">// each pron</span></span><br><span class="line">      <span class="keyword">for</span> (j=<span class="number">2</span>; j&lt;=npii; j++) &#123;</span><br><span class="line">         n=pii[j].t;</span><br><span class="line">         <span class="keyword">if</span> (pii[j].pron==<span class="literal">NULL</span>) <span class="keyword">continue</span>;</span><br><span class="line">         <span class="keyword">for</span> (k=<span class="number">1</span>; k&lt;j; k++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (pii[j].pron==<span class="literal">NULL</span> || pii[k].pron==<span class="literal">NULL</span> ||</span><br><span class="line">                pii[k].t!=n || pii[j].pron-&gt;prob!=pii[k].pron-&gt;prob) </span><br><span class="line">               <span class="keyword">continue</span>;</span><br><span class="line">            <span class="comment">// each phones</span></span><br><span class="line">            <span class="keyword">for</span>(l=<span class="number">0</span>;l&lt;n;l++) </span><br><span class="line">               <span class="keyword">if</span> (pii[j].phones[l]!=pii[k].phones[l]) <span class="keyword">break</span>;</span><br><span class="line">            <span class="comment">// equal</span></span><br><span class="line">            <span class="keyword">if</span> (l==n) pii[j].pron=<span class="literal">NULL</span>,t++;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">   <span class="comment">/* Now make the PronHolders */</span></span><br><span class="line">   <span class="keyword">for</span> (j=<span class="number">1</span>; j&lt;=npii; j++) &#123;</span><br><span class="line">      <span class="comment">/* Don't add duplicates */</span></span><br><span class="line">      <span class="keyword">if</span> (pii[j].pron==<span class="literal">NULL</span>) <span class="keyword">continue</span>;</span><br><span class="line">      <span class="comment">/* Build inst for each pron */</span></span><br><span class="line">      pInst=NewPronHolder(heap,hci,pii[j].pron,pii[j].t,pii[j].phones);</span><br><span class="line">      <span class="comment">// ln: Node that created this instance</span></span><br><span class="line">      pInst-&gt;ln = thisLNode;</span><br><span class="line">      <span class="comment">// add pInst into the head of lnode</span></span><br><span class="line">      pInst-&gt;next = (PronHolder*)thisLNode-&gt;sublat;</span><br><span class="line">      thisLNode-&gt;sublat = (SubLatDef*) pInst;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// pInst-&gt;fct: LM likelihood to be factored into each phone</span></span><br><span class="line">      <span class="keyword">if</span> (pInst-&gt;nphones&lt;=<span class="number">0</span>) pInst-&gt;fct = <span class="number">0.0</span>;</span><br><span class="line">      <span class="keyword">else</span> pInst-&gt;fct = thisLNode-&gt;score/pInst-&gt;nphones;</span><br><span class="line"></span><br><span class="line">      <span class="comment">/* Fake connections from SENT_[START/END] */</span></span><br><span class="line">      <span class="comment">// Number of cross word contexts</span></span><br><span class="line">      <span class="keyword">if</span> (hci-&gt;xc&gt;<span class="number">0</span>) &#123;</span><br><span class="line">         <span class="comment">// start node ?</span></span><br><span class="line">         <span class="keyword">if</span> (thisLNode-&gt;pred==<span class="literal">NULL</span>)</span><br><span class="line">            <span class="comment">// Left contexts</span></span><br><span class="line">            pInst-&gt;lc[<span class="number">0</span>]=(NetNode*)lat;</span><br><span class="line">         <span class="comment">// end node ?</span></span><br><span class="line">         <span class="keyword">if</span> (thisLNode-&gt;foll==<span class="literal">NULL</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (pInst-&gt;nphones==<span class="number">0</span>) lc=<span class="number">0</span>;</span><br><span class="line">            <span class="comment">// pInst-&gt;fc: final context</span></span><br><span class="line">            <span class="keyword">else</span> lc = pInst-&gt;fc;</span><br><span class="line">            type = n_word + lc*n_lcontext; <span class="comment">/* rc==0 */</span></span><br><span class="line">            wordNode=FindWordNode(net-&gt;heap,pInst-&gt;pron,pInst,type);</span><br><span class="line">            wordNode-&gt;tag=SafeCopyString(net-&gt;heap,thisLNode-&gt;tag);</span><br><span class="line">            wordNode-&gt;nlinks = <span class="number">0</span>;</span><br><span class="line">            pInst-&gt;rc[<span class="number">0</span>]=wordNode;</span><br><span class="line">         &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (thisLNode-&gt;foll==<span class="literal">NULL</span>) &#123;</span><br><span class="line">         wordNode = FindWordNode(net-&gt;heap,pInst-&gt;pron,pInst,n_word);</span><br><span class="line">         wordNode-&gt;tag=SafeCopyString(net-&gt;heap,thisLNode-&gt;tag);</span><br><span class="line">         wordNode-&gt;nlinks = <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">   Dispose(&amp;gstack,++pii);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="ProcessCrossWordLinks"><a href="#ProcessCrossWordLinks" class="headerlink" title="ProcessCrossWordLinks"></a>ProcessCrossWordLinks</h3><p>这个函数将被执行两次，第一次<code>heap != NULL</code>，第二次<code>heap == NULL</code>。<br>遍历<code>Lattice</code>网络中所有的弧，弧两端节点的不同pron构成全连接关系，第一次仅仅为开端节点标记tag。</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// through all the arcs</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;lat-&gt;na; i++) &#123;</span><br><span class="line">    thisLArc = NumbLArc(lat, i);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// start word's pron</span></span><br><span class="line">    <span class="keyword">for</span> (lInst=(PronHolder*)thisLArc-&gt;start-&gt;sublat;lInst!=<span class="literal">NULL</span>;lInst=lInst-&gt;next)</span><br><span class="line">        <span class="comment">// end word's pron</span></span><br><span class="line">        <span class="keyword">for</span> (rInst=(PronHolder*)thisLArc-&gt;<span class="built_in">end</span>-&gt;sublat;rInst!=<span class="literal">NULL</span>;rInst=rInst-&gt;next) &#123;</span><br><span class="line">            <span class="comment">// xc: Number of cross word contexts</span></span><br><span class="line">            <span class="comment">// n_word: Node Instance represents word end</span></span><br><span class="line">            <span class="keyword">if</span> (xc==<span class="number">0</span>) &#123;</span><br><span class="line">                wordNode = FindWordNode(heap,lInst-&gt;pron,lInst,n_word);</span><br><span class="line">                <span class="comment">// first time</span></span><br><span class="line">            <span class="keyword">if</span> (heap!=<span class="literal">NULL</span>)</span><br><span class="line">                wordNode-&gt;tag=SafeCopyString(heap,thisLArc-&gt;start-&gt;tag); </span><br><span class="line">            <span class="keyword">if</span> (heap==<span class="literal">NULL</span>) &#123;</span><br><span class="line">                  <span class="comment">// links: Array[0..nlinks-1] of links to connected nodes</span></span><br><span class="line">                  <span class="comment">// one to multi</span></span><br><span class="line">                  <span class="comment">// wordNode-&gt;nlinks = 0;</span></span><br><span class="line">                  <span class="comment">// </span></span><br><span class="line">                  wordNode-&gt;links[wordNode-&gt;nlinks].node=rInst-&gt;starts;</span><br><span class="line">                  wordNode-&gt;links[wordNode-&gt;nlinks].like=thisLArc-&gt;lmlike;</span><br><span class="line">               &#125;</span><br><span class="line">            <span class="comment">// has many linked nodes</span></span><br><span class="line">            wordNode-&gt;nlinks++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>接下来，执行<code>CreateWIModels</code>之前，有一块处理没用看明白。<br>还有，<code>CreateWIModels</code>和<code>CreateIEModels</code>函数执行的对象是<code>Lattice</code>中每一个节点对应的词中的每一个发音实例。一个发音实例用三音素或者五因素模型建模。这两个函数主要是处理边界音素和中间音素的。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* Build models on basis of contexts seen */</span></span><br><span class="line">net-&gt;teeWords=FALSE;</span><br><span class="line"></span><br><span class="line"><span class="comment">// all the nodes</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i &lt; lat-&gt;nn; i++) &#123;</span><br><span class="line">    thisLNode = lat-&gt;lnodes+i;</span><br><span class="line">    thisWord = thisLNode-&gt;<span class="keyword">word</span>;</span><br><span class="line">    <span class="keyword">if</span> (thisWord==<span class="literal">NULL</span>) </span><br><span class="line">        thisWord=voc-&gt;nullWord;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// word's pron</span></span><br><span class="line">    <span class="keyword">for</span>(pInst=(PronHolder*)thisLNode-&gt;sublat;pInst!=<span class="literal">NULL</span>;pInst=pInst-&gt;next) &#123;</span><br><span class="line">        <span class="comment">/* !NULL consists only of word ends */</span></span><br><span class="line">        <span class="keyword">if</span> (pInst-&gt;nphones==<span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">/* Flawed */</span></span><br><span class="line">            <span class="keyword">if</span> (hci-&gt;xc==<span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">/* But we need a pointer for xc==0 cases */</span></span><br><span class="line">                wordNode = FindWordNode(<span class="literal">NULL</span>,pInst-&gt;pron,pInst,n_word);</span><br><span class="line">                <span class="comment">// Chain of initial models</span></span><br><span class="line">                pInst-&gt;starts = wordNode;</span><br><span class="line">                <span class="comment">// Number of models in starts chain</span></span><br><span class="line">                pInst-&gt;nstart = <span class="number">0</span>; <span class="comment">/* Stops us adding node into chain twice */</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/* Determine which bits of word are l and r cd */</span></span><br><span class="line">        <span class="keyword">if</span> (hci-&gt;xc&gt;<span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">for</span> (p=<span class="number">0</span>;p&lt;pInst-&gt;nphones;p++)</span><br><span class="line">               <span class="keyword">if</span> (GetHCIContext(hci,pInst-&gt;phones[p])&gt;=<span class="number">0</span>) <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">for</span> (q=pInst-&gt;nphones<span class="number">-1</span>;q&gt;=<span class="number">0</span>;q--)</span><br><span class="line">               <span class="keyword">if</span> (GetHCIContext(hci,pInst-&gt;phones[q])&gt;=<span class="number">0</span>) <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            p=<span class="number">0</span>;</span><br><span class="line">            <span class="comment">// nphones: Number of phones for this instance</span></span><br><span class="line">            q=pInst-&gt;nphones<span class="number">-1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">         </span><br><span class="line">        pInst-&gt;tee=TRUE;</span><br><span class="line">        <span class="comment">/* Make wrd-int cd phones (possibly none!) */</span></span><br><span class="line">        <span class="comment">// p = 0; q = pInst-&gt;nphones - 1;</span></span><br><span class="line"></span><br><span class="line">        CreateWIModels(pInst,p,q,net,hci);</span><br><span class="line">        <span class="keyword">if</span> (hci-&gt;xc==<span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">/* Word internal context only */</span></span><br><span class="line">            CreateIEModels(thisWord,pInst,p,q,net,hci);</span><br><span class="line">         &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h3 id="CreateWIModels"><a href="#CreateWIModels" class="headerlink" title="CreateWIModels"></a>CreateWIModels</h3><p>这个函数主要处理非边界音素，该处理过程针对一个发音实例，操作完毕之后的结果如图所示：<br><img src="http://www.funcwj.cn/images/CreateWIModels.png", width="300"></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">NetNode *node;</span><br><span class="line">HLink hmm;</span><br><span class="line"><span class="keyword">int</span> j;</span><br><span class="line">   </span><br><span class="line"><span class="comment">// num of phones</span></span><br><span class="line"><span class="comment">// [0, 4] =&gt; 3 2 1 each phone is different</span></span><br><span class="line"><span class="keyword">for</span>(j=q<span class="number">-1</span>;j&gt;p;j--) &#123;</span><br><span class="line">    <span class="comment">// find HMM model for a single phone</span></span><br><span class="line">    hmm=GetHCIModel(hci,FindLContext(hci,pInst,j,<span class="number">0</span>),</span><br><span class="line">                    pInst-&gt;phones[j],</span><br><span class="line">                    FindRContext(hci,pInst,j,<span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// not tee</span></span><br><span class="line">    <span class="keyword">if</span> (hmm-&gt;transP[<span class="number">1</span>][hmm-&gt;numStates]&lt;LSMALL) </span><br><span class="line">        pInst-&gt;tee=FALSE;</span><br><span class="line">  </span><br><span class="line">    nwi++;</span><br><span class="line">    <span class="comment">// new a node by hmm, each has at most one connected node</span></span><br><span class="line">    node=NewNode(net-&gt;heap,hmm,(pInst-&gt;chain==<span class="literal">NULL</span>?<span class="number">0</span>:<span class="number">1</span>));</span><br><span class="line">    <span class="keyword">if</span> (pInst-&gt;chain!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">        nil++;</span><br><span class="line">        <span class="comment">// each phone pointed to the chain, but chain is modified by current node</span></span><br><span class="line">        <span class="comment">// so the later one is pointed to the previous one</span></span><br><span class="line">        <span class="comment">// 2-&gt;3 1-&gt;2</span></span><br><span class="line">        node-&gt;links[<span class="number">0</span>].node=pInst-&gt;chain;</span><br><span class="line">        node-&gt;links[<span class="number">0</span>].like=pInst-&gt;fct;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// node-&gt;chain may be NULL</span></span><br><span class="line">    node-&gt;chain=pInst-&gt;chain;</span><br><span class="line">    pInst-&gt;chain=node;</span><br><span class="line">    <span class="comment">// 1-&gt;2-&gt;3</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="CreateIEModels"><a href="#CreateIEModels" class="headerlink" title="CreateIEModels"></a>CreateIEModels</h3><p>这里针对边界音素，操作结果可以表示如图：<br><img src="http://www.funcwj.cn/images/CreateIEModels.png", width="300"></p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">NetNode *node,*wordNode;</span><br><span class="line">HLink hmm;</span><br><span class="line"></span><br><span class="line"><span class="comment">// p = 0 q = nphones - 1: 如果只有一个节点</span></span><br><span class="line"><span class="keyword">if</span> (q==p) &#123;</span><br><span class="line">    <span class="comment">/* One phone word */</span></span><br><span class="line">    hmm=GetHCIModel(hci,<span class="number">0</span>,pInst-&gt;phones[<span class="number">0</span>],<span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (hmm-&gt;transP[<span class="number">1</span>][hmm-&gt;numStates]&lt;LSMALL) pInst-&gt;tee=FALSE;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// the last node is word node</span></span><br><span class="line">    wordNode = FindWordNode(<span class="literal">NULL</span>,pInst-&gt;pron,pInst,n_word);</span><br><span class="line">  </span><br><span class="line">    nin++; nil++;</span><br><span class="line">    node=NewNode(net-&gt;heap,hmm,<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// pointed to a word node</span></span><br><span class="line">    node-&gt;links[<span class="number">0</span>].node=wordNode;</span><br><span class="line">    node-&gt;links[<span class="number">0</span>].like=pInst-&gt;fct;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// Chain of initial models</span></span><br><span class="line">    pInst-&gt;starts=node;</span><br><span class="line">    <span class="comment">// Number of models in starts chain</span></span><br><span class="line">    pInst-&gt;nstart=<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 正常情况</span></span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// 处理exit节点 </span></span><br><span class="line">    hmm=GetHCIModel(hci,FindLContext(hci,pInst,q,<span class="number">0</span>),</span><br><span class="line">                  pInst-&gt;phones[q],<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (hmm-&gt;transP[<span class="number">1</span>][hmm-&gt;numStates]&lt;LSMALL) </span><br><span class="line">        pInst-&gt;tee=FALSE;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 该节点之后跟着一个词节点</span></span><br><span class="line">    wordNode = FindWordNode(<span class="literal">NULL</span>,pInst-&gt;pron,pInst,n_word);</span><br><span class="line">  </span><br><span class="line">    nfi++; nil++;</span><br><span class="line">    node=NewNode(net-&gt;heap,hmm,<span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 指向词节点</span></span><br><span class="line">    node-&gt;links[<span class="number">0</span>].node=wordNode;</span><br><span class="line">    node-&gt;links[<span class="number">0</span>].like=pInst-&gt;fct;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// Chain of final models</span></span><br><span class="line">    pInst-&gt;ends=node;</span><br><span class="line">    <span class="comment">// Number of models in ends chain</span></span><br><span class="line">    pInst-&gt;nend=<span class="number">1</span>;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">/* Start */</span></span><br><span class="line">    hmm=GetHCIModel(hci,<span class="number">0</span>,pInst-&gt;phones[p],</span><br><span class="line">                  FindRContext(hci,pInst,p,<span class="number">0</span>));</span><br><span class="line"></span><br><span class="line">    <span class="comment">// #define LSMALL (-0.5E10)</span></span><br><span class="line">    <span class="keyword">if</span> (hmm-&gt;transP[<span class="number">1</span>][hmm-&gt;numStates]&lt;LSMALL) </span><br><span class="line">        pInst-&gt;tee=FALSE;</span><br><span class="line">  </span><br><span class="line">    nin++; nil++;</span><br><span class="line">    node=NewNode(net-&gt;heap,hmm,<span class="number">1</span>);</span><br><span class="line">    <span class="comment">// 开始节点只需要调整其后继即可</span></span><br><span class="line">    node-&gt;links[<span class="number">0</span>].node=(pInst-&gt;chain?pInst-&gt;chain:pInst-&gt;ends);</span><br><span class="line">    node-&gt;links[<span class="number">0</span>].like=pInst-&gt;fct;</span><br><span class="line">    pInst-&gt;starts=node;</span><br><span class="line">    pInst-&gt;nstart=<span class="number">1</span>;</span><br><span class="line">  </span><br><span class="line">    <span class="comment">// Chain的最后一个节点指向exit节点</span></span><br><span class="line">    <span class="keyword">if</span> (pInst-&gt;chain!=<span class="literal">NULL</span>) &#123;</span><br><span class="line">        <span class="keyword">for</span> (node=pInst-&gt;chain;node-&gt;chain!=<span class="literal">NULL</span>;node=node-&gt;chain);</span><br><span class="line">        <span class="comment">// position to last node</span></span><br><span class="line">        node-&gt;nlinks=<span class="number">1</span>;</span><br><span class="line">        nil++;</span><br><span class="line">        node-&gt;links=(NetLink*) New(net-&gt;heap, <span class="keyword">sizeof</span>(NetLink));</span><br><span class="line">        node-&gt;links[<span class="number">0</span>].node=pInst-&gt;ends;</span><br><span class="line">        node-&gt;links[<span class="number">0</span>].like=pInst-&gt;fct;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>最后一部分，进行第二次的<code>ProcessCrossWordLinks</code>，第二次指定开端节点的后继节点，将他们分别指向末端节点发音实例的开始节点，操做完结果图示如下：<br><img src="http://www.funcwj.cn/images/ProcessCrossWordLinks.png" width="500"></p>
<p>上述过程中用到了一个哈希表，寻访<code>Lattice</code>中所有节点所用到的词节点，下面的操作先为这些词节点分配后继空间，之后使用<code>ProcessCrossWordLinks</code>完成这些节点关系的指派。<br><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">// Allocate NetLinks from hash table stats：分配后继空间</span></span><br><span class="line"><span class="comment">// Zero counters </span></span><br><span class="line"><span class="comment">// all nodes is word end node</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;WNHASHSIZE; i++) &#123;</span><br><span class="line">    <span class="comment">/* Build links for each word end model */</span></span><br><span class="line">    <span class="keyword">for</span> (node=wnHashTab[i];node!=<span class="literal">NULL</span>;node=node-&gt;chain) &#123;</span><br><span class="line">        <span class="keyword">if</span> (node-&gt;nlinks&gt;<span class="number">0</span>)&#123;</span><br><span class="line">            <span class="comment">// alloc node-&gt;links memory</span></span><br><span class="line">            node-&gt;links=(NetLink*) New(net-&gt;heap,<span class="keyword">sizeof</span>(NetLink)*node-&gt;nlinks);</span><br><span class="line">        &#125;<span class="keyword">else</span></span><br><span class="line">            node-&gt;links=<span class="literal">NULL</span>;</span><br><span class="line"></span><br><span class="line">        nxl+=node-&gt;nlinks;</span><br><span class="line">        <span class="comment">// reset to 1</span></span><br><span class="line">        node-&gt;nlinks=<span class="number">0</span>;</span><br><span class="line">        node-&gt;aux=<span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Finally put in the cross word links */</span></span><br><span class="line"><span class="comment">// 之前构建控件，在这里指派指向关系</span></span><br><span class="line">ProcessCrossWordLinks(<span class="literal">NULL</span>,lat,hci-&gt;xc);</span><br><span class="line"></span><br><span class="line"><span class="comment">/* First disassemble wnHashTab and link to end nodes as necessary */</span></span><br><span class="line"><span class="comment">// handle init and final node</span></span><br><span class="line">AddInitialFinal(lat,net,hci-&gt;xc); </span><br><span class="line"></span><br><span class="line"><span class="comment">// net-&gt;chain指向的是Lattice中所有词节点和模型节点，线性表示</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i&lt;WNHASHSIZE; i++) &#123;</span><br><span class="line">    <span class="comment">// word node</span></span><br><span class="line">    <span class="comment">// append word node list to the net's chain</span></span><br><span class="line">    AddChain(net,wnHashTab[i]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Finally chain all nodes together */</span></span><br><span class="line"><span class="keyword">for</span> (i=<span class="number">0</span>; i &lt; lat-&gt;nn; i++) </span><br><span class="line">    <span class="keyword">for</span> (pInst=(PronHolder*)lat-&gt;lnodes[i].sublat;</span><br><span class="line">            pInst!=<span class="literal">NULL</span>;pInst=pInst-&gt;next) &#123;</span><br><span class="line">        <span class="keyword">if</span> (pInst-&gt;nstart&gt;<span class="number">0</span>)</span><br><span class="line">            AddChain(net,pInst-&gt;starts);</span><br><span class="line">        AddChain(net,pInst-&gt;chain);</span><br><span class="line">        AddChain(net,pInst-&gt;ends);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//...</span></span><br></pre></td></tr></table></figure></p>
<p>所以现在总的来看这个层次的网络结构图如下：<br><img src="http://www.funcwj.cn/images/struction.png" width="500"></p>
]]></content>
      <categories>
        <category>ASR</category>
      </categories>
      <tags>
        <tag>HTK</tag>
        <tag>Decoder</tag>
        <tag>Code</tag>
      </tags>
  </entry>
  <entry>
    <title>非阻塞套接字模型</title>
    <url>/2017/05/23/nonblock-socket-demo/</url>
    <content><![CDATA[<p>首先说明这不是近期写的东西，主要想通过它来看看站点显示是否正常。时间应该回退到2016年的七月，由于某些原因，要啃一下grpc的源码，回想起来还是蛮痛苦的（可怜现在已经忘的差不多了……）。</p>
<a id="more"></a>

<p>那时候的我还是对网络编程很感兴趣的。</p>
<p>最近发现套接字在使用中阻塞型使用的非常少，在非阻塞模型中，错误码十分关键，一般都是在操作返回之后，根据错误码和返回值判断相应的操作结果，之后做分别处理。</p>
<p>这里简单的写了一个服务端的模型，代码如下：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/socket.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;sys/types.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;errno.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;netinet/in.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fcntl.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> PORT 10010</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> BUFF 256</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span> <span class="keyword">const</span> *argv[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> server_fd = socket(AF_INET, SOCK_STREAM, <span class="number">0</span>);</span><br><span class="line">	<span class="keyword">if</span>(server_fd == <span class="number">-1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"create server socket error[%s]...\n"</span>, strerror(errno));</span><br><span class="line">		<span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">server_addr</span>;</span></span><br><span class="line">	bzero(&amp;server_addr, <span class="keyword">sizeof</span>(server_addr));</span><br><span class="line"></span><br><span class="line">	server_addr.sin_family = AF_INET;</span><br><span class="line">	server_addr.sin_addr.s_addr = htonl(INADDR_ANY);</span><br><span class="line">	server_addr.sin_port = htons(PORT);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(bind(server_fd, (struct sockaddr*)&amp;server_addr, <span class="keyword">sizeof</span>(sockaddr)) == <span class="number">-1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"bind on local address error[%s]\n"</span>, strerror(errno));</span><br><span class="line">		<span class="built_in">close</span>(server_fd);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(<span class="built_in">listen</span>(server_fd, <span class="number">1</span>) == <span class="number">-1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"listen on local address error[%s]\n"</span>, strerror(errno));</span><br><span class="line">		<span class="built_in">close</span>(server_fd);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">puts</span>(<span class="string">"listening on local address..."</span>);</span><br><span class="line"></span><br><span class="line">	<span class="class"><span class="keyword">struct</span> <span class="title">sockaddr_in</span> <span class="title">client_addr</span>;</span></span><br><span class="line">	<span class="keyword">socklen_t</span> client_addr_len = <span class="keyword">sizeof</span>(client_addr), client_fd;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>((client_fd = accept(server_fd, (struct sockaddr*)&amp;client_addr, &amp;client_addr_len)) == <span class="number">-1</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"accept connection error[%s]\n"</span>, strerror(errno));</span><br><span class="line">		<span class="built_in">close</span>(server_fd);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">puts</span>(<span class="string">"accept one connection..."</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">int</span> flags = fcntl(client_fd, F_GETFL, <span class="number">0</span>);</span><br><span class="line">	<span class="keyword">if</span>(fcntl(client_fd, F_SETFL, flags | O_NONBLOCK) &lt; <span class="number">0</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">puts</span>(<span class="string">"set socket fd to nonblock failed..."</span>);</span><br><span class="line">		<span class="built_in">close</span>(server_fd);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">puts</span>(<span class="string">"set client_fd to nonblock..."</span>);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">int</span>  recv_len = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">char</span> recv_buf[BUFF];</span><br><span class="line">	bzero(recv_buf, BUFF);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">do</span></span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">do</span></span><br><span class="line">		&#123;</span><br><span class="line">			sleep(<span class="number">1</span>);</span><br><span class="line">			recv_len = recv(client_fd, recv_buf, BUFF, <span class="number">0</span>);</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">"recv len = %d\n"</span>, recv_len);</span><br><span class="line">			<span class="keyword">if</span>(errno == EINTR)</span><br><span class="line">				<span class="built_in">puts</span>(<span class="string">"EINTR"</span>);</span><br><span class="line">			<span class="keyword">if</span>(errno == EAGAIN)</span><br><span class="line">				<span class="built_in">puts</span>(<span class="string">"EAGAIN"</span>);</span><br><span class="line">		&#125;<span class="keyword">while</span>(recv_len &lt; <span class="number">0</span> &amp;&amp; (errno == EINTR || errno == EAGAIN));</span><br><span class="line"></span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">"%s\n"</span>, recv_buf);</span><br><span class="line">		bzero(recv_buf, BUFF);</span><br><span class="line"></span><br><span class="line">	&#125;<span class="keyword">while</span>(recv_len != <span class="number">0</span>);</span><br><span class="line">	</span><br><span class="line">	<span class="built_in">puts</span>(<span class="string">"server done..."</span>);</span><br><span class="line">	<span class="built_in">close</span>(client_fd);</span><br><span class="line">	<span class="built_in">close</span>(server_fd);</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用telnet到端口10010，可以观测到在没有数据到来时，错误码为    <code>EAGAIN</code><br>退出<code>telnet</code>客户端，这时观察到返回值变为0，程序退出，也就是说，<code>recv</code>返回值为0表示的是链接的断开，而非没有收取到数据。<br><img src="http://www.funcwj.cn/images/exit-log.png" width="50%"></p>
]]></content>
      <categories>
        <category>Engineering</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>Socket</tag>
      </tags>
  </entry>
  <entry>
    <title>写在前面</title>
    <url>/2017/05/22/write-first/</url>
    <content><![CDATA[<p>为什么要搭blog？从实际需要角度来说，我完全必要在腾讯云上搭的这个站点，可能就是，我好奇心重吧……<br><a id="more"></a></p>
<p>目前感觉这里既放不上心灵鸡汤，也拿不出什么技术软文，甚至能写到什么时候都是一个未知数。搭博客也不是什么新鲜事了，作为大学生涯最后一部分的体验吧。开心就好。</p>
<p>另外，可能先会把以前的杂七杂八的东西放上来，这估计要花上点时间。</p>
]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>checkpoint</tag>
      </tags>
  </entry>
</search>
