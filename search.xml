<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[GWPE Algorithm]]></title>
    <url>%2F2018%2F09%2F20%2Fgwpe-algorithm%2F</url>
    <content type="text"><![CDATA[最近在一批实录的数据上尝试了一下GWPE算法，发现有一定的效果，随之研究了一下原始论文，并在这里对其原理做一下简要介绍。 GWPE算法在提出的时候，对应用的声学环境没有建立一些常见的约束条件，比如speaker数量（原始WPE算法要求single source），noise环境等等，因此在一些复杂条件下的鲁棒性会相对强一些。原论文中将一些随机向量用黑体大写字母表示，实际观测向量用小写字母，在这篇文章中，我统一用后者表示。 从论文题目可以看出，GWPE解决的是MIMO下，impluse response的shorten问题，也可以理解为multi-channel的dereverbration。主要贡献在于使用了一种新的相关性度量作为predict filter估计的代价函数，并导出了对应的估计方法。 New Cost Function先介绍一下是PE（predict error），$\mathbf{y}_{f,t}$表示$N$路麦克风的观测信号，滤波配置（$\Delta, K, \mathcal{G}_f=\{\boldsymbol{G}_{f,\tau}\}_{\tau = \Delta}^{\Delta + K -1}$）下对$\mathbf{y}_{f,t}$的PE表示为： \hat{\mathbf{x}_{f,t}} = \mathbf{y}_{f,t} - \sum_{\tau = \Delta}^{\Delta + K - 1} \boldsymbol{G}_{f,t}^H \mathbf{y}_{f,\tau} \tag{1}其中第二项 \mathbf{x}_{f,t} = \sum_{\tau = \Delta}^{\Delta + K - 1} \boldsymbol{G}_{f,t}^H \mathbf{y}_{f,\tau}称为在该滤波配置下对$\mathbf{y}_{f,t}$的线性预测。$K$表示滤波器阶数，$\Delta$表示延迟，$\boldsymbol{G}_{f,\tau} \in \mathbf{C}^{N \times N}, \mathbf{x}_{f,t}, \mathbf{y}_{f,t} \in \mathbf{C}^{N \times 1}$。 WPE算法中，在PE中引入权重因子作为cost function，GWPE使用新的Hadamard-Fischer mutual correlation作为cost function，定义如下： C_{HF}(\boldsymbol{U}_1, \dots, \boldsymbol{U}_N) = \frac{1}{N} \sum_n \log (\det E(\boldsymbol{U}_n\boldsymbol{U}_n^H)) - \log (\det E(\boldsymbol{U}\boldsymbol{U}^H)) \tag{2}$\boldsymbol{U}_{1\cdots N}$表示复值随机向量。$C_{HF}$具有非负性，当且仅当$\boldsymbol{U}_{1\cdots N}$两两完全不相关时取0值。 借用$C_{HF}$来衡量在滤波矩阵$\mathcal{G}_f = \{\boldsymbol{G}_{f,\tau}\}_{\tau = \Delta}^{\Delta + K -1}$下线性预测$\mathbf{x}_{f,t} = \sum_{\tau = \Delta}^{\Delta + K - 1} \boldsymbol{G}_{f,t}^H \mathbf{y}_{f,\tau}$的相关性： \mathcal{J}(\mathcal{G}_f) = \frac{1}{T}\sum_t \log \left( \det E(\mathbf{x}_{f,t}\mathbf{x}_{f,t}^H) \right) - \log (\det E(\boldsymbol{X}_f\boldsymbol{X}_f^H)) \tag{3}可以证明，$(3)$式的第二项是一个常数，因此，$\mathcal{J}(\mathcal{G}_f)$可以简化为： \mathcal{J}(\mathcal{G}_f) = \frac{1}{T}\sum_t \log \left( \det E(\mathbf{x}_{f,t}\mathbf{x}_{f,t}^H) \right) \tag{4}上式便是GWPE的cost function。到此为止，MIMO的response shorten问题转化成了： \mathcal{G}_f = \arg \min_{\mathcal{G}_f} \mathcal{J}(\mathcal{G}_f)的优化问题。 Estimate Filters$(4)$式的最小值没有解析解，因此，需要导出一种稳定的求解方法。论文中给出的辅助函数方法，即构造辅助函数$\mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{L}_f)$，将原始问题分解成两个子问题依次优化： \mathcal{\hat{L}}_f = \arg \min_{\mathcal{L}_f} \mathcal{\hat{J}}(\mathcal{\hat{G}}_f, \mathcal{L}_f) \tag{5} \\ \mathcal{\hat{G}}_f = \arg \min_{\mathcal{G}_f} \mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{\hat{L}}_f)其中$\mathcal{L}_f = \{\boldsymbol{\Lambda}_{f,t} \}_{t = 0}^{T - 1}$。 辅助函数定义为： \mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{L}_f) = \frac{1}{T}\sum_t \left( E(\mathbf{x}_{f,t}^H \boldsymbol{\Lambda}_{f,t}^{-1} \mathbf{x}_{f,t}) - N + \log(\det(\boldsymbol{\Lambda}_{f,t})) \right)依据性质： \log \left| \det E(\boldsymbol{U}\boldsymbol{U}^H) \right| \leqslant E(\boldsymbol{U}^H\boldsymbol{\Lambda}^{-1}\boldsymbol{U}) -N + \log(\det \boldsymbol{\Lambda})当且仅当$\boldsymbol{\Lambda} = E(\boldsymbol{U}\boldsymbol{U}^H)$时取等号。因此，对于$\mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{L}_f)$： \mathcal{J}(\mathcal{G}_f) \leqslant \mathcal{\hat{J}}(\mathcal{G}_f, \mathcal{L}_f)取得等号时，$(5)$式的解为： \mathcal{\hat{L}}_f = \{\boldsymbol{\hat{\Lambda}}_{f,t} \}_{t = 0}^{T - 1} = \{E(\mathbf{\hat{x}}_{f,t}\mathbf{\hat{x}}_{f,t}^H)\}_{t=0}^{T-1}这一步的核心在于$E(\mathbf{\hat{x}}_{f,t}\mathbf{\hat{x}}_{f,t}^H)$（spatial correlation matrix）的估计，最常见的方法是做time average： \boldsymbol{\hat{\Lambda}}_{f,t} = E(\mathbf{\hat{x}}_{f,t}\mathbf{\hat{x}}_{f,t}^H) = \sum_{k=t-\delta}^{t+\delta} = \frac{1}{2\delta+1} \mathbf{\hat{x}}_{f,k}\mathbf{\hat{x}}_{f,k}^H论文中也提供了其他四种可选方法，可用于简化计算。 $\mathcal{\hat{G}}_f$的解相推导对麻烦一些，我只说一下计算方法，首先构造$\boldsymbol{\psi}_{f,t}$矩阵： \boldsymbol{\psi}_{f,t} = [\boldsymbol{Y}_{f,t}^H, \cdots, \boldsymbol{Y}_{f,t-K+1}^H]^T \in \mathbf{C}^{KN^2 \times N}其中： \boldsymbol{Y}_{f,t} = \begin{bmatrix} \mathbf{y}_{f,t} & & \mathbf{o}\\ & \ddots & \\ \mathbf{o} & & \mathbf{y}_{f,t} \\ \end{bmatrix} \in \mathbf{C}^{N^2 \times N}其次，计算$\boldsymbol{g}_f = \overline{\boldsymbol{R}_f^{-1}\boldsymbol{r}_f}$，其中： \begin{align} \boldsymbol{R}_f &= \sum_t \boldsymbol{\psi}_{f,t - \Delta} \boldsymbol{\hat{\Lambda}}_{f,t} \boldsymbol{\psi}_{f,t - \Delta}^H \in \mathbf{C}^{KN^2 \times KN^2} \\ \boldsymbol{r}_f &= \sum_t \boldsymbol{\psi}_{f,t - \Delta} \boldsymbol{\hat{\Lambda}}_{f,t} \mathbf{y}_{f,t} \in \mathbf{C}^{KN^2 \times 1} \end{align}$\boldsymbol{g}_f$和$\boldsymbol{G}_{f,\tau}$的对应关系为： \boldsymbol{g}_l = \begin{bmatrix} \boldsymbol{G}_{f,\Delta,:, 1} \\ \vdots \\ \boldsymbol{G}_{f,\Delta,:, N} \\ \vdots \\ \boldsymbol{G}_{f,\Delta + K - 1,:, N} \end{bmatrix} \\最后reshape一下成为$\mathcal{\hat{G}}_f$的更新值。 Application目前GWPE由fgnt开源了一版python的实现（https://github.com/fgnt/nara_wpe），效果挺好，可以参考一下实现细节，有空的话，我自己也想实现一版。 GWPE最直接的用处就是multi-channel的dereverbration，如下图（这是4麦的实录数据，混响不是非常严重），对比来看，还是可以比较明显的看出GWPE处理之后的音频扫尾现象少了很多。由于混响对识别任务而言是一个影响较大的因素，因此，在WER上往往可以比较明显的对比出差距。 其次就是和前端的一些mask估计，beamforming结合起来用，因为增强/分离/定位这些任务也是混响敏感的，用GWPE做一遍数据预处理通常会有ASR上的增益。fgnt在interspeech2018上有一篇文章[2]专门分析WPE和beamforming的结合，有兴趣的同学可以参考一下。目前我手上的实验也验证了这一点，参考结果如下（WER绝对提升）： RAW-CH1 GWPE-CH1 DS CGMM-MVDR GWPE-CGMM-MVDR 0% 2.07% 1.98% 3.37% 4.35% 可以看出，单独过一遍GWPE就可以获得2%的绝对提升，在CGMM-MVDR基础上，替换输入为GWPE结果之后，可以继续获得一个点的绝对提升。 Reference[1]. Yoshioka T, Nakatani T. Generalization of multi-channel linear prediction methods for blind MIMO impulse response shortening[J]. IEEE Transactions on Audio, Speech and Language Processing, 2012, 20(10): 2707-2720. [2]. Drude L, Boeddeker C, Heymann J, et al. Integrating Neural Network Based Beamforming and Weighted Prediction Error Dereverberation[J]. Proc. Interspeech 2018, 2018: 3043-3047.]]></content>
      <tags>
        <tag>Speech Enhancement</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Analysis/Synthesis window of STFT]]></title>
    <url>%2F2018%2F08%2F13%2Fstft-problem%2F</url>
    <content type="text"><![CDATA[这里提一个(i)STFT的细节。做短时傅里叶分析的时候，通常会选取窗函数，缓解频谱泄露。把频域的谱通过OLA（overlap add）转换到时域上时，我以前的做法是选取相同的窗函数。这么做会带来一个问题，如果直接把OLA的结果写入磁盘，特别容易出现clipping，所以我通常会在OLA之后对samples做一个renorm/rescale操作，避免数值超出wav的采样单元，但是这么一做，往往就丢失了原先音频的能量信息。理想情况下，在频域不做任何处理，变换到时域，应该存在条件，使得时域结果完美重构的。 后来逐渐的在一些文献中看到了一些资料。发现这个窗函数的选取，不是那么随意，要想达到最佳重构，正逆过程的窗需要满足一个约束条件，有些文献中也称为双正交。正过程的窗称为分析（analysis）窗，逆过程的窗（synthesis）称为合成窗。下面导出这个约束条件。 令$t$表示帧索引，$S$表示帧移，$w, v$分别表示analysis和synthesis window。$s, \hat{s}$表示原始信号和合成信号。 基于以上定义，分帧过程可以表示为： x_t(n) = w(n) s(n + tS) \tag{1}OLA过程表示为： \hat{s}(n) = \sum_t v(n - tS) x_t(n - tS) \tag{2}将式$(1)$重写为： x_t(n - tS) = w(n - tS) s(n)带入$(2)$式 \begin{align} \hat{s}(n) & = \sum_t v(n - tS) w(n - tS) s(n) \\ & = s(n) \sum_t v(n - tS) w(n - tS) \end{align}因此达到完美重构条件（完全相等），analysis和synthesis窗需要满足条件 \sum_t v(n - tS) w(n - tS) = 1 \tag{3}此式即为所谓的双正交约束。 另外在做短时傅里叶分析的时候，主流工具喜欢对wave进行padding，以期望达到更好的重构效果，这里这么理解，如果不进行padding的话，第一帧和最后一帧必然存在某些samples，无法通过叠加得到（即仅仅只做了加窗），因此，这些点难以达到完美重构条件，padding的目的是对这些点位置进行shift，尽可能的使它们可能达到完美重构条件（这里理解未必正确，看官需小心）。 其次，librosa和fgnt的实现版本也不完全一样，前者是对合成的samples最后做了normalize，后者则是根据analysis窗，构建synthesis窗，之后进行OLA，我参考后者，在kaldi-enhan上的实现如下： 12345678910111213141516171819202122void ShortTimeFTComputer::CacheSynthesisWindow(const ShortTimeFTOptions &amp;opts) &#123; int32 window_size = opts_.frame_length; Vector&lt;BaseFloat&gt; analysis_window_square(analysis_window_), denominator(window_size); analysis_window_square.ApplyPow(2); int32 width = static_cast&lt;int32&gt;((window_size - 1) / opts_.frame_shift), s; for (int32 i = -width; i &lt;= width; i++) &#123; s = i * opts_.frame_shift; if (s &lt; 0) &#123; // [0: end - s] += [-s: end] denominator.Range(0, window_size + s).AddVec(1, analysis_window_square.Range(-s, window_size + s)); &#125; else&#123; // [s: end] += [0: end - s] denominator.Range(s, window_size - s).AddVec(1, analysis_window_square.Range(0, window_size - s)); &#125; &#125; // synthesis_window_.Resize(window_size); // synthesis_window_.CopyFromVec(analysis_window_); synthesis_window_.DivElements(denominator);&#125; 关于这里提的问题，在”Springer Handbook of Speech Processing”的12.1节 The Short-Time Fourier Transform中有详细论述，想要继续深入的可以做一下参考。]]></content>
      <tags>
        <tag>Speech Separation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[From QRNN]]></title>
    <url>%2F2018%2F08%2F02%2Fqrnn-sru%2F</url>
    <content type="text"><![CDATA[最近听说上交提了一个SRNN，相比普通RNN的效率提升100+倍，这让想起了去年的QRNN[1]和SRU[2]，借这篇文章说一下关于RNN的长期依赖和计算效率的问题。 RNN的效率瓶颈在于时间轴上state的传递依赖，借鉴现在大部分DL框架api的设计，可以用下式表示： \mathbf{y}_t, \mathbf{h}_t = \mathcal{C}(\mathbf{x}_{t - 1}, \mathbf{h}_{t - 1})$\mathcal{C}$可以用于表示LSTM，GRU这类cell逻辑。如果具体展开的话，和$x$相关的计算，在每个时间步上没有依赖，因此可以一次计算完毕（即form成矩阵的形式），涉及到$h$相关的计算时，因为$h_{t}$需要等待$h_{t-1}$，因此，整个序列上的$h$推断过程需要串行进行（step by step）。QRNN这类方案的出发点都是对$h$的计算进行局部的依赖解除（但是不能完全解除，否则就不是传统意义上的循环结构了，因此必然存在recurrent逻辑），从而加速inference过程。 LSTM结构中，每一个门状态的计算都需要依赖$h_{t - 1}$，导致门状态计算时$h_{t - 1}$相关的矩阵运算必须串行进行。QRNN将门状态的计算化简为仅仅对当前输入依赖，即$x_{[t - k + 1 \cdots t]}$，$k$是可配置参数，论文中称为filter width，理解为门输入的context就行，在QRNN的开源实现（pytorch-qrnn）中，$k$只支持1和2，用$\mathbf{g}_t$表示门$g$（$g = {z, f, o}$）在$t$时刻的状态值，$\sigma$表示对应的激活函数，那么门状态的计算统一可以用下式表示： \mathbf{g}_t = \sigma(\mathbf{W}_g * \mathbf{x}_{[t - k +1 \cdots t]}) \tag{1}不像LSTM那样存在对$h$的依赖，因此，可以一次计算出所有时刻的门状态值$\mathbf{G}$： \mathbf{G} = \sigma(\mathbf{W}_g * \mathbf{X}_s) \tag{2}$\mathbf{X}_s$表示根据$k$拼帧的结果。需要注意的是，实现的时候，$*$用一个线性层就行了，并没有像论文中所说的卷积操作。 以上是QRNN的parallel部分，不可缺少的recurrent部分，QRNN中称为“dynamic average pooling”，描述cell之间的依赖关系，这部分和LSTM &amp; GRU很像，以fo-pooling为例： \begin{align} \mathbf{c}_t &= \mathbf{f}_t \odot \mathbf{c}_{t - 1} + (1 - \mathbf{f}_t) \odot \mathbf{z}_{t - 1} \\ \mathbf{h}_t &= \mathbf{o}_t \odot \mathbf{c}_t \end{align}这部分的计算量集中在Hadamard Product（逐元素相乘）上，相比原始RNN/LSTM中的矩阵乘法，加上在CUDA上的优化，recurrent部分的计算效率得到了极大的提升。 总结一下QRNN的设计思路，将门状态的计算独立到循环逻辑之外，仅仅保留cell的循环依赖，宏观上就是高计算量的部分parallel进行，小计算量的部分串行计算。这时候再看论文中的QRNN的Block diagrams就很容易体会其中的思想了： 红色区域表示$(2)$式的计算，一次将门状态计算完毕，之后用”dynamic average pooling“层计算recurrent依赖。 SRU和QRNN中$k = 1$的结构十分相似，思路上也都是解除门状态的依赖关系。不添加highway的情况下只设置一个forget门，网络结构写成： \begin{align} \hat{\mathbf{x}_t} &= \mathbf{W}_x \mathbf{x}_t \\ \mathbf{f}_t &= \sigma(\mathbf{W}_f \mathbf{x}_t + \mathbf{b}_f) \\ \mathbf{c}_t &= \mathbf{f}_t \odot \mathbf{c}_{t - 1} + (1 - \mathbf{f}_t) \odot \hat{\mathbf{x}_t} \\ \mathbf{h}_t &= g(\mathbf{c}_t) \end{align}可以看出$\mathbf{f}_t$的计算逻辑也是基于当前输入的一个线性层激活层。 SRNN（Spliced Recurrent Neural Networks）的逻辑是把长序列划分成若干的等长的子序列，再将每个子序列的最后一个状态视为新的序列进行划分，直到新形成的序列长度不能被继续划分为子序列为止。循环过程在每个子序列中进行，并用每个子序列的最后一个状态值初始化父序列的state。由于同一层的每个子序列之间被强制分割，断开了时间上的依赖性，因此可以并行计算状态值。 根据论文中的结论，如果处理的序列足够长，SRNN的效率提升是惊人的。 当然是否所有任务都满足训练序列越长越好，还需要具体的实验对比。在ASR任务中，我本人并不倾向于选择过长的序列进行训练。 最后我再说一下TDNN[4]和FSMN[5]，这是很早以前我就想写一点的东西。这两种结构在ASR中被广泛应用，对识别率的提升做出了巨大的贡献。由于本质上他们是前馈结构，因此，在训练和推断的效率上相比RNN具有巨大的优势，对于ASR这种在实际应用中对实时要求较高的任务上，这一点就显得尤为重要。 TDNN(Time Delay)的历史十分久远[1]，近年来JHU那边主推，并在kaldi的nnet2/3上做了实现，得到了大规模的尝试和应用。它的思想用四个词来表述就行，即层间拼帧。一般的DNN结构，如果要增加输入信息量，只在输入层做拼帧，但是通常不会拼帧过多，否则会导致输入层参数量过大，因此限制了网络的输入信息量。如果同时允许隐层拼帧，那么在多层叠加的情况下，网络输入的context就可以得到扩展，同时也可以保证每一层的参数量不会十分巨大，如果画出整个TDNN的依赖关系图，会得到一种类似金字塔的结构，如下： 以上图为例，输出$t$时刻的后验，输入的context为$[-13, +9]$。 实际熟悉kaldi的人也知道，tdnn层实际配置的时候当成对线性层的一种扩展，添加了拼帧选项而已，可以放在任意网络结构中间，CNN和LSTM等。同时拼帧允许sub-sampling，以上图的layer 2为例子，context为$[-1, +2]$，相比$[-1,0,+1,+2]$，减少了隐层的参数量的同时保证了网络的context。 FSMN的思想来源于信号处理中，一个无限冲击响应可以用高阶的有限冲击响应来近似。它的隐层输入来源于两部分，一部分来自上层的输入，另一部分来自一个称为memory block的结构，写为： \mathbf{h}_t^{\ell + 1} = f(\mathbf{W}^\ell \mathbf{h}_t^\ell + \mathbf{\tilde{W}}^\ell \mathbf{\tilde{h}}_t^\ell + \mathbf{b}^{\ell})其中$ \mathbf{\tilde{h}}_t^\ell$表示$\ell$层的memory block，有两种计算方式： \mathbf{\tilde{h}}_t^\ell = \sum_{c = -M}^N \alpha_{c + M} \mathbf{h}_{t + c}^\ell \tag{3} \\被称为sFSMN（scalar encoding FSMN）以及 \mathbf{\tilde{h}}_t^\ell = \sum_{c = -M}^N \mathbf{c}_{c + M} \odot \mathbf{h}_{t + c}^\ell \tag{4}称为vFSMN（vector encoding FSMN）。$N &gt; 0$时，类似于双向RNN的逻辑。从$(3,4)$式可以看出，memory block强制存储下了若干时刻的记忆块，并用于当前时刻的输入，记忆长度以当前时刻为参考为$M + N$。由于最终的输入是记忆块加权和的形式，因此，FSMN的隐层维度同样不会过大。用信号流图来表示因果系统下memory block的计算如下： FSMN后续还有相关实验，包括deep FSMN和compact FSMN等等，有兴趣的读者可以参阅一下下面的参考文献。 [1]. Zhang S, Jiang H, Xiong S, et al. Compact Feedforward Sequential Memory Networks for Large Vocabulary Continuous Speech Recognition[C]//INTERSPEECH. 2016: 3389-3393. [2]. Zhang S, Lei M, Yan Z, et al. Deep-FSMN for Large Vocabulary Continuous Speech Recognition[J]. arXiv preprint arXiv:1803.05030, 2018. 最后总结一下，RNN的耗时来自时间轴上的展开过程，原始的LSTM和GRU，门状态的计算存在时间上的依赖，矩阵乘法无法并行。QRNN和SRU的思路都是将门状态的依赖关系解除，放到循环外解决，只保留cell state的时间依赖。FSMN和TDNN虽然是前馈结构，但是通过结构上的设计，强制网络获得额外的context信息，相比RNN在效率上具有很大优势，相比传统的DNN/CNN更加适用于long context建模，在ASR任务上均取得了巨大的成功，其中阿里的线上模型已经由LC-BLSTM替换为FSMN，充分体现了其在ASR和工业界的价值。 参考文献： [1]. Bradbury J, Merity S, Xiong C, et al. Quasi-recurrent neural networks[J]. arXiv preprint arXiv:1611.01576, 2016.[2]. Lei T, Zhang Y. Training rnns as fast as cnns[J]. arXiv preprint arXiv:1709.02755, 2017.[3]. Waibel A, Hanazawa T, Hinton G, et al. Phoneme recognition using time-delay neural networks[M]//Readings in speech recognition. 1990: 393-404.[4]. Peddinti V, Povey D, Khudanpur S. A time delay neural network architecture for efficient modeling of long temporal contexts[C]//Sixteenth Annual Conference of the International Speech Communication Association. 2015.[5]. Zhang S, Liu C, Jiang H, et al. Feedforward sequential memory networks: A new structure to learn long-term dependency[J]. arXiv preprint arXiv:1512.08301, 2015.]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduction to Wiener Filter]]></title>
    <url>%2F2018%2F07%2F08%2Fsimple-wiener-filter%2F</url>
    <content type="text"><![CDATA[维纳滤波信号领域最基本，最常见的滤波方法之一，陈老师的麦克风阵列处理一书中首先介绍的就是维纳滤波。本篇文章中我简单的介绍一下维纳滤波。 因为是从ASR看到前端来的，因此，对维纳滤波的理解做不到十分深入。在我看来，维纳滤波的典型特征是MMSE准则，由此就带来一个困惑，没有参考信号或者目标信号，如何做均方误差最小化。换句话说，很多时候，如果已经知道参考信号了，那何须继续滤波呢…… 后来我突然想到手机上大部分人容易忽略的一个器件，辅助降噪麦克风（就是那个小圆圈），才对这个疑惑有了解释，在使用维纳滤波的系统中，多少是存在办法获取参考信号的，辅助降噪麦克风的功能不出意外的话，就是采集环境噪声，给系统提供参考信号的统计量。有时间我觉得有必要研究一下webrt中的维纳滤波算法，听说是目前效果最好的实现。 针对单通道的denoise任务，时域上MSE准则写成： \mathcal{J}(\mathbf{h}) = E\left[\left(z(k) - \mathbf{h}^\top\mathbf{y}(k)\right)^2\right] \tag{1}其中： \mathbf{y}(k) = [y(k), y(k -1), \cdots, y(k - L + 1)]$\mathbf{h}$表示要估计的滤波器系数（有限冲击响应，FIR），$L$表示$\mathbf{h}$的阶数。 解目标函数$(1)$可以得到解析解： \mathbf{h}_W = \arg \min_{\mathbf{h}} \mathcal{J}(\mathbf{h}) = \mathbf{R}_{yy}^{-1} \mathbf{r}_{yx}其中$\mathbf{R}_{yy}$表示观测信号的相关矩阵： \mathbf{R}_{yy} = E[\mathbf{y}(k)\mathbf{y}(k)^T ]$\mathbf{r}_{yx}$表示期望信号和观测信号的协相关矩阵： \mathbf{r}_{yx} = E[\mathbf{y}(k) x(k)]在噪声和期望信号相互独立的假设下，$\mathbf{r}_{yx} $可以写成： \mathbf{r}_{yx} = \mathbf{r}_{yy} - \mathbf{r}_{vv} = E[\mathbf{y}(k) y(k)] - E[\mathbf{v}(k) v(k)] \tag{2}以降噪麦克风为例，可以获取参考噪声，因此估计$\mathbf{r}_{vv}$十分方便。如果要直接计算$\mathbf{r}_{yx}$，就要得到目标信号参考，这个难度显然要大很多，因此，多用$(2)$式间接计算。在我后面的实验中，取起始的一段噪声信号计算$\mathbf{r}_{vv}$，$\mathbf{r}_{yy}, \mathbf{R}_{yy}$根据观测信号均可直接算出。 下面用一个toy简单验证一下，噪声类型为白噪声 1234567891011121314151617181920212223242526272829303132333435363738wav = 'wav/egs1.wav';snr = 1;filter_size = 512;warm_up = 51200;speech = audioread(wav);M = norm(speech, inf);% modify matlab's awgn[noisy, noise] = my_awgn(speech, snr, 'measured');T = length(noisy);warm_up = min(warm_up, T);fprintf("using first %d samples to estimate rvv, totally %d samples...\n", warm_up, T);padding = zeros(1, filter_size - 1);Y = toeplitz([noisy' padding], [noisy(1), padding]);V = toeplitz([noise' padding], [noise(1), padding]);Ryy = Y' * Y / T;ryy = mean(Y(1: T, :) .* noisy, 1);rvv = mean(V(1: warm_up, :) .* noise(1: warm_up), 1);ryx = ryy - rvv;Hw = Ryy \ ryx';denoise = Y * Hw;denoise = denoise(1: T, :);subplot(3, 1, 1);plot(speech);title("Clean Speech");xlim([1, T]); ylim([-1, 1]);subplot(3, 1, 2);plot(noisy / norm(noisy, inf) * M);title("Noisy Speech");xlim([1, T]); ylim([-1, 1]);subplot(3, 1, 3);plot(denoise / norm(denoise, inf) * M);title("Wiener Denoised Speech");xlim([1, T]); ylim([-1, 1]); 测试的时候其实发现denoise效果一般（如果上面的toy实现没有什么大问题的话）。下面给出一个$\text{SNR}=2$的例子（还是可以看出噪声部分得到了部分削弱）。]]></content>
      <tags>
        <tag>Speech Enhancement</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Speech Separation - DPCL & uPIT]]></title>
    <url>%2F2018%2F07%2F02%2Fnn-speech-separation%2F</url>
    <content type="text"><![CDATA[上个月做了一下single-channel下supervised语音分离的两种比较经典的方法，DPCL和uPIT，略有感触。在这篇文章中，我结合我的实践和理解，对它们做一些简单介绍。 首先我再次用自己的语言介绍一遍mask，因为前几天突然有非语音相关的人突然问mask相关的概念。单通道的增强或者分离任务中的mask实际全称应该是TF-mask（TF表示time and frequency），定义在T-F域上。TF-mask被定义的前提通常是信号仅仅为加性混叠（分离任务，混叠信号为说话人，增强任务，混叠信号为语音和加性噪声），因此广泛应用于分离，增强，而非解混响等任务中。不做区分，定义混叠信号如下： \mathbf{x} = \mathbf{s}_1 + \mathbf{s}_2 + \cdots \mathbf{s}_N + \mathbf{n} 其中$\mathbf{s}_i$表示第$i$个说话人，$\mathbf{n}$表示加性噪声。变换到短时频域上： \mathbf{X} = \mathbf{S}_1 + \mathbf{S}_2 + \cdots \mathbf{S}_N + \mathbf{N} \tag{1}其中$\mathbf{S}_i = \text{STFT}(\mathbf{s}_i), \mathbf{N} = \text{STFT}(\mathbf{n}) \in \mathbf{C}^{T \times F}$。 注：$\text{STFT}$表示短时傅里叶变换，其实这里面讲究的东西还是蛮多的，由于我也不确认我的每处理解都十分准确，因此这里不做仔细挖掘。但是有几个概念需要说明一下： 短时傅里叶变换之后的结果$\mathbf{S}$在复数域，我们将$|\mathbf{S}|$称为幅度谱（Magnitude Spectrum），$|\mathbf{S}|^2$称为功率谱（Power Spectrum），$\angle \mathbf{S}$称为相位谱。 使用mask的初衷是，希望通过TF-mask $\mathbf{M}_i$，最大程度还原出希望的语音信号$\mathbf{s}_i$。使用mask还原出的语音信号定义为（在“语音增强mask方法”中我也提到了）： \mathbf{s}'_i = \text{iSTFT}(\mathbf{X} \odot \mathbf{M}_i) \tag{2}得到还原的信号之后，根据不同的任务，就可以使用SNR，SDR或者WER来衡量质量高低了，一般在分离中使用SDR（signal distortion rate）指标。 目前常用的mask种类有IBM（binary mask），IAM（amplitude mask），IRM（ratio mask），PSM（phase sensitive mask），定义如下： IBM： \mathbf{M}_{\text{IBM}}^i = \left(\bigwedge_{n \ne i}^{N} |\mathbf{S}_i | > |\mathbf{S}_n|\right) \wedge \left(|\mathbf{S}_i | > |\mathbf{N}|\right) IAM： \mathbf{M}_{\text{IAM}}^i = \frac{|\mathbf{S}_i|}{|\mathbf{X}|} IRM： \mathbf{M}_{\text{IRM}}^i = \frac{|\mathbf{S}_i|}{\sum_{i = 1}^N|\mathbf{S}_i| + |\mathbf{N}|} PSM： \mathbf{M}_{\text{IAM}}^i = \frac{|\mathbf{S}_i| \cos(\angle \mathbf{X} - \angle \mathbf{S}_i )}{|\mathbf{X}|} 其中，$ \mathbf{M}_{\text{IBM}}^i \in {0, 1}，\mathbf{M}_{\text{IRM}}^i \in [0, 1]$，范围均被限定，PSM可能出现负值。 在wsj0-mix2数据集上，上面四种mask oracle的分离效果如下（SDR） Mask FM FF MM FF/MM AVG IAM 12.49 12.73 11.58 11.88 12.19 IBM 12.94 13.20 12.04 12.35 12.65 IRM 12.86 13.14 11.96 12.27 12.57 PSM 15.79 16.03 14.90 15.20 15.50 可以看出，oracle的情况下，PSM的优势确实很明显。 Label Permutationlabel的置换问题是使用监督性学习解决说话人无关的语音分离问题首先要解决的问题。在增强任务中，我们只需要学习到speech的mask，而分离任务中，则需要学习到多个说话人的mask，由此引入了训练过程中的label置换问题。 置换问题怎么理解？假设网络结构存在两个线性层输出$\mathbf{m}_1$和$\mathbf{m}_2$，对应的label为$s_1, s_2$。这样就存在两种匹配方式，即$\mathbf{m}_1 \to s_1, \mathbf{m}_2 \to s_2$和$\mathbf{m}_1 \to s_2, \mathbf{m}_2 \to s_1$。由此拓展下去，$N$个说话人存在$N!$种对应方式。传统的训练方法，输出和label之间的对应关系是固定的，以增强网络为例，一个对应speech，另一个对应noise，网络收敛之后，label对应speech的输出speech的mask，对应noise的输出noise的mask。在分离任务中，训练语料存在多个说话人（多余网络输出个数），因此，不可能将网络的输出和确定的说话人对应起来，故而无法组织训练。 相关理解可以参考如何理解语音分离中的置换问题（permutaiton problem） DPCL和uPIT就是从两个角度入手解决label的置换问题的。 DPCLDeep Clustering没有正面和label permutation硬怼，而是绕过了这个问题，尝试将每个TF-bin映射到一个高维的特征上，使得其可以更好的被区分开来。这个embedding过程表示为： \mathbf{X}_{tf} \to \mathbf{v}_{tf} \in \mathbf{R}^{D \times 1} \tag{3}得到embedding $\mathbf{v}_{tf}$之后，接一个分类算法，将类别转换为binary mask就可以根据$(2)$进行分离了。在oracle的情况下，将speaker的IBM one-hot编码的分类结果和IBM可以相互转换。 $(3)$式是对单个TF-bin进行的embedding，实际训练中输入以帧为单位，因此，进行的实际上是 \mathbf{X}_{t\cdot} \to \mathbf{Y}_{t\cdot} \in \mathbf{R}^{DF \times 1}的过程。 DPCL的loss function通过亲和性矩阵$\mathbf{A}^\top\mathbf{A}, \mathbf{A} \in \mathbf{R}^{D \times T}$定义，$\mathbf{A}$的列向量表示embedding，$(\mathbf{A}^\top\mathbf{A})_{ij} = 1$表示embedding $\mathbf{A}^\top_i$和$\mathbf{A}^\top_j$属于一个类别。 令$\mathbf{V} \in \mathbf{R}^{S \times F}$表示IBM的one-hot编码结果，$\mathbf{Y} \in \mathbf{R}^{D \times F}$表示DPCL输出embedding。loss function用两种embedding亲和性矩阵之差的F范数表示： \mathcal{J} = \Vert \mathbf{Y}^\top\mathbf{Y} - \mathbf{V}^\top\mathbf{V}\Vert_F^2在具体实现的时候，以整句训练为例，$\mathbf{Y} \in \mathbf{R}^{D \times FT}$。这样$ \mathbf{Y}^\top\mathbf{Y} \in \mathbf{R}^{FT \times FT}$，显存很快就爆掉，可以采用等价计算方式： \mathcal{J} = \Vert \mathbf{Y}\mathbf{Y}^\top \Vert_F^2 + \Vert \mathbf{V}\mathbf{V}^\top \Vert_F^2 - 2\Vert \mathbf{V}\mathbf{Y}^\top \Vert_F^2 \tag{4}进行。 下面提几个比较细节的地方： 计算$(4)$式的时候，原始论文应该是mask掉了silence的T-F bin，因此，注意计算的时候掩蔽掉silence部分。是否silence取决于每个TF bin的能量值，论文中将每个句子比最大能量值小40dB的bin认为成silence。 DPCL收敛的loss比较大，我收敛结果是3700+每个TF-bin，参考一下。 训练和测试时候的特征一定要保证一致（是否log，是否cmvn等等），我开始时训练的cmvn代码逻辑有问题，测试时分离效果总是高低频对半分，查了一周多才找到问题所在…… 测试时聚类的时候，最好也将silence部分掩蔽掉，提高聚类的效果。 整个实验下来，主要是上面的3耗了一点时间，其他过程均比较顺利。代码和结果可以参看deep-clustering。 DPCL这块我没有调过多的配置，目前存在的问题是batch训练的时候，效果会比逐句训练差不少（average SDR-impr 只能在8.5这样子），后面有空还要check一下问题所在。 Utterance Level PITPIT采取的方案就硬怼，既然pair方式有$N!$种，那就直接遍历一遍，把最小的当loss，强制让网络学习align过程和对应的mask。它最早提出的时候，loss定义在帧级别（frame level），但是因为不能保证不同时刻网络的mask和speaker的对应关系保持一致，因此需要加一个speaker tracking的后处理过程（本身论文并没有提出speaker tracking的算法，直接和target比算的oracle结果）。uPIT的u表示utterance level，loss定义在整个句子上，用RNN建模： \mathcal{J}_{\text{psm}} = \arg \min_{\phi \in \mathcal{P}} \sum_s \left \Vert \mathbf{M}_s \odot |\mathbf{X}_s| - |\mathbf{X}_{\phi(s)} | \odot \cos \left( \angle \mathbf{X}_s - \angle \mathbf{X}_{\phi(s)} \right) \right \Vert_F^2 \\ \mathcal{J}_{\text{iam}} = \arg \min_{\phi \in \mathcal{P}} \sum_s \left \Vert \mathbf{M}_s \odot |\mathbf{X}_s| - |\mathbf{X}_{\phi(s)} | \right \Vert_F^2$\mathcal{P}$表示$S$个speaker的排列方案。把上述定义成为permutate loss。 uPIT遇到的坑主要是batch情况下，permutate loss的计算。如果N个句子同时训练，permutate loss是每个句子的permutate loss之和。我第一次实现写成了batch的permutate loss，训练不收敛。除此之外，其他过程也都顺风顺水。代码可以参见uPIT-for-speech-separation。 uPIT调了几组参数，主要是dropout，weight decay，mask类型，激活函数，输入特征等等，到目前为止总结实验结果如下： 从表中可以看出，dropout，weight decay等正则化手段对最终的结果提升影响较大，线性谱不做cmvn的效果最好，ReLU在不同的mask类型上表现均强于sigmoid，但是和论文结论不同的是，PSM并没有显示出相对IAM的优势，二者的结果相差不大。 最后再说一点感触吧，现在大家都在用DL做东西，框架也很方便，因此可能最多的时间可能都不是耗在代码实现，而是debug和调参这些比较枯燥的任务上。对于这些，还是将它看成一种能力比较好，网络不收敛，如何找出问题，或者应用trick，如何根据实验结果调整参数，使模型更优，如何（尽量）解释（分析）不同参数对模型的影响等等，这些都是通过不断的实验和观察，才能得出规律，因此，切忌浮躁，多做实验！]]></content>
      <tags>
        <tag>Speech Separation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TDOA - SRP-PHAT方法]]></title>
    <url>%2F2018%2F05%2F29%2Fsrp-phat-for-tdoa-estimate%2F</url>
    <content type="text"><![CDATA[接着上次GCC-PHAT算法。 GCC-PHAT只利用了两个麦克风的信息，如果麦数多于两路，就可以使用其他的一些方法进行DoA估计，比如Music，SRP算法等等，前者是一个叫做子空间方法的应用，后者这篇文章会进行介绍。 首先认识一下SRP（steered response power）的概念。SRP可以用FS（filter and sum）beamformer的输出功率来表示，如果FS表达为： Y(\omega, t) = \sum_{m = 1}^M G(\omega)_m X_m(\omega, t) e^{-j\omega \tau_m} \tag{1}注：实际中通常在短时频域进行计算，因此，上面的表达式我加上了时间项$t​$。 其中$\tau_m$表示第$m$个麦克风相对参考麦克风的时间延迟，同上篇GCC-PHAT中的定义，对于线阵而言： \tau_m = \frac{\cos(\theta)d_m}{c} \tag{2}那么： \text{SRP}_\text{out}(t) = \sum_\omega Y(\omega, t) Y(\omega, t)^* \tag{3}表示$t$时刻的SRP值，在FS固定的情况下，它只和波达方向$\theta$相关。把$(1)$带入$(3)$，可得： \begin{align} \text{SRP}_{\text{out}}(t) &= \sum_\omega \left(\sum_{p = 1}^M G(\omega)_p X_p(\omega, t) e^{-j\omega \tau_p} \right) \left(\sum_{q = 1}^M G(\omega)_q X_q(\omega, t) e^{-j\omega \tau_q} \right)^* \\ & = \sum_p^M\sum_q^m \left(\sum_\omega G(\omega)_p G(\omega)^*_q X_p(\omega, t)X_q(\omega, t)^* e^{j\omega(\tau_q - \tau_p)} \right) \end{align}上式中括号中的表达式即为选取麦克风$p,q$时的GCC： \text{GCC}_{pq}(t) = \sum_\omega G(\omega)_p G(\omega)^*_q X_p(\omega, t)X_q(\omega, t)^* e^{j\omega(\tau_q - \tau_p)} \tag{4}因此，SRP是所有麦克风两两组合的GCC之和： \text{SRP}_\text{out}(t) = \sum_p^M \sum_q^M \text{GCC}_{pq}(t) \tag{5}若选取$G(\omega)$为$\frac{1}{X(\omega, t)}$，仅仅保留相位信息，那么此时上式的结果称为SRP-PHAT。 表达式$(4)$中，将$\tau_q - \tau_p$写成$\theta$的函数： \tau_p - \tau_q = \frac{d_{pq}\cos \theta}{c}令 \widehat{X_i}(\omega, t) = G(\omega)_i X_i(\omega, t)将GCC对应的表示为时间$t$和波达方向$\theta$的函数： \text{GCC}_{pq}(t, \theta) = \sum_\omega \widehat{X_p}(\omega, t) \widehat{X_q}(\omega, t)^* e^{j \omega\cos \theta d_{pq} / c}GCC那篇文章已经提过，对$\theta \in [0, \pi]$进行采样，上述结果被称为augular spectrum。在这里，$\text{SRP}_\text{out}(t, \theta)$亦然。 根据式$(5)$，如果已经有了GCC（-PHAT）的实现，得到对应的SRP（-PHAT）并不难，做一次遍历即可： 123456789aug = zeros(num_frames, num_doa);for p = 1: num_chs for q = 1: num_chs d = topo(p) - topo(q); tau = linspace(-d / c, d / c, num_doa); aug = aug + gcc_phat(Sx(:, :, p), Sx(:, :, q), tau, fs); endend 由于SRP的计算涵盖了所有可能组合的GCC值，因此，得到的结果相比GCC稳定性更高，比如4麦的线阵，我对比GCC-PHAT（channel 1, 4）的augular spectrum和SRP-PHAT的结果如下： GCC-PHAT SRP-PHAT 图中黄色的斑点表示值大的区域，不难看出，后者augular spectrum的peak点更加明显，非peak区域的数值分布也相对平稳，因此在后处理进行DoA决策的时候，往往可靠性更高。 如果是单一说话人，且说话较为连续时，往往只需要沿时间轴做个平均，之后找到峰值对应的DoA即可。如果涉及到多个说话人，存在背景噪声，且说话不连续的情况，那么角度谱显示的信息就相对较多，比如说话人数量，说话区间，噪声区间等等，此时，如何利用这些信息进行鲁棒的后处理就显得尤为关键。]]></content>
      <tags>
        <tag>Microphone Array Processing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mask Based Methods]]></title>
    <url>%2F2018%2F05%2F26%2Fmask-methods%2F</url>
    <content type="text"><![CDATA[嗯，现在正式结合着我自己的实践，开讲mask在Speech Enhancement中的应用。 开门见山，本文主要focus下面三点： mask的定义 mask的估计 mask的使用 Introduction to mask在一个存在加性噪声的场景下，我们观测到信号可以写成如下形式： y(t) = x(t) + n(t)对上式变换到短时频域，有： \mathbf{Y}(t, f) = \mathbf{X}(t, f) + \mathbf{N}(t, f)这里的每个时频点在文献中常常被称为一个T-F bin。如果给每个bin关联一个mask值，那么，就可以根据形成的mask矩阵$\mathbf{M} \in R^{T \times F}$，抽取到一个信号成分，即： \mathbf{Y}_m = \mathbf{Y} \odot \mathbf{M}在这里，考虑一种简单的情况，即对于相对干净的音频，如果以每一帧的能量作为阈值判断，设置$\mathbf{M}_t = {\mathbf{0}, \mathbf{1}}$，那么，此时的mask其实就起到了一个VAD的作用。 回到原题中去，频域中，每个T-F bin上的值落在复数域，如果仅仅从幅值的角度考虑，我们需要恢复出$|\mathbf{X}|$，mask矩阵应该如下计算： \mathbf{M} = \frac{|\mathbf{X}|}{|\mathbf{Y}|} = \frac{|\mathbf{X}|}{|\mathbf{X}| + |\mathbf{N}|}在这种情况下$\mathbf{M}(t, f) \in [0, 1]$，被称为IRM（ideal ratio mask），也是如今最常见的一种mask之一。在IRM之前，传统信号处理往往认为每个T-F bin只是独立的属于某一成分，比如以信噪比来看，认为高于阈值$\delta$的bin属于语音信号，由此，T-F mask成为一个非0即1的量，称为IBM（ideal binary mask），如下 \mathbf{M}(t, f) = \begin{cases} 1 \quad \text{SNR} > \delta \\ 0 \quad \text{others} \end{cases}但是，如今在NN框架中的mask常常被用来当做网络训练的target，因此，如何让网络学得更加鲁棒，更加稳健的掩蔽能力，就成为语音增强的一个方向。一种是设计新的mask，让网络进行学习，比如complex mask，phase sensitive mask等等（都是汪德亮老师他们实验室的杰作），另一方面就是设计新的训练方法，应用新的网络结构，比如GAN，T-S结构等等。 继续本文之前，先给出IRM和IBM的一个简单的例子，直观的了解一下什么是mask。我以一定的SDR混合spk1和spk2，计算IBM并在T-F bin上做mask，结果如下（简单处理，$\delta = 0$），第一行的图为原始的speaker语谱，第二行为对应的IBM，两者互补，最后一行是在T-F域上做mask的结果。 由于IBM非零即1，因此，oracle的处理结果在语谱上看的比较别扭，实际中用IBM训练的网络推断时加入sigmoid函数，使得输出在0和1之间，因此掩蔽的效果不会像上图这样，和IRM比较类似。IRM的demo如下，简单期间，将白噪声以一定的信噪比和speech混合： 由上图可以看出，IRM可以很好的反应出原始speech的语谱特征，oracle的掩蔽效果也很完美。 Estimate mask监督学习方法火起来之后，mask的估计就方便很多，一般是数据准备（加噪），计算mask，模型训练，应用评估这四步就完了，下面简单说一下每一步需要注意的地方。 加噪，从实录（noisy）的数据中是无法获得mask信息的（否则你还训模型干啥），因此，数据准备就是要造一批我们知道mask信息的数据，用于网络训练。仅仅是加性噪声的准备非常简单，定义一个信噪比（SNR）范围，从噪声数据库中抽取噪声样本$\mathbf{n}_i$，对原始数据$\mathbf{x}_j$在时域上相加即可： \mathbf{y}_j = \mathbf{x}_j + \sum_i^N \gamma_i\mathbf{n}_i$\gamma_i$根据信噪比得出： \gamma_i = (10^{\frac{-\text{SNR}}{10}} \cdot E_{\mathbf{x}_j}/E_{\mathbf{y}_i})^{0.5} mask计算，这部分不用多说，根据不同mask的定义，根据$\mathbf{x}_j​$和$\mathbf{y}_i​$进行计算即可。 模型训练，分三个点，特征，模型，损失函数。 特征：一般的网络结构和mask而言，输入特征没有什么限制，fbank，lsp，ivector，mfcc以及multi-channel下的一些spatial特征（GCC，SCM，ITD等等）都可以使用。 模型：目前DNN/LSTM/BLSTM结构都可以使用，multi-task，teacher-student结构等等，没有什么十分特别的地方 损失函数：对于IBM，可以当成二分类任务，用binary CE，其余的mask，通常采用MSE进行优化，即： \mathcal{J}= \Vert \mathbf{M}_t - \mathbf{M}_p \Vert_F^2其中$\mathbf{M}_t,\mathbf{M}_p$分别表示target和网络的预测结果，另外一种常用的方式，优化mask的结果$\mathbf{Y}_s \odot \mathbf{M}_p$： \mathcal{J}= \Vert \mathbf{Y}_t - \mathbf{Y}_s \odot \mathbf{M}_p \Vert_F^2$\mathbf{Y}_t$表示clean的target，$\mathbf{Y}_s$表示对应的noisy数据。这种方式得到的mask更加接近于最终我们期望的target，而且，不需要显式的计算mask作为target，得到了广泛的应用。 应用评估，得到了mask模型之后，根据不同的任务，进行不同的性能评估，一般的，通过： \mathbf{x}' = \text{iSTFT}(\mathbf{Y}_s \odot \mathbf{M}_p, \phi)转换到时域，$\phi​$表示相位信息，对于irm/ibm这类不记录相位信息的mask而言，相位采用noisy的结果。下面给出一个网络的预测样例，一般的，如果可以看到比较清晰的共振峰脉络，那么就可以确定网络的学习结果没有什么严重的问题。 得到时域音频之后，识别任务通过WER进行，不过由于增强之后的结果会和原始noisy数据训练的am存在较大的mismatch，因此，用增强的数据进行retrain是十分必要的。增强/分离任务通过PESQ，SNR/SDR等指标判定（但是其往往只能在模拟数据上进行，因为指标的计算需要给出相应的reference）。多通道的情况，mask往往在beamformer中用于channel之间协方差矩阵（covariance matrix）的估计（具体参见本文第三部分）。需要提一下，multi-channel情况下，模型对每一个channel都会给出一个mask预测，一般会对这些mask进行average/median等操作来获得一路mask，带入beamformer。 注：mask这个东西和传统信号处理中的一个概念十分相似，叫做SPP（speech presence probability），有兴趣的读者可以查阅一下传统的方法如何进行SPP的估计的。 从上面的第四点也可以看出，mask的应用不仅仅在于single channel processing，也广泛存在于multi-channel的场景下。DL方法诞生之前，如果可以获取多通道的数据，那么mask可以通过NMF，TF-clustering等方法等获得，下面以NTT比较新的CGMM方法，介绍一下TF-clustering的思路。 CGMM可以参考如下两篇论文 [1]. Higuchi, Takuya, et al. “Online MVDR beamformer based on complex gaussian mixture model with spatial prior for noise robust ASR.” IEEE/ACM Transactions on Audio, Speech, and Language Processing 25.4 (2017): 780-793. [2]. Higuchi, Takuya, et al. “Robust MVDR beamforming using time-frequency masks for online/offline ASR in noise.” Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on. IEEE, 2016. 假设现有$M$路信号（即一个$M$麦的阵列）$\mathbf{Y}$，target成分$K + 1$（$K$个speaker，1个噪声成分），其中 \mathbf{Y} = [\mathbf{Y}_1, \mathbf{Y}_2, \cdots, \mathbf{Y}_M], \;\mathbf{Y}_m \in \mathbf{C}^{F \times T}TF-clustering需要引入一个先验，比如在CGMM里面，假设target成分$k$的每个T-F bin服从均值为0，方差为$\phi_{ft}^k$的Complex Gaussian分布，即： \mathbf{X}_k(f, t) = x_{ft}^k \sim \mathcal{N}_c(0, \phi_{ft}^k)令$\mathbf{r}_f^k \in \mathbf{C}^{M \times 1}$表示第$k$个目标成分到每个麦克风，在频率$f$处的响应，将每个T-F bin上，所有channel形成的观测向量称为$\mathbf{y}_{ft}$： \mathbf{y}_{ft} = [\mathbf{Y}(f, t)_1, \mathbf{Y}(f, t)_2, \cdots, \mathbf{Y}(f, t)_M]那么有： \mathbf{y}_{ft} = \sum_k \mathbf{r}_f^k x_{ft}^k =\sum_k \mathbf{y}_{ft}^k其中$\mathbf{y}_f^k = \mathbf{r}_f^k x_{ft}^k​$，根据$x_{ft}^k​$的分布，有： \mathbf{y}_{ft}^k \sim \mathcal{N}_c(0, \phi^k_{ft}\mathbf{R}_f^k), \; \mathbf{R}_f^k = \mathbf{r}_f^k(\mathbf{r}_f^k)^H$\mathbf{y}_{ft}$用$K + 1$个成分的Complex Gaussian Mixture Model（CGMM）建模： \mathbf{y}_{ft} \sim \sum_k \alpha_f^k \mathcal{N}_c(0, \phi^k_{ft}\mathbf{R}_f^k)，\; \sum_k \alpha_f^k = 1如果成功的估计了上式中的$\alpha_f^k, \phi_{ft}^k, \mathbf{R}_f^k$，那么，target $k$的mask $m_{ft}^k$可以通过： m_{ft}^k = \frac{\alpha_f^k \mathcal{N}_c(\mathbf{y}_{ft}|0, \phi^k_{ft}\mathbf{R}_f^k)}{\sum_k \alpha_f^k \mathcal{N}_c(\mathbf{y}_{ft}|0, \phi^k_{ft}\mathbf{R}_f^k)}计算得到，之后的事情就行用EM算法估计这三个参数量了，这部分可以参考原始论文，这里不做赘述。 这种在时频域进行聚类的方法有一个严重的问题就是permutation problem（置换问题），这里解释一下：在进行EM过程中，每个频点是完全独立的进行迭代（实现的时候，对频域进行一次扫描，每个频点上独立的进行EM算法估计），因此，不能保证在频率$f_1, f_2$处，$m_{f_1 t}^k$和$m_{f_2t}^k$对应同一个目标成分（比如初始化的原因，可能造成两者的进化方向不同），这就是所谓的置换问题，需要专门的后处理算法解决，将每个频点的mask进行对齐。 假设只有一个target，那么后处理的方式简单很多，正确的初始化也可以解决置换问题，比如论文中建议的，采用单位矩阵初始化$\mathbf{R}_f^n$，观测信号channel之间的协方差矩阵初始化$\mathbf{R}_f^s$，在实践中表现的较好。我的实现最终版本未做后续处理，也取得了不错的结果。下面给出一个CGMM方法估计出的mask，我们可以从中清晰的看出语谱（target speech）的脉络。 我的实现在cgmm-mask-estimator，感兴趣的看观可以参阅一下。 Using mask第二部分也提到了一些，得到mask之后，如何使用，主要取决于自己的任务（实际上这一点在表明需要mask之前就应该已经明确）。目前我接触的主要是两点： 去除噪声/语音分离： 在T-F域上，将target mask和观测信号做Hadamard Product，之后配合相位信息做iSTFT即可。iSTFT一般用overlap add算法实现。 \mathbf{x}' = \text{iSTFT}(\mathbf{Y}_s \odot \mathbf{M}_p, \phi) Adaptive beamformer的相应target的相关矩阵估计 主要看使用什么beamformer了，相关矩阵的估计方法上面也已经提到： \mathbf{R}^k_f = \frac{1}{\sum_t m_{tf}^k}\sum_t m_{tf}^k \mathbf{y}_{tf}^k(\mathbf{y}_{tf}^k) ^H \in \mathbf{C}^{M \times M} ConclusionTF-mask被研究的时间比较久了，目前在很多地方都可以看到它的身影，比如single channel的分离任务上，uPIT，DAnet等等都有mask相关的东西在里面。传统的BSS方法，很多也是构建生成模型，在T-F bin上做clustering的思路。目前来看，新的mask类型和应用点也还有产生（比如结合NMF和mask），感兴趣的可以关注一下汪德亮老师的实验室主页，前端的一些论文，包括speech separation/enhancement, beamforming在内，以及在CHiME数据集上的一些实验结果和探索。]]></content>
      <tags>
        <tag>Speech Enhancement</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Beam Pattern]]></title>
    <url>%2F2018%2F05%2F12%2Fbeampattern-and-fixed-beamformer%2F</url>
    <content type="text"><![CDATA[在看前端方面的论文的时候，一定会遇到beam pattern这个概念，本篇文章主要讲述beam pattern的意义，应用以及可视化方面的东西。 beamformer很重要的一个性质就是它的指向性，指向性可以反映波束形成器对每个方向的信号，哪些频率进行增强，哪些频率进行抑制。如果可以准确的估计出DoA的话，增强声源方向的信号，抑制其他方向，就成为了beamformer的主要任务。 根据上述表述，beamformer要想表现的完美，准确的DoA不可或缺。如果可以实时的根据信号环境调整DoA，那么在工作中，beamformer的指向性便会发生改变，这种波束形成器被称为adaptive beamformer。反之，如果固定其指向性，在工作中只增强事先设定的方向信号，便被称为fixed beamformer。反映到beam weights上，如果beam weights被计算出并保持不变，对应后者，如果有声学环境的参数掺杂在其中，或者不断的update DoA，则对应前者，比如MVDR，PMWF，Max-SNR等等。 上篇文章中也提到了，用NN做前端，一般用mask模型估计adaptive beamformer中target的协相关/功率谱密度矩阵，并用其最大特征向量来估计steer vector。我们更加在意系统最终对WER或者PESQ，SDR，SNR等等（根据任务不同）的贡献，而不会刻意的去分析其指向性。这种不涉及麦克风拓扑结构，不涉及声源信息的方法称为Blind方法。 Beam Pattern现在做如下定义：存在$M$个麦克风的线阵中，第$i$个麦克风相对第一个的距离为$d_i(d_0 = 0, d_i &lt; d_j \;\text{if} \; i &lt; j)$，如果DoA为$\theta(\theta \in [0, \pi])$，声速为$c$，那么，第$i$个麦克风相对第一个的延时$\tau_i$定义为： \tau_{\theta i} = \frac{\cos(\theta)d_i}{c}以MVDR为例，已知相对延迟$\tau$，beam weights由下式得出： \mathbf{w}(\omega) = \frac{\mathbf{R}_{vv}^{-1}(\omega) \mathbf{d}_\tau(\omega)}{\mathbf{d}_\tau^H(\omega)\mathbf{R}_{vv}^{-1} (\omega)\mathbf{d}_\tau(\omega)}其中： \mathbf{d}_\tau = [e^{-j\pi \omega\tau_0}, e^{-j\pi \omega\tau_1}, \cdots, e^{-j\pi \omega\tau_{M - 1}}]^T如果我们想要分析在该$\mathbf{w}, \mathbf{w} \in \mathbf{C}^{F \times M}​$下，beamformer对任意方向信号的作用，就可以借助beam pattern进行。 令$Z \in \mathbf{C}^{F \times T}$为beamformer输出的信号，那么有（详细见文章“Overview of beamformer”）： Z(\omega) = \mathbf{w}(\omega)^H \mathbf{y}(\omega)其中$\mathbf{y} = [Y_0, Y_1, \cdots, Y_{M-1}] \in \mathbf{C}^{F \times M \times T}$。 把假设DoA为$\theta$下计算的beam weights表示为$\mathbf{w}(\omega, \theta)$： \mathbf{w}_\theta(\omega) = \frac{\mathbf{R}_{vv}^{-1}(\omega) \mathbf{d}_\theta(\omega)}{\mathbf{d}_\theta^H(\omega)\mathbf{R}_{vv}^{-1}(\omega) \mathbf{d}_\theta(\omega)}$\mathbf{d}_\phi​$表示DoA为$\phi​$时的steer vector： \mathbf{d}_\phi = [e^{-j\pi \omega\tau_{\phi 0}}, e^{-j\pi \omega\tau_{\phi 1}}, \cdots, e^{-j\pi \omega\tau_{\phi{M - 1}}}]^T考虑到 \mathbf{y}(\omega) = \mathbf{d}_\phi(\omega) X(\omega) + \mathbf{v}(\omega)那么在beam weights为$\mathbf{w}(\omega, \theta)$下，有 Z(\omega) = \mathbf{w}_\theta(\omega)^H \mathbf{y}(\omega) = \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega) X(\omega) + \mathbf{w}_\theta(\theta)^H\mathbf{v}(\omega)把上式中$X(\omega)$的系数称为beam pattern $\mathcal{B}(\omega, \phi)$： \mathcal{B}(\omega, \phi) = \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega)从这里可以看出，beam pattern是频率$\omega​$和DoA $\phi​$的函数，$\mathcal{B}(\omega, \phi)​$越大，表示对应方向上和频率处的信号增益越大。也就是说，通过beam pattern我们可以看出一组空间滤波器在方位轴和频率轴上的表现。这是分析滤波器性能的一个很方便的手段。 Fixed Beamformer Design根据beam pattern的定义，我们可以由$\mathcal{B}(\omega, \phi)$反推$\mathbf{w}_\theta(\omega)$。 假设我们想要增强$\theta$方向的信号，对应的在beam pattern中反映的应该是$\delta \in [\theta - \epsilon,\theta +\epsilon ]$处的beam pattern较大。将其作为beam weights的target，在频率$\omega$处，令： \mathcal{B}_{\text{target}}(\omega, \delta) = 1现在，想要求出$\mathbf{w}_\theta(\omega)​$，使得 $ \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega)​$的结果接近$\mathcal{B}_{\text{target}}​$，转化为下面的优化问题： \mathbf{w}_\theta(\omega) = \arg \min_{\mathbf{w}_\theta(\omega)} \Vert \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega) - \mathcal{B}_{\text{target}}(\omega) \Vert_2^2$\mathbf{d}_\phi(\omega) $的定义和上一部分相同，表示假设DoA为$\phi$时，算出的steer vector矩阵。和MVDR一样，需要限制DoA方向的语音不失真，即： \mathbf{w}_\theta(\omega)^H\mathbf{d}_\theta(\omega) = 1求解上述问题即可得到指向$\theta$方向的beam weights。不过这样求出的beam weights在低频处权值很大，往往上百上千，beamforming之后，低频信号放大的很厉害。通过加入WNG（白噪声增益，White Noise Gain）约束可以缓解这种情况的发生。 WNG定义如下： A(\omega) = \frac{|\mathbf{w}_\theta(\omega)^H\mathbf{d}_\theta(\omega)|^2}{\mathbf{w}_\theta(\omega)^H\mathbf{w}_\theta(\omega)}约束$A(\omega) \geqslant \gamma$可以改写为： \mathbf{w}_\theta(\omega)^H\mathbf{w}_\theta(\omega) = \Vert\mathbf{w}_\theta(\omega) \Vert_2^2 \leqslant 1/\gamma通常设置$20 \log10(\gamma) = 0, -10 \text{dB}$。 因此，Fixed Beamformer的设计流程如下： 根据DoA，定义$\mathcal{B}_{\text{target}}(\omega, \delta)$。 求解凸优化问题： \begin{align} \mathbf{w}_\theta(\omega) &= \arg \min_{\mathbf{w}_\theta(\omega)} \Vert \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega) - \mathcal{B}_{\text{target}}(\omega) \Vert_2^2 \\ & \text{s.t} \quad \mathbf{w}_\theta(\omega)^H\mathbf{d}_\theta(\omega) = 1, \; \Vert\mathbf{w}_\theta(\omega) \Vert_2^2 \leqslant 1/\gamma \end{align} 分析$\mathcal{B}(\omega, \phi) = \mathbf{w}_\theta(\omega)^H\mathbf{d}_\phi(\omega)$验证 Visualize Beam Pattern将$\theta = 60^\circ$时的$\mathcal{B}(\omega, \phi)$整体绘制，纵轴表示DoA，横轴表示频率 黄色区域表示响应越大，即这个部分的语音gain越多，可以看出，60度方向，全频带范围内gain值都很高，和设计初衷相符。如果固定频率比如5kHz，画出极坐标图，可以得到下面的图（图的幅值方向单位为dB）： 在信号处理中，$\mathbf{w}_\theta(\omega)$可以准确的求出，因此，beam pattern是可以求出解析的表达式的，那么往往喜欢用极坐标图的形式显示。 总结下来，这种套路应该是信号那边常见的方法，将beam weights的设计转为凸优化问题进行求解。实际应用中，不同DoA下设计的weights作用在相同的输入上，结果应该会有明显的不同。 另外，需要注意$\omega \in [0, 2 \pi]$这个量，角频率，和频率$f$的关系是： \omega = 2\pi fDFT中，时域，频域采样数相同，设为$N$，$f$为信号的采样频率，那么 \omega_k = 2 \pi \frac{kN}{T} = 2\pi f_k，f_k = \frac{kN}{T} = 2\pi f \quad 0 \leqslant k < N在短时域中，考虑DFT的共轭对称性，只保留前$\frac{N}{2} +1$个点，即$0 \leqslant k \leqslant \frac{N}{2} +1$。 具体编程实现的时候，需要注意它们之间的转换关系。]]></content>
      <tags>
        <tag>Microphone Array Processing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TDOA - GCC-PHAT方法]]></title>
    <url>%2F2018%2F05%2F10%2Fgcc-phat-for-tdoa-estimate%2F</url>
    <content type="text"><![CDATA[TDOA（Time Difference of Arrival，到达时间差）是一个在语音前端信号处理中很常见的名词，和它比较相像，也同样重要的还有一个DOA（Direction of Arrival，到达方向）。在麦克风拓扑结构已知的情况下，两者可以相互转换。TDOA表示不同通道之间语音信号的延迟程度，是一个相对的概念，一般用$\tau$表示。最简单的beamforming方法delay and sum中的delay针对的就是它。DOA表示信号源相对麦克风的到达角度，一般用$\theta$表示，如果是线阵的话，范围在0到180度之间。如下图所示，假设麦克风1和麦克风2之间的距离为$\delta$，DOA为$\theta_d$，声速$c$，那么$\tau_{12}$可以有简单的数学计算得到： \tau_{12} = \frac{\cos\theta_d \cdot \delta}{c}那么DOA/TDOA这个信息怎么用呢？个人觉得可以从下面几个角度理解： 如果目标声源只有一个，外加一些环境噪声，那么TDOA可以用来指导beamformer对该方向的信号进行增强。 如果存在多个说话人，且说话人的方位不同，比如圆桌会议这种，那么： 估计的TDOA的数目可以认为是说话人的数量（speaker counting） 通过跟踪TDOA的变化，追踪特定的说话人 对同一段语音，对估计的DOA方向进行增强，增强说话人 当然现实可能不会这么理想，如果说话人距离较远，说话人方向重合，以及环境复杂（噪声，混响）情景下，都会使得估计方法失效或者beamformer不理想等等。鸡尾酒会问题确实是语音这块一个非常难啃的骨头。现在学术界比较流行的一种Blind的方法就是在不知道声源信息和阵列拓扑的情况下，通过一些先验，或者概率模型估计beamforming中的统计量进行计算，我做过的有CGMM，NN-mask+MVDR/GEV等等，在一些数据集上（比如CHiME4）也取得了很好的效果。 在这里我主要说一个最简单的TDOA估计方法，GCC-PHAT。 首先说一下互相关（CC，Cross-Correlation）。信号处理中，互相关可以用来描述两个信号之间的相似性。离散信号$x_k, y_k$的互相关函数定义为： R^{xy}_\tau = E[x_k y_{k + \tau}] = \sum_k x_k y_{k+\tau}从上式可知，CC是相对延时$t​$的一个函数，显然，可以取使得互相关系数最大的延时值作为TDOA的估计，即： \tau = \arg \max_\tau R^{xy}_\tau现在普遍认为，这种算法在实际中容易受到噪声和混响的影响，表现不是很稳定，因此引入了广义互相关的概念（GCC，Generalized Cross-Correlation）。和CC一样，TDOA通过获得最大化GCC函数的延迟值得到： \mathbf{\tau} = \arg \max_{\tau} \widehat{R}^{xy}_\tau其中$\widehat{R}^{xy}_t ​$定义为generalized cross-spectrum的IDTFT： \widehat{R}^{xy}_\tau = \mathcal{F}^{-1}[\gamma_f \cdot \phi^{xy}_f ]$\gamma_f$为频域的权重方程，$\phi_f^{xy}$表示cross-spectrum，定义为$E[X_fY_f^*]$，$*$表示共轭。如果将$\gamma_f$定义为$\frac{1}{|\phi_f^{xy}|}$，那么这种估计方法称为为GCC-PHAT。PAHT表示phase transform，因为做了幅值的归一化之后，相当于只留下了相位信息。 语音信号处理中，我们通常在短时频域上进行。在每一帧上，进行一次$\widehat{R}^{xy}_\tau$计算，可以得到所谓的angular spectrogram： \varPsi_{\tau t} = \sum_f \overline{H_{tf}} e^{j2\pi f\tau}其中$H_{tf} = X_{tf} \odot Y_{tf}^*$，$\overline{H_{tf}}$表示做幅值归一化。实际计算中，构建矩阵$\varOmega \in R^{\varTheta \times F}$，使得 \varOmega_{\tau f} = e^{j2\pi f\tau}之后计算矩阵乘法$\varPsi =\overline{H} \varOmega$即可。下面贴一段我写的可视化angular spectrogram的程序，旨在说明计算逻辑： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#!/usr/bin/env python# coding=utf-8# wujian@2018import argparseimport globimport numpy as npimport matplotlib.pyplot as pltimport utilsspeech_speed = 340.29distance_of_mic = 1samp_frequency = 16000def compute_stft(wave_path, frame_length, frame_shift): wave_samp = utils.audio_read(wave_path) return utils.stft(wave_samp, frame_length, frame_shift)def compute_angspect(coherence, num_tdoa): """ coherence: num_bins x num_frames return num_tdoa x num_frames """ # num_bins x num_toda num_bins, num_frames = coherence.shape max_tdoa = distance_of_mic / speech_speed # from 0 to 180 est_tdoa = np.linspace(-max_tdoa, max_tdoa, num_tdoa) sep_freq = np.linspace(0, samp_frequency / 2, num_bins) # num_tdoa x num_bins exp_part = np.outer(2j * np.pi * est_tdoa, sep_freq) return np.dot(np.exp(exp_part), coherence).realdef run(args): stft = [compute_stft(wave, args.frame_length, args.frame_shift) for wave in sorted(glob.glob(args.pattern))] assert len(stft) == 2, 'Check pattern &#123;&#125; please'.format(args.pattern) coherence = stft[0] * stft[1].conj() / (np.abs(stft[0]) * np.abs(stft[1])) angspect = compute_angspect(coherence， args.num_tdoa) angspect[angspect &lt; 0] = 0 plt.subplot(211) plt.ylabel('TDOA index') plt.xlabel('Frame index') plt.title('GCC-PATH Angular Spectrogram') plt.imshow(angspect, cmap=plt.cm.binary, aspect='auto', origin='lower') plt.subplot(212) plt.ylabel('Frequency index') plt.xlabel('Frame index') plt.title('Log-Magnitude Spectrogram') plt.imshow(np.log(np.abs(stft[0])), cmap=plt.cm.jet, aspect='auto', origin='lower') plt.show()if __name__ == '__main__': parser = argparse.ArgumentParser(description="Command to compute angular spectrogram using GCC-PHAT methods") parser.add_argument('pattern', type=str, help='location of 2-channel wave files') parser.add_argument('--num-of-tdoa', type=int, default=128, dest="num_toda", help='Number of todas to estimate') parser.add_argument('--frame-shift', type=int, default=256, dest="frame_shift", help='Frame shift in number of samples') parser.add_argument('--frame_length', type=int, default=1024, dest="frame_length", help='Frame length in number of samples') args = parser.parse_args() run(args) 注：程序无法完整运行，utils.py我未给出。 在一些比较理想或者simulate的数据下，这种方法work的很好，这部分例子可以参见“Blind Speech Separation and Enhancement With GCC-NMF ”这系列论文以及github。实际的数据中，表现还是差强人意的，我在实录的数据上只在部分条件下（比如说话人距离麦克风较近等等）可以提供较为准确的TDOA估计信息。比如下面几种情况： 上图中的angular spectrum中在index-80的位置，在时间轴上出现几段较为明显的峰值，由此可以得到以下信息： 峰值出现的所在的index即为估计的最佳TDOA索引。 峰值不连续处表示该说话人尚未说话（起到类似VAD的作用）。 峰值所对应的index分布向着90处移动，说明该说话人可能相对麦克风在移动。 如果在不同index处，同时出现峰值，那么就说明存在多个说话人，比如下面这种情况，可以认为在这段语音中，可能存在三个说话人。 GCC-PHAT方法的局限性还表现在仅仅只能依据两路信号进行估计。如果现在有多路麦克风，那么就需要在原有算法的基础上进行改进。这部分由于我还没有具体的实践，暂时无法继续深入。 之前也提到过，Blind的方法目前已经摆脱对具体TDOA/DOA的依赖的，以MVDR beamformer为例子，往往会用noise的协相关矩阵的最大特征值作为steer vector的估计。而在传统的信号处理中，TDOA是形成steer vector不可或缺的一个因素，假如已经计算出相对延迟序列$\tau_1, \tau_2, \cdots, \tau_{N-1}$，那么steer vector为： \mathbf{d}_{\theta} = [1, e^{j\omega \tau_1}, e^{j\omega \tau_2}, \cdots, e^{j\omega \tau_{N-1}}]在beamformer设计中很重要的一个东西是beam pattern，在我们做Blind Source Separation/Enhancement的时候，往往会忽视这个分析手段，只看重最终的WER，在后面我会开一篇文章，介绍使用TDOA进行beamformer，以及使用beam pattern进行分析的方法。什么时候更呢……等哪天准备工作做得充分了吧。]]></content>
      <tags>
        <tag>Microphone Array Processing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Speech Separation - NMF methods]]></title>
    <url>%2F2018%2F05%2F06%2Fspeech-separation-nnmf%2F</url>
    <content type="text"><![CDATA[最近在看一些语音分离的文章，时间旧了，需要做一些总结。这篇文章先说一种传统而有效的方法，NMF（非负矩阵分解）。 将一个矩阵$\mathbf{V}$分解成两个非负矩阵的乘积形式，这种方法就叫非负矩阵分解，数学表达为： \mathbf{V} \approx \mathbf{W} \mathbf{H}若$\mathbf{V} \in \mathbf{R}^{F \times T}$，那么$\mathbf{W} \in \mathbf{R}^{F \times D}, \mathbf{H} \in \mathbf{R}^{D\times T}$，其中$D$为分解过程的一个超参数，在一些文献中，$\mathbf{W}$被称为dictionary或者basis functions，$\mathbf{H}$被称为atoms或者activations，这种称呼的原因会在后文中解释。 下面将从三个方面认识这个概念： 如何得到这种表示 这种表示的意义何在 在分离任务中如何应用 NMF有定义可知，虽然NMF的分解形式不唯一，但是最终得到的结果，需要尽量降低和原始矩阵的误差（否则恢复不过来，失去意义了），定义$D(\mathbf{V}|\mathbf{WH})$表示误差函数，那么我们要求解的问题就表示为： \mathbf{W},\mathbf{H} = \arg \min_{\mathbf{W}, \mathbf{H}} \mathcal{D}(\mathbf{V}|\mathbf{\Lambda})其中$\mathbf{\Lambda} = \mathbf{WH}$。$\mathcal{D}$不唯一，可以根据任务不同分别定义，如欧式距离，KL散度等等，目前文献中常用$\beta$-divergence统一描述如下 \mathcal{D}_\beta(\mathbf{V} | \mathbf{\Lambda}) = \begin{cases} \frac{\mathbf{V}}{\mathbf{\Lambda}} - \log \frac{\mathbf{V}}{\mathbf{\Lambda}} - 1 & \beta = 0\\ \mathbf{V} (\log \mathbf{V} - \log \mathbf{\Lambda} ) + \mathbf{\Lambda} - \mathbf{V} & \beta = 1\\ \frac{\mathbf{V}^\beta - \mathbf{\Lambda}^\beta -\beta \mathbf{\Lambda}^{\beta - 1}(\mathbf{V} - \mathbf{\Lambda})}{\beta(\beta - 1)} & \beta \in (0, 1) \end{cases}定义$\mathbf{D}_\beta$之后，$\mathbf{W}$，$\mathbf{H}$的求解通过如下迭代的方式进行： \mathbf{H} \leftarrow \mathbf{H} \odot \frac{\mathbf{W}^\top(\mathbf{V}\odot \mathbf{\Lambda}^{\beta -2})}{\mathbf{W}^\top\mathbf{\Lambda}^{\beta -1}} \\ \mathbf{W} \leftarrow \mathbf{W} \odot \frac{(\mathbf{V}\odot \mathbf{\Lambda}^{\beta -2})\mathbf{H}^\top}{\mathbf{\Lambda}^{\beta -1}\mathbf{W}^\top} \\很多时候，我们期望$\mathbf{H}$的具有较高的稀疏程度，因此，$\mathcal{D}$中常常出现关于$\mathbf{H}$的正则项： \mathbf{W},\mathbf{H} = \arg \min_{\mathbf{W}, \mathbf{H}} \mathcal{D}(\mathbf{V}|\mathbf{\Lambda}) + \mu |\mathbf{H}|_1其中$|\cdot|_1$表示$L_1$范数。在这种情况下，需要修正矩阵的更新公式，一种简单的处理方式是保持$\mathbf{W}$的更新法则不变，$\mathbf{H}$更新的分子加上正则系数$\mu$： \mathbf{H} \leftarrow \mathbf{H} \odot \frac{\mathbf{W}^\top(\mathbf{V}\odot \mathbf{\Lambda}^{\beta -2})}{\mathbf{W}^\top\mathbf{\Lambda}^{\beta -1} + \mu}这种NMF在文献[1]中被称为NMF+S（NMF with Sparsity)而非SNMF(Sparse NMF)，后者修正的$\mathbf{W}$的更新公式，且在分离任务中表现优于前者。讨论可以详细参考原始论文，这里不做过多叙述。 NMF历史悠久，实现方便，在MATLAB，sklearn等工具中均有实现，论文[1]也开源了SNMF的MATLAB代码，可以通过链接下载。 在语音信号处理中，NMF通常用于对信号的频谱进行分解，如下，图（2，1）表示原始的频谱，图（1，2）为NMF近似的结果，使用MERL的SNMF工具，参数配置$\beta = 1, \mu = 5, D = 64$。 如果用MATLAB中的nnmf方法，在相同的配置下，结果如下： 可以看出，SNMF估计的$\mathbf{H}$矩阵稀疏性更高。 如何理解关于表达式： \mathbf{V} = \mathbf{WH}我们可以换一种写法，即： \mathbf{V} = \begin{bmatrix} \mathbf{v}_1, \mathbf{v}_2, \cdots, \mathbf{v}_T \end{bmatrix} = \mathbf{W} \begin{bmatrix} \mathbf{h}_1, \mathbf{h}_2, \cdots, \mathbf{h}_T \end{bmatrix}$\mathbf{v}_i, \mathbf{h}_i$表示各自矩阵中第$i$列的列向量。对于$\mathbf{v}_i$，有： \mathbf{v}_t = \mathbf{W} \mathbf{h}_t = [\mathbf{w}_1, \mathbf{w}_2, \cdots, \mathbf{w}_D] \mathbf{h}_t = \sum_{d = 0}^{D - 1} \mathbf{w}_d \cdot h_{td}上式表明，$t$时刻的频谱，可以表示为$\mathbf{W}$矩阵列向量的线性组合，组合系数为$\mathbf{H}$矩阵的第$t$列。也就是说，NMF会将原始矩阵分解成一组非负的向量组，和对应的一组非负权值。理解这点对于理解NMF在语音分离中的应用比较重要。 另外一点需要提到，一般情况下，设置的$D$值小于$T$值，既然$\mathbf{W}$具有描述原始矩阵的性质，那么可以视其为一组具有非负性的特征向量。我们希望使用少数的特征向量就可以表示原始矩阵，一方面可以减少向量之间的相关性，避免冗余，一方面为了计算，存储的高效性。 另外，有时我们会看到如下定义： \mathbf{V} = \sum_{c}\mathbf{W}_c \mathbf{H}_c即几组$\mathbf{W}$和$\mathbf{V}$矩阵的乘积和，典型的比如语音分离任务中。这种形式依旧可以规整成上面的原始表示形式，如下： \mathbf{V} = \sum_{c}\mathbf{W}_c \mathbf{H}_c = [\mathbf{W}_1, \mathbf{W}_2, \cdots, \mathbf{W}_C] \begin{bmatrix} \mathbf{H}_1 \\ \mathbf{H}_2 \\ \cdots \\ \mathbf{H}_C \\ \end{bmatrix}语音分离：NMF方法在比较理想的情况下，混合语音信号$\mathbf{S}$由多路信号相加表示： \mathbf{S} = \sum_c \mathbf{S}_c对$\mathbf{S}_c$做NMF，有： \mathbf{S} = \sum_c \mathbf{S}_c = \sum_c \mathbf{W}_c \mathbf{H}_c = \widetilde{\mathbf{W}} \widetilde{\mathbf{H}}若$\widetilde{\mathbf{W}} \widetilde{\mathbf{H}}$可被估计，那么，可以下式分离出对应的语音信号： \mathbf{S}'_c = \frac{\mathbf{W}_c \mathbf{H}_c}{\widetilde{\mathbf{W}} \widetilde{\mathbf{H}}} \odot \mathbf{S}supervised NMF方法中，分为训练阶段和测试阶段。训练阶段需要单一说话人的监督数据，用来得到说话人的特征集合$\widetilde{\mathbf{W}} $，测试阶段，将其作为初始$\mathbf{W}$进行NMF，过程中只训练$\mathbf{H}$。收敛之后，用上式做说话人分离。 有一点需要注意，就是测试的时候可以将句子分block进行，类似于声学模型中的拼帧。分离的结果只保留中间位置的帧即可。主要是希望利用picth和vocal在时间轴上的局部相似性，获取更好的分离效果。 我进行了Oracle-NMF作实验验证上述流程，之所以称之为Oracle，是因为我直接从$\mathbf{S}_c$中学习speaker的特征矩阵，将他们进行concat作为NMF中的初始化，得到$\mathbf{H}$进行分离，而非从该说话人的其他说话语料中进行。 实验使用MERL实现的SNMF，数据为wsj0的2spk混合数据（用的Deep Clustering的混合程序，生成16k数据），拼左右4帧，帧长和帧移为64ms，16ms。我可视化几个样例结果如下： 从语谱图上可以看出，结果还是比较理想的。下面这个两个例子可以看出，在silence段，NMF的表现也不差。 参考文献[2]中也使用了NMF，不过整体思路非上面所述，后期我会更一版GCC-PHAT，在那里简单讨论一些它的想法。 Reference[1]. Le Roux J, Weninger F J, Hershey J R. Sparse NMF–half-baked or well done?[J]. Mitsubishi Electric Research Labs (MERL), Cambridge, MA, USA, Tech. Rep., no. TR2015-023, 2015. [2]. Wood S U N, Rouat J, Dupont S, et al. Blind speech separation and enhancement with GCC-NMF[J]. IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP), 2017, 25(4): 745-755.]]></content>
      <tags>
        <tag>Speech Separation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SETK - Speech Enhancement Tools based on Kaldi]]></title>
    <url>%2F2018%2F04%2F14%2Fsetk-speech-enhancement-tookit%2F</url>
    <content type="text"><![CDATA[趁着最近手头上的事比较少，想把自己前段时间的事情总结一下，由于目前主流的开源识别项目Kaldi前端支持较差，我闲着没事干，把前期做的一些事情迁移到Kaldi上来。为啥叫做闲着没事呢，因为这些代码用python或者MATLAB实现相比C++真的太简单了（就当是为开源社区做点贡献吧）……不过话说回来，迁移到Kaldi上还是有一点方便的，就是速度，以后做一些验证性的实验或者前端baseline，前后端打通的话，基本做一下数据准备就OK了，省去了很多重新组织代码，脚本的时间。 我前期做的一些事情个人感觉比较简单，主要是基于mask的单通道，多通道增强（此处应有汪大师的一系列论文）。目前想做的工作如下： Different mask computation(binary|ratio|complex|phase-sensitive） CGMM mask estimator on Kaldi STFT-based feature extraction and wave reconstruction Adaptive (MVDR/GEV/GSC) beamformer based on mask or signal methods TDOA estimation algorithm NMF methods on speech enhancement or seperation repo地址kaldi-enhan，目前已经实现和测试完成的部分包括 Compute binary|ratio masks Compute (phase angle/power&amp;magnitude spectrum/complex STFT results) of source wave Seperate target component from source wave according to reference masks Estimate wave from enhanced spectrum and reference wave MVDR/GEV beamformer(based on mask model) 前端实现的核心库操作主要是复矩阵的运算，我目前已经整体搭建起来了，风格同Kaldi的Matrix/Vector Class，内部调用OpenBlas/CLAPACK接口，目前我在OSX和RedHat上已经测试通过。 关于以上的一些工作我一直觉得比较简单没有写Blog，尤其是single channel的部分，后期考虑有时间的话补上。 写于2018.4.14]]></content>
      <tags>
        <tag>Speech Enhancement</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Overview of E2E Methods]]></title>
    <url>%2F2018%2F03%2F13%2Fend-to-end-overview%2F</url>
    <content type="text"><![CDATA[本篇Blog虽然看起来像极了新闻稿，但实际上只是自己想做一个E2E的梳理（顺便交了某课程大作业），毕竟这玩意最近这么火。有一部分论文自己只看个大概，说法未必准确，各位看观小心~。 语音识别（Automatic Speech Recognition，ASR）是要完成输入音频的采样序列到字符序列的映射任务。传统识别模块主要包含声学模型，字典，语言模型三个部分，其中声学模型用于将输入特征转化为声学单元的后验概率，字典用于表示声学单元序列到字符的映射关系，而语言模型则用于表示字符上下文之间的条件概率。由于声学模型的训练需要预知声学单元和输入特征之间的对齐信息，而常见的声学单元，比如CD-state，CD-phone等的时间对齐信息无法直接从抄本中的字符序列中获知。因此，DNN等声学模型的训练需要以传统的HMM-GMM模型进行启动引导，获得帧级别的状态标签，这一步操作称为对齐。也正是由于CD-state之类的建模单元颗粒度太小，无法直接转化成字符级别的输出，因此，需要融合字典，语言模型等信息，信息融合在声学解码器中进行。 因为抄本的长度往往小于特征序列的长度， 所以，实现特征到序列直接映射的核心在于如何处理这种对齐关系。传统的NN-HMM框架正是无法进行这种不等长的序列映射，因此才需要对齐和解码。很显然，我们期望的是一种更加自然的模型结构，可以直接以抄本作为label完成训练，直接以字/词作为输出单元，从而简化训练和解码流程。2012年之后，随着传统声学建模技术的逐渐成熟，国内外学者和研究机构开始基于语音识别这种序列映射的特性，借鉴图像，机器翻译领域的一些成功案例，开始尝试端到端（End-to-End，E2E）的建模方法。 为了保持脉络清晰，本部分会顺着时间线介绍三种比较成熟的端到端的建模方法：CTC[13][14]（Connectionist Temporal Classification）RNN Transducer[12]，Attention[5][9][10]机制及其在声学建模中的应用，中间会穿插一些分析和讨论，帮助理清思路。有些文章中会以Sequence to Sequence（Seq2Seq）的概念表达声学建模中端到端的含义，在这里统一称为E2E。需要注意一点，本节所述方法的输入均为声学特征，并非直接基于原始采样信号（raw waveform）建模。 CTC最早被提出用于E2E训练的是Alex Graves在2006年提出的CTC准则[13]，当时用于处理一些输入和标签不等长的问题中，比如手写识别，语音识别等等。本质上说，CTC只是一个定义在序列上的损失函数，而非一种新的网络模型。传统声学模型是一个分类器，其损失函数交叉熵是一个定义在帧级别上的度量函数，最大化当前标签被分类正确的概率，并不能很好的反映网络输出的序列特性，而CTC将句子级别的对齐信息融合在了损失函数中，通过最大化所有和和抄本对齐序列的概率和，实现E2E的模型训练，这种方式由于包含了显式的对齐计算，后来也常常称之为硬对齐（hard-alignment）。 对齐路径$\mathbf{\pi}$和抄本$\mathbf{y}$和是多对一关系，为了更好的描述这种关系，Graves额外引入了blank标签$\epsilon$的概念，用于隔断不同字符，比如在$T = 5$的约束下，抄本${a,b}$的对齐序列可以是${a\epsilon b\epsilon \epsilon}$，${a\epsilon\epsilon \epsilon b}$，${\epsilon ab\epsilon \epsilon}$等等。用函数$\mathcal{F}$描述$\pi \to \mathbf{y}$映射关系为$\mathcal{F}(\pi) = \mathbf{y}$。若定义输入特征序列$\mathbf{x} = \{\mathbf{x}_1, \mathbf{x}_1, \cdots, \mathbf{x}_T\}$，那么CTC损失准则表达为： \mathcal{L}_{\text{ctc}}(\mathbf{y}|\mathbf{x}) = \sum_{\pi \in \mathcal{F}^{-1}(\mathbf{y})} P(\pi | \mathbf{x})考虑$\pi \in \mathcal{F}^{-1}$的元素呈指数级增长，故在实际中采用动态规划原理，即前向-后向算法计算$\mathcal{L}_{\text{ctc}}$。为了计算$P(\pi | \mathbf{x})$，Graves引入假设：在不同时刻，模型的输出概率相互独立，那么根据条件概率公式，有 P(\pi|\mathbf{x}) = \prod_{t = 1}^T P(y_{\pi}^t | \mathbf{x}_{1 \cdots t})其中$P(y_{\pi}^t | \mathbf{x}_{1 \cdots t})$用RNN的输出层概率表示，需要注意的是，由于引入了blank符号$\epsilon$，实际网络建模中输出层节点需要在原建模单元个数之上加1，比如在TIMIT数据上，61个音素单元的输出层个数应为62。网络训练时，用梯度下降法最小化$-\mathcal{L}_{\text{ctc}}$。2006年Graves提出CTC时，用BLSTM建模获得了30.51%的PER，超越了传统的BLSTM-HMM（33.84%）方法。网络收敛时候，各个符号之间被blank隔断，输出概率分布呈现尖峰特性，因此，通过简单的greedy-search或者beam-search方法即可完成序列解码。 不过，CTC最大的诟病在于Graves为了计算$P(\pi|\mathbf{x})$引入的假设，因为无论从声学特性还是语言模型上说，相邻时刻的输出概率往往是极大相关的，因此，后续的其他方法往往会消除这样的假设。 CTC based SystemCTC被提出之后产生了很多成功的应用案例，结合不断改进的RNN[27]，CNN[32]用于声学建模的思路不断出现，比较典型的算是百度硅谷研究院的Deep Speech[2][16]系列。 Deep Speech 1，2是均以CTC准则构建的端到端识别系统。2014年，Deep Speech 1公布，主体上沿用Graves等人的建模思路，但是在声学模型上做了简化。前三层为使用clipped ReLU（$g(z) = \min \{ \max \{0, z\}, 20 \}$）作为激活函数的全连接网络，第四层采用双向RNN，第五层为全连接层，接受双向RNN的输出，输出层使用CTC作为误差准则。配合数据抖动和dropout等正则化优化技巧，Deep Speech 1最终在SWB+FSH 2000h数据集上超越了当时传统方法最好的开源结果。 2014年到2016年之间，CNN[1][26]以及BatchNorm[1]等正则化方法相继被引入声学建模中，并取得了很好的结果。Deep Speech 2在2016年公开，和DS1相比，声学模型中加入了如下新的特性： 引入卷积层用于特征抽取，替代之前的全连接层，在时域和频域的二维卷积可以明显增强声学模型在噪声环境下的识别鲁棒性 RNN部分采用sequence-wise的BatchNorm，用于加速网络收敛，并且发现，随着网络层数的加深，对收敛度的提升越好 使用Cho等人在2014年提出的GRU代替普通RNN，相比LSTM，GRU[8]可以获得相近的结果，同时计算复杂度更小 在GRU层之上加入lookahead卷积层，用于获取一些future context。 DS2在普通话和英语上同时取得了可观的结果，在普通话带噪测试集上，使用了BatchNorm和2D卷积的模型相比浅层的RNN在WER上有了48%的相对提升，并且在voice query数据上超越了人类水平。 Google在2017年提出的Neural Speech Recognizer[29]也是以CTC为准则的识别系统。NSR采用双向LSTM建模，在超过12万小时的数据上进行训练，对比了CD-phone和word两种建模单元，在YouTube转写任务上，以word作为建模单元的NSR超越了传统CD-phone的ASR效果。 在开源社区CTC也相当活跃，Miao等人基于Kaldi语音识别工具包开源了eesen[20]，满足了CTC和传统声学解码器的耦合，Baidu开源了社区效率最高的CTC实现warp-ctc，在同等的计算量下，其耗时远低于其他工具包，Facebook研究院开源了他们基于CTC的端到端识别工具wav2letter[11]，CUDNN7.0中也增加了CTC的API接口。此外，受到CTC的启发，Dan等人提出的Lattice Free MMI（LF-MMI，chain model）[22]获得巨大成功，一方面降低了区分性训练的耗时，另一方面可以获得8%的相对提升，被誉为声学模型近几年最大的创新。 RNN Transducer为了进一步提升CTC的表现，Graves后来提出了RNN Transducer[12]结构，用于修正CTC在计算序列概率中的假设缺陷。思路是保留原CTC声学模型（称为转录网络）的同时，引入一个额外的网络，称为为预测网络，用于对抄本序列的输出进行预测，起到类似语言模型的作用。在$t$时刻，当前符号为$u$时，网络输出符号$k$的概率表示为： P(k | t, u) = \frac{\exp(\mathbf{f}_t^k + \mathbf{g}_u^k)}{\sum_{k'} \exp(\mathbf{f}_t^{k'} + \mathbf{g}_u^{k'})}其中$\mathbf{f}_t,\mathbf{g}_u$表示转录和预测网络的输出概率向量。训练时，预测网络的输入源自抄本序列，解码时，预测网络的输入来自转录网络的输出，输入采用one-hot编码的形式，因此，在RNN Transducer中，$P(\pi|\mathbf{x})$的计算公式变为： P(\pi | \mathbf{x}) = \prod_{t=1}^T P(y_{\pi}^t | \mathbf{x}_{1 \cdots t}, \pi_{\{1,\cdots,t\}})从这里可以看出，由于$t$时刻的输出$y{\pi}^t$会作为预测网络的输入，因此，$t + 1$时刻的输出$y{\pi}^{t+1}$不再和$y_{\pi}^t$相互独立，这种条件更加符合语音上下文之间的相关性。实验中，一层128节点的预测网络和两层128节点的转录网络在TIMIT上取得了23.2%的PER，相比纯转录网络（25.5%），降低了2.3%个百分点。 在2013年，Graves用多层LSTM建模[15]，并用CTC网络的权值初始化转录网络，在TIMIT上取得了17.7%的PER，成为当时最好的结果，而同结构的CTC结果为18.6%。研究同时表明： LSTM的建模能力远远超越普通RNN 网络走向深度的收益好于扩展宽度 双向网络的建模能力胜于单向网络 RT的问题在于，转录网络和预测网络除了通过$P(k|u, t)$进行信息融合之外，并不相互依赖，因此，二者较为独立。其次，RT依旧保持了CTC设计中硬对齐部分，用于计算损失函数，在这点上计算复杂度较高，本质上说，属于对CTC的改进。 Encoder-Decoder Structure在提Attention机制之前需要先说一下Encoder-Decoder结构。Encoder-Decoder是Cho等人在2014年提出的一种包含两个RNN的网络结构[8]，最初用于机器翻译，也正是在这篇论文中，他们提出了LSTM的简化版本GRU（Gated Recurrent Unit）。 在E-D结构中，编码器用于将输入的变长序列$\mathbf{x}$编码成定长表示$\mathbf{c}$，而解码器用于将此定长表示解码成另一种符号序列$\mathbf{y}$，两个网络做联合训练，最大化条件概率$P(\mathbf{y} | \mathbf{x})$，以此完成序列映射。一般的，$\mathbf{c}$用encoder扫描一遍$\mathbf{x}$之后的hidden state表示。对于decoder，在生成$y_t$时，接受上一时刻的输出$y_{t - 1}$和$\mathbf{c}$作为输入，hidden state的更新表示为： \mathbf{s}_t = \mathcal{R}(\mathbf{s}_{t - 1}, y_{t - 1}, \mathbf{c})在生成$t$时刻生成$y_t$的条件概率$P(y_t | y_{1 \cdots (t - 1)}, \mathbf{x})$表示为： P(y_t | y_{1 \cdots (t - 1)}, \mathbf{x}) = \mathcal{G}(\mathbf{s}_t, y_{t - 1}, \mathbf{c})其中$\mathcal{G}$可以用一个带有softmax输出层的MLP表示。在E-D结构下，decoder生成序列$\mathbf{y}$的条件概率可以根据条件概率公式得到： P(\mathbf{y} | \mathbf{x}) = \prod_t P(y_t |y_{]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BPTT of RNN]]></title>
    <url>%2F2018%2F01%2F05%2Fbptt-of-rnn%2F</url>
    <content type="text"><![CDATA[我在这一篇里推导一下RNN的反向传播算法，尝试从另一个角度来理解在RNN在时间轴上的依赖关系，由此导出所谓的梯度消失问题，即原始的RNN为什么难以训练。 首先定义RNN的前向过程如下： \mathbf{z}_t = W_x \mathbf{x_t} + W_h \mathbf{h}_{t - 1} + \mathbf{b} \\ \mathbf{h}_{t} = \tanh(\mathbf{z}_t)网上常见的解释是，对于RNN，在$t$时刻的输入不仅可以直接影响当前时刻的输出$\mathbf{h}_t$，而且可以通过$\mathbf{h}_t$对下一时刻的输出$\mathbf{h}_{t + 1}$产生影响，因此计算梯度的时候，需将$t + 1$时刻的误差也传递到当前时刻。个人觉得这种解释没有真实的反映出时间序列上的依赖关系，因为$t$时刻输入会对后续时刻的整个序列的输出产生影响，不仅仅是下一个时刻的输出，因此，从这里理解，$t$时刻的误差应该是后续时间步上误差传递到当前时刻值的总和，也正是由于这种在时间轴上从后向前的传递，导致了在时间步（time step）变大时，靠后时刻的误差不能传递到序列的早期时刻，引发了所谓的梯度消失问题（长期依赖问题）。下面对这段文字描述做数学推导。 首先定义序列时长为$T$（即time_step = $T$）。假设这是一个多层的many-to-many的RNN，对于其中某一层，输入和输出表示为： \mathbf{X}_l = \{\mathbf{x}_1, \mathbf{x}_2, \dots, \mathbf{x}_T\} \\ \mathbf{H}_l = \{\mathbf{h}_1, \mathbf{h}_2, \dots, \mathbf{h}_T\}在每个时刻，可以获得由上一层网络的传递得到误差项（实际为梯度，这里为了方便），表示为 \mathcal{L}_l = \{\ell_1, \ell_2, \dots, \ell_T\}定义$\delta_k$: \delta_k = \frac{\partial \mathcal{L}_{k \leqslant t \leqslant T}}{\partial \mathbf{z}_k} = \sum_{k \leqslant t \leqslant T} \frac{\partial \ell_t}{\partial \mathbf{z}_k} = \sum_{k \leqslant t \leqslant T} \delta_k^t那么$\delta_k$就表示在当前输入序列下，$k \leqslant t \leqslant T$时刻范围内对$\mathbf{z}_k$的梯度之和，这也是我们最终要求的真实梯度，即在当前输入序列下，可以计算出的误差对$\mathbf{z}_k$的梯度。 再看一下$\delta_k^t$：表示当前输出的误差对$\mathbf{z}_k$的梯度，在feed forward的网络结构中，这里$\delta_k^t = \delta_k$。 根据$\delta_k^t$的性质： \begin{align} \delta_k^t & = \frac{\partial \ell_t}{\partial \mathbf{z}_k} = \frac{\partial \ell_t}{\partial \mathbf{z}_{k + 1}} \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} \\ & = \delta_{k + 1}^t \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} \\ & = \frac{\partial \ell_t}{\partial \mathbf{z}_t} \prod_{k + 1 \leqslant i \leqslant t} \frac{\partial \mathbf{z}_{i}}{\partial \mathbf{z}_{i - 1}} \end{align}结合$\delta_k^t​$和$\delta_k​$，可以得到$\delta_k​$的表达式： \delta_k = \sum_{k \leqslant t \leqslant T} \left(\frac{\partial \ell_t}{\partial \mathbf{z}_t} \prod_{k + 1 \leqslant i \leqslant t} \frac{\partial \mathbf{z}_{i}}{\partial \mathbf{z}_{i - 1}} \right)从上面的这个式子可知，如果要计算时刻$k$的梯度，那么需要两层循环，内循环处理连乘，外循环处理加和，显然，实际的bptt实现并没有这个复杂，因为$\delta_k$可以用更简洁的形式表达。下面导出这种具体形式。 首先$\delta_k^t$和$\delta_{k + 1}^t$的关系为： \delta_k^t = \frac{\partial \ell_t}{\partial \mathbf{z}_k} = \frac{\partial \ell_t}{\partial \mathbf{z}_{k + 1}} \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} = \delta_{k + 1}^t \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}}根据$\delta_{k + 1}$的表达式，对其右乘$\frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_k}$ \begin{align} \delta_{k + 1} \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} & = \left(\sum_{k + 1\leqslant t \leqslant T} \delta_{k + 1}^t \right) \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} \\ &= \sum_{k + 1\leqslant t \leqslant T} \left(\delta_{k + 1}^t \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} \right) \\ & = \sum_{k + 1\leqslant t \leqslant T} \delta_k^t = \sum_{k\leqslant t \leqslant T} \delta_k^t - \delta_k^k \\ & = \delta_k - \delta_k^k \end{align}因此得到了递推式： \delta_k = \delta_{k + 1} \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}} + \delta_k^k = \delta_{k + 1} \cdot \frac{\partial \mathbf{z}_{k + 1}}{\partial \mathbf{z}_{k}}+ \frac{\partial \ell_k}{\partial \mathbf{z}_k}上式就是RNN的BPTT在实现时的逻辑，从这里可以更加容易看出时间依赖的本质，注意$\delta_{k + 1} \ne \delta_{k + 1}^{k + 1}$，$\delta_k$表示的是在时刻$t \in [k + 1, T]$，对时刻$\mathbf{z}_{k + 1}$梯度的累积量，而$\delta_{k + 1}^{k + 1}$仅仅表示$\ell_{k + 1}对$$\mathbf{z}_{k + 1}$的梯度。 因此本质上不能理解成$t$时刻输入$\mathbf{x}_t$仅仅会对$\mathbf{h}_t, \mathbf{h}_{t + 1}$产生影响，就此在反向传播的时候将两个时刻产生的梯度相加，因为时间依赖的本质是可以无限延伸的，即沿着时间轴从$T \to 1$传播，这也就是所谓TT：through time的含义。 这里还要提一下RNN的几种常见结构，many-to-one, one-to-one, one-to-many, 和many-to-many，我上面的分析是针对最后一种即从上层网络传递下来的误差向量维度和输入维度保持一致。前面三种现在理解起来也十分容易了。many-to-one就是要将最后时刻（一般是这样）的梯度传递到输入的每个时刻，one-to-many就是将每个时刻的梯度传递到起始时刻，one-to-one只需要将最后时刻传递到起始时刻就行了，即$\delta_1^T$。 再以one-to-one分析一下梯度消失问题，根据上面的解释，可以写出$\delta_1^T$： \delta_1^T = \frac{\partial \ell_T}{\partial \mathbf{z}_T} \prod_{2 \leqslant t \leqslant T} \frac{\partial \mathbf{z}_t}{\partial \mathbf{z}_{t - 1}}其中 \frac{\partial \mathbf{z}_t}{\partial \mathbf{z}_{t - 1}} = \frac{\partial \mathbf{z}_t}{\partial \mathbf{h}_t} \frac{\partial \mathbf{h}_t}{\partial \mathbf{z}_{t - 1}} = W_h \mathcal{D}(\tanh'(\mathbf{z}_{t - 1}))当时间步$T$过大时，矩阵和激活值的连乘很容易导致$\delta_1^T$过大或者过小。过大的解决方法比较简单，目前都采用梯度裁剪的方法（clip gradient）。过小就是所谓的梯度消失问题，RNN无法从训练中获得远距离梯度的更新，也就无法学习到远距离的依赖关系，解决的方法可以是重新设计循环结构，合理初始化权值以及使用合适的激活函数等等。]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSA - Clonal Selection Algorithm]]></title>
    <url>%2F2017%2F12%2F16%2Fcsa-presentation%2F</url>
    <content type="text"><![CDATA[吐槽：其实我特别反感老师自己不上课，让学生挨个领任务的这种行为，虽然好（jiu）像（shi）越来越多的老师喜（bian）欢（de）上（yue）这（lai）一（yue）点（lan）了。课下已经是百分之百靠自学，课上想听一下你的观点这么难？好吧，这个题目，其实是我领的任务……本身我也不想准备这个东西，但是恰逢考试周，老刷那些数学题也没啥意思，就花点时间做了个PPT当放松了。 下面进入正题。 克隆选择算法（Clonal Selection Algorithm，CSA）是依据克隆选择原理提出的一种进化算法。由于借鉴了生物体免疫系统的免疫过程，算法的很多定义和过程都和生物学中的免疫系统类似，比如抗原，抗体，浆细胞之间的关系和作用等等。从免疫过程中我们知道，只有被抗原刺激的抗体才会增殖（克隆）和分化，形成记忆细胞，从而在下次抗原到来时，加速免疫反应。也就是说，和抗原亲和度高的抗原会以更高的概率保留下来，并增殖分化，这就是CSA的核心思想。 应用到具体的问题中，CSA算法中，可以将抗原视为我们要解决的问题，抗体表示问题的解，而抗原和抗体之间的亲和度可以用解的优良程度来表示。后来的生物学家还研究到，抗体会有一种称之为超突变的机制来增强抗体的免疫性，产生所熟知的交叉免疫现象，即增强的抗体的泛化能力，使得其不仅能够免疫之前刺激的抗原，而且可以免疫和其相类似的抗原。 因此，结合亲和性选择和超突变，CSA算法的一般流程如下： 生成候选抗体（解） 根据亲和度，选择优秀的抗体克隆 克隆的结果进行超突变 重新选择突变个体，替换亲和度低的个体成为候选抗体 在多目标优化（MO）中，算法没有牵扯到抗原这个概念，因为优化函数唯一且确定，因此可以直接定义亲和性函数$\mathcal{F}$，它的输入为抗体编码，输出为亲和度，用$\mathbf{Ab}$表示抗体，这个过程表示如下： \mathbf{f}_i = \mathcal{F}(\mathbf{Ab}_i)算法框架中，抗体$\mathbf{Ab}$需要以编码的形式进行迭代，令抗体个数为$N$，编码长度为$L$，那么$\mathbf{Ab} \in S^{N \times L}$。 根据亲和度选择好克隆对象之后，就要进行克隆和超突变操作，一般是选择最好的若干个抗原（称之为$\mathbf{Ab}_{\{n\}}$）参与克隆和超突变，这个过程可以表示如下： \mathbf{A}b_j \xrightarrow{\text{clone}} \mathbf{C}_j \xrightarrow{\text{maturate}} \mathbf{C}_j^* \quad \mathbf{C}_j \in S^{N_c \times L}$\mathbf{C}，\mathbf{C^*}$表示克隆后和超突变之后的抗体集合。关于克隆的个数$N_c$，一般的，我们希望亲和度越高的个体克隆的越多，在MO问题中，我没有区分对待每一个待克隆抗体，即对$\mathbf{Ab}_{\{n\}}$的个体取相同的克隆个数，令克隆系数为$\beta$，则 N_c = [\beta N]之后对超突变的个体进行重新选择生成下一次迭代的候选解形成Loop就是完整的CSA过程了，有的时候考虑到解的鲁棒性，允许随机产生一些抗原进入下一次迭代的候选解中。以上CAS的MO优化过程可以用下面的流程图表示： 下面介绍两个实现的重点： 浮点编码 之前也提到了，抗原需要根据问题的定义进行编码之后才能参与CSA过程，以便进行突变操作。多目标优化问题中，$\mathbf{x}$表示最优点的位置坐标，因此，需要对浮点数进行编码。对于$L$位编码长度的序列$(b_0, b_1, \cdots, b_{L - 1})，b_i \in \{0, 1\}$，通过如下方式编码成浮点数$z，z \in [0, 1]$： z = \frac{\sum_{n = 0}^{L - 1} b_n 2^n}{2^L - 1} 之后配合缩放因子$\xi$，生成编码结果$d$： d = -\xi + 2 \xi z，d \in [-\xi, \xi] 用MATLAB实现如下： 123456789function x = decode(v, L) % N x L s = size(v); % 1 x L b = 0: 1: L - 1; % N x L bs = repmat(2 .^ b, s(1), 1); x = -1 + sum(v .* bs, 2) .* (2 / (2 ^ L - 1));end 因此，计算亲和度的时候，将编码序列解码成浮点值，进行克隆和超突变的时候，在原编码序列上进行。 超突变 由于浮点值被编码成二进制序列，因此，突变即在某些位上的值进行翻转，这一操作可以用异或表示，和1取异或会将原值翻转，比如： 00110010 \; \text{xor} \; 00010001 \to 00100011 只要控制生成的mask中1的概率即可，这个概率称为超突变概率$P_{\text{mu}} $。 关于CSA的介绍，demo实现，实验配置和结果，以及我参阅的参考文献请戳CSA-WJ-Presentation，代码比较简单我就不贴了。 PPT模板从阿里带回来的…&gt;_&lt;…]]></content>
      <tags>
        <tag>杂七杂八</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Internship in iDST]]></title>
    <url>%2F2017%2F12%2F05%2Finternship-in-idst%2F</url>
    <content type="text"><![CDATA[来阿里iDST的第三周了，开始的两天在西溪园区里面还是有点晕头转向，不清楚工作区和食堂的结构，乃至于每次吃饭都从七号楼走到二号楼，因为不知道七号楼和八号楼有食堂……大概到了第四天就基本熟悉了，每天装的像个老员工一样上班，开会，吃饭，午休。 老实说，在这里的感觉和学校很相似，毕竟作为一个实习生，没有工作上的压力，也没有正式员工各种项目和各种会。每天和在校一样，跑实验，写代码，带着期待看实验结果……，效率上还是要优于学校的，很多方面原因吧，机器比实验室的好，实验跑的快，任务相关度较高，也没有学校的很多杂事，每天的精神高度集中，倒是每天早上要开个立会。考虑到人员的分布，所谓的立会也就是个电话会议，汇报一下前一天的工作，我的效率自我感觉还可以，每天的进展还是可以保证的。周末我还是照常去公司，我比较喜欢安静吧，周末去公司的员工比较少，一个人待在里面很安静，毕竟工作日的话，淹没在各种讨论，电话之中，心里还是有些不自在的。 我在这边做一些前端的工作，来之前向老板主动请缨的。说实话，前端我没有多少积累（但是未知对我有很大的吸引力），来之前花了几周时间看相关论文和麦克风阵列，信号处理相关的东西，到这边之后也差不多够用的。其实这边这个组（智能语音交互团队）在前端方面也没有很多技术积累，主要还是偏声学/语言模型的，因此，没有多少可以与之讨论的人，这点比较遗憾（来之前其实想找个大佬带的）。过去两周终于把CHiME4讯飞的前端复现了，中间出一了一点叉子，耽误了一点时间，好在后来check代码的时候发现了，用一个周末把结果跑出来了。 阿里入职之后的麻烦事还是蛮多的，首先就是各种权限问题，机器账户，网址访问，邮件组等等，每次申请都要一批人挨个审核……，大概前三天基本都在解决权限问题，直到上周才算初步搞定权限。实习生配置的是台式机+显示器+键盘+鼠标，这个真是要吐槽了，台式机意味着我只能在公司工作（并不允许使用自己笔记本，想要远程看个实验结果都不行）……键盘，鼠标，罗技，凑合用吧（我下次还是自备吧），显示器标配DELL P2417H，但是配个台式机并没有什么卵用，连个HDMI接口都不给，因为那个台式机上没有……。前一周的工作基本都是用自己笔记本连阿里guest wifi，远程学校机器做的。机器上只能钉钉，我来了之后基本一个教研室同一届的几个人全配合我装上了钉钉，否则他们找不到我，还有一个原因，给我发数据。我是空手来的，之前的数据，代码全在学校机器上，差不多麻烦他们用钉钉给我传了好几个G的数据，然后，MATLAB和Audition，光下载就下了一天（来之前没带安装包，这边又没有ipv6，虽然阿里网速确实快，但是百度云还是慢啊），前一周基本都在解决这些破事，有点心疼时间。 阿里iDTS给我的印象，实话实说吧，来之前以为是个做research的地方，来之后感觉一股浓浓的产品风。总感觉做搞开发（移动端和web）的和iDST的工位混在一起。我软件工程本科，对产品汪的各种讨论到是感觉倍加亲切，尤其某天中午正在午休，突然被一声“你好，电视”惊醒了，我看着那位对着电视debug的前辈，想起了我当年在实验室做KWS Demo的情景，场面一度十分亲切……不过五楼有个AI LIB，不知道那边在搞些什么（PS：iDST对面是咸鱼）。说到我们这个组吧，大部分人还是在搞项目，在实验室其实不太明白KWS这个东西有什么做头，来了之后倒是明白了，产品驱动，入口嘛…… 工作压力这边感觉一般吧，大家一般晚八九点走，周末也没有多少人加班，我和团队的人交流不是很多，一点可能是年龄上有差距，大部分人都是85后，要么成家，要么有对象，和我这个还待在学校里面的人关心的东西已经有很大的不同了感觉（可能我这个人care的东西也不是很主流，只想找个地方安心做事）。其次就是团队有人做AM和LM，貌似还有人搞合成，boss应该也是做AM出身，但是搞前端的人不在这个团队内（貌似在西雅图……钉钉上总有时差），因此技术上的交流也不多，这点还是有些失望的。 工作上，把讯飞的CHiME4的Loop复现了，CGMM的效果还是一般，用NN估计mask表现的我这边普遍比CGMM好，其次就是MVDR和GEV的对比上，GEV虽然语音失真比较厉害，但是可以在eval-real这个集合上获得更低的wer，在其他三个集合上表现不如MVDR，我一直觉得四个测试集合音频的性质有差异，经常出现某个集合上变差，另一个集合上变好的现象。讯飞的思路是用VAD信息和IRM修正CGMM的mask，我这边用增强的数据重新算一遍mask和noisy数据的mask做一个combine，也就是说，NN这里扮演着IRM和mask estimator两个角色，VAD方法和讯飞保证一致，今天总算做出gain了，wer降了一个多点，GEV降到6.0%以下，这个结果还是比较正常的。由于目前这个AM是用6ch的noisy数据训练的，所以我对beamforming的结果用IRM做一个单通道的增强，虽然滤去了大部分噪声，但是在wer上是没有gain的，应该是mismatch更大了吧。其实我还想把mask estimator的NN换一个模型，隐式的学习clean/noise的mask，而不是目前的用人工计算的mask作为target，这个实验室他们搞增强的人试过，听说效果不错，可以拿来一试。 学校的考试还有三周，略慌，要开始复习了&gt;_&lt;。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Overview of Beamformer]]></title>
    <url>%2F2017%2F11%2F11%2Foverview-of-beamformer%2F</url>
    <content type="text"><![CDATA[好久没更……过去一段时间接触了一下beamforming，连看论文加做实验，大概理出了一些头绪。初步理解beamforming就是对多路信号进行频域滤波，从而获取一路增强信号，所谓的增强就是最大可能的滤除噪声，同时保留我们期望的信号。比较经典的方法有：延时相加，Max-SNR，MVDR，GSC（LCMV）等等（详细可学习陈老师的麦克风阵列信号处理[2]一书）。学习期间会接触到一些非常频繁的概念，比如信噪比，相关系数矩阵，PSD（功率谱密度），steer vector，以及一些数学问题的求解方法，比如拉格朗日乘子法，广义特征值等问题，深层次的理解还是需要扎实的统计，矩阵，优化理论基础，相关概念以后可能会写一篇专做解释。 我这里从DS（延迟相加）开始，引入频域beamforming的一般数学模型，再介绍GEV，MVDR，PMWF三种beamformer。虽然我的出发点和实验都是和NN结合来做的，但是本篇里面不牵扯到NN（神经网络）的东西，只说纯粹的信号处理。 延时相加（DS）方法是最简单的一种波束形成方法。它利用已知是麦克风阵列的拓扑结构，算出不同通道之间的相对延时，通过对多路信号进行时间上的同步和平均操作完成通道合并和增强效果。 对于有$N$个麦克风的阵列，在$t$时刻，麦克风$n(n = {1, 2, \cdots, N})$处收集的信号$y_n(t)$可以表达为： y_n(t) = x_n(t) + v_n(t)$v_n(t)$表示该处噪声，$x_n(t)$表示声源到达麦克风的信号，考虑麦克风之间的空间分布，声源到达麦克风处的衰减和延迟是不同的，引入衰减因子$\alpha_n$和相对延时$\tau_n$，$x_n(t)$可以表示为： x_n(t) = \alpha_n s(t - \tau_n)$s$表示未知的声源信号。首先对多路信号进行延时操作： y_n'(t) = y_n(t + \tau_n) = \alpha_ns(t) + v_n(t + \tau_n)相加取平均获取DS方法的输出$z_{DS}(t)$： z_{DS}(t) = \frac{1}{N} \sum_{n = 1}^N y_n'(t) = \frac{1}{N}\left[ \left(\sum_{n = 1}^N \alpha_n \right) s(t) + \sum_{n = 1}^N v_n(t + \tau_n) \right]令$\alpha_{DS} = \sum_n \alpha_n, v_{DS}(t + \tau_n) = \sum_n v_n(t + \tau_n)$，定义输出信号的SNR： \text{oSNR} = \alpha_{DS}^2 \frac{E[s(t)^2]}{E[v_{DS}(t + \tau_n)^2]} = \left( \sum_{n = 1}^N \alpha_n \right)^2 \frac{\sigma_s^2}{\sigma_{v_{DS}}^2}以$s_1(t)$为参考，定义此处的信噪比： \text{SNR} = \frac{\sigma_{x_1}^2}{\sigma_{v_1}^2} = \alpha_1^2 \frac{\sigma_s^2}{\sigma_{v_1}^2}显然，期望的波束形成结果应该满足$\text{oSNR} &gt; \text{SNR}$。 若$\alpha_i = 1, \sigma_{v_1}^2 = \sigma_{v_2}^2 = \cdots = \sigma_{v_n}^2$且$v_i(t)$之间互不相关（因此不同噪声信号之间的协方差为0），那么： \sigma_{v_{DS}}^2 = \sum_{n = 1}^N \sigma_{v_n}^2 = N \sigma_{v_1}^2故$\text{oSNR} = N \cdot \text{SNR}$。在DS方法中，准确的估计$\tau_n$十分重要，在线阵中，需要知道各个麦之间的间距$d$以及以及声源波面和线阵形成的夹角$\theta$。假设各麦间距相同，那么TDOA计算有简单的几何关系得到： \tau_n = (n - 1)d \cos(\theta) / c其中$c$表示声速。 以上分析是在时域上进行的，上面的各个变量下标为$t$，DS首先需要做的是在时域上进行对齐，之后叠加取均值。若变换到频域，那么$y_n(t) = x_n(t) + v_n(t)$写为： Y_n(\omega) = X_n(\omega) + V_n(\omega)由$x_n(t) = \alpha_n s(t - \tau_n)$： X_n(\omega) = \alpha_n \cdot X(\omega) \cdot e^{-j\omega\tau_n}令： \begin{align} \mathbf{y}(\omega) &= [Y_1(\omega), Y_2(\omega), \cdots, Y_N(\omega)]^T \\ \mathbf{d}(\omega) &= [\alpha_1e^{-j\omega\tau_1}, \alpha_2e^{-j\omega\tau_2}, \cdots, \alpha_Ne^{-j\omega\tau_N}]^T \\ \mathbf{v}(\omega) &= [V_1(\omega), V_2(\omega), \cdots, V_N(\omega)]^T \end{align}这里$\mathbf{d}(\omega)$称为steer vector。那么频域关系可以用向量形式描述为： \mathbf{y}(\omega) = \mathbf{d}(\omega) X(\omega) + \mathbf{v}(\omega)在频域上，波束形成是要在每个频率点上操作，完成$\mathbf{y}(\omega)$到$Z(\omega)$的映射，这种映射关系通过设计滤波器$\mathbf{h}(\omega)$实现，即： Z(\omega) = \mathbf{h}^H(\omega) \mathbf{y}(\omega)注意，这里的$Z(\omega)$为数值，而$\mathbf{h}(\omega), \mathbf{y}(\omega)$为向量，实际的操作为： Z(\omega) = \sum_{n = 1}^N \overline{H}_n(\omega) Y_n(\omega)其中，$\mathbf{h}(\omega) = [H_1(\omega), H_2(\omega), \cdots, H_N(\omega)]^T$, $\overline{H}_n(\omega)$表示$H_n(\omega)$的共轭。 从频域来看，DS设计的beamformer应该是： \mathbf{h}(\omega) = \frac{1}{N} [\alpha_1^{-1}e^{j\omega\tau_1}, \alpha_2^{-1} e^{j\omega\tau_2}, \cdots, \alpha_N^{-1} e^{j\omega\tau_N}]^T使得$\mathbf{h}^H(\omega) \mathbf{d}(\omega) = 1$。 更一般的表示，可令$\mathbf{x}(\omega) = \mathbf{d}(\omega) X(\omega)$，则： \mathbf{y}(\omega) = \mathbf{d}(\omega) X(\omega) + \mathbf{v}(\omega) =\mathbf{x}(\omega) + \mathbf{v}(\omega)带入$Z(\omega)$可知，滤波器同时作用于$\mathbf{x}(\omega)$和$\mathbf{v}(\omega)$： \mathbf{y}(\omega) = \mathbf{h}^H(\omega) \mathbf{x}(\omega) + \mathbf{h}^H(\omega) \mathbf{v}(\omega)一般的可以将作用于前者的结果$\mathbf{h}^H(\omega) \mathbf{x}(\omega)$称为增强信号或者输出信号（desired speech），因为这是我们最终期望的结果，作用后者的结果$\mathbf{h}^H(\omega) \mathbf{v}(\omega)$称为残留噪声（residual noise）。显然，我们期望滤波器对前者产生增强效果，对后者产生削弱效应。 再往下需要补充一个关于PSD（power spectrum density，功率谱密度）的定义，对于复数域的向量$\mathbf{v}(\omega)$，称： \mathbf{\Phi}_{vv}(\omega) = E[\mathbf{v}(\omega) \mathbf{v}^H(\omega)]为$\mathbf{v}(\omega)$的PSD。假设噪声和原始信号之间是不相关的，那么$\mathbf{x}(\omega), \mathbf{v}(\omega), \mathbf{y}(\omega)$之间的PSD满足如下关系： \mathbf{\Phi}_{yy}(\omega) = \mathbf{\Phi}_{xx}(\omega) + \mathbf{\Phi}_{vv}(\omega)对于$Z(\omega) = \mathbf{h}^H(\omega) \mathbf{y}(\omega) = \mathbf{h}^H(\omega) \mathbf{x}(\omega) + \mathbf{h}^H(\omega) \mathbf{v}(\omega)​$，有： \begin{align} \mathbf{\Phi}_{zz}(\omega) &= \mathbf{h}^H(\omega) \mathbf{\Phi}_{yy}(\omega) \mathbf{h}(\omega) \\ &= \mathbf{h}^H(\omega) \mathbf{\Phi}_{xx}(\omega) \mathbf{h}(\omega) + \mathbf{h}^H(\omega) \mathbf{\Phi}_{vv}(\omega) \mathbf{h}(\omega) \end{align}在每个频率点$\omega​$上，定义一个局部信噪比（local SNR）: \text{SNR}(\omega) = \frac{E \left[|\mathbf{h}^H(\omega) \mathbf{x}(\omega)|^2 \right]}{E\left[|\mathbf{h}^H(\omega) \mathbf{v}(\omega)|^2\right]} = \frac{\mathbf{h}^H(\omega) \mathbf{\Phi}_{yy}(\omega) \mathbf{h}(\omega) }{\mathbf{h}^H(\omega) \mathbf{\Phi}_{vv}(\omega) \mathbf{h}(\omega) } - 1所谓GEV（Generalized Eigenvalue Decomposition） beamformer，就是要设计一个滤波器$\mathbf{h}(\omega)$，使得在频率点$\omega$处$\text{SNR}(\omega)$达到最大，即： \mathbf{h}_\text{GEV}(\omega) = \arg \max_{\mathbf{h}} \text{SNR}(\omega)称之为GEV，是因为该极值求解问题是一个瑞利商问题，可以用广义特征值来求解，即$\mathbf{h}_\text{GEV}(\omega)$实际上就是$\mathbf{\Phi}_{vv}^{-1}(\omega)\mathbf{\Phi}_{yy}(\omega)$最大特征值对应的特征向量。在编程实现的时候，遍历每一个$\omega$就可以得到每个频率上对应的滤波系数了。 接下来引入使用非常广泛的一种波束形成方法：MVDR（Minimum Variance Distortionless Response ）。它通过最小化残留噪声的能量，同时约束期望（方向）的信号不失真来实现。 引入GEV的过程中，通过$\mathbf{x}(\omega)$将$\mathbf{d}(\omega) X(\omega)$整体看待，在DS中，$\mathbf{d}(\omega)$（steer vector）描述的是衰减因子和延时的综合作用，现在推广它的含义，用$\mathbf{d}(\omega)$描述声源到每一个麦克风的转移方程，那么： Z(\omega) = \mathbf{h}^H(\omega) \mathbf{y}(\omega) = \mathbf{h}^H(\omega)\mathbf{d}(\omega) X(\omega) + \mathbf{h}^H(\omega) \mathbf{v}(\omega)MVDR的求解问题可以表示为： \mathbf{h}_\text{MVDR}(\omega) = \arg \min_{\mathbf{h}} E\left[ |\mathbf{h}(\omega)^H \mathbf{v}(\omega)|^2\right] \;\text{s.t} \;\;\mathbf{h}(\omega)^H \mathbf{d}(\omega) = 1约束条件$\mathbf{h}(\omega)^H \mathbf{d}(\omega) = 1$可以保证MVDR滤波器在满足转移方程$\mathbf{d}(\omega)$的方向或者条件下，增强的信号不失真。同时也表示$\mathbf{d}(\omega)$需要估计或者已知。用拉格朗日乘子法得到$\mathbf{h}_\text{MVDR}$的数学表达式： \mathbf{h}_\text{MVDR} = \frac{\mathbf{\Phi}_{vv}^{-1}(\omega) \mathbf{d}^H(\omega)}{\mathbf{d}^H(\omega)\mathbf{\Phi}_{vv}^{-1}(\omega) \mathbf{d}^H(\omega)}现在可以对MVDR的约束条件加以推广，MVDR约束信号不失真通过转移方程或者steer vector完成，约束residual noise通过获取最小化能量完成。如果定义一个参考信号/麦克风（reference microphone ）$r$，那么衡量信号的失真程度可以通过误差$\epsilon_r(\omega)$进行： \epsilon_r(\omega) = X_r(\omega) - \mathbf{h}^H(\omega) \mathbf{x}(\omega) = [\mathbf{u}_r - \mathbf{h}(\omega)]^H \mathbf{x}(\omega)其中$\mathbf{u}_r = [0_1, 0_2, \cdots, 1_r, 0_{r + 1}, \cdots, 0_N]^T​$用于选择出第$r​$路参考信号。 仿照MVDR，写下约束优化问题： \mathbf{h}(\omega) = \arg \min_{\mathbf{h}} E \left[ |\mathbf{h}^H(\omega) \mathbf{x}(\omega)|^2\right] \; \text{s.t} \;\; E\left[\epsilon_r(\omega)^2 \right] \leqslant \sigma^2(\omega)该问题的解称之为PMWF（Parameterized Multichannel Wiener Filter ）: \mathbf{h}_\text{PMWF}(\omega) = \left[\mathbf{\Phi}_{xx}(\omega) + \beta \cdot \mathbf{\Phi}_{vv}(\omega)\right]^{-1} \mathbf{\Phi}_{xx}(\omega)\mathbf{u}_r$\beta = 1 / \gamma$，其中$\gamma$是拉格朗日乘子。利用$\mathbf{\Phi}_{xx}(\omega)$的秩为1（因为$\mathbf{\Phi}_{xx}(\omega) = \Phi_{ss}(\omega)\mathbf{d}(\omega)\mathbf{d}^H(\omega)$），可将解化简为以下形式： \mathbf{h}_\text{PMWF}(\omega) = \frac{\mathbf{\Phi}_{vv}^{-1}(\omega)\mathbf{\Phi}_{xx}(\omega)}{\beta + \lambda(\omega)} \mathbf{u}_r其中$\lambda(\omega) = \text{tr}[\mathbf{\Phi}_{vv}^{-1}(\omega)\mathbf{\Phi}_{xx}(\omega)]$。其中的数学推导可以参见[1]。 从编程的角度说，获取到不同beamformer的滤波系数$\mathbf{h}(\omega)$之后，就可以对多路的麦克风信号进行滤波和重建。假设谱中有$F$个频率点（bin），麦克风数量为$N$个，语音段帧数为$T$，在频率$f$上，滤波操作为： \mathbf{s}(f)_{1 \times T} = \mathbf{h}(f)_{1 \times M} \mathbf{X}(f)_{M \times T}遍历频率bin一次就可以得到滤波后的频谱$S_{F \times T}$，使用重叠相加即可对其进行重建。同样，计算PSD的时候，不同频率点之间的计算是完全不相关的，在每个频率上，将通道视为随机变量，计算相关系数矩阵，得到$R(f)_{M \times M}$即为PSD。 参考文献： [1]. On Optimal Frequency-Domain Multichannel Linear Filtering for Noise Reduction[2]. Microphone Array Signal Processing[3]. Blind Acoustic Beamforming Based on Generalized Eigenvalue Decomposition[4]. Performance Study of the MVDR Beamformer as a Function of the Source Incidence Angle]]></content>
      <tags>
        <tag>Microphone Array Processing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Deep RNN]]></title>
    <url>%2F2017%2F10%2F08%2Fdeep-rnn%2F</url>
    <content type="text"><![CDATA[话说图像分类那边喜欢把网络往深处设计，语音这边也跟风走势，DeepRNN和DeepCNN接连出现在各种实验论文中。不过在网络成功走向深处之前，它的难点也是疑问在于，不加修正的加深网络层数，并不能获得相应的结果提升。于是各方大佬就进行了各种尝试和改良。截止目前，成功尝试包括以下三种： Highway Network Residual Network，可以看做HN的特殊情况，ResNet在图像分类上用的很成功 Recurrent Highway Network，中了ICML2017 语音这边也基本是拿大佬们成功的实践往声学模型上尝试，也得到了一些识别率上的提升。 再谈RNN这里主要以pytorch为参考，说明一下RNN的输入输出关系以及内在设计思路，从而加深对RNN的理解。对于BaseRNN，GRU，LSTM，我们可以用一个笼统的式子表示其内在变换： y, s_T = \mathcal{H}(x, s_0)$s$表示state，即RNN内在的状态值，这个状态的解释如下： 对于BaseRNN和GRU而言，状态表示RNN之前某时刻的输出，即$h_t$，原式可写为：$y, h_T = \mathcal{H}(x, h_0)$ 对于LSTM而言，由于cell存储了主要信息，状态表示之前某时刻下的输出和cell值，原式可写为：$y, h_T, c_T = \mathcal{H}(x, h_0, c_0)$ $x, y$分别表示$t$时刻的输入和对应的输出。$\mathcal{H}$用来描述不同RNN对输入和状态的一系列操作。如果是LSTM的话，首先计算$i, f, g, o$各个门的值，之后更新cell值$c_t$，给出输出值$h_t$；GRU则计算$r, z$以及候选$\hat{h}_t$，给出$h_t$。 pytorch里面，考虑到批训练准则（min-batch SGD），输入$x$的维度被设计为$[T, N, I]$，分别表示time_steps,batch_size, input_size，其中time_steps的存在由RNN的BPTT训练算法决定。与此对应的输出维度为$[T, N, O]$。$s_t$则记录下了每一个batch对应的每一层的状态值。如果不做sequence训练的话，那么一般是不需要使用$T$时刻的状态值$s_T$的，只需要拿到$y$将其返回给后续网络做输入即可。但是在类似CharRNN的任务中，仍旧需要将$T$时刻的状态传递下去，作为初始的$s_0$输入，这时候状态这个量就起到相应的作用了。 以上这个过程是一个高度封装的结果，因为它既包含了时间轴上的展开，也包含了层间的传递，深入一点，即如何做时间展开（定义在Recurrent中），层与层之间如何堆叠传递（定义在StackedRNN中，实际上是在每一层中依次做的时间展开），可以参考pytorch的源码，RNN这部分代码主要分布在如下几个地方： pytorch/torch/nn/_functions/thnn/rnn.py：实际定义了RNN的各种cell和层次封装 pytorch/torch/nn/_functions/backends：1和3之间的grue pytorch/torch/nn/_functions/modules/rnn.py：最外层的封装，核心调用backends.RNN Deep RNN定义$h_l^t$表示DeepRNN中第$l$层$t$时刻的输出，$s_l^t$为第$l$层$t$时刻的状态，那么依据StackRNN的前一层的输入作为后层输入的关系，有： h_l^t = \mathcal{H}(h_{l - 1}^t, s_l^{t - 1})从上式可以看出，$l - 1$层的输入信息是无法直接到达下一层的。网络走向Deep的方案之一就是通过创建一条旁路（skip connection），允许输入通过，直接汇入输出中，这就是所谓的Highway Network（高速路网络，HWN）和Residual Network（残差网络， ResNet）的设计思路。通用的表示如下： h_l^t = h_{l - 1}^t \odot w_i + \mathcal{H}(h_{l - 1}^t, s_l^{t - 1}) \odot w_oHWN的形式更加通用一些，它允许网络动态的学习,权衡两者的权值$w_i, w_o$，即用一层仿射变换定义权值： h_l^t = h_{l - 1}^t \odot C(h_{l -1}^t) + \mathcal{H}(h_{l - 1}^t, s_l^{t - 1}) \odot T(h_{l -1}^t)也可以减少一部分学习参数，将$C$用$1 - T$来表示。ResNet可以看做HWN的一种特殊形式，即$C = T = 1$： h_l^t = h_{l - 1}^t + \mathcal{H}(h_{l - 1}^t, s_l^{t - 1})强制网络的输出学习$\mathcal{F} - h_l^t$，其中$\mathcal{F}$表示我们期望的结果。Interspeech2017上谷歌有一篇文章（相关文献[5]）对比了两种跳转方案的优劣，发现HWN的学习能力强大一些。 LSTM的情况可能要特殊一点，因为除了和RNN&amp;GRU共有的$h$之外，自己还有一个细胞状态$c$。我个人觉得如果按照上面的框架只考虑输出状态也是可行的，毕竟LSTM的输出也是读取了cell的结果。HW-LSTM和Res-LSTM的设计和应用可以参见相关文献[4]，[6]。 在[4]中，LSTM的cell之间被加入了一个称为gated connection的东西$d$，将其用于修正LSTM中$c$的计算逻辑，即联通相邻层的cell。标准的LSTM，$c_t$计算逻辑如下： c_t^l = f_t^l \odot c_{t - 1}^l + i_t^l \odot g_t^l其中 g_t^l = \tanh(\mathbf{W}^l_{xg} x_t^l +\mathbf{W}^l_{hg}h_{t-1}^l + b_g)上面的公式加上上标$l$是为了和HW-LSTM做对比。标准的LSTM仅仅允许$l$层的输出作为下一层的输入，不允许层间cell的信息流动。HW-LSTM添加了这种流动路径，将其修改为： c_t^l = d_t^l \odot c_t^{l-1} + f_t^l \odot c_{t-1}^l + i_t^l \odot g_t^l从上面的公式可以看出，$d_t^l$决定了下一层cell信息流动到当前层的量，值有下式给出： d_t^l = \sigma(\mathbf{W}_{xd}^l x_t^l + \mathbf{w}_{cd}^l \odot c_t^{l - 1} +\mathbf{w}_{ld}^l \odot c_t^l + b_d)文章中的示意图如下，红色区域即为添加的用来允许cell之间信息流动的connection： [6]中所谓Res-LSTM的设计就没有考虑cell之间的信息流动，仅仅在输出门上加了shortcut路径。不考虑Project层的话，输出$h_t$由$o_t \odot \tanh(c_t)$变为$h_t = o_t \odot (\tanh(c_t) + x_t)$。如果考虑Project层，那么考虑到project之后的维度和LSTM输入的维度未必保持一致，因此需要给$x_t$乘一个变换矩阵$\mathbf{W}_H$，即： h_t = o_t \odot (\mathbf{W}_p p_t + \mathbf{W}_H x_t)以上主要是通过HWN和ResNet使得RNN变得Deeper，ICML2017上出现了一种新的结构，循环高速网络，针对RNN提出的加深方案。 Recurrent Highway Networks（简称RHN吧）中定义了一种新层：RHN层，并将该层的深度称为Recurrent Depth（简称RD）。对于RD为$L$的RHN层而言，它由一层RNN层和$L - 1$层HW层构成，若$L = 1$，那么所谓的RHN就和传统的RNN一致了，论文中配的单层RHN示意图如下： 图中的$C,T,H$均表示激活变换（先进行仿射变换，再输入激活函数），输入有箭头的指向决定。可以看出，实际只有第一层输入了上一时刻的历史信息，但是每一层都有HW的逻辑在里面，最后一层的输出作为下一时刻第一层的输入。可以这么理解，传统的RNN保留当前层的输出作为自己的状态值，RHN允许RNN层的输入继续传递若干个HW层的输出作为状态值保留。 对于$l(l &gt; 1)$层而言，输出$s_l^t$可以表达为： s_l^t = s_{l-1}^{t} \odot T( s_{l - 1}^{t}) + H(s_{l - 1}^{t}) \odot T(s_{l - 1}^{t})$l = 1$时： s_1^t = s_{L}^{t - 1} \odot T(x_1, s_{L}^{t - 1}) + H(x_1, s_{L}^{t - 1}) \odot T(x_1, s_{L}^{t - 1})以上所说只是一层RHN层，只是这一层里面有着$L$层的HW层。增大网络深度可以从增大RD和增加RHN层层数两个角度入手，在相关文献[5]中发现，堆叠RHN层比增大RD在近似参数量下更加有效（堆叠RHN引入了更多的Recurrent成分）。 相关文献[1]. Deep residual learning for image recognition[2]. Highway Networks[3]. Recurrent highway networks[4]. Highway long short-term memory RNNS for distant speech recognition[5]. Highway-LSTM and Recurrent Highway Networks for Speech Recognition[6]. Residual LSTM: Design of a Deep Recurrent Architecture for Distant Speech Recognition]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CNN for ASR part-1]]></title>
    <url>%2F2017%2F10%2F07%2FCNN-for-ASR-1%2F</url>
    <content type="text"><![CDATA[ASR这块的CNN&amp;RNN大约从13年开始就已经被陆续玩烂了。从CLDNN之后，最近几年貌似在深度和端到端上更加引人关注，例如DeepRNN（Highway, Residual等等）声学建模，DeepCNN的前端增强，前段时间看了一下Interspeech的论文，发现声学模型这块RNN和E2E明显成为两大热门专题。我之前看过KWS和解码的一些东西，没有过多的花精力在声学模型上。因此，也一直想多搭搭模型，跑跑实验，测测WER。 我想将声学模型这块任务从kaldi迁移到pytorch/tensorflow上，理由是自己可以多了解一些流程上的具体工作。kaldi的强大在于，它从前端的特征提取，数据准备，语料对齐，到声学模型的训练，后期的解码，提供了整套的服务。但是问题是，很多人跑完脚本之后，并不知道我这个模型的输入构建，以及训练流程具体是怎么进行的，除非细致的看一下代码。我个人认为这对学习者而言不是什么好事。因此考虑切换工具，自己把控数据格式，模型搭建和训练流程。 这里先说一下CNN。 CNN概述卷积这个操作在信号领域本身就是含有特殊意义的，传统的方法可以人工设计一个滤波器（高通/低通/带通之类的）对输入信号进行信息/特征提取或者过滤，它不像仿射变换，很难理解它在实际问题中到底做了什么。比如在图像中，高通滤波可以检测出图片的边缘信息，这就可以理解成一种图像特征（边缘特征）。检测出这种特征的滤波器当然不止一种，边缘检测这块就有Roberts，Sobel，Prewitt等等算子（具体可以参见冈萨雷斯的数字图像处理，本科的东西有点忘了）。 CNN的卷积层就可以理解为一组（假设为$N$）这样的滤波器，分别对输入信号进行卷积（根据输入的维度，可以是一维/二维的），得到$N$组特征。CNN的训练就是要训出这样的一组滤波器。 使得在这组滤波特征之上，配合激活，池化，以及feed后续网络层的操作使得模型分类/回归效果最佳。 实际网络输入都是离散化（经过采样）的值，因此所谓的卷积均为离散形式。记得在数字信号里面，解释卷积是这么回事： 信号$A$和$B$卷积，将$B$翻转，从左往右的逐步移动，每移动一次，计算对应位置的乘积之和，直到两者完全不相交为止 这个时域上的翻转比较难理解，但是如果$B$是卷积核，又是对称的，那么解释卷积就变成了模板操作，即将卷积核/模板$B$在$A$上移动，在$A$被$B$覆盖的区域内（感受野）两者对应相乘。所以实际操作中并不考虑这个翻转操作。也可以这么理解，CNN训练之前，各个滤波器/卷积核/模板都是未知的，卷积的时候不做翻转，那么最终训出的结果就是翻转之后的结果，道理是一样的。另外需要注意的是，信号里面的卷积默认做padding的，即超出被卷信号$A$的时长部分按照0处理，因此卷积之后的结果一定比原来信号时长长，我记得好像有个结论$M+N-1$之类的。但是CNN里面的卷积（以二维为例），如果设置padding大小，那么卷出来的结果是越来越小的。 因此卷积这一步有如下概念： 卷积核大小 卷积核移动步长，即每次在特定方向上移动多少步 是否要做边缘padding，是否要边缘补充0 类似的，池化操作也有以上概念。池化层相当于一组特征的滤波器/卷积核，它对输入进行特定的变换，比如取最大（maxpool）或者取平均（avgpool）等等。池化层的作用在于减少信息冗余量，提高特征鲁棒性。CNN设计者认为卷积层之后的结果在空间上是具有variation的，对相邻区域的特征进行将采样，可以减少这种variation带来的不稳定性。另外池化层需要放在激活层之后。 在设计CNN的时候，需要关注输入输出信号之间的大小关系，定义在某方向上的卷积核大小为$N_k$，移动步长为$N_s$，padding长度为$N_p$，该方向上输入信号长度为$N_i$，那么对应方向上输出长度$N_o$由下式得出： N_o = \text{floor}((N_i + 2N_p - (N_k - 1) - 1) / N_s + 1)如果要保证输入输出信号大小不发生变化，那么保证$N_s = 1$，$N_p = (N_k - 1) / 2$。 CNN这块还有一个信道（channel）的概念，比如语音信号中的delta，图像的RGB等等。假设输入为3个信道，那么$N$个卷积核产生的特征个数是$3N$还是$N$？我的理解还是$N$，只不过卷积需要在三个信道上进行，并将对应的结果相加，表示如下： O_i = \sigma \left(\sum_j^J I_j * W_{ji} \right)其中$J$表示输入信道个数，$I,O$表示输入输出，$W_{ij}$表示输入信道$i$和输出信道$j$之间的卷积核。 补充，Github上关于卷积的一个可视化 CNN in ASR首先需要说明，CNN在语音中被设计来降低频域的variation（时域的variation是用HMM来建模）的，因此很多声学模型中的CNN仅仅在输入特征的频率轴上进行卷积（已经有实验验证，在频率轴上卷积的效用更大一些。频率轴卷积是什么意思后面给出自己的理解）。故输入CNN的特征不可以是MFCC（因为其中做了iFFT，破坏了频谱的局部相关性），只能是谱特征以及其衍生特征比如FBANK等等。通过语谱图可以知道，同一个音素的发音在各个频率的分布是有规律的，但是不同的人，不同的性别在频率轴上的共振峰会有shift。通过卷积和池化操作可以降低这种shift带来的影响，相当于提取了一个更加鲁棒的特征。 其次，就是卷积这个操作的参数量很少，对于$N$个卷积核，一层仅仅会产生$N \times K_x \times K_y$个参数，因此在移动终端设备上的应用前景很大（模型复杂度低，计算量少，不同卷积之间可以并行等等）。CNN常见的使用方式是通过卷积层提取鲁棒特征，作为后续的全连接层的输入。 图像自然就是二维的，语音的基本单位为帧，一帧特征对应的只是向量，输入CNN的话，取一个时间窗$T$内的特征构成二维的频谱图$F_{B \times T}$。我对进行频率轴上的卷积的理解如下： 即卷积核的长度和时间窗保持一致，宽度自定（也就是指定的filter_size），移动仅仅在频率轴上进行。这样实际上卷积的结果是一个向量。而如果在时间轴也进行卷积，那么卷积核的大小均可以自定，卷积产生一个矩阵。 但是在文献[4]中提出了两种组织方式，这里以40维FBANK特征来说明： 组织成$N$个$T \times F$的矩阵，故进行二维卷积。$N$为feature maps的个数，取决于是否进行delta 组织成$N \times T$个向量，故进行一维卷积。每个向量长度为$F$，$N \times T$为feature maps的个数，取决于是否delta以及上下文的宽度。 ASR这边的文献中有几个常见的概念，我的理解如下： feature maps：$N$个卷积核卷积输入信号得到$N$组卷积特征，每一组滤波特征称为一个feature maps，等于卷积层的输出信道数目，可以理解为信道。 feature bands：以40维FABNK特征为例子，每一维上的特征序列称为一个feature band。如果连续多帧，一个feature band对应一个特征向量，单帧仅仅为一个数值。 LWS/FWS（local/full weight sharing）：默认一个卷积核一次卷积操作中保持不变，称为FWS，如果在不同的频率值上允许卷积核变化，称为LWS。 沿着频率轴的FWS卷积过程可以参考下图理解，图选自相关文献[2]： CNN在文献[4]中总结的比较全面，[4]和[1]，[2]的第一作者都是一个人，因而可以看做他工作的总结。 实验目前在TIMIT语料上简单跑了几组实验，与很多文献不同的是，我的建模单元采用对齐模型(SAT)的1923个pdf，而不是$61 \times 3 = 183$个。评估方法依旧是标准test集合的PER。主要和传统的DNN比较结果（RNN的结果还没有出来）。模型用pytorch训练，解码使用kaldi内置的latgen-faster-mapped命令，将模型后验转为lattice进行PER的打分计算。其中CNN部分的频轴卷积是按照我自己的理解实现的。实验结果如下： MODEL PER DNN(3X1024) + BN 25.3% DNN(4X512) + BN 24.1% DNN(4X512) + BN + Dropout 23.8% DNN(4X1024) + BN + Dropout 23.7% CNN(K10,P6) + DNN(2X512) 23.1% CNN(K10,P6) + DNN(2X512) + BN + Dropout 22.7% 从实验记录中可以看出： BN和Dropout的正面作用。 DNN中深度比宽度更有助于提高识别率。 CNN的声学建模的鲁棒性（参数量最少，但是获得了最低的错误率）。 相关文献[1]. Applying convolutional neural networks concepts to hybrid NN-HMM model for speech recognition[2]. Exploring convolutional neural network structures and optimization techniques for speech recognition.[3]. Deep convolutional neural networks for LVCSR[4]. Convolutional neural networks for speech recognition]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建SSR服务]]></title>
    <url>%2F2017%2F10%2F02%2Fbuilding-ssr-service%2F</url>
    <content type="text"><![CDATA[Hello, Google! 本来出发点只是找一个托管blog的server…… 写在前面之前的博客是搭在腾讯云上面的，考虑到当时临近毕业，就没有做学生认证。开学之后，没有找到认证入口，提交工单之后却被告知活动取消了，取消了（&gt;_&lt;）…… 话说腾讯云的租赁费用对于在校学生而言还是蛮高的，于是就转投阿里云。阿里云的经历也是奇葩，找不到（没有）腾讯云那样的工单系统，几乎全是机器客服，因此出现了一点问题便很难得到及时的答复。具体经历如下： 注册阿里云之后，进行学生认证，提示可以从支付宝导入认证信息，但是支付宝上的信息是本科阶段的，目前已经失效，而且无法更改（&gt;_&lt;），所以，只能在阿里云网页端重新认证。 找入学年份竟然没有2017年（&gt;_&lt;）！！！这已经是2017年的九月份了…… 估计是开学认证的人多了，过了大约一个星期，入学年份增加了2017一项，进行认证，失败，提示学信网没有我的学业信息…… 后来就继续等学信网更新，更新之后，再次注册，还是失败（&gt;_&lt;），无解弃坑…… 后来又用github的学生优惠想先使用一年的DigitalOcean（简称DO）吧，注册PayPal的时候因为没有信用卡也卡住了（因为需要先充值激活）。 后来发现推荐Vultr的也比较多，加上官网做的清爽，支持支付宝（支付），价格也可以接受，因此就此尝试一下。实际上我在购买的时候新用户的优惠已经没有了，而且最低价的2.5\$的VPS已经售罄，所以选了5\$（一个月三十多）的方案。考虑到毕竟VPS搞到了国外，不做点什么有点遗憾，就此搭一个SS服务，也不需要购买什么VPN的服务了。 SS搭建我这个时间段有点不讨巧，随着国家对网络安全的重视，近几个月来已经有一大批VPN提供商销声匿迹（GreenVPN等等），IOS的App Store也做出响应，把相关的软件下架，比如我使用过了Wingy以及大家推荐的什么土豆丝，shadowrocks等等，如果不换换美区的账号下载的话，实际上在iphone上是没法享受自建的服务的。还有就是关于shadowsocks（简称SS）和shadowsockR（简称SSR）的停止更新。目前github上相关的项目也只留下了一个”romoved according to regulations”的提示。话说前端时间这两个作者貌似吵起来了，我竟然没怎么关注…… 部署服务还是很简单的，网上的一键脚本很多，教程也不少，关于SS和SSR的区别以及概念相关的东西可以参见DB根据地，这个网站上的东西写的很详细，因此也被墙了。 Vultr节点选区的话，可以看一下网上推荐，如果不确定可以多部署几个，测一下速度再把慢的删掉。实测东京节点ping值100多ms，相比洛杉矶300ms+还是明显要快很多。 我这边主要搭的是SSR服务和优化加速服务，单用户的SSR安装时需要确定端口号和密码，脚本有默认值，他们是需要在客户端使用的，安装完成之后的配置在/etc/shadowsocks.json里面（不同版本的配置文件位置不同）。加速服务一般推荐的是锐速或者BBR。我使用的是bbr，在自动安装的过程中如果遇到不支持的内核会做一个自动的内核更新。两者的安装脚本可以在teddysun的github上找到。熟悉linux的话安装是没有什么困难的。 BBR装好之后我测试了一下Youtube的1080p播放效果，确实加速明显。虽然我不大可能经常逛这个视频网站，作为一种好奇心理还是确认了一下效果。 有的时候需要看一下ssr的log，所以还改了一下vps的时间，和本地保持一致。之后就是客户端的问题了。win和mac下的客户端蛮友好的，基本输入服务地址，端口和对应的密码和加密方式之后连接即可，我在使用的时候，这两个平台很快能接入的。我在在学校的主力机是Ubuntu，却一直没有找到方便的客户端（尝试了很多，没有成功）为此暂时转战windows了（考虑可以服务端换成ss，客户端应该方便一点）。 这里没有写的太细，一是因为这方面网上资料很多，过程也很简单，个人感觉不是小白的话，基本都可以轻车熟路。二是考虑敏感话题，尽量少写一点吧。 后续体验Google Drive，Gmail，Google Search完美体验，唯一的不爽是谷歌学术访问不了。访问网页的时候，会出现 We’re sorry…… but your computer or network may be sending automated queries. To protect our users, we can’t process your request right now. 的提示，网上多说是因为Vultr的东京和新加坡的ipv4已经被谷歌全部禁调了，我尝试部署了一台洛杉矶的主机，但是卡的要死，所以还是选择坚持东京的主机。 搜了很久，看见网上有人提出强制用ipv6地址访问的方法，亲测有效，才算是解决了这个问题。首先可以使用ping -6得到谷歌学术的ipv6地址，在hosts文件中配置一下，之后重启机器即可（也有说重启服务的）。话说这个问题还是困扰了一天的。 再者就是Dropbox和Google Drive了。在Windows下代理模式设置为全局之后，就可以直接上手了。Mac上的Dropbox可以在Preference里面手动设置一下本地代理，选sock5配置localhost:default_port即可。Google Drive目前没有自动设置代理的功能，可以下载一个Proxifier，配置一下代理，比如。关于Proxifier需要说几句，这个Mac下的软件可以为不能够自动检测代理或者不支持sock5代理的软件配置代理规则，比如iTerm（终端github加速），Google Drive这些，因为并不是所有的需求通过浏览器就可以满足。下面记两个参考链接 解决mac终端上代理的难题 Mac全局代理 后来有一次突然网络断了，发现vps的v4地址Ping不通，数据包到陕西商洛就丢了，考虑到vps还有一个v6地址，那为何不用它来指定主机？。然后就突发奇想，既然v6地址可以直接路由到主机，那何不将校园网下线？在本地主机拥有v6地址的情况下，配合本地的ss代理（代理指定远程ss服务器的v6地址），就可以实现直接实现上网的功能，而无需通过校园网客户端的认证。如果想要机器上的其他软件（Dropbox可以自动检测代理）比如QQ，云音乐也顺利联网，需要借助之前提到的Proxifier工具，强制指定一下转发规则。当然这时ss需要设置成全局模式，唯一的缺陷就是访问国内站点，使用日常软件的话，速度稍慢，但不是太影响体验。vultr日本节点的速度确实可以，全局模式下，IDM下载速度还是足够的。由于自己购买的方案流量足够，因此，可以体验一下避开校园网认证的生活了。 总的来说，5\$的主机资源对于个人还是有点资源过剩，1G内存，25GSSD和1000G/月的带宽用作Web/SSR的Server绰绰有余。还有，博客部署在Vultr上，但是DNS解析还是用的腾讯云，只是把IP换了一下，Vultr也提供了DNS解析服务，我在这里并没有使用。 注：本篇目的仅在于记录SS搭建过程的相关感受，无推销，教唆等不良他意。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaldi中ivector的提取【二】]]></title>
    <url>%2F2017%2F08%2F29%2Fkaldi-ivector-extract-2%2F</url>
    <content type="text"><![CDATA[本篇接着kaldi中ivector的提取【一】继续分析ivector的在线提取方法。 特征设计在feed模型之前，前端的特征处理操作包括如下： 基本的特征提取（PLP，MFCC，FBANK） 拼帧 Delta 线性变换（LDA，PCA） 特征融合（MFCC + Pitch） 归一化（CMVN） 在线状态下，由于上述操作必须online的进行，kaldi将上述操作封装成下面几个类，定义在online-feature.h中 123456789101112131415// 模板类，提取PLP,MFCC,FBANK特征// typedef OnlineGenericBaseFeature&lt;MfccComputer&gt; OnlineMfcc;// typedef OnlineGenericBaseFeature&lt;PlpComputer&gt; OnlinePlp;// typedef OnlineGenericBaseFeature&lt;FbankComputer&gt; OnlineFbank;class OnlineGenericBaseFeature;// 在线拼帧class OnlineSpliceFrames;// deltaclass OnlineDeltaFeature;// LDA等线性变换class OnlineTransform;// 特征拼接:MFCC+Pitchclass OnlineAppendFeature;// 在线cmvnclass OnlineCmvn; 以上特征类继承OnlineFeatureInterface 通过GetFrame(int32, VectorBase&lt;BaseFloat&gt;*)获取特征输出，在构造函数中指定输入源。 比如，在ivector提取中，UBM模型的输入特征需要经过online-CMVN+Splice+LDA，那么最终的特征构造如下： 12345678// base表示基本声学特征PLP/MFCC/FBANK// cmvn表示对base做了cmvn的结果OnlineCmvnState naive_cmvn_state(info.global_cmvn_stats);cmvn = new OnlineCmvn(info.cmvn_opts, naive_cmvn_state, base);// splice_normalized表示对cmvn进行在线拼帧splice_normalized = new OnlineSpliceFrames(info_.splice_opts, cmvn);// lda_normalized表示对splice_normalized进行在线LDAlda_normalized = new OnlineTransform(info.lda_mat, splice_normalized); 可以这么理解这种设计，将OnlineFeatureInterface的基类理解为一个节点，那么制定每个节点之间的输入输出关系，输入节点为原始音频采样数据，调用输出节点的GetFrame()函数即可获得最终的特征，计算逻辑在节点的内部实现。 在ivector-extract-online2.cc中，实现ivector提取的类OnlineIvectorFeature也是OnlineFeatureInterface的基类。调用GetFrame(int32, VectorBase&lt;BaseFloat&gt;*)即可获得截止当前帧的估计ivector。 在ivector提取的过程中，需要用到两种特征 Splice + LDA：作为ivector的零阶统计量 CMVN + Splice + LDA：作为UBM的输入，获取后验概率 在OnlineIvectorFeature中，用成员lda_和lda_normalized_表示。 在线估计OnlineIvectorFeature类内部使用num_frames_states_来追踪上次估计的时间戳，每一次估计首先遍历新增的帧，更新统计量，并以一定的周期提取ivector。这个周期是可以设置的，代码逻辑如下： 12345678for (; num_frames_stats_ &lt;= frame; num_frames_stats_++) &#123; // 更新统计量 UpdateStatsForFrame(num_frames_stats_, 1.0); // 以一定的周期提取ivector if (t % ivector_period == 0) // ivector_stats_: OnlineIvectorEstimationStats ivector_stats_.GetIvector(num_cg_iters, &amp;current_ivector_);&#125; 更新的统计量包括通过UBM获取的后验和Splice+LDA的特征。GetIvector函数内部使用共轭梯度法计算ivector，（没有直接计算ivector）主要考虑这么做可以减少计算耗时。 OnlineIvectorEstimationStats类中具体实现ivector的在线估计算法，核心函数是累积统计量的AccStats(IvectorExtractor, VectorBase&lt;BaseFloat&gt;, std::vector&lt;std::pair&lt;int32, BaseFloat&gt; &gt;)和ivector估计函数GetIvector(int32, VectorBase&lt;double&gt;*)。 首先看一下ivector的计算： 123456789101112131415161718void OnlineIvectorEstimationStats::GetIvector( int32 num_cg_iters, VectorBase&lt;double&gt; *ivector) const &#123; if (num_frames_ &gt; 0.0) &#123; // 也可以这么做得到准确结果 // SpMatrix&lt;double&gt; quadratic_inv(quadratic_term_); // quadratic_inv.Invert(); // ivector-&gt;AddSpVec(1.0, quadratic_inv, linear_term_, 0.0); if ((*ivector)(0) == 0.0) (*ivector)(0) = prior_offset_; LinearCgdOptions opts; opts.max_iters = num_cg_iters; LinearCgd(opts, quadratic_term_, linear_term_, ivector); &#125; else &#123; ivector-&gt;SetZero(); (*ivector)(0) = prior_offset_; &#125;&#125; 根据注释部分，ivector提取方式为： \mathbf{w}' = \mathbf{w} + \mathbf{Q}^{-1}\mathbf{L} \tag1$\mathbf{Q}$（quadratic_term_），$\mathbf{L}$（linear_term_）在AccStats中完成估计。 123456789101112131415161718192021void OnlineIvectorEstimationStats::AccStats( const IvectorExtractor &amp;extractor, const VectorBase&lt;BaseFloat&gt; &amp;feature, const std::vector&lt;std::pair&lt;int32, BaseFloat&gt; &gt; &amp;gauss_post) &#123; Vector&lt;double&gt; feature_dbl(feature); int32 ivector_dim = this-&gt;IvectorDim(), quadratic_term_dim = (ivector_dim * (ivector_dim + 1)) / 2; SubVector&lt;double&gt; quadratic_term_vec(quadratic_term_.Data(), quadratic_term_dim); for (size_t idx = 0; idx &lt; gauss_post.size(); idx++) &#123; int32 g = gauss_post[idx].first; double weight = gauss_post[idx].second; if (weight == 0.0) continue; linear_term_.AddMatVec(weight, extractor.Sigma_inv_M_[g], kTrans, feature_dbl, 1.0); SubVector&lt;double&gt; U_g(extractor.U_, g); quadratic_term_vec.AddVec(weight, U_g); &#125;&#125; 离线方法中，$\mathbf{L},\mathbf{Q}$的计算如下： \mathbf{L}_{R \times 1} = \sum_{c = 1}^C (\mathbf{B}_c^T)_{R \times F} (\mathbf{F}_c)_{F \times 1} \\ \mathbf{Q}_{R \times R} = \sum_{c = 1}^C \mathbf{U}_c\gamma_c + \mathbf{I}在线方法中，一帧一帧的以累加形式不算修正： \mathbf{L}_{R \times 1}' = \mathbf{L}_{R \times 1} + \sum_{c = 1}^C (\mathbf{B}_c^T)_{R \times F} (p_c \mathbf{x})_{F \times 1} \\ \mathbf{Q}_{R \times R}' =\mathbf{Q}_{R \times R} + \sum_{c = 1}^C p_c\mathbf{U}_c$\mathbf{Q}$被初始化为$\mathbf{I}$。$\mathbf{x}$表示当前输入特征（feature_dbl），$p_c$表示以$\mathbf{x}$为输入的情况下，UBM第$c$个component的后验。$\mathbf{B}_c$和$\mathbf{U}_c$为ivector提取器中的Sigma_inv_M_[g]和U_g。 结合对OnlineIvectorEstimationStats::GetIvector的分析，式子$(1)$可以写成： \mathbf{w}' = \mathbf{w} + (\mathbf{Q}'_{R \times R})^{-1}\mathbf{L}'_{R \times 1}综上所述，考虑到在线方法中的ivector输出周期，因此，一个句子（$T$帧）作为输入往往可以得到$N$个ivector（$N &lt; T$）。 共轭梯度法考虑到效率问题，每次计算$\mathbf{w}$的时候都需要对矩阵求逆，共轭梯度法在这里起的作用是在不进行矩阵求逆的操作下求出$\mathbf{Q}\mathbf{w} = \mathbf{L}$的解$\mathbf{w}$，即线性方程组求解问题。 使用共轭梯度法求解线性方程组的思想是将$\mathbf{w}$看成方程： f(\mathbf{w}) = \mathbf{w}^\top \mathbf{Q} \mathbf{w} / 2 - \mathbf{L}^\top \mathbf{w}的驻点。此时$\nabla_w f(\mathbf{w}) = \mathbf{Q}\mathbf{w} - \mathbf{L} = 0$。 定义$\mathbf{d}_1, \mathbf{d}_2$，若满足$\mathbf{d}_1^\top \mathbf{Q} \mathbf{d}_2 = 0$，那么称$\mathbf{d}_1, \mathbf{d}_2$关于$\mathbf{Q}$共轭。令$\mathbf{d}_k$表示迭代第$k$次的搜索方向，那么第$k + 1$次的搜索方向$\mathbf{d}_{k + 1}$为： \mathbf{d}_{k+1} = - \mathbf{g}_{k + 1} + \beta_k \mathbf{d}_k$\beta_{k}$使得$\mathbf{d}_{k + 1}$和$\mathbf{d}_k$关于$\mathbf{Q}$共轭。它的计算可以通过FR和PR算法得到，kaldi中使用的FR算法如下： \beta_k = \frac{\mathbf{g}_k^\top \mathbf{g}_k}{\mathbf{g}_{k-1}^\top \mathbf{g}_{k - 1}}在第$k$步的搜索步长$\alpha_k$使得解从$\mathbf{w}_k$迁移到$\mathbf{w}_{k + 1}$： \begin{align} \mathbf{w}_{k + 1} & = \mathbf{w}_k + \alpha_k \mathbf{d}_k \notag \\ \mathbf{g}_{k + 1} & = \mathbf{g}_k + \alpha_k \mathbf{Q} \mathbf{d}_k \notag \end{align}其中$\alpha_k$计算如下： \alpha_k = \frac{\mathbf{g}_k^\top \mathbf{g}_k}{\mathbf{d}_{k}^\top \mathbf{Q} \mathbf{d}_k}共轭梯度法初始化$\mathbf{w}_0$为之前估计的ivector： \begin{align} \mathbf{g}_0 &= \mathbf{Q}\mathbf{w}_0 - \mathbf{L} \notag \\ \mathbf{d}_0 &= \mathbf{g}_0 \notag \end{align}之后反复的计算$\mathbf{w}_k,\mathbf{g}_k,\mathbf{d}_k$，直到$\mathbf{g}_k = \mathbf{0}$的时候，$\mathbf{w}_k$即为所求的ivector。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RNN & LSTM & GRU]]></title>
    <url>%2F2017%2F08%2F23%2Frnn-lstm-gru%2F</url>
    <content type="text"><![CDATA[一直觉得RNN是一个可玩性很高的模型，因为现实中我们需要建模的对象往往都可以理解为时间或者空间上的序列（sequence），比如语音，视频，字迹，文本，这种特性极大丰富了RNN处理问题的种类（语言模型，声学模型，机器翻译等等）。一直很火的End-to-End，比如我知道的CTC，RNN-Transducer，Attention（encoder-decoder）也全部based on RNN。既然它可以对序列建模，那么根据不同的输入和输出设计，就可以完成Classification（one-to-one），Embedding（many-to-one），序列生成（one-to-many），seq2seq（many-to-many）等任务。 RNN的进化简单说一下RNN的发展，由于FNN（前馈网络）的结果只依赖于当前输入，而实际处理问题的序列特征往往是上下文相关的，因此融入上下文信息是可以提高模型的准确度的，这一点在FNN中是通过单纯的增加输入信息量完成的。后来就有人提出了将网络隐层上一时刻的输出再次作为输入传递到下一时刻，以此获取所谓的历史信息。考虑到网络节点的信息流走向存在了自环，故称之为RNN（Recurrent，循环）。一开始纯粹的RNN会出现所谓的梯度消失问题无法长久记忆历史信息，为了解决这个问题，1997年Hochreiter &amp; Schmidhuber提出了所谓的LSTM。 后来就是LSTM的不断改进，一开始LSTM的一个记忆块只有输入输出和细胞三个元素，后来在1999年，F.A.Gers et al.等人增加了遗忘门，2003年在各个门和cell之间增加了Peephole Connections，2005年，Graves &amp; Schmidhuber写了一本书《Supervised Sequence Labelling with Recurrent Neural Networks》，里面对LSTM的结构描述如下（虚线表示peephole connections）： 再后来，2014年谷歌的Hasim Sak et al.提出在LSTM层之后加上一个project层（如下图表示，recurrent表示recurrent project layer，memory block表示和Graves的是等效的），即LSTMP用于语音识别中；多伦多大学的Cho et al. 提出RNN encoder-decoder框架的时候设计了一种新的隐藏单元GRU，单元中只含有重置门和更新门（reset and update gate），计算复杂度更小。 RNN普通RNN涉及到自环和上一时刻的输入，定义$n$隐层的RNN，隐层输入，输出，输入变换矩阵，自环变换矩阵以及偏置向量为$(\boldsymbol{i}_i, \boldsymbol{o}_i, \boldsymbol{W}{i}, \boldsymbol{H}_{i}, \boldsymbol{b}_i)$，激活函数为$\theta$，那么前向传播可以表示为： \begin{align} \boldsymbol{z}_i^t &= \boldsymbol{W}_{i} \boldsymbol{i}_i^t + \boldsymbol{H}_{i} \boldsymbol{o}_{i}^{t - 1} + \boldsymbol{b}_i \notag \\ \boldsymbol{o}_i^t &= \theta(\boldsymbol{z}_i^t) \notag \end{align}$t$时刻的网络输出$\boldsymbol{y}^t$（$f$为输出层激活函数）表示为： \begin{align} \boldsymbol{z}_o^t &= \boldsymbol{W}_o \boldsymbol{o}_n^t + \boldsymbol{H}_{o} \boldsymbol{o}_n^{t - 1} + \boldsymbol{b}_o \notag \\ \boldsymbol{y}^t &= f(\boldsymbol{z}_o^t) \notag \end{align}LSTM注：个人觉得一般情况下一个memory block中只含有一个cell，存储一个浮点值（虽然它们的关系是一对多的），所以如果说LSTM层cell个数为$N_c$个，那么意味着该层含有$N_c$个记忆块，用向量表示，该层的各个门和cell的长度均为$N_c$。 参照图1中的信息流，定义输入门，输出门，遗忘门和记忆单元的激活值$\boldsymbol{i}, \boldsymbol{o}, \boldsymbol{f}$, $\boldsymbol{h}$为最终输出，那么，在$t$时刻，各门的激活值和输出由以下各式计算得到： \begin{align} \boldsymbol{i}_t &= \sigma(\boldsymbol{W}_{ix}\boldsymbol{x}_t + \boldsymbol{W}_{ih}\boldsymbol{h}_{t - 1} + \boldsymbol{W}_{ic}\boldsymbol{c}_{t - 1} + \boldsymbol{b}_i) \notag \\ \boldsymbol{f}_t &= \sigma(\boldsymbol{W}_{fx}\boldsymbol{x}_t + \boldsymbol{W}_{fh}\boldsymbol{h}_{t - 1} + \boldsymbol{W}_{fc}\boldsymbol{c}_{t - 1} + \boldsymbol{b}_f) \notag \\ \boldsymbol{c}_t &= \boldsymbol{f}_t \odot \boldsymbol{c}_{t - 1} + \boldsymbol{i}_t \odot g(\boldsymbol{W}_{cx}\boldsymbol{x}_t + \boldsymbol{W}_{ch}\boldsymbol{h}_{t - 1} + \boldsymbol{b}_c) \notag \\ \boldsymbol{o}_t &= \sigma(\boldsymbol{W}_{ox}\boldsymbol{x}_t + \boldsymbol{W}_{oh}\boldsymbol{h}_{t - 1} + \boldsymbol{W}_{oc}\boldsymbol{c}_t + \boldsymbol{b}_o) \notag \\ \boldsymbol{h}_t &= \boldsymbol{o}_t \odot h(\boldsymbol{c}_t) \notag \end{align}$\boldsymbol{W}_{*h}$表示peephole connection（对角矩阵），$\sigma, g, h$为对应门的激活函数（一般$h = \tanh$，$g, \sigma$为sigmoid），$\odot$表示逐元素的相乘。project层（如果存在的话）$\boldsymbol{p}_t$由下式得到： \boldsymbol{p}_t = \boldsymbol{W}_{pr}\boldsymbol{h}_ttensorflow里面LSTM的细胞有两个实现版本，LSTMCell和BasicLSTMCell。前者相对丰富一些，可以选择配置peephole，project layer，cell clipping，而后者是没有这些功能的。根据代码注释，BasicLSTMCell参考论文为[7]（LSTM记忆块结构如下），而LSTMCell为Acoustic Modeling那篇。 从图中也可以看出，输入输出和遗忘门和cell之间没有peephole connection。这篇文章的重点是提出了一种在LSTM中使用dropout达到正则化效果的建议，即dropout不要在循环信息上作用，仅仅作用在节点的当前输入输出即可。 GRUGRU（Gated recurrent unit）这个循环单元直观上看起来和LSTM还是有很大差别的，论文中只用了一个很简单的图示就说明了其结构（如下）。单元中仅仅含有一个更新门$z$和重置门$r$。这两个门的计算逻辑也是相同的（类似LSTM的输入输出遗忘三个门），更新门决定了当前的输入结果的影响大小，可以理解为一个权值。两者由下式得出： \boldsymbol{r}_t = \sigma(\boldsymbol{W}_{rx}\boldsymbol{x}_t + \boldsymbol{W}_{rh}\boldsymbol{h}_{t - 1}) \\ \boldsymbol{z}_t = \sigma(\boldsymbol{W}_{zx}\boldsymbol{x}_t + \boldsymbol{W}_{zh}\boldsymbol{h}_{t - 1})最终的单元输出$\boldsymbol{h}_t$计算如下： \boldsymbol{h}_t = (1 - \boldsymbol{z}_t) \odot \boldsymbol{h}_{t - 1} + \boldsymbol{z}_t \odot \phi(\boldsymbol{W} \boldsymbol{x}_t + \boldsymbol{U}(\boldsymbol{r}_t \odot \boldsymbol{h}_{t - 1}))更新门作为上一时刻信息的系数，控制着上一时刻到当前时刻的信息流量。如果更新门$\boldsymbol{z}_t \to \mathbf{0}$，那么$\boldsymbol{h}_t$的第二项忽略，该层忽略了当前输入。将$\phi(\boldsymbol{W} \boldsymbol{x}_t + \boldsymbol{U}(\boldsymbol{r}_t \odot \boldsymbol{h}_{t - 1}))$理解为新的状态计算候选值，若$\boldsymbol{r}_t \to \mathbf{0}$，该候选值则相当于遗忘了历史信息的候选值，仅仅依赖当前输入$\boldsymbol{x}_t$。 对比GRU和LSTM，可以发现： LSTM的cell溢出信息被输出门控制，而GRU的单元信息是完全暴露的（可以理解为删除了输出门控）。 LSTM并不直接的从上一时刻中获取信息，而是通过输入门和遗忘门对待选cell值和上一时刻cell值的加权得到的，GRU可以直接通过更新门获取上一时刻信息。 GRU中的信息直接存储在历史状态$h$中，而LSTM存储在cell中。更新门对应遗忘门，重置门对应输入门。 上图是论文[8]中对两种结构单元的对比图，详细的分析和实验对比也可以看一下这篇论文。 相关文献 [1]. Long short-term memory（Hochreiter &amp; Schmidhuber et al.） [2]. Learning to forget: Continual prediction with LSTM（F.A.Gers et al.） [3]. Learning precise timing with LSTM recurrent networks（F.A.Gers et al.） [4]. Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation（Cho et al.） [5]. Long Short-Term Memory Recurrent Neural Network Architectures for Large Scale Acoustic Modeling（Hasim Sak et al.） [6]. LSTM: A Search Space Odyssey（Klaus Greff et al.） [7]. Recurrent Neural Network Regularization（Wojciech Zaremba） [8]. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling（J Chung et al.）]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DL中的常见正则化方法]]></title>
    <url>%2F2017%2F08%2F18%2Fregularization-in-deeplearning%2F</url>
    <content type="text"><![CDATA[平时训练模型的时候知道一些常见的防止过拟合的tricks，但是也只是拿来用一下，比如dropout和BN等等，基本没有了解过why层面的东西。最近看了一下dropout，batch-normalization的论文，以及DeepLearning Book里面正则化那一章，做一下小结。 DropoutDropout的提出者（Srivastava etc.）认为使用多个模型的平均结果是十分有效的一种正则化方法，即从不同的模型获取结果进行加权平均。但是它的缺点显而易见，一个是需要大量模型的训练（要么网络架构不同，要么数据集不同），另一个就是较高的计算复杂度（获取输出+平均操作）。Dropout的巧妙之处在于通过它可以在同一个模型上实现类似模型平均的效果。 Dropout是指训练阶段对网络的隐藏节点以一定的概率独立的在网络中丢弃的操作（见下图）。某个节点被丢弃，意味着它的输出输出一并不再存在。丢弃节点之后的网络称为瘦身网络（减少了节点数）。排列组合一下，对于节点数为$N$的网络，其可能存在的瘦身网络为$2^N$个。对于每一批输入数据，反向传播阶段仅仅是对当前采样生成的瘦身网络进行训练，因此从整个网络的训练过程来看，可以认为成是对指数级个子网络的同时训练，而这些网络是共享权值的。 如果要等效模型平均，Dropout网络的前向过程（推断）必须具有average的功能。一般的隐层节点的dropout/采样概率$\mathbf{r}_l^i$服从伯努利分布，推断过程进行如下： \widehat{\mathbf{x}}_l = \mathbf{r}_l * \mathbf{x}_l \\ \mathbf{x}_{l + 1} = f(\mathbf{W}_l \widehat{\mathbf{x}}_l + \mathbf{b}_l)在DeepLearning Book里面提到了正则化的Bagging方法（多模型结果的加权平均），Dropout可以理解为指数级别集成网络的Bagging方法。 参数正则参数正则这里包括$L^1$（promote sparsity）和$L^2$（weight decay）正则，虽然这两个概念经常见到，但是我却在相当长的一段时间内没有去理解其背后的原理。看到DeepLearning Book就顺便和Dropout在一起总结一下了。 参数正则是指对原目标函数$J$加上一个参数相关的惩罚项$\ell$： J'(\mathbf{w}) = J(\mathbf{w}) + \alpha \ell(\mathbf{w})梯度更新变化为： \mathbf{w}' = \mathbf{w} - \eta \nabla_w J'(\mathbf{w}) \\ = \mathbf{w} - \eta \nabla_w J(\mathbf{w}) - \eta \alpha \nabla_w\ell(\mathbf{w})一般的正则项只针对网络中的权值（和偏置无关），系数$\alpha$控制惩罚项作用大小。$L^1$和$L^2$正则的$\ell$定义如下： \ell(\mathbf{w}) = \begin{cases} \Vert \mathbf{w} \Vert_1 = \sum_i \vert w_i \vert & \text{for}\; L^1\\ \Vert \mathbf{w} \Vert_2^2 = \mathbf{w}^\top \mathbf{w} & \text{for}\; L^2 \end{cases}带入$\mathbf{w}’$： \mathbf{w}' = \begin{cases} (1 - \eta \alpha)\mathbf{w} - \eta \nabla_w J'(\mathbf{w}) & \text{for}\; L^1\\ \mathbf{w} - \eta \alpha \cdot \text{sgn}(\mathbf{w})- \eta \nabla_w J'(\mathbf{w}) & \text{for}\; L^2 \end{cases}根据DeepLearning Book中的表述，$L^1$正则会产生更加稀疏的解，即权值矩阵中零元素增加，而$L^2$正则不具有这种效果，它会使权重的分布更加接近于原点。 Batch NormalizationBatch-Normalization（简称BN）的提出是要解决一个叫Internal Covariate Shift的问题，如果将DNN简单理解成为若干个层级子网络的堆叠，那么网络训练的收敛可以认为是后继网络不断学习其前置网络的数据分布的过程。但是由于学习过程中参数不断变化，各个子网络的分布也会随之变化，由此带来了所谓的Internal Covariate Shift问题。BN的解决思路也比较简单，就是normalize上述层级子网络输入的均值和方差，BN的论文中认为其优势在于： 加速网络的收敛，即可以在较小的steps下达到相同的收敛程度（相对于没有BN层） 允许使用较大的学习率 减少对参数初始化的敏感度 减少Dropout的需要 之前往往只是对训练数据的分布进行归一化操作，BN相当于是将这种normalize引入了网络中成为独立的BN层，随之而来的问题就是BN层如何设计以及如何训练的问题了。 对于特征$\mathbf{x} \in \mathbf{R}^D$，将输入网络前的归一化操作 $\widehat{\mathbf{x}} = \text{Norm}(\mathbf{x})$： \widehat{\mathbf{x}}_d = (\mathbf{x}_d - E[\mathbf{x}_d]) / V[\mathbf{x}_d]引入网络层间，$\mathbf{x}$即为每个子网络对应的输入。根据论文中的表述，$\widehat{\mathbf{x}}$和$\mathbf{x}$的表征能力并不完全相同，因而引入一个逆操作Scale and Shift，对normalized的特征进行重新表示： \mathbf{y}_d = \gamma_d\widehat{\mathbf{x}}_d + \beta_d其中$\gamma_d, \beta_d$是需要学习的参数。 在SGD框架中，使用一个mini-batch内的数据来预估$E[\mathbf{x}_d]$和$V[\mathbf{x}_d]$，定义batch-size为$m$，那么BN层的变换可以表示为$\text{BN}_{\gamma, \beta}(\mathbf{x}, \mathbf{y})$： \mu_{\mathcal{B}} = E[\mathbf{x}_{1\cdots m}] \\ \sigma^2_{\mathcal{B}} = V[\mathbf{x}_{1\cdots m}] \\ \widehat{\mathbf{x}}_i = \text{Norm}(\mathbf{x}; \mu_{\mathcal{B}}, \sigma^2_{\mathcal{B}}) \\ \mathbf{y}_i = \gamma \widehat{\mathbf{x}}_i + \beta训练阶段，已知$\frac{\partial \ell}{\partial \mathbf{y}_i}$，需要计算出$\frac{\partial \ell}{\partial \gamma}, \frac{\partial \ell}{\partial \beta}, \frac{\partial \ell}{\partial \mathbf{x}_i}$（用于BP传递梯度到前一层）： \frac{\partial \ell}{\partial \gamma} = \sum_{i = 1}^m \frac{\partial \ell}{\partial \mathbf{y}_i} \widehat{\mathbf{x}}_i \\ \frac{\partial \ell}{\partial \beta} = \sum_{i = 1}^m \frac{\partial \ell}{\partial \mathbf{y}_i} \\ \frac{\partial \ell}{\partial \mathbf{x}_i} = \frac{\partial \ell}{\partial \widehat{\mathbf{x}}_i} \frac{\partial \widehat{\mathbf{x}}_i}{\partial \mathbf{x}_i} + \frac{\partial \ell}{\partial \sigma_{\mathcal{B}}^2}\frac{\partial \sigma_{\mathcal{B}}^2}{\partial \mathbf{x}_i} + \frac{\partial \ell}{\partial \mu_{\mathcal{B}}} \frac{\partial \mu_{\mathcal{B}}}{\partial \mathbf{x}_i}\\ = \frac{\partial \ell}{\partial \widehat{\mathbf{x}}_i} \frac{1}{\sqrt{\sigma_{\mathcal{B}}^2 + \epsilon}} + \frac{\partial \ell}{\partial \sigma_{\mathcal{B}}^2} \frac{2(\mathbf{x}_i - \mu_{\mathcal{B}})}{m}+ \frac{\partial \ell}{\partial \mu_{\mathcal{B}}} \frac{1}{m}在训练阶段，参数的更新是依赖当前的batch的，但是单纯的使用模型的时候，必须使得当前输入的结果仅仅依赖当前输入，因此需要解决BN变换中的均值方差估计问题。 BN层的均值方差可以通过对若干个mini-batch处理结果的平均得到： E[\mathbf{x}] = E_{\mathcal{B}}[\mu_{\mathcal{B}}] \\ V[\mathbf{x}] = \frac{m}{m - 1}E_{\mathcal{B}}[\sigma^2_{\mathcal{B}}]对于输入$\mathbf{x}$，使用训练好的参数$\gamma, \beta$和估计好的均值方差，BN层的整体变换可以表示为： \mathbf{y} = \gamma \cdot \frac{\mathbf{x} - E[\mathbf{x}]}{\sqrt{V[\mathbf{x}] + \epsilon}} + \beta参考文献 Dropout: A Simple Way to Prevent Neural Networks from Overfitting Batch normalization-accelerating deep network training by reducing internal covariate shift DeepLearning Book]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[梯度下降中的优化策略]]></title>
    <url>%2F2017%2F08%2F17%2Foptimization-in-sgd%2F</url>
    <content type="text"><![CDATA[模型训练中的学习率是最重要的超参数之一，目前的学习率优化方法主要有两大类，一类可以在训练过程中定义存在其他动态的超参数参与的调整更新规则，另一类是预先设定的更新（一般是衰减）规则，比如线性衰减，指数衰减等。 min-batch SGD从训练集中随机fetch出大小为m的batch，执行更新规则如下： \mathbf{g}_t = \nabla_\theta \sum_{i = 1}^m \mathcal{L}(\mathbf{x}_i, \mathbf{y}_i, \theta_t) / m \\ \theta_{t + 1} = \theta_t - \eta \mathbf{g}_t 动量法在SGD之上考虑了之前的梯度方向对当前更新梯度的影响，即用动量$\mathbf{m}$来代替梯度更新超参数，动量的计算依赖上一时刻的动量和当前梯度（也可以理解为之前的累计梯度的信息）： \mathbf{m}_{t + 1} = \mu \mathbf{m}_t + \mathbf{g}_t \\ \theta_{t + 1} = \theta_t - \eta \mathbf{m}_{t + 1}动量因子$\mu$可以描述之前累计的梯度对当前梯度的影响，假设在SGD过程中梯度抖动的十分厉害（方向，大小），那么引入动量可以一定程度上对这种抖动起到抑制作用。反之如果保持相对平稳，那么动量可以起到放大梯度的作用（相当于增大步长）。 此外还有一种称为Nesterov动量的变式，在计算$\mathbf{g}_t$时，用的不是参数$\theta_t$，而是施加了动量$\mathbf{m}_t$之后的参数，即： \mathbf{g}_t = \nabla_\theta \sum_{i = 1}^m \mathcal{L}(\mathbf{x}_i, \mathbf{y}_i, \theta_t -\eta\mu\mathbf{m}_t) / m之后再进行$\mathbf{m}_{t + 1}, \theta_{t + 1}$的更新。 下面是三个常见的自适应学习率调整方法，即AdaGrad，RMSProp，Adam： AdaGradAdaGrad每一次会更急累计更新梯度的平方和，对当前得出的梯度矩阵进行缩放。缩放大小反比与该平方和的平方根，即累计损失越多的方向学习率越高： \mathbf{n}_{t + 1} = \mathbf{n}_t + \mathbf{g}_t^2 \\ \theta_{t + 1} = \theta_t - \;\frac{\eta \mathbf{g}_t}{\sqrt{\mathbf{n}_{t + 1}} + \epsilon}注：缩放方式为对应元素的缩放。 RMSProp从AdaGrad的更新公式可以看出，累积量$\mathbf{n}_t$在时间轴上是没有加权的，RMSProp丢弃较远的历史信息，将累计平方梯度更新公式变换为： \mathbf{n}_{t + 1} = \rho\mathbf{n}_t + (1 - \rho)\mathbf{g}_t^2AdamAdam结合了动量和和RMSProp，将动量并入一阶矩的估计，同时加入偏差修正，更新过程如下： \mathbf{m}_{t + 1} = \mu \mathbf{m}_t + (1 - \mu)\mathbf{g}_t \\ \mathbf{m}_{t + 1}' = \frac{\mathbf{m}_{t + 1}}{1 + \mu^{t + 1}} \\ \mathbf{n}_{t + 1} = \rho \mathbf{n}_t + (1 - \rho)\mathbf{g}_t^2 \\ \mathbf{n}_{t + 1}' = \frac{\mathbf{n}_{t + 1}}{1 + \rho^{t + 1}} \\ \theta_{t + 1} = \theta_t - \;\frac{\eta \mathbf{m}_{t + 1}'}{\sqrt{\mathbf{n}_{t + 1}'} + \epsilon}除此之外还有AdaDelta，AdaDec等优化方法在相应的论文中，这里有时间再加上…… 一些常用衰减规则主要有： Exponential Scheduling：在nnet2/3中使用的是指数衰减，计算出训练需要的轮数，在设置的初始学习率和终止学习率之间进行指数衰减。 Power Scheduling Performance Scheduling：一般在测试集上的loss不再下降时（或者满足某种折半条件），将学习率乘以一个decay rate，比如在nnet1中进行折半（乘以0.5）。 参考文献 DeepLearning Book第八章 An empirical study of learning rates in deep neural networks for speech recognition]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Training in ASR]]></title>
    <url>%2F2017%2F08%2F13%2Fsequence-training%2F</url>
    <content type="text"><![CDATA[在识别任务中，我们会产生这样的一个疑问，即分类器训练的越充分，是否会带来更高的识别率？从经验上来说不能承认这一点，因为基于CE的分类只是针对frame级别的判别（误差定义在frame上）而识别的本质是一个序列mapping的任务。序列区分性训练尝试在识别序列上定义误差，从这一点上来看，更加接近于识别的最终目标，因而也会相应的获得较高的识别率。 目前的区分性准则（在kaldi中）主要有MMI（最大互信息），MPE（最小音素错误），MBR（最小贝叶斯风险，一般是state-level的，称为sMBR）。 CE将$y_{ut}$定义为softmax层的输出，$\alpha_{ut}$定义为softmax层的输入，网络的每个输出节点对应一个pdf（状态s）的后验： y_{ut}(s) = \frac{e^{\alpha_{ut}(s)}}{\sum_{s'}e^{\alpha_{ut}(s')}}交叉熵的代价函数定义为： \mathcal{F}_{CE} = -\sum_{t}\sum_{s} p(s)\log y_{ut}(s) \\ = -\sum_{t}\log y_{ut}(s_{ut})和交叉熵比较相似的一个概念是相对熵（也称为KL散度），用来衡量两个分布之间的差异（egs. $p, q$）： D_{KL}(p || q) = \sum_{i} p(i) \log \frac{p(i)}{q(i)} \\ = \sum_{i}p(i) \log p(i) - \sum_{i}p(i) \log q(i)其中，$- \sum_{i}p(i) \log q(i)$就是交叉熵： H(p, q) = - \sum_{i}p(i) \log q(i)$p$为真实分布，$q$为网络拟合的分布，网络训练的目标是让$q$的分布接近于$p$，在$p$已知的情况下，$\sum_{i}p(i) \log p(i)$为常数，因此$D_{KL}$和$H$同时取得最小值，因此可用交叉熵来替代KL散度作为目标函数。 执行分类任务时候，先验分布编码为one-hot形式，即$p(s) = \delta_{s, s_{ut}}$，$\delta$为克罗内克函数，$s_{ut}$为句子$u$在$t$时刻的label（类别）索引。因此在表达式$\mathcal{F}_{CE}$中，有 \sum_{s} p(s)\log y_{ut}(s) = \log y_{ut}(s_{ut})MMI定义特征（观测）序列 $\mathbf{O}_u = \{\mathbf{o}_{u1}, \mathbf{o}_{u2}, \cdots, \mathbf{o}_{uT_u}\}$，$W_u$为句子$u$的抄本序列，$S_u$为在抄本$W_u$下对齐得到的中间状态序列$\{\mathbf{s}_{u1}, \mathbf{s}_{u2}, \cdots, \mathbf{s}_{uT_u}\}$。MMI准则下的目标函数为： \mathcal{F}_{MMI} = \log \frac{p(\mathbf{O}_u | S_u)^k p(W_u)}{\sum_W p(\mathbf{O}_u | S)^k p(W)}显然，MMI是定义在整个句子上的，直观的理解就是要最大化正确解码序列概率在所有可能序列中的占比（关注句子的正确率）。 MPE/sMBR延续MMI中的定义，MPE和sMBR的目标函数可以统一用下面的式子表示： \mathcal{F}_{MPE} = \frac{\sum_W p(\mathbf{O}_u | S)^k p(W) A(W, W_u)}{\sum_W p(\mathbf{O}_u | S)^k p(W)}其中$A(W, W_u)$表示以$W_u$为参考，音素（MPE）和状态（sMBR）的正确率。也就是说，它们更加关注解码序列中的音素/状态的正确率。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对kaldi中Online-Decoder的分析]]></title>
    <url>%2F2017%2F08%2F02%2Fkaldi-online-decoder%2F</url>
    <content type="text"><![CDATA[解码是指在构建好的解码网络（图）中，根据输入的音频，生成最优序列的过程。在kaidi中，解码之前，解码网络（实际上是一个巨大的WFST）是已经构建好了的（一般称之为静态解码器），也就是熟知的HCLG。在这张图中，状态节点并无太大意义（毕竟不是自动机），信息存储在状态和状态的转移边之间。输入为tid（tid为0表示没有输入/输入为空$\epsilon$，因而可以连续跳转），输出为词，权值为语言模型的权值。解码过程中，声学模型的后验概率需要实时计算得出（特征+声学模型）。理解解码过程需要弄清以下几个方面： 解码过程中使用到的数据结构及其拓扑关系 解码过程中的剪枝策略（个人觉得这部分比较抽象） 解码过程中的特征供给 下面是以LatticeFasterOnlineDecoder为分析对象的一些记录。 数据结构解码过程是一帧一帧进行的，在约束图（解码图）中，$t$时刻可以到达的状态必然是由$t - 1$时刻的状态出发的，也就是说，信息流从$t - 1$时刻向$t$时刻传递。如果不考虑效率问题，将每个时刻可能到达的状态按照时间展开，那么就可以得到一颗巨大的树。每一个从根节点到叶子节点的路径都可以理解为一条可能路径，只不过有的出现概率高，有的低而已。 用token表示上述过程中描述的信息，那么每一时刻，每一状态维护一个token，在$t \in [0, T]$时刻，新的一轮token由$t - 1$时刻的token和解码图的路径约束共同形成。kaldi中token用结构体Token来描述，同一时刻的token通过next指针相连，从该时刻可以传递到的状态用ForwardLink描述，前一时刻的token由HashList&lt;StateId, Token*&gt;描述（这是一个kaldi自己实现的模板，其中的Hash元素本质上是使用链表连接的，但是也可以像Hash表一样随机获取），而整个解码过程中每一时刻产生的token（相当于上面说的树）用std::vector&lt;TokenList&gt;描述，下标为当前帧数，TokenList相当于一个Token的链表头，通过它可以依次获取到相应时刻的所有活跃token，具体的成员及其含义如下： Token 12345678struct Token &#123; BaseFloat tot_cost; // 到该状态的累计cost BaseFloat extra_cost; ForwardLink *links; // 也是一个链表，因为由该token可以到达下一时刻的token不止一个 Token *next; // 指向同一时刻的下一个token Token *backpointer; // 指向上一时刻的最佳token，相当于一个回溯指针， // 到达该状态的token可能会有很多，但只取最优的一个&#125;; ForwardLink 12345678struct ForwardLink &#123; Token *next_tok; // 这条链接指向的token Label ilabel; // 这下面的四个量取自解码图中的跳转/弧/边，因为每一个状态 Label olabel; // 维护一个token，那么token到token之间的连接信息和状态到状态之间的信息 BaseFloat graph_cost; // 应该保持一致，所以会有输入（tid），输出，权值（就是graph_cost） BaseFloat acoustic_cost; // acoustic_cost就是tid对应的pdf_id的在声学模型中的后验 ForwardLink *next; // 链表结构，指向下一个&#125;; TokenList 12345struct TokenList &#123; Token *toks; // 同一时刻的token链表头 bool must_prune_forward_links; // 这两个是Lattice剪枝标记 bool must_prune_tokens;&#125;; 这几部分的关系可以用下图描述： 另一个重要的数据结构是kaldi中自己实现的HashList，一个类似于跳表的数据结构，里面维护的元素本质上以链表的形式相连，同时通过一个Hash表建立索引。元素和哈希通过Elem和HashBucket实现：12345678910struct Elem &#123; I key; // State T val; // Token Elem *tail; // 链表，指向下一个元素&#125;;struct HashBucket &#123; size_t prev_bucket; // 指向前一个桶的下标，类似静态链表的索引方法 Elem *last_elem; // 指向挂在该桶上的最后一个元素，找到他就可以索引该桶上所有元素了&#125; 整个哈希结结构存在容器std::vector&lt;HashBucket&gt; buckets_中，通过SetSize()可以分配buckets_的大小。需要注意的是，前一个HashBucket的last_elem.tail指向当前HashBucket的第一个元素。其他重要的变量如下：1234Elem *list_head_; // Elem链表会不断释放，分配，该变量记录链表头部Elem *freed_head_; // 记录空闲链表的头部，分配新的Elem就是从该头部取出一个空闲Elemsize_t bucket_list_tail_; // 当前活跃的最后一个桶的下标size_t hash_size_; // 当前活跃的桶的个数 该数据结构的操作逻辑如下： 获取当前活跃的所有元素Elem只需要返回list_head即可，通过链表的遍历即可访问到所有活跃元素（即上一时刻的State和对应的Token）。 如何遍历Hash通过bucket_list_tail_获取到最后一个活跃桶下标，通过HashBucket.prev_bucket访问到前一个，直到访问到-1标记结束位为止。 如何清空Hash清空Hash只需要将相应的标记置为“空”即可，不需要实际释放元素内存。对于Hash而言，遍历一遍，将HashBucket.last_elem置为NULL，bucket_list_tail_置为-1，对于Elem而言，将链表头部list_head_置为NULL即可。 如何删除元素将需要删除的元素从list_head_中插入到freed_head_中，采用头插法（插入freed_head_头部） 如何查找元素首先通过哈希函数对Key哈希到下标，定位到具体的bucket，之后，根据之前提到的关系：“前一个HashBucket的last_elem.tail指向当前HashBucket的第一个元素*first_elem”，就可以在链表头尾之间遍历查询了。 如何增加元素如果freed_head_不为空，那么意味着存在可用的空闲元素，将free_head_指向的元素返回，并后移一位即可，如何已经耗尽，那么新分配一批（默认是1024个）Elem赋给free_head_，重复之前的过程即可。 如何插入元素首先拿出一个空闲的元素，赋值为相应的Key/Value，使用Key哈希到bucket的下标： 如果该桶不为空，将该元素插入到当前桶的尾部即可 若该桶为空，需要将bucket_list_tail_指向该桶，还要修正该桶的prev_bucket（指向修改前的bucket_list_tail_）以及last_elem（指向该元素）。 如果调用toks = HashList.Clear()，那么拿到的toks实际上是被置为NULL之前的HashList.list_head_的值，也就是清空前哈希的链表结构，这时候由于HashList已经重置过了，所以toks成为了前一状态产生的哈希/Elem链表的唯一引用。之后再对HashList操作都不会干扰到toks。因此，可以用toks来替代prev_toks，清空之后的HashList代替cur_toks。由于我们只需要遍历toks，用一下token中的信息，使用完之后，通过Delete函数，就可以将toks中的元素插入到HashList.free_head_中，实现内存的回收。 解码逻辑解码的逻辑非常简单，在解码正式开始之前调用InitDecoding()做一些初始化的工作，之后就是不断接受新的音频数据，调用AdvanceDecoding()（每一次DecodableInterface中的新的可用特征一次解码完毕），直至音频输入终止，调用FinalizeDecoding()结束解码。 在AdvanceDecoding()中，对于每一帧调用ProcessEmitting()和ProcessNonemitting()，后者处理ilabel == 0的token传递（考虑到解码图中每一个状态均有自环，所以可以肯定的是，自环的输入label必然不能为空，否则就会陷入死循环）。每隔几帧剪一次枝。主要逻辑代码如下：1234567891011// 解码到没有为止// NumFramesDecoded(): active_toks_.size() - 1while (NumFramesDecoded() &lt; target_frames_decoded) &#123; // 剪枝：默认25 if (NumFramesDecoded() % config_.prune_interval == 0) &#123; PruneActiveTokens(config_.lattice_beam * config_.prune_scale); &#125; // 这里active_toks_扩充一个空间 BaseFloat cost_cutoff = ProcessEmitting(decodable); ProcessNonemitting(cost_cutoff); &#125; 下面对每个函数块逐一分析： ProcessEmitting这部分代码主要实现两个功能，一个是token信息沿着输入不为空的弧上的传递，另一个就是若干剪枝阈值的评估。这部分的剪枝有两层，第一层决前一时刻的token能否继续存在，也就是说，如果前一时刻某一个token的tot_cost相比最好的token的tok_cost差的太多，那么它就没有必要继续传递下去了（这条路径概率过低）。第二层决定前一时刻的token是否能将信息沿着解码图中的路径约束传递到当前时刻，这一步需要预估一个当前时刻的最优权值，如果token沿着某条弧转移过来过低于我们这个预估的值，那么也不允许它传递（因为就算传递了，也会在下一时刻的第一层剪枝中被剪掉）。 解释一下所谓的beam，beam的含义是，允许过滤项和最优项之间的差距在beam之内。解码过程中的cost越低越优，因此，当得出所谓的best_cost之后，往往将best_cost + beam最为剪枝的阈值。 代码中将上述第一层剪枝的阈值命名为cur_cutoff，第二层剪枝阈值命名为next_cutoff。第一层剪枝阈值的计算在函数GetCutoff()中实现，这个函数不只计算出前一时刻的剪枝阈值，同时得出前一时刻token链表中token的个数，最佳token，以及估计next_cutoff需要的adaptive_beam。 考虑到解码中允许设置--max-active(default = MAX_INT)和--min-active(default = 200)，不同的设置在GetCutoff()中的计算逻辑不同，因为beam本身就是一个容差估计（只是这种估计并没有什么参照标准），但是现在有新的约束条件（token数目）约束了，因而需要结合在这种约束下的估计值选一个。分如下两种情况： 假设没有约束，即某一时刻的token数目没有限制，那么使用beam作为容差（默认为16），即： 12cur_cutoff = best_weight + config_.beam; // default config_.beam = 16.0adaptive_beam = config_.beam; 存在$[N_{min}, N_{max}]$约束：那么令$C_{min}$(max_active_cutoff)和$C_{max}$(min_active_cutoff)分别为token链中第max-active和min-active小的cost。显然，前者小于后者（约束更紧）。用$W_{best}$表示best_weight，$b$表示config_.beam:那么cur_cutoff取$\min_{2nd}(W_{best} + b, C_{min}, C_{max})$。如果结果是$W_{best} + b$，那么和情况1结果保持一致，否则adaptive_beam计算如下： 12// config_.beam_delta = 0.5adaptive_beam = cur_cutoff - best_weight + config_.beam_delta; 因此，adaptive_beam的作用是作为next_cutoff的beam替代，在--min-active/--max-active形成约束力的时候。 对于next_cutoff，使用上一时刻最优token前向传递产生的cost（加上adaptive_beam）作为初始值。之后在处理token第二层剪枝过程中，如果传递形成的新的cost高于next_cutoff，则不予传递，否则产生新的token。若tot_cost + adaptive_beam &lt; next_cutoff，则更新next_cutoff。这部分代码如下：12345678910111213141516171819202122232425262728293031323334 for (Elem *e = final_toks, *e_tail; e != NULL; e = e_tail) &#123; StateId state = e-&gt;key; Token *tok = e-&gt;val; if (tok-&gt;tot_cost &lt;= cur_cutoff) &#123; for (fst::ArcIterator&lt;fst::Fst&lt;Arc&gt; &gt; aiter(fst_, state); !aiter.Done(); aiter.Next()) &#123; // 遍历状态的连接弧 const Arc &amp;arc = aiter.Value(); if (arc.ilabel != 0) &#123; BaseFloat ac_cost = cost_offset - decodable-&gt;LogLikelihood(frame, arc.ilabel), graph_cost = arc.weight.Value(), cur_cost = tok-&gt;tot_cost, tot_cost = cur_cost + ac_cost + graph_cost; // 剪枝 if (tot_cost &gt; next_cutoff) continue; // 继续更新，这是一个不断估计的过程 else if (tot_cost + adaptive_beam &lt; next_cutoff) next_cutoff = tot_cost + adaptive_beam; // 一开始调用时tok_已经是空的了。这一步产生的是新的tok Token *next_tok = FindOrAddToken(arc.nextstate, frame + 1, tot_cost, tok, NULL); // 把当前时刻的新token加入上一时刻的前向链表中 tok-&gt;links = new ForwardLink(next_tok, arc.ilabel, arc.olabel, graph_cost, ac_cost, tok-&gt;links); &#125; &#125; &#125; // 下一个element e_tail = e-&gt;tail; // 从链表中拿掉/回收 toks_.Delete(e);&#125; 函数FindOrAddToken()的作用是创建新的token（当前时刻）或者更新已有token的参数（tot_cost或者回溯指针等等）。因为同一个状态可能会有不同的token带着不同的tot_cost到达，但是只保留最优的一个。之前也说过，新建的token以链表形式相连，头部挂在std::vector&lt;TokenList&gt; active_toks_中：1234567891011121314151617181920FindOrAddToken(StateId state, int32 frame_plus_one, BaseFloat tot_cost, Token *backpointer, bool *changed) &#123; // ... Token *&amp;toks = active_toks_[frame_plus_one].toks; // 注意引用，实际修改了 Elem *e_found = toks_.Find(state); if (e_found == NULL) &#123; const BaseFloat extra_cost = 0.0; // NULL表示暂时没有forwardlinks，t时刻只能形成t-1时刻的前向链表 // 头插法：这里new_tok.next = toks // 这里的new_tok暂时不释放的 Token *new_tok = new Token (tot_cost, extra_cost, NULL, toks, backpointer); toks = new_tok; num_toks_++; // 整个解码过程中的token数目 // 插入hash中维护，维护的是Elem，删除它不会释放token toks_.Insert(state, new_tok); if (changed) *changed = true; return new_tok; &#125; // ...&#125; active_toks_也是一个十分重要的变量，它的大小是逐渐增加的，每一次调用ProcessEmitting()都会扩充一次。整个解码器用它的大小来追溯已经处理了的总帧数：1inline int32 NumFramesDecoded() const &#123; return active_toks_.size() - 1; &#125; 假设现在处理的是第frame帧（frame从0开始计数），那么要获得该帧产生的token链表，active_toks_的index应该是frame + 1。 ProcessNonemitting从函数名可以看出，这一步处理的当前帧下输入为$\epsilon$的跳转/弧，也就是说没有声学的观测概率。这部分代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748ProcessNonemitting(BaseFloat cutoff) &#123; KALDI_ASSERT(!active_toks_.empty()); // active_toks_在ProcessEmitting()中已经扩容了/+1，所以要访问 // 当前帧需要-2 int32 frame = static_cast&lt;int32&gt;(active_toks_.size()) - 2; KALDI_ASSERT(queue_.empty()); // push当前时刻到达的状态 // toks_.GetList()获取的是在ProcessEmitting()中新产生的token // 也就是当前时刻的token for (const Elem *e = toks_.GetList(); e != NULL; e = e-&gt;tail) queue_.push_back(e-&gt;key); // queue_中存储的是由当前时刻token对应的状态出发，可以通过空跳转 // 到达的所有状态 while (!queue_.empty()) &#123; StateId state = queue_.back(); queue_.pop_back(); Token *tok = toks_.Find(state)-&gt;val; BaseFloat cur_cost = tok-&gt;tot_cost; if (cur_cost &gt; cutoff) continue; // 一般而言，当前时刻的token没有前向链表 tok-&gt;DeleteForwardLinks(); tok-&gt;links = NULL; for (fst::ArcIterator&lt;fst::Fst&lt;Arc&gt; &gt; aiter(fst_, state); !aiter.Done(); aiter.Next()) &#123; const Arc &amp;arc = aiter.Value(); // ilabel == 0表示non-emitting if (arc.ilabel == 0) &#123; // propagate nonemitting only... BaseFloat graph_cost = arc.weight.Value(), tot_cost = cur_cost + graph_cost; // acoustic_cost = 0 if (tot_cost &lt; cutoff) &#123; bool changed; Token *new_tok = FindOrAddToken(arc.nextstate, frame + 1, tot_cost, tok, &amp;changed); // ilabel == 0则acoustic_cost = 0 // tok指的是当前时刻的token tok-&gt;links = new ForwardLink(new_tok, 0, arc.olabel, graph_cost, 0, tok-&gt;links); // 形成新的token或者更新了权值，说明新状态可到达 if (changed) queue_.push_back(arc.nextstate); &#125; &#125; &#125; &#125;&#125; 总体而言，解码过程就是不断的对一帧处理可观测跳转和空跳转，在拓展token的过程中执行剪枝策略，并将每一时刻的token链保存在active_tok_中，用于最终形成Lattice。 PruneActiveTokens除了在token传递过程中执行剪枝，kaldi还会每隔几帧执行一次PruneActiveTokens操作。该操作虽然也会删掉一些不必要的token，但是阈值的计算是在active_toks_中进行的（存在时间跨度）。首先执行PruneForwardLinks()，剪去一些token的前向指针，之后会调用PruneTokensForFrame()，将前向链接为空的token删去。 在PruneForwardLinks()中，对于当前时刻的每一个token，程序会遍历其ForwardLinks，算出每一条link和最优路径的cost差/距离link_extra_cost，如果差距过大（大于lattice_beam）就剪掉该link。token-&gt;extra_cost置为所有前向链接的link_extra_cost中最小的一个（如果前向链接被删完了，token-&gt;extra_cost会被置为无穷）。在下一步的PruneTokensForFrame()就是通过token-&gt;extra_cost来断定该token是否有前向链接的。整个搜索过程是一个时间轴上的回溯过程，即从当前时刻向初始时刻0开始。这里需要注意一个顺序问题，比如在$t - 1$时刻执行PruneForwardLinks()，需要用到$t$时刻的token信息，因此这里的执行顺序应该是先执行$t$时刻的Links剪枝，再执行$t + 1$时刻的Token剪枝。PruneForwardLinks()核心操作代码如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758PruneForwardLinks(int32 frame_plus_one, bool *extra_costs_changed, bool *links_pruned, BaseFloat delta) &#123; // ... bool changed = true; // 新的tok_extra_cost - 旧的tok_extra_cost &gt; 1.0 ? while (changed) &#123; changed = false; // 当前时刻的每一个token for (Token *tok = active_toks_[frame_plus_one].toks; tok != NULL; tok = tok-&gt;next) &#123; ForwardLink *link, *prev_link = NULL; BaseFloat tok_extra_cost = std::numeric_limits&lt;BaseFloat&gt;::infinity(); // 对于每一个token的每一个前向链接 // tok_extra_cost 取最小的link_extra_cost for (link = tok-&gt;links; link != NULL; ) &#123; Token *next_tok = link-&gt;next_tok; // extra_cost 初始化的时候为0 // 和最优路径的差距 // (tok-&gt;tot_cost + link-&gt;acoustic_cost + link-&gt;graph_cost) // - next_tok-&gt;tot_cost &gt;= 0 BaseFloat link_extra_cost = next_tok-&gt;extra_cost + ((tok-&gt;tot_cost + link-&gt;acoustic_cost + link-&gt;graph_cost) - next_tok-&gt;tot_cost); // 超过了阈值，删掉link if (link_extra_cost &gt; config_.lattice_beam) &#123; ForwardLink *next_link = link-&gt;next; if (prev_link != NULL) prev_link-&gt;next = next_link; else tok-&gt;links = next_link; delete link; link = next_link; *links_pruned = true; // 表示有link删除，可能产生没有link的token了 &#125; else &#123; // 更新tok_extra_cost，保留link if (link_extra_cost &lt; 0.0) &#123; // 正常不会这样 if (link_extra_cost &lt; -0.01) KALDI_WARN &lt;&lt; "Negative extra_cost: " &lt;&lt; link_extra_cost; link_extra_cost = 0.0; &#125; // keep最小的 if (link_extra_cost &lt; tok_extra_cost) tok_extra_cost = link_extra_cost; // 指向没有被删除的最后一个 prev_link = link; link = link-&gt;next; // 下一个link &#125; &#125; // ForwardLink循环结束 // delta默认1.0 // 新的tok_extra_cost - 旧的tok_extra_cost &gt; 1.0 if (fabs(tok_extra_cost - tok-&gt;extra_cost) &gt; delta) changed = true; tok-&gt;extra_cost = tok_extra_cost; // 要么+infinity 要么 &lt;= lattice_beam_ // +infinity就会被剪掉 &#125; // 曾经有一次是true，它就是true // extra_costs_changed表示tok-&gt;extra_cost更新了 // 因此前一时刻的tokens的extra_cost也需要重新计算了 if (changed) *extra_costs_changed = true; &#125;&#125; PruneForwardLinks()会在两中情况下被执行： 在active_toks_中有新的TokenList被拓展，因为初始化的时候must_prune_forward_links和must_prune_tokens为true。 下一时刻的TokenList中，有token的extra_cost变化了，所以之前时刻都需要重新计算。PruneActiveTokens()的核心代码如下：12345678910111213141516171819202122232425PruneActiveTokens(BaseFloat delta) &#123; // ... for (int32 f = cur_frame_plus_one - 1; f &gt;= 0; f--) &#123; if (active_toks_[f].must_prune_forward_links) &#123; bool extra_costs_changed = false, links_pruned = false; PruneForwardLinks(f, &amp;extra_costs_changed, &amp;links_pruned, delta); // extra_costs_changed表示f时刻的token-&gt;extra_cost发生了变化 // 因此之前时刻的token-&gt;extra_cost的需要相应的重新计算 if (extra_costs_changed &amp;&amp; f &gt; 0) active_toks_[f-1].must_prune_forward_links = true; // links_pruned 表示是否有link被剪掉了 if (links_pruned) active_toks_[f].must_prune_tokens = true; // 剪完了 active_toks_[f].must_prune_forward_links = false; &#125; // f + 1 != cur_frame_plus_one - 1 还没有ForwordLink // f + 1时刻 if (f+1 &lt; cur_frame_plus_one &amp;&amp; active_toks_[f+1].must_prune_tokens) &#123; PruneTokensForFrame(f+1); active_toks_[f+1].must_prune_tokens = false; &#125; &#125;&#125; 特征供给这部分会和ivector的在线提取放在一起，说明kaldi对Online-Feature的包装。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaldi中ivector的提取【一】]]></title>
    <url>%2F2017%2F07%2F28%2Fkaldi-ivector-extract-1%2F</url>
    <content type="text"><![CDATA[kaldi中ivector的提取程序在ivector-extract和ivector-extract-online2中，分别提取离线和在线的ivector。考虑到后续需要分析online的解码逻辑，所以在第二篇笔记中会仔细介绍在线情况下统计信息的累计和ivector估计方法。本篇主要介绍离线方法以及在线方法的整体框架。 离线方法离线方法是指，在事先获取了句子的特征和高斯后验的情况下，估计出一个ivector向量。对于句子 $\mathbf{U}_{T \times F} = \{\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_T\}^T$和对应的高斯后验 $\mathbf{P}_{T \times C}= \{\mathbf{p}_1, \mathbf{p}_2, \cdots, \mathbf{p}_T\}^T$，首先得到提取ivector所需要的零阶和一阶统计量： \gamma_c = \sum_{t = 1}^T \mathbf{p}_{t,c} \\ \mathbf{F}_c = \sum_{t = 1}^T \mathbf{p}_{t,c} \mathbf{x}_t存储在$\boldsymbol{\gamma}_{C \times 1}$和$\mathbf{F}_{C \times F}$中。 之后利用加载好的ivector提取器，调用GetIvectorDistribution函数并传入上述统计量将得到的均值作为ivector。ivector提取器IvectorExtractor中维护ivector提取过程中说话人无关的一些量，比如$\mathbf{T}$矩阵和UBM方差等等，由于kaldi代码中变量命名和我们常见的公式中不一致，这里以论文中常见的表示为标准。比较重要的量如下：1234std::vector&lt;Matrix&lt;double&gt; &gt; M_;std::vector&lt;SpMatrix&lt;double&gt; &gt; Sigma_inv_;Matrix&lt;double&gt; U_; //上三角作为一行std::vector&lt;Matrix&lt;double&gt; &gt; Sigma_inv_M_; 其中M_表示$\mathbf{T}_{C \times F \times R}$，表示为： \mathbf{T} = [\mathbf{T}_1, \mathbf{T}_2, \cdots, \mathbf{T}_C]Sigma_inv_表示$\mathbf{\Sigma}^{-1}_{C \times F \times F}$，表示为： \mathbf{\Sigma}^{-1} = [\mathbf{\Sigma}^{-1}_1, \mathbf{\Sigma}^{-1}_2, \cdots, \mathbf{\Sigma}^{-1}_C]U_和Sigma_inv_M_由上面两个变量计算得到，分别定义为$\mathbf{U}_{C \times R \times R}, \mathbf{B}_{C \times F \times R}$： \mathbf{U} = \mathbf{T}^T \cdot \mathbf{\Sigma}^{-1} \cdot \mathbf{T} = [\mathbf{T}_1^T \mathbf{\Sigma}^{-1}_1\mathbf{T}_1, \mathbf{T}_2^T \mathbf{\Sigma}^{-1}_2\mathbf{T}_2, \cdots, \mathbf{T}_C^T \mathbf{\Sigma}^{-1}_C\mathbf{T}_C ] \\ \mathbf{B} = \mathbf{\Sigma}^{-1} \cdot \mathbf{T} = [\mathbf{\Sigma}^{-1}_1\mathbf{T}_1, \mathbf{\Sigma}^{-1}_2\mathbf{T}_2, \cdots, \mathbf{\Sigma}^{-1}_C \mathbf{T}_C]令$\mathbf{w} = \mathbf{Q}^{-1}\mathbf{L}$，那么$\mathbf{Q}, \mathbf{L}$的计算过程如下： \mathbf{L}_{R \times 1} = \sum_{c = 1}^C (\mathbf{B}_c^T)_{R \times F} (\mathbf{F}_c)_{F \times 1} \\ \mathbf{Q}_{R \times R} = \sum_{c = 1}^C \mathbf{U}_c\gamma_c + \mathbf{I}观察到$\mathbf{T}_i^T \mathbf{\Sigma}^{-1}_i\mathbf{T}_i$为对称矩阵，所以为了存储高效，保留上三角即可，因而$\mathbf{U}_{C \times R \times R}$可以退化为$\mathbf{U}_{C \times (R + 1) / 2}$，写成： \mathbf{U}_{C \times (R + 1) / 2} = \begin{vmatrix} \text{Utri}(\mathbf{T}_1^T \mathbf{\Sigma}^{-1}_i\mathbf{T}_1) \\ \text{Utri}(\mathbf{T}_2^T \mathbf{\Sigma}^{-1}_i\mathbf{T}_2) \\ \cdots \\ \text{Utri}(\mathbf{T}_C^T \mathbf{\Sigma}^{-1}_i\mathbf{T}_C) \end{vmatrix}那么$\mathbf{Q}_{R \times R}$可由$\mathbf{U}^T_{(R + 1) / 2 \times C} \boldsymbol{\gamma}_{C \times 1}$计算得到。 上述过程对应的代码在下面的函数中实现，参数mean即为传入的ivector向量。1234void IvectorExtractor::GetIvectorDistribution ( const IvectorExtractorUtteranceStats &amp;utt_stats, VectorBase&lt;double&gt; *mean, SpMatrix&lt;double&gt; *var) const 在线方法在线方法需要提供一个配置文件，这个文件使用脚本prepare_online_decoding.sh生成，一个典型的配置文件如下：1234567891011--splice-config=$PREFIX/exp/nnet2_online/nnet2_ms_online/conf/splice.conf--cmvn-config=$PREFIX/exp/nnet2_online/nnet2_ms_online/conf/online_cmvn.conf--lda-matrix=$PREFIX/exp/nnet2_online/nnet2_ms_online/ivector_extractor/final.mat--global-cmvn-stats=$PREFIX/exp/nnet2_online/nnet2_ms_online/ivector_extractor/global_cmvn.stats--diag-ubm=$PREFIX/exp/nnet2_online/nnet2_ms_online/ivector_extractor/final.dubm--ivector-extractor=$PREFIX/exp/nnet2_online/nnet2_ms_online/ivector_extractor/final.ie--num-gselect=5--min-post=0.025--posterior-scale=0.1--max-remembered-frames=1000--max-count=100 其中前六个比较熟悉，分别是拼帧配置，在线cmvn配置，LDA变换矩阵，全局cmvn统计量，UBM和训练好的ivector提取器。还有两个配置参数比较重要，分别是--use_most_recent_ivector和--ivector_period。前者默认为true，表示每次使用最估计的ivector，否则计算出的ivector需要缓存下来，以便获取到设定时间估计出的ivector，后者设置每多少帧估计一个ivector。 这些配置文件用来初始化OnlineIvectorExtractionConfig，具体的对象载入在OnlineIvectorExtractionInfo中完成，前者作为后者初始化的参数。核心代码流程如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546for (; !spk2utt_reader.Done(); spk2utt_reader.Next()) &#123; std::string spk = spk2utt_reader.Key(); const std::vector&lt;std::string&gt; &amp;uttlist = spk2utt_reader.Value(); // adaptation_state是针对一个同一个说话人的，结构体成员： // OnlineCmvnState cmvn_state; // OnlineIvectorEstimationStats ivector_stats; OnlineIvectorExtractorAdaptationState adaptation_state(ivector_info); // 对于同一个说话人的所有句子 for (size_t i = 0; i &lt; uttlist.size(); i++) &#123; std::string utt = uttlist[i]; // 得到该句子的特征 const Matrix&lt;BaseFloat&gt; &amp;feats = feature_reader.Value(utt); OnlineMatrixFeature matrix_feature(feats); // 根据ivector_info初始化一系列具体的online特征 // 比如OnlineSpliceFrames，OnlineTransform，OnlineCmvn等等 OnlineIvectorFeature ivector_feature(ivector_info, &amp;matrix_feature); // ivector_stats_和cmvn_初始化 ivector_feature.SetAdaptationState(adaptation_state); // repeat 默认false，ivector_period表示每多少帧取一个ivector，默认为10 int32 T = feats.NumRows(), n = (repeat ? 1 : ivector_config.ivector_period), num_ivectors = (T + n - 1) / n; // num_ivectors 决定一句话提取多少个ivector Matrix&lt;BaseFloat&gt; ivectors(num_ivectors, ivector_feature.Dim()); for (int32 i = 0; i &lt; num_ivectors; i++) &#123; int32 t = i * n; // 对应第i个ivector SubVector&lt;BaseFloat&gt; ivector(ivectors, i); // 核心过程，调用函数UpdateStatsUntilFrame ivector_feature.GetFrame(t, &amp;ivector); &#125; // Update diagnostics. // ... // 更新adaptation_state ivector_feature.GetAdaptationState(&amp;adaptation_state); // 完成提取 ivector_writer.Write(utt, ivectors); num_done++; &#125;&#125; 上述过程的核心：GetFrame方法的逻辑会在kaldi中ivector的提取【二】中详细分析。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ivector的初步了解]]></title>
    <url>%2F2017%2F07%2F27%2Flearn-about-ivector%2F</url>
    <content type="text"><![CDATA[本篇主要解释我在学习ivector中遇到的一些比较困惑的点。在kaldi的nnet3中传统声学模型加上ivector已经成为online模型的标配。对于在线模型的特征提取，传统的方法采取全局和滑动窗的CMVN对输入特征进行归一化，而kaldi推荐的方案是使用ivector加上原始声学特征（参见论文A time delay neural network architecture for efficient modeling of long temporal contexts）。 supervector超向量是一个比较重要的概念，在说话人识别和自适应中被广泛使用。对于一个GMM，一般将它的均值向量连接成的向量称为supervector。若特征维度为$F$，混合高斯数目为$C$，那么超向量的长度即为$F \times C$。它被认为包含了一个说话人相关的所有信息，后续要引出的本征音，联合因子分析（JFA）等方法也是从超向量的分解的角度来切入的。 UBM和MAP在训练ivector的提取器之前，需要训练一个UBM，那么就产生了两个问题，UBM是什么以及UBM起到什么作用，UBM如何训练等等。 UBM翻译为统一背景模型，它是一个包含很多分量的GMM（文献中一般分量个数为2048）。在说话人识别任务中，如果我们对每一个说话人的特征用一个GMM来建模，那么，得到的一系列GMM就是说话人相关的。而UBM用来对说话人无关的信息进行建模。为什么需要说话人无关的模型呢？因为我们可以认为说话人相关的建模目标可以通过训练数据和一种适应方法修正UBM达到。而这种适应/调节方法称为MAP（最大后验概率），UBM在其中作为先验模型。最终得出的结论是，相比针对每一个说话人训练一个GMM，从一个好的UBM出发进行adaptation的方法表现的更好。 对于说话人数据${\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_T}$，对于含有$C$个分量的UBM，观测$\mathbf{x}_i$来自第$c$个分量的概率记为： \gamma_i^c = \frac{\pi_c \mathcal{N}_c(\mathbf{x}_i|\Theta_c)}{\sum_{c = 1}^C \pi_c \mathcal{N}_c(\mathbf{x}_i|\Theta_c)}由此可以得到每个分量的零阶，一阶和二阶统计量，分别记为： N_c = \sum_{i = 1}^T \gamma_i^c \\ \mathbf{F}_c = \sum_{i = 1}^T \gamma_i^c \mathbf{x}_i \\ \mathbf{S}_c = \sum_{i = 1}^T \gamma_i^c \mathbf{x}_i \mathbf{x}_i^TMAP按照如下更新方法调整UBM中的统计参数（Bayesian adaptation）： \pi'_c = [\alpha_c N_c / T + (1 - \alpha_c)\pi_c]\beta \\ \mu'_c = \alpha_c E_c(\mathbf{x}) + (1 - \alpha_c)\mu_c \\ \mathbf{\Sigma}'_c = \alpha_c E_c(\mathbf{x}^2) + (1 - \alpha_c)(\mathbf{\Sigma}_c + \mu_c\mu_c^T) - \mu'_c \mu'^T_c其中 E_c(\mathbf{x}) = \mathbf{F}_c / N_c \\ E_c(\mathbf{x}^2) = \mathbf{S}_c / N_c \\ \alpha_c = N_c / (N_c + r)$r$一般在$C = 2048$时取16，$\beta$用来保证$\sum_{c = 1}^C\pi’_c = 1$。$\alpha_c$这个量用来表示UBM受新数据影响的程度。比如$\alpha_c \to 1$时，更新公式中原来的参数受到屏蔽，更多的依赖新一轮的统计信息，因而更加的偏向说话人相关的概率模型。 把adaptation得到的模型均值取出来进行拼接得到的超向量再加上一些后处理方法，比如cos距离或者SVM分类，就可以搭建最基本的说话人系统了。 supervector的分解上面提到，既然supervector可以作为一个很好的说话人特征，那么就可以着手对其进行集中分析了。目前形成的体系是对说话人相关的超向量$\mathbf{s}$视为以下几个部分的叠加： 说话人/信道无关的分量 说话人相关的分量 信道相关的分量 其余动态分量 用公式可以表示为： \mathbf{s} = \mathbf{m}_0 + \mathbf{m}_{spk} + \mathbf{m}_{chn} + \mathbf{m}_{res}其中说话人/信道无关的分量可以用UBM的超向量来表示。对于剩下的三个分量的处理，目前形成的方法主要有本征音（Eigenvoice），本征信道（Eigenchannel），联合因子分析（JFA），ivector等几种方法，它们对应的分解形式如下： Eigenvoice针对说话人信息 \mathbf{s} = \mathbf{m}_0 + \mathbf{V}\mathbf{y} Eigenchannel针对信道信息 \mathbf{s} = \mathbf{m}_0 + \mathbf{D}\mathbf{z} + \mathbf{U}\mathbf{x} JFA结合了Eigenvoice和Eigenchannel \mathbf{s} = \mathbf{m}_0 + \mathbf{V}\mathbf{y} + \mathbf{D}\mathbf{z} + \mathbf{U}\mathbf{x} ivector将Eigenvoice和Eigenchannel两个空间合并为一个统一变化空间进行分析 \mathbf{s} = \mathbf{m}_0 + \mathbf{T}\mathbf{w} $\mathbf{w}$即是传说中的ivector。我这里重点关注它和Engenvoice，一来是目前ivector已经被广泛应用，二是$\mathbf{T}$矩阵的训练和$\mathbf{V}$的训练过程相同，只需要将训练集合中的每个句子都视为不同的说话人即可。ivector这里也有如下几个疑问： $\mathbf{T}$矩阵如何训练 $\mathbf{w}$如何计算 ivector怎么用 ivector的计算注：这部分没有加上说话人的下表$s$，在下一部分“$\mathbf{T}$矩阵的训练”中再添加下标。 ivector计算和训练过程中有这样的一个假设，即$\mathbf{w}$服从正态分布$\mathcal{N}(\mathbf{w}; \mathbf{0}, \mathbf{I})$，基于这个假设，可以得到如下如下推论： $\mathbf{w}$在说话人数据$\mathcal{X}$上满足高斯分布，即 $p(\mathbf{w}|\mathcal{X}) = \mathcal{N}(\mathbf{w}|\mathbf{L}^{-1}\mathbf{T}^T\mathbf{\Sigma}^{-1}\mathbf{F}, \mathbf{L}^{-1})$，其中： \mathbf{L} = \mathbf{I} + \mathbf{T}^T\mathbf{\Sigma}^{-1}\mathbf{N}\mathbf{T} 用$\mathbf{N}_{c}, \mathbf{F}_{c}$表示数据集合$\mathcal{X}$上第c个分量的零阶和归一化的一阶统计量： \mathbf{N}_{c} = \sum_{i = 1}^T \gamma_i^c \\ \mathbf{F}_{c} = \sum_{i = 1}^T \gamma_i^c (\mathbf{x}_i - \mu_c)\\$\mu_c，\Sigma_c$为UBM中第$c$个分量的均值和方差。那么$\mathbf{N}, \mathbf{F}$表示为： \mathbf{N}_{CF \times CF} = \begin{vmatrix} \mathbf{N}_1\mathbf{I} & & &\\ & \mathbf{N}_2\mathbf{I} & & \\ & & \cdots & \\ & & & \mathbf{N}_c\mathbf{I}\\ \end{vmatrix} \quad \mathbf{F}_{CF \times 1} = \begin{vmatrix} \mathbf{F}_1\\ \mathbf{F}_2\\ \cdots\\ \mathbf{F}_c\\ \end{vmatrix} \\$\mathbf{\Sigma}$定义为： \mathbf{\Sigma}_{CF \times CF} = \begin{vmatrix} \Sigma_1 & & &\\ & \Sigma_2 & & \\ & & \cdots & \\ & & & \Sigma_c\\ \end{vmatrix}$\mathbf{T}$是需要训练的，它的维度是$CF \times R$，因而计算出来的$\mathbf{L}$维度为$R \times R$。要计算的ivector就是分布$p(\mathbf{w}|\mathcal{X})$的均值，加上说话人下标$s$，写成： \mathbf{w}_s = \mathbf{L}_s^{-1}\mathbf{T}^T\mathbf{\Sigma}^{-1}\mathbf{F}_s$\mathbf{w}_s$的维度为$R \times 1$。分布$p(\mathbf{w}|\mathcal{X})$的均值和方差是如何得出的？它的处理思路是这样的，应用贝叶斯公式可以将该条件分布写成： p(\mathbf{w}|\mathcal{X}) = \frac{p(\mathcal{X} | \mathbf{w})p(\mathbf{w})}{p(\mathcal{X})} \propto p(\mathcal{X} | \mathbf{w}) \mathcal{N}(\mathbf{w}| \mathbf{0}, \mathbf{I})$p(\mathcal{X} | \mathbf{w})$也是可以推出的，由此就可以得到现在看到的$\mathbf{w}$的分布结果了。所以在训练出$\mathbf{T}$矩阵之后，就可以求出所谓的ivector了。 T矩阵的训练在ivector中$\mathbf{T}$矩阵的训练过程和JFA以及Eigenvoice里面的$\mathbf{V}$矩阵的训练过程类似。训练过程如下： E步： \mathbf{C}_c = \sum_{s} \mathbf{F}_{c, s} \mathbf{w}_s^T \\ \mathbf{A}_c = \sum_{s} N_{c, s} (\mathbf{L}_s^{-1} + \mathbf{w}_s \mathbf{w}_s^T) M步： \mathbf{T} = \begin{vmatrix} \mathbf{T}_1 \\ \mathbf{T}_2 \\ \cdots \\ \mathbf{T}_C \\ \end{vmatrix} = \begin{vmatrix} \mathbf{C}_1 \mathbf{A}_1^{-1} \\ \mathbf{C}_2 \mathbf{A}_2^{-1} \\ \cdots \\ \mathbf{C}_C \mathbf{A}_C^{-1} \\ \end{vmatrix} 参考文献 Speaker recognition by machines and humans A tutorial review Comparison of background normalization methods for text-independent speaker verification Eigenvoice modeling with sparse training data Front-End Factor Analysis forSpeaker Verification Speaker recognition by machines and humans A tutorial review]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用自然梯度的神经网络并行训练【译】]]></title>
    <url>%2F2017%2F07%2F25%2Fparallel-training-by-ng%2F</url>
    <content type="text"><![CDATA[本篇是对论文 Parallel training of DNNs with Natural Gradient and Parameter Averaging前几个部分的翻译。 摘要我们描述了一种在kaidi语音识别工具中使用的一种面向多核，多GPU机器的神经网络训练框架。为了尽可能与硬件无关，我们需要一种方法来使用多台机器，而不会产生过多的网络流量。这里使用的方法是周期性的平均网络参数（每一或者两分钟），然后将平均之后的参数重新分布到机器上进行进一步的训练。每台机器都只能看见自己的训练数据。本身来说，这种方法并不能很好的工作。但是，我们有另外一种方法，就是正确且有效的实现了针对随机梯度下降的自然梯度，它可以允许我们的周期性平均方法工作的很好，并且极大的提高了在单个机器上的SGD收敛程度。 介绍神经网络的并行训练一般是数据并行和模型并行的结合。一般的数据并行的方法是每个minibatch交换一下模型参数。这里我们介绍的并行训练框架使用了不同的数据并行方式：我们在不同的机器上有多个执行SGD的进程，每隔几分钟平均一下模型参数并且将他们重新分布到各自的机器上。这对于大规模的语音识别系统训练是非常有效的，但是在我们的例子中，只有和我们实现的有效的自然梯度随机梯度下降结合起来工作的才比较好。考虑到DNN的非收敛性，在这篇文章中我们不解释为什么参数平均可以工作的很好，或者为什么NG-SGD作用很大。这篇文章的要点在于描述我们的方法，并且从经验上说明他们工作的很好。这篇文章的重要性在于，我们展现了当增加GPU数量时，可以收获线性的加速效果，在没有平凡的数据传输的情况下。 在第二部分我们描述了问题的设置，就是DNN在语音识别中的应用-虽然我们的点子比这更加宽泛。在第三部分我们介绍了并行训练方法。在第四部分我们描述了在自然梯度方法背后更加一般的点子，虽然大部分技术细节都被放在了附录部分。在这篇文章中我们不给出任何证明，但是我们在第五部分讨论一些我们认为可以但是证明不了的东西。第六部分有带有/不带有自然梯度和并行的SGD收敛性的实验。我们在第七部分做总结。 NG-SGD有两个版本，一个是简单的版本，还有一个在线版本。技术细节分别在附录A和B。附录C有关于我们DNN实现的背景知识。 问题设置在训练语音识别的DNN模型时，直接的问题就是将向量$\mathbf{x} \in \mathbf{R}^D$分类为离散的label（$y \in \mathcal{Y}$）。维度$D$常常数以百计。$\mathbf{x}$是从声学信号中提取的短时谱特性，$\mathcal{Y}$是CD-phone聚类之后绑定的HMM状态，正常情况下，5000左右是典型的。每一对$(\mathbf{x}, y)$对应于音频数据的一帧。帧长和帧移一般是25ms和100/s，$\mathbf{x}$含有几个相邻上下文的谱信息。我们最终不是只对这个$y$感兴趣，而是所有$y$的log概率$\log p(y|\mathbf{x})$，因为我们要将它作为在维特比搜索算法中的权值，用来生成最大概率的词序列。训练的目标函数是在所有训练集上的帧，给出$\mathbf{x}$时$y$出现的概率：$\sum_{i}\log(y_i|\mathbf{x}_i)$。由于我们要最小化这个目标，我们使用SGD这个方法有点轻微的用词不当，它是梯度上升。监督标记$y$由训练语料的抄本生成的HMM模型进行维特比对齐得到。 带参数平均的SGD参数平均概览在我们的训练中参数平均十分简单。我们有$N$个机器（比如$N = 4$），每一个机器独自的在训练数据的随机子集上运行，我们允许它们的参数逐渐的发散。在每个机器训练完一定数量$K$的数据时（典型的$K = 400000$）。我们平均所有进程的参数，之后将结果重新分发（实际中，我们通过在GridEngine，或者在我们使用的任何管理系统中生成新的作业）。重复这个过程直到完成在全部数据上的若干轮训练，比如说10轮。 我们将训练的外部迭代定义为每个作业处理完$K$批数据的时间。那么每一轮外部迭代的次数和训练数据量和$K$有关。 我们发现给并行的SGD流程设置一个有效的学习率是非常有用的，因为学习率$\eta_t$被每个独立的作业使用，需要除以作业数$N$。当我们为了获得线性的加速而增加作业量$N$时，我们需要按比例的增大学习率以保证有效的学习率不变。这个概念是我们进行参数平均时，任何一个SGD作业的参数更新被稀释为$N$倍造成的。 我们将其设置为参数平均而不是将各个作业的参数变化相加的原因是稳定性考虑。试想这样一种情形，在参数空间中某些方向的Hessian矩阵非常大（我们的学习率也足够大），以至于SGD在执行完$K$个样本时，随机梯度下降已经到达了平衡点。假如有四个作业，那么处理完$K$个样本之后将参数变化量相加，得到的参数不再接近于平衡态，而是在相反的方向，相对于起始点三倍远的地方。显然这会导致模型发散。 我们SGD实现的其他方面在这里我们提供一些关于SGD实现上的其他方面的一些细节的特性，即用来避免模型发散的学习率调度策略和强制最大参数变化量。 还有一些其他的和主题并不直接相关的我们放在附录C中，即基于CPU和GPU的SGD（C.1），数据随机化（C.2），一般模型平均（C.4），混合分量，子空间（C.5），输入数据的正则化（C.6），参数初始化（C.7），序列训练（C.8）以及使用i-vector的在线解码。 学习率调度（Senior et al., 2013）中指出，在训练DNN的声学模型时，学习率的指数衰减效果很好，我们也独立的发现了这一现象。通常在训练阶段，我们使用指数衰减将学习率调小10倍。除非特殊说明，我们这里提到的实验，学习率初始设置为0.01，到0.001停止。我们提前说明训练的论数，典型的在4到20之间（如果数据更多，轮数就少一些）。 需要说明的是我们这里的实验都没有独立的针对SGD和NG-SGD调整学习率（我们只是使用了以前在NG-SGD上表现比较好的值），我们在过去也做过拓展性的实验，在小数据集上，学习率是独立调整的。最终在所有的情况下，我们发现NG-SGD是有帮助的。现在在大规模数据集上不方便做这些重复了。 最大参数变化在深度学习上SGD训练阶段，常见的问题是参数会突然变的很大，目标函数也会变成负无穷。这被称为参数发散。常见的方法是减小学习率重新训练，但是这十分的不方便。为了避免这种情况，我们更改了SGD程序，在每个minbatch上强制一个最大的参数变化量。这样的限制在训练的早期比较活跃，尤其在趋向于输出层的层中。我们在附录C.3中做了进一步说明。 针对SGD的自然梯度这节描述我们对SGD的自然梯度修正，我们通过一个对称正定矩阵，即对Fisher矩阵的逆的估计来缩放梯度。 从技术上讲，自然梯度是指在黎曼参数表面，沿着常规参数空间中的弯曲路径走一步。它极难计算，但是，前面的工作（Yang &amp; Amari, 1998; Roux et al., 2007）已经使用了“自然梯度”来描述像我们这样的方法，即使用一个Fisher矩阵的估计作为学习率矩阵，因此我们跟随着他们，称呼我们的方法为“自然梯度”。 我们可以在SGD中将常量的学习率替换为一个矩阵在SGD中，学习率常常被假设为一个常量$\eta_t$，伴随着时间减少，更新等式如下： \boldsymbol{\theta}_{t + 1} = \boldsymbol{\theta}_{t} + \eta_t\mathbf{g}_t其中$\mathbf{g}_t$是目标函数在时刻$t$的梯度（从一个训练样本或者minibatch获得）。然而，将这个标量用一个对称正定矩阵替换是可能的，我们可以改写上式为： \boldsymbol{\theta}_{t + 1} = \boldsymbol{\theta}_{t} + \eta_t\mathbf{E}_t\mathbf{g}_t其中$\mathbf{E}_t$是学习率的矩阵分量，为了证明方便，我们没有把$\eta_t$合并到$\mathbf{E}_t$中去。$\mathbf{E}_t$随机是可被接受的：如果我们用可以提前获知的正常数限制$\mathbf{E}_t$的特征值的上下限，那么在给出$\boldsymbol{\theta}$时的$\mathbf{g}_t$和$\mathbf{E}_t$是独立采样的，我们可以证明在某些条件被满足的情况下的收敛性，就像使用一个标量的学习率一样（Bottou, 1998, Sec. 4.2.2）。 总的来说，学习率矩阵不是一个当前处理的样本数据的函数，否则它可能会阻止收敛到一个局部最优解。举一个例子，对于特定类型的训练数据，较小的矩阵将通过对该数据进行加权来明确地偏差学习。 Fisher矩阵的逆是一个合适学习率矩阵在和自然梯度这个点子相关的统计学习理论中，有理由可以说明为什么我们可以将$\mathbf{E}_t$设置为Fisher矩阵的逆。比如（Murata &amp; Amari, 1999）和（Roux et al., 2007）。Fisher矩阵是在我们要学习一个分布时最直接的定义，而不是分类问题，比如我们现在处理的这个。设想$x$，这个我们要对它的分布建模的变量，它可能是离散的，连续的，$f(x;\boldsymbol{\theta})$是给出$\boldsymbol{\theta}$时$x$的可能性。Fisher信息矩阵$\mathcal{I}(\boldsymbol{\theta})$被定义为log概率对参数偏导的二阶矩。 \frac{\partial}{\partial \boldsymbol{\theta}} \log f(x;\boldsymbol{\theta})以上偏导在信息论中称为“score”。在某些情况下，Fisher矩阵和Hessian是相同的。很明显为什么Hessian的逆可以称为一个很好的梯度下降方向。这些条件十分严格，包括正确的模型，$\boldsymbol{\theta}$是基于可以描述正确的数据分布的值的。但是即使这些条件不适用，Fisher矩阵在某种意义上也是和Hessian相同的，也就是说，它在参数变换的情况下也随之变换，因此它的逆依旧是学习率矩阵的一个很好的选择。 将Fisher信息矩阵的概念推广到预测问题$p(y;x,\boldsymbol{\theta})$上也是非常容易的。假设我们已经知道了$x$的分布$q(x)$，那么$p(y, x; \boldsymbol{\theta}) = q(x)p(y;x, \boldsymbol{\theta})$。不难看出“score”就等于$\frac{\partial}{\partial \boldsymbol{\theta}} \log f(x;y, \boldsymbol{\theta})$，因为$q(x)$不依赖$\boldsymbol{\theta}$，所以没有关于$q(x)$的表达式了。在计算Fisher矩阵时计算的期望是在$x$和$y$联合分布上的期望。这个结论在（Roux et al., 2007, Section 3）中同样存在。 更一般的来说，对于任意的目标函数，不一定得是log概率或者log似然，我们都可以计算出一个类似于Fisher矩阵的东西，在变量变化时，它的变换方式和Hessian矩阵类似，比如，它的逆也可以是一个学习率矩阵的合理选择。 在实际中我们需要估计Fisher矩阵对于大规模的问题，比如参数量达到百万的语音识别问题，即使一次Fisher矩阵的求逆也是不切实际的因为它的时间复杂度是$O(n^3)$的。但是处理它的分解形式还是可以的。之前也有文献在这方面。在（Roux et al., 2007）中，Fisher矩阵被分解成多个对角阵，其中每个阵使用一个低秩的矩阵估计。这个对角阵的点子在（Bastian et al., 2011）也被研究了，每一个阵对应一个权值矩阵，我们的方法也是用的类似的思想。在未发表的手稿（Yang &amp; Amari, 1997）中（有些材料说1998年发表了），作者尝试去证明在一些假设下，对于单个隐层的神经网络的Fisher矩阵是一个Kronecker积的形式。虽然我们考虑的网络形式比他们更加通用，Kronecker积同样出现在我们Fisher矩阵的分解中。 需要说明的是，不进行分解也是可以使用NG的，只是每一轮的时间代价会剧增，可以看一下（Pascanu &amp; Bengio, 2013）中的例子，他们使用阶段牛顿法近似Fisher矩阵的逆。 Fisher矩阵的分解我们的分解形式是这样的：对于一个有$I$个权值矩阵的神经网络，我们把Fisher矩阵划分为$I$对角阵，每一个对应一个权值矩阵。考虑Fisher矩阵第$i$个对角块，它对应的权值矩阵是$\boldsymbol{W}_i$，在这里我们假设没有单独的偏置存在。那么第$i$块Fisher矩阵可以视为两个对称正定矩阵$\boldsymbol{A}_i$，$\boldsymbol{B}_i$的Kronecker积，其中$\boldsymbol{A}_i$的维度是$\boldsymbol{W}_i$的行数，$\boldsymbol{A}_i$的维度是$\boldsymbol{W}_i$的列数。我们进一步将$\boldsymbol{A}_i$和$\boldsymbol{B}_i$分解为一个低秩的对称矩阵和单位矩阵的倍数的和，那么Fisher矩阵$\boldsymbol{F}$可以被写为： \boldsymbol{F} = \text{diag}(\boldsymbol{A}_1 \otimes \boldsymbol{B}_1, \boldsymbol{A}_2 \otimes \boldsymbol{B}_2, \dots, \boldsymbol{A}_I \otimes \boldsymbol{B}_I)其中$\boldsymbol{A}_i$，$\boldsymbol{B}_i$以 $\lambda\boldsymbol{I} + \boldsymbol{X}\boldsymbol{X}^T$的形式分解。$\boldsymbol{A}_i$，$\boldsymbol{B}_i$在Kronecker积中的顺序取决于矩阵的存储形式，行主序的还是列主序。实际中我们不显式的处理Kronecker积或者向量化的权值矩阵，所以这个选择不重要。不难证明如果Fisher矩阵可以被这么分解，那么它的逆也可以以同样的形式分解。 我们如何估计Fisher矩阵我们有两种方法估计Fisher矩阵的分解形式 简单方法：我们从一个minibatch里面拿一些其他的数据来估计Fisher矩阵。这样做十分高效，细节在附录A中。 在线方法：我们从之前所有的minibatch中估计Fisher矩阵。时间较远的minibatch使用一个遗忘因子来减少权重。细节在附录B中。 我们通常使用在线方法，因为在GPU上它跑的很快，模型学习的也很快。这可能是因为它对Fisher矩阵的估计是比较干净的。我们描述简单方法是因为它更加好懂，可以帮助我们启发在线方法。 向量操作虽然我们描述Fisher矩阵是一个Kronecker积的形式，但是在我们没有显式的实现它。 假设我们当前一次训练一批/个数据。那么SGD按照如下方法更新第$i$个权值矩阵： \boldsymbol{W}_{it} = \boldsymbol{W}_{i(t-1)} + \eta_t\boldsymbol{x}_{it}\boldsymbol{y}_{it}^T$\boldsymbol{x}_{it}$是目标函数的偏导，$\boldsymbol{y}_{it}$是权值作用的输入。这个公式最初存在BP算法中。 在我们的自然梯度下降算法中，这被改写成： \boldsymbol{W}_{it} = \boldsymbol{W}_{i(t-1)} + \eta_t\boldsymbol{A}_{it}^{-1}\boldsymbol{x}_{it}\boldsymbol{y}_{it}^T\boldsymbol{B}_{it}^{-1}其中$\boldsymbol{A}_{it}$和$\boldsymbol{B}_{it}$是Fisher矩阵的因子。很容易表明，这相当于将参数阶乘以由A和B量形成的Fisher矩阵的倒数。 minibatch的操作如果不是一次训练一批数据，而是minibatch个数据。那么上一节中的向量$\boldsymbol{x}_{it}$和$\boldsymbol{y}_{it}$就相应的变成了矩阵$\boldsymbol{X}_{it}, \boldsymbol{Y}_{it}$，那么更新公式写为： \boldsymbol{W}_{it} = \boldsymbol{W}_{i(t-1)} + \eta_t\boldsymbol{X}_{it}\boldsymbol{Y}_{it}^T注意，我们没有像有些作者一样，将梯度除以minibatch的大小，这样可以更加容易的独立的调minibatch的大小和学习率。NG的更新公式为： \boldsymbol{W}_{it} = \boldsymbol{W}_{i(t-1)} + \eta_t\bar{\boldsymbol{X}}_{it}\bar{\boldsymbol{Y}}_{it}^T其中带横杠的参数表示修正过的$\boldsymbol{X}，\boldsymbol{Y}$。在在线版本中可以写为： \bar{\boldsymbol{X}}_{it} = \boldsymbol{X}_{it} \boldsymbol{A}_{it}^{-1}\\ \bar{\boldsymbol{Y}}_{it} = \boldsymbol{Y}_{it} \boldsymbol{B}_{it}^{-1}在简单方法中，由于$\boldsymbol{A},\boldsymbol{B}$是从minibatch中的其他元素估计的，所以我们不能这么写（每行单独的乘法），附录A中有高效的实现。 从编程的角度说，我们可以这么描述NG的接口： 简单方法：给出一个minibatch$\boldsymbol{X}_{it}$，每一行是minibatch的一个元素，我们通过每个样本来估计Fisher矩阵，并乘以他们的逆，返回修正过的$\bar{\boldsymbol{X}}_{it}$ 在线方法：给出一个minibatch$\boldsymbol{X}_{it}$和前一次的Fisher矩阵因子估计，计算$\bar{\boldsymbol{X}}_{it} = \boldsymbol{X}_{it} \boldsymbol{A}_{i(t-1)}^{-1}$，之后更新$\boldsymbol{A}_{it}$ 以上接口对于$\boldsymbol{Y}$和$\boldsymbol{B}$执行流程和$\boldsymbol{X}$和$\boldsymbol{A}$是一样的。对于一个minibatch，我们调用接口$2I$次：每个权值矩阵两次。 因子调整在两个NG方法中，我们想阻止Fisher矩阵极大的影响整体的更新，相比于标准的SGD。对此有几点原因： 在训练的早期，$\boldsymbol{x}$和$\boldsymbol{y}$的量可以非常小，甚至是0，这会导致Fisher矩阵的逆很大甚至是无穷。 常规的收敛防御技术要求学习率矩阵的矩阵分量应具有预先知道的常数的上下限的特征值，但是我们不确定我们使用的Fisher矩阵是否是不变的。 从经验的角度来看，如果使用不调整的Fisher矩阵，我们很难阻止参数发散。 我们的方法是调整$\bar{\boldsymbol{X}}_{it}$和$\bar{\boldsymbol{Y}}_{it}$的量，使得它们的Frobenius范数和输入$\boldsymbol{X}_{it}$和$\boldsymbol{Y}_{it}$一样，我们会在附录中介绍它。 因子调整会引入证明上的微小的问题，那就是每一个样本都会影响它们自己的学习率矩阵了（通过缩放矩阵的缩放因子）。我们之前也提过，虽然使用单个样例的学习率也是允许的，但是在实际问题中这不是一个问题，因为我们基本上不适用小于100的minibatch大小。 使用单位矩阵平滑Fisher矩阵在两种方法中，我们通过在转置之前给Fisher矩阵加上一个单位矩阵的倍数来平滑它。在简单方法中，这是必要的，因为通常从minibatch中估计的Fisher矩阵都不是满秩的。在在线方法中不是必要的，因为Fisher矩阵的分解已经包含了加上单位矩阵这一操作。但是我们发现通过加上单位矩阵的倍数这一操作，比如对简单方法而言，我们可以调高SGD方法的收敛性。在两种情况下，平滑操作实现如下，如果$\boldsymbol{S} \in \boldsymbol{R}^{D \times D}$是一个从$\boldsymbol{x}$或者$\boldsymbol{y}的协方差中估计的$Fisher矩阵因子，那么我们使用$\boldsymbol{S} + \beta\boldsymbol{I}$来代替Fisher矩阵因子$\boldsymbol{A}$或者$\boldsymbol{B}$，其中 \beta = \frac{\alpha}{D}\max(\text{tr}(\boldsymbol{S}), \epsilon)$\epsilon = 10^{-20}$用来防止平滑的$\boldsymbol{S}$值为0。也就是说，我们通过将单位矩阵缩放$\alpha$乘以$\boldsymbol{S}$的对角元素的平均值倍来平滑Fisher矩阵。我们在调参实验中发现，在大部分情况下，$\alpha = 4$对于两种方法，甚至是$\boldsymbol{S}$中存在影响不大的噪声时是合适的，比如minibatch比较大时。我们的理解是，$\alpha$相当大时，我们在$\boldsymbol{x}$和$\boldsymbol{y}$的值协相关性比较大的方向上使用了一个比正常情况小的学习率，在其他方向上使用了一个相对稳定的学习率。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全连接神经网络的BP推导]]></title>
    <url>%2F2017%2F07%2F24%2FBP-for-dense%2F</url>
    <content type="text"><![CDATA[全连接神经网络是最简单的一种深度神经网络模型，网络的输出仅仅和当前的输入有关。多层的全连接网络由单层网络通过简单的线性堆叠而成，即前一层的输出是后一层的输入。一般而言，每一层可视为仿射变换层和激活层耦合而成，其中激活层通过激活函数向系统中引入非线性分量，从而使得多层的全连接网络在训练充分的情况下具有强大的数据拟合能力。也就是说，全连接神经网络完成的是向量在空间和空间之间的一种映射功能，这种映射过程称为网络的前向传递。网络的参数更新通过反向传播（Back Propagation）算法进行，这是一种基于梯度下降的训练算法。 在神经网络中（不仅仅是全连接神经网络），节点表征单个数据，一层网络含有多个数据节点，构成一个向量，网络输出用输出层表示，网络输入用输入层表示，输入层和输出层之间称为隐层，每一层均可对输入进行一次仿射变换和一次非线性变换。节点和节点之前具有全连接结构，连接权重构成变换矩阵。每个节点上存在偏置。下面对前向传递和反向传播过程进行数学推导。 前向传递上文已经提到，前向传递过程是完成空间映射的过程，定义网络输入，输出分别为$\boldsymbol{x}, \boldsymbol{y}$，对于有$n$层隐层的前馈网络，隐层输入，输出，变换矩阵，偏置向量为$(\boldsymbol{i}_i, \boldsymbol{o}_i, \boldsymbol{W}_i, \boldsymbol{b}_i) (1 \leqslant i \leqslant n)$，其中$\boldsymbol{x} = \boldsymbol{i}_1$，根据定义： \boldsymbol{i}_{i + 1} = \boldsymbol{o}_{i} (1 \leqslant i \leqslant n - 1)对于隐层，激活函数为$\theta$，前向传递表示为： \begin{align} \boldsymbol{z}_i &= \boldsymbol{W_i} \boldsymbol{i_i} + \boldsymbol{b_i} \notag \\ \boldsymbol{o}_i &= \theta(\boldsymbol{z}_i) \notag \end{align}对于输出层，激活函数为$f$，前向传递表示为： \begin{align} \boldsymbol{z}_o &= \boldsymbol{W_o} \boldsymbol{o_n} + \boldsymbol{b_o} \notag \\ \boldsymbol{y} &= f(\boldsymbol{z}_o) \notag \end{align}反向传播在一般的回归，分类任务中，网络训练是监督学习的过程，也就是说，需要提前对训练数据进行标注，定义对于输入$\boldsymbol{x}$的标注数据为$\boldsymbol{l}$，在此之上，定义误差函数$\mathcal{L}(\boldsymbol{y}, \boldsymbol{l})$ ，对于回归任务，一般定义为均方误差（Mean Squared Error, MSE）： \mathcal{L}(\boldsymbol{y}, \boldsymbol{l}) = (\boldsymbol{y} - \boldsymbol{l})^2 / 2反向传播的原理是，在给定输入，根据当前模型计算出输入之后，在误差函数之上，对网络的偏置和权置进行逐层求导，计算更新量，之后根据制定的更新法则进行参数更新，以此反复迭代，直至网络收敛。 根据损失函数，对输出层偏置和权置求导： \begin{align} \frac{\partial\mathcal{L}}{\partial \boldsymbol{b}_o} &= \frac{\partial\mathcal{L}}{\partial \boldsymbol{y}} \frac{\partial \boldsymbol{y}}{\partial \boldsymbol{z}_o} \frac{\partial \boldsymbol{z}_o}{\partial \boldsymbol{b}_o} = (\boldsymbol{y} - \boldsymbol{l}) \cdot f'(\boldsymbol{z}_o) \notag \\ \frac{\partial\mathcal{L}}{\partial \boldsymbol{W}_o} &= \frac{\partial\mathcal{L}}{\partial \boldsymbol{y}} \frac{\partial \boldsymbol{y}}{\partial \boldsymbol{z}_o} \frac{\partial \boldsymbol{z}_o}{\partial \boldsymbol{W}_o} = (\boldsymbol{y} - \boldsymbol{l}) \cdot f'(\boldsymbol{z}_o) \cdot \boldsymbol{o}_n \notag \end{align}为了推导隐层参数的更新公式，定义： \boldsymbol{e}_i = \frac{\partial\mathcal{L}}{\partial \boldsymbol{z_i}}则： \begin{align} \boldsymbol{e}_{i - 1} &= \frac{\partial\mathcal{L}}{\partial \boldsymbol{z}_{i - 1}} = \frac{\partial\mathcal{L}}{\partial \boldsymbol{z}_i} \frac{\partial \boldsymbol{z}_i}{\partial \boldsymbol{z}_{i - 1}} \notag \\ & = \boldsymbol{e}_i \cdot \frac{\partial \boldsymbol{z}_i}{\partial \boldsymbol{o}_{i - 1}} \frac{\partial \boldsymbol{o}_{i - 1}}{\partial \boldsymbol{z}_{i - 1}} \notag \\ & = \boldsymbol{e}_i \cdot \boldsymbol{W}_i^T \cdot \theta'(\boldsymbol{z}_{i - 1}) \notag \end{align}由此，可以得到隐层参数的梯度： \begin{align} \frac{\partial\mathcal{L}}{\partial \boldsymbol{b}_i} &= \frac{\partial\mathcal{L}}{\partial \boldsymbol{z}_i} \frac{\partial \boldsymbol{z}_i}{\partial \boldsymbol{b}_i} = \boldsymbol{e}_{i + 1} \cdot \boldsymbol{W}_{i + 1}^T \cdot \theta'(\boldsymbol{z}_i) \notag \\ \frac{\partial\mathcal{L}}{\partial \boldsymbol{W}_i} &= \frac{\partial\mathcal{L}}{\partial \boldsymbol{z}_i} \frac{\partial \boldsymbol{z}_i}{\partial \boldsymbol{W}_i} = \boldsymbol{e}_{i + 1} \cdot \boldsymbol{W}_{i + 1}^T \cdot \theta'(\boldsymbol{z}_i) \cdot \boldsymbol{o}_{i - 1} \notag \end{align}在学习率为$\eta$时，可以按照以下规则更新参数： \begin{align} \boldsymbol{b}_i &= \boldsymbol{b}_i - \eta \cdot \frac{\partial\mathcal{L}}{\partial \boldsymbol{b}_i} \notag \\ \boldsymbol{W}_i &= \boldsymbol{W}_i - \eta \cdot \frac{\partial\mathcal{L}}{\partial \boldsymbol{W}_i} \notag \end{align}实际在训练中执行的梯度下降过程和上述推导会有所不同。上述的参数更新过程只是针对一对训练样例进行的（称为随机梯度下降法），由此产生的问题如下： 由于误差不是在整体数据集上定义的，那么产生的梯度就可能不是指向全局最优的方向，因而对噪声数据较为敏感，网络收敛情况较差。 对于大批的训练数据，可能在一轮（遍历一次数据集）尚未结束时，网络已经达到收敛状态，无法充分利用训练数据。 考虑到如果载入全部数据进行参数更新会带来内存消耗过大，计算效率过低等问题，目前一般使用min-batch梯度下降法作为折中方案，即一次从数据集中取出min-batch个样例进行误差计算，参数更新。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在安卓上使用kaldi进行模型开发]]></title>
    <url>%2F2017%2F07%2F20%2Flink-kaldi-on-android%2F</url>
    <content type="text"><![CDATA[为什么有这个想法，因为自己有过体验，当初做的第一个语音增强的demo，傻乎乎的自己实现特征提取，自己实现网络前向，于是就需要将kaldi的网络参数转写成方便自己程序读取的格式，还需要不断对比自己实现的特征结果和HTK的结果是否一致，这期间花费的时间个人觉得已经远远的超出做demo本身的意义，最主要的是，由于当初实现的代码仅仅是针对当初的需求，而一旦后期的特征配置或者网络结构发生变化，之前的工作就要重复一次，如此低效率的事情我个人是不想重复做的。 所以，最简单的方法就是，将计算逻辑交给kaldi完成，自己只需要完成控制逻辑上的编码。本身使用NDK+JNI进行开发并不是很难，无非是将kaldi的依赖和自身编译成库，和自己编写的JNI接口链接，通过Android Studio支持的cmake或者ndk构建最终的动态库就行了，但是，由于网上资料过少，链接错误又比较难查，所以还是耗费了不少时间的。 我的需求是提取nnet1和feat两块，所以不需要openfst以及其他无关的代码，最终提取出的工作目录如下（实际上还可以进一步精简，test文件一律删除） 1base cudamatrix feat hmm itf matrix nnet thread tree util 所有步骤都可以从以下链接中获取 谷歌官方的NDK指南 LINK AndroidStudio的用户手册 LINK kaldi的交叉编译 LINK OpenBlas的编译 LINK 我踩过的坑如下： 配置本地编译环境这一步之前编译OpenBlas的时候也用过，使用ndk自带的make_standalone_toolchain.py脚本配置编译环境，安装完毕之后，将安装目录下的bin文件夹导入环境变量。脚本比较重要的参数是--api和--stl。其中--stl配置NDK的运行时（gnustl/libc++/stlport），--api配置SDK的版本，这两个配置选项要和后续的Application.mk保持一致的，分别对应APP_STL和APP_PLATFORM。--arm配置编译平台，安卓手机对应arm或者arm64，对应Application.mk中APP_ABI的armeabi/armeabi-v7a和arm86-v8a。另外，切记，openblas和kaldi在同意一个toolchain下完成编译。 编译clapack这个也很简单，github上有人已经构建好了工程，简单修改Android.mk执行ndk-build就行。 编译openblasopenblas编译基本不会出现问题，参照上面给出的链接即可。将clapack生成的blas，lapack，clapack，f2c四个库拷贝到openblas安装目录下的lib中，kaldi会自动配置到kaldi.mk中作为链接库。 编译kaldi由于修改了原先的工程目录，所以需要修改一下Makefile和configure文件 去除configure文件中关于openfst的检查脚本 修改Makefile中的SUBDIR(控制编译那些目录)，以及各子目录中的Makefile（ADDLIBS是本目录的依赖库，OBJFILES是要打包到静态库中的目标文件，不需要生成测试文件就将TESTFILES注释即可) 注释android_openblas.mk中openfst的宏定义，将宏ANDROIDINC修正为ANDROIDINCDIR（脚本的bug，因为configure中定义的是ANDROIDINCDIR），注意一下CXXFLAGS的参数，后面链接的时候要用到。 kaldi默认在编译android平台只能生成静态库 AS的配置上述过程倒是很少出现问题，在AS中用cmake或者ndk生成动态库是主要的头疼点（一系列让人摸不着头脑的链接错误）。首先说明kaldi的编译和链接参数如下（来自android_openblas.mk）：12345-DKALDI_DOUBLEPRECISION=0 # BaseFloat为单精度 -DHAVE_CXXABI_H -DHAVE_OPENBLAS # 在cblas_wrapper.h中用到，表示blas用openblas实现-DANDROID_BUILD -ftree-vectorize -mfloat-abi=hard -mfpu=neon -mhard-float -D_NDK_MATH_NO_SOFTFP=1 # openblas用到 以及12-Wl,--no-warn-mismatch -lm_hard # openblas用到 以上参数需要在Android.mk或者CmakeLists.txt中等价的实现，cmake我没有成功过，Android.mk目前配置如下：123456789101112131415161718192021222324252627LOCAL_PATH := $(call my-dir)# 预构建静态库include $(CLEAR_VARS)LOCAL_MODULE := kaldi-prebuildLOCAL_SRC_FILES := libkaldi.ainclude $(PREBUILT_STATIC_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE := kaldiLOCAL_SRC_FILES := impl.cpp# 编译选项LOCAL_CFLAGS += -DKALDI_DOUBLEPRECISION=0 -DHAVE_CXXABI_H \ -DHAVE_OPENBLAS -DANDROID_BUILD -ftree-vectorize \ -mfloat-abi=hard -mfpu=neon -mhard-float -D_NDK_MATH_NO_SOFTFP=1# 链接选项LOCAL_LDFLAGS += -Wl,--no-warn-mismatch -lm_hard# 链接静态库，为什么只有一个？我把各个静态库压成一个了LOCAL_STATIC_LIBRARIES += kaldi-prebuild# 定义头文件路径LOCAL_C_INCLUDES += $(LOCAL_PATH)/blas $(LOCAL_PATH)# 动态链接log库LOCAL_LDLIBS += -lloginclude $(BUILD_SHARED_LIBRARY) 对应的Application.mk如下，之前说明过，配置要和toolchain保持一致1234APP_ABI := armeabi-v7a # 用到了openblasAPP_STL := c++_static # libc++APP_CPPFLAGS := -fexceptions # 打开异常开关APP_PLATFORM := android-24 # SDK-24 这期间遇到的问题如下： cmake的VFP问题使用链接openblas如果不加-mhard-float -D_NDK_MATH_NO_SOFTFP=1 -lm_hard这些选项的话，会出现*.a use VFP arguments, but output not的链接错误，但是，我在CmakeLists.txt中的add_definitions和gradle中的cppFlags都尝试过添加这些选项，均没有解决该问题，只能转战ndk+Android.mk了。 f2c_的未定义问题这个推测应该是和静态库的链接顺序有关系，Android.mk要链接静态库，须先预构建一下（我暂时不知道其他链接方法），然后将预构建好的模块进行连接（加到LOCAL_STATIC_LIBRARIES参数之后），有一种说法是越基本的库放的越靠后，我在kaldi-base.a kaldi-matrix.a和五个blas相关的库上做过各种顺序的尝试，但是始终没能解决该问题（要么是f2c的为定义，要么是openblas的未定义），最终用粗暴的方法，将这几个库打包成一个静态库解决该问题的（尽量保证openblas和clapack库是同一个toolchain构建的） ndk命名空间错误这个错误是后来做了若干修正之后解决的，现在回想，可能的原因是Application.mk中的APP_PLATFORM和APP_STL和toolchain配置的api/stl不匹配。 到这里，在jni文件夹外边使用ndk-build已经可以直接生成静态库了，但是，如果在AS中build的话，还是会出现rand_r, rand, posix_memalign这些函数的未定义，目前这些问题还没有解决，我通过gradle配置ndk的构建方法替换AS自身的逻辑来跳过这个错误，在gradle中android{}添加配置如下：123456789101112131415sourceSets.main &#123; jni.srcDirs = [] # 禁用AS默认的jni目录 &#125;task ndkBuild(type: org.gradle.api.tasks.Exec, description: &quot;compile JNI by NDK&quot;) &#123; commandLine &quot;/Users/wujian/Library/Android/sdk/ndk-bundle/ndk-build&quot;, &apos;NDK_PROJECT_PATH=build/intermediates/ndk&apos;, &apos;NDK_LIBS_OUT=src/main/jniLibs&apos;, &apos;APP_BUILD_SCRIPT=src/main/jni/Android.mk&apos;, &apos;NDK_APPLICATION_MK=src/main/jni/Application.mk&apos;&#125;tasks.withType(JavaCompile) &#123; compileTask-&gt;compileTask.dependsOn ndkBuild&#125; 这种方法并不推荐，实际上个人觉得还是AS支持的ndk和cmake最佳，右击app，选择构建工具，link一下CMakeLists.txt或者Android.mk就行了。以后找到问题所在还是会切换过去的。 无非就是一个链接问题，前后折腾了五天，现在总结的话，大致也只用这么多可以被写下来的东西。不过，想到今后从模型到demo的可以省下的大把时间，还是一件值得的事情。]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DTW在语音唤醒中的应用]]></title>
    <url>%2F2017%2F06%2F20%2Fapply-dtw-in-kws%2F</url>
    <content type="text"><![CDATA[语音唤醒任务的一种常见解决方案是通过评估连续语音中分段时间窗内的音频特征和预先置入的关键词模板之间的相似性来决定系统是否唤醒，而DTW（动态时间规整算法）能够有效的衡量两个不等长序列之间的最短距离/相似性，因此在这类解决思路下被广泛使用。这里可以采用的特征有声学特征，后验特征，embedding特征或者BN特征等等，鲁棒的特征对最终的系统表现有着积极的影响。将连续语音和关键词模板之间的距离矩阵绘制出来（关键词模板在纵轴方向），可以得到如下的结果（使用的是MFCC特征）。图中蓝色的路径为最低代价下对齐/匹配路径。在唤醒系统中，我们将当前滑动窗下的最低匹配代价作为相似性打分，调出一个合理的阈值就可以做一个简单的唤醒演示系统了（实际表现中，打分平滑，模板平均等等还是有很多trick的）。 DTW算法是一种衡量两个不同长度的序列之间距离的一种算法，主要的思想是将序列元素之间通过某种规则对应起来得到等长序列，在计算这种情况下的距离。由于这种映射方式有很多种，DTW采用动态规划思想，每一次取最小距离代价的映射方案，以此获得最小的匹配距离以及对应的匹配方案。 定义序列$\boldsymbol{X}, \boldsymbol{Y}$，DTW算法可以找出一条匹配路径$\pi$满足： D = \underset{\pi}{\text{argmin}} \sum_{(i, j) \in \pi} \text{dis}(\boldsymbol{X}_i, \boldsymbol{Y}_j) \notag令$D_{ij}$表示子序列$\boldsymbol{X}_{0 \to i}, \boldsymbol{Y}_{0 \to j}$的最小匹配距离，由动态规划思想，可以得到如下状态转移方程： D_{ij} = \text{dis}(\boldsymbol{X}_i, \boldsymbol{Y}_j) + \min\{D_{(i - 1)j}, D_{i(j - 1)}, D_{(i - 1)(j - 1)}\} \notag由此，可以在$O(n^2)$的时间复杂度内得到两个序列的最小匹配距离。该距离越小，表示序列相似度越高。在KWS任务中，$\boldsymbol{X}_i,\boldsymbol{Y}_j$表示的是声学特征或者因素后验，定义距离度量如下： \begin{align} \cos(i, j) &= 1 - \frac{\boldsymbol{X}_i^T \boldsymbol{Y}_j}{|\boldsymbol{X}_i| \cdot |\boldsymbol{Y}_j|} \notag \\ \log(i, j) &= -\log(\boldsymbol{X}_i^T \boldsymbol{Y}_j) \notag \end{align}一般而言，对于声学特征采用余弦距离，对于后验特征采用内积度量。 以上是基本的DTW算法，对于KWS任务，最终的目标是从句子$\boldsymbol{U} = \{\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_U\}$中获取模板$\boldsymbol{T} = \{\mathbf{x}_1, \mathbf{x}_2, \cdots, \mathbf{x}_T\}$可能出现的位置。而在实际的系统中，$U$要远远大于$T$，所以在应用中还是需要对DTW算法进行改进的。目前常见的方法是分段动态时间规整（SDTW）和分段局部正则（SLN-DTW）算法。 分段动态时间规整算法简单的理解（实际上论文中的表述不是这样）为通过设置一个滑动窗（窗长为$W$，窗移为$S$），在每一个滑动窗内，用标准DTW计算和模板的最小匹配距离。该方法计算复杂度较高（每$S$帧就要进行一次$O(n^2)$的计算），而且性能表现和窗长$W$以及窗移$S$相关。 分段局部正则（SLN-DTW）算法修改了标准DTW中的初始化方法，并且引入了平均距离作为距离度量方式，默认每一帧均可以作为最优匹配的起始点，这样无需通过句子切分得到匹配起点，也无需重新计算距离矩阵，极大的降低了算法 的计算复杂度。定义累积步长$S$， $\Theta = {(i - 1, j - 1), (i, j - 1), (i - 1, j)}$，初始化$D_{0j} = \text{dis}(\boldsymbol{T}_0, \boldsymbol{U}_j)$，$S_{0j} = 1$，则状态转移方程修正为： \begin{align} D_{ij} &= \text{dis}(\boldsymbol{T}_i, \boldsymbol{U}_j) + D_{uv} \notag \\ S_{ij} &= 1 + S_{uv} \notag \end{align}其中 (u, v) = \underset{(u, v) \in \Theta}{\text{argmin}} \frac{D_{uv} + \text{dis}(\boldsymbol{T}_i, \boldsymbol{U}_j)}{S_{uv} + 1}在关键词只出现一次的情况下，回溯位置$j = \underset{j}{\text{argmin}}\{D_{Tj}, 0 \leqslant j \leqslant U\}$处的得到的最优路径作为最优匹配路径。 在实验中，SLN-DTW效率和准确性上要优于前者。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LDA线性判别分析]]></title>
    <url>%2F2017%2F06%2F15%2Fkaldi-lda%2F</url>
    <content type="text"><![CDATA[LDA（线性判别分析，又称为Fisher线性判别）是对标记数据的一种常见的降维算法。kaldi在对原始特征的常见处理中，就包括了应用LDA变换这一操作（但是一般不降维，比较奇怪）。本文主要讲解LDA的数学原理和在kaldi中的具体实现。 坐标变换首先，对于坐标变换这个任务，变换之后的坐标可以理解为点在新的空间基向量方向上的投影。 对于变换空间的一组基向量 $\overrightarrow{\boldsymbol{w}} = \{\boldsymbol v_1, \boldsymbol v_2, \cdots, \boldsymbol v_n\}$和原空间的点 $\boldsymbol{x} = \{x_1, x_2, \cdots, x_n\}^T$，变换之后的坐标 $\boldsymbol y$表示为： \boldsymbol y = \boldsymbol{w}^T \cdot \boldsymbol xLDALDA的期望是，将高维度的数据通过某种变换/降维（投影到低维度），使得类间方差最大，类内方差最小，也就是要让同一类数据尽可能的接近，不同类数据尽可能的分开。所以，如果定义要优化的目标函数，那么，表征不同数据接近程度的离散矩阵和表征同类数据类内离散程度的离散矩阵应该被分别放置在分母和分子位置，最终取使得优化目标最大的变换矩阵即可。 定义原始数据维度为$D$，数据集标注为$C$类，对于类$P_i$，类内离散程度$\boldsymbol{S}_w$用类内方差$\boldsymbol{V}_i$之和表示： \boldsymbol{S}_w = \frac{1}{C}\sum_{i = 1}^C \boldsymbol{V}_i = \frac{1}{C}\sum_{i = 1}^C \frac{1}{N_i}\sum_{\boldsymbol{x} \in P_i}(\boldsymbol{x} - \boldsymbol{\mu}_i)(\boldsymbol{x} - \boldsymbol{\mu}_i)^T \\ = \frac{1}{C}\sum_{i = 1}^C E[\boldsymbol{X}_i^2] - E[\boldsymbol{X}_i]^2类间方差$\boldsymbol{S}_b$用各类中心点$\boldsymbol{\mu}_i$相对整体样本的中心点$\boldsymbol{\mu}$计算得到的协方差$\boldsymbol{V}_i^r$之和表示： \boldsymbol{S}_b = \frac{1}{C}\sum_{i = 1}^C \boldsymbol{V}_i^r = \frac{1}{C}\sum_{i = 1}^C (\boldsymbol{\mu}_i - \boldsymbol{\mu})(\boldsymbol{\mu}_i - \boldsymbol{\mu})^T\\ = E[\boldsymbol{\mu}_c^2] - E[\boldsymbol{X}]^2由以上两式，可以得到优化的目标函数： J(\boldsymbol{W}) = \frac{\boldsymbol{W}^T\boldsymbol{S}_b\boldsymbol{W}}{\boldsymbol{W}^T\boldsymbol{S}_w\boldsymbol{W}}kaldi中的LDA变换kaldi中经常对提取的声学特征做LDA变换，也是首先收集统计量，之后做LDA变换，输出变换矩阵。统计量累计lda-acc接受GMM模型，声学特征和后验，输出统计量（主要是以下三个变量的值）。从GMM模型中可以知道pdf_class的个数，也就是数据集合的总的类别，记为$C$，特征维度记为$D$。那么统计量的维度以及存储的信息如下：123456// C X 1 每一类的累计后验Vector&lt;double&gt; zero_acc_;// C X D 每一类的累计特征Matrix&lt;double&gt; first_acc_;// D X D 对称矩阵，存下三角 所有类的累计加权特征的平方SpMatrix&lt;double&gt; total_second_acc_; 具体求解变换矩阵的过程没有找到对应的理论依据，根据代码，过程如下：定义全局方差（将所有数据视为一个整体）： \boldsymbol{S}_t = E[\boldsymbol{X}^2] - E[\boldsymbol{X}]^2之后按照如下的过程求解： $\boldsymbol{S}_w = \boldsymbol{S}_t - \boldsymbol{S}_b = \boldsymbol{L}\boldsymbol{L}^T$（乔列斯基分解） $\boldsymbol{L}^{-1}\boldsymbol{S}_b = \boldsymbol{U}\boldsymbol{D}\boldsymbol{V}^T$（SVD分解） $\boldsymbol{W} = \boldsymbol{U}\boldsymbol{L}^{-1}$（投影变换） 补充：后来在看ivector的时候发现上面的第一步做的应该是WCCN（Within-Class Covariance Normalization）。对于类内方差$\boldsymbol{W}$，WCCN定义变换： \phi(\boldsymbol{w}) = \boldsymbol{L}^T\boldsymbol{w}其中$\boldsymbol{W}^{-1} = \boldsymbol{L}\boldsymbol{L}^T$，即$L$通过对$\boldsymbol{W}^{-1}$的乔列斯基分解得到。令： \boldsymbol{S}_w = \boldsymbol{L}\boldsymbol{L}^T则$\boldsymbol{S}_w^{-1} = (\boldsymbol{L}^T)^{-1}\boldsymbol{L}^{-1} = (\boldsymbol{L}^{-1})^T\boldsymbol{L}^{-1}$，所以： \phi(\boldsymbol{S}_b) = \boldsymbol{L}^{-1}\boldsymbol{S}_b]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编辑距离]]></title>
    <url>%2F2017%2F06%2F14%2Fedit-distance%2F</url>
    <content type="text"><![CDATA[编辑距离指在有限编辑条件下（增加，删除，替换），将一个字符串变换成另一个字符串所需的最小操作次数。语音中用到编辑距离的地方还是蛮多的，比如对CTC的预测进行评估的时候，就可以采用编辑距离。 一开始接触这个问题还是比较难和动态规划结合起来的，但是指明DP之后，转移方程还是很好写出来的，定义$D_{i, j}$为子串$A_{0 \to i}$和$B_{0 \to j}$的编辑距离，显然，状态$(i, j)$可以退化为三个状态：$(i - 1, j - 1), (i - 1, j), (i, j - 1)$，下面就是指出三个子状态和目标状态的关系。 若$A[i] = B[j]$，则$D_{i, j} = D_{i - 1, j - 1}$，如果不相等，替换其中一个使它们相等，引入一步操作。 删除$A[i]$或者$B[j]$，引入一步操作。 反过来考虑，子状态转移到目标状态的话，删除逻辑改为增加逻辑即可。程序的话，习惯记忆化搜索，自上而下的逻辑。边界条件：$D_{0, i} = D_{i, 0} = i$，代码逻辑如下：12345678910111213141516int EditDist(char *a, char *b, int i, int j) &#123; if (i + j &lt; 0) return 0; if (i == 0 || j == 0) return dis[i][j] = (i == 0 ? j: i); if (dis[i][j] &gt;= 0) return dis[i][j]; if (a[i] == b[j]) return dis[i][j] = EditDist(a, b, i - 1, j - 1); else return dis[i][j] = min( EditDist(a, b, i - 1, j - 1), EditDist(a, b, i, j - 1), EditDist(a, b, i - 1, j) ) + 1;&#125;]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于attention机制]]></title>
    <url>%2F2017%2F06%2F12%2Fabout-attention-model%2F</url>
    <content type="text"><![CDATA[语音识别这块目前常见的端到端的方法除了CTC之外，就是attention（注意力）机制了。attention不同于CTC有着比较明确的数学定义和模式，它描述的应该是心理学现象中人注意力的某个特性，比如人的视觉上的注意力短期内只能集中在某一个区域中，而没有涵盖全部的视野范围。具体到语音识别任务（相比于图像和机器翻译领域，应用的算是比较晚的了）上，从字面意思看不出应该如何使用它。不过目前常见的使用方式和机器翻译类似，还是在encoder-decoder框架中使用。这种结合的思想是，定义一种描述注意力的方式，使得decoder可以尽量关注“有用”部分的信息，而不是全部的编码信息或者历史信息。 RNN Encoder-Decoder许多机器学习任务都可以看成是一种不等长序列之间的转换任务，比如机器翻译（句子到句子），语音识别（特征序列到句子）等等。编码解码框架是一种解决变长序列映射问题的思路。核心思想是将待转换序列编码成一个特征向量，再通过解码将其转换成目标序列。 许多论文在介绍RNN-Encoder-Decoder的时候都是直接给出公式，没有过多的介绍，后来意外的在找GRU的原始论文的时候，发现GRU是Cho在提出RNN-Encoder-Decoder的时候，顺带对LSTM做的一个改动，鉴于论文一开始提到了 In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). 我这里将其视为RNN-Encoder-Decoder的原始论文，其中第二部分详细介绍了Cho提出的所谓编码解码框架。 定义RNN的隐层状态为$\mathbf{h}$，输入序列$\mathbf{x} = \{x_1, x_2, \cdots, x_T\}$，对于普通的RNN，在$t$时刻，$\mathbf{h}$的更新由下式产生： \mathbf{h}_t = f(\mathbf{h}_{t - 1}, x_t)由于RNN对过去信息具有一定的记忆功能，在$t$时刻网络的输出可以视为其在历史信息下的条件概率，即$p(x_t | x_1, x_2, \cdots, x_{t - 1})$。累计每个时刻下的条件概率可以得到序列$\mathbf{x}$出现的概率： p(\mathbf{x}) = \prod_{t = 1}^Tp(x_t | x_1, x_2, \cdots, x_{t - 1})所谓的编解码方案是通过两个RNN网络，学习概率$p(\mathbf{y}|\mathbf{x})$（$\mathbf{x},\mathbf{y}$不等长）的分布，其中一个（编码器）学习将变长序列表示成定长序列，另一个（解码器）学习将此定长序列生成边长序列。 两者协调工作如下：编码器读入序列$\mathbf{x}$，处理完之后，隐层状态视为$\mathbf{c}$，解码器和编码器不同，解码器的隐层状态和预测输出均依赖于$\mathbf{c}$和前一时刻预测的输出$y_{t-1}$，表示如下： \mathbf{h}_t = f(\mathbf{h}_{t - 1}, y_{t - 1}, \mathbf{c}) \\ p(y_t | y_1, y_2, \cdots, y_{t - 1}, \mathbf{c}) = g(\mathbf{h}_t, y_{t - 1}, \mathbf{c})从这里可以看出，$\mathbf{c}$在解码器中是一成不变的，变化的只是$\mathbf{h}_t$和$y_t$，那么attention机制常见的应用点就集中在$\mathbf{c}$上。注意$\mathbf{h}_t$和$y_t$的生成顺序。 Attention机制以上描述的encoder-decoder在后续论文中基本都会提到，大部分情况下讲attention都会提到机器翻译领域的一篇文章（Neural Machine Translation by Jointly Learning to Align and Translate），包括那张经典的配图，如下 图中的解码器的$s$和上一部分解码器中定义的$\mathbf{h}$相同。在不引入attention机制的情况下，$s$和$y$的更新如下（$\to$表示更新）： \begin{align} c, s_{t - 1}, y_{t - 1} &\to s_t \notag \\ c, s_t, y_{t - 1} &\to y_t \notag \end{align}引入attention之后，修正每一次的$c$为$c_t$，得到 \begin{align} c_t, s_{t - 1}, y_{t - 1} &\to s_t \notag \\ c_t, s_t, y_{t - 1} &\to y_t \notag \end{align}这篇论文中用图中$\oplus$节点表示$c_t$，计算流程如下： c_t = \sum_{t' = 1}^Ta_{tt'}h_{t'} \\ a_{tt'} = \text{softmax}(e_{tt'}) \\ e_{tt'} = a(s_{t - 1}, h_{t'})$a$这里是一个对齐模型（align model），其中$a_{tt’}$（$a_{tt’}$和$e_{tt’}$的意义一样）表示在时刻$t$，解码器中隐层状态$h_{t’}$对上一时刻预测输出$y_{t - 1}$的重要程度，越重要在$c_t$中占比越大。训练阶段，$a$需要和编解码器一块训练，在这篇论文中，$a$使用的是一个一层的前向网络。 attention在语音识别中的应用Cho在“Attention-Based Models for Speech Recognition”中提出了一种ARSG（attention-based recurrent sequence generator）的结构来生成序列。文中给出的计算示意图如下： 论文中将$c_t$重新称为glimpse，即$g_t$，定义的计算流程如图，貌似这里$y_t$和$s_t$的生成顺序变化了。 \begin{align} \alpha_{t - 1}, s_{t - 1}, h &\to \alpha_t \notag \\ \alpha_t, h &\to g_t \notag \\ s_{t - 1}, g_t &\to y_t \notag \\ s_{t - 1}, g_t, y_t &\to s_t \notag \end{align}论文“End-to-End Attention-based Large Vocabulary Speech Recognition”也是在ARSG上做的改进，文中解释attention配图如下，基本和NMT那篇的逻辑一致。 \begin{align} \alpha_{t - 1}, s_{t - 1}, h &\to \alpha_t \notag \\ \alpha_t, h &\to c_t \notag \\ s_{t - 1}, c_t, y_{t - 1} &\to s_t \notag \\ s_t, c_t, y_{t - 1} &\to y_t \notag \end{align} 以上是对attention的一个大致学习，后续待补……]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaldi中的决策树]]></title>
    <url>%2F2017%2F06%2F10%2Fkaldi-decision-tree%2F</url>
    <content type="text"><![CDATA[三音素状态绑定这部分通过以下四个步骤完成，分别对应acc-tree-stats，cluster-phones，compile-question，build-tree： 统计量累计 音素聚类 问题集生成 决策树构建 统计量累计累计统计量在acc-tree-stats.cc中的AccumulateTreeStats函数中完成，接受一个transition model，特征序列和对应的对齐信息，输出统计量表示。 统计量的结构表示：123456// 如果EventKeyType表示position信息，那么EventValueType表示该位置上的phone_id// 如果EventKeyType为kPdfClass，那么EventValueType为对应的pdf_class// pair&lt;EventKeyType, EventValueType&gt;组合为一个vector表示成一个EventType// 一般单因素，1+1，三因素，3+1typedef std::vector&lt;std::pair&lt;EventKeyType, EventValueType&gt; &gt; EventType;std::map&lt;EventType, GaussClusterable*&gt; tree_stats; 统计量的具体信息在GaussClusterable里面，里面维护的是特征计数，特征向量和其平方和：12345// ndouble count_;// stats_(0) =&gt; X1 + X2 + ... + Xn// stats_(1) =&gt; X1^2 + X2^2 + ... + Xn^2Matrix&lt;double&gt; stats_; 在后续聚类操作的时候，用到了一个Objf函数计算似然值，函数逻辑是：1234567891011121314BaseFloat GaussClusterable::Objf() const &#123; size_t dim = stats_.NumCols(); Vector&lt;double&gt; vars(dim); double objf_per_frame = 0.0; for (size_t d = 0; d &lt; dim; d++) &#123; // default var_floor_ = 0.01 double mean(stats_(0, d) / count_), var = stats_(1, d) / count_ - mean * mean, floored_var = std::max(var, var_floor_); vars(d) = floored_var; objf_per_frame += -0.5 * var / floored_var; &#125; objf_per_frame += -0.5 * (vars.SumLog() + M_LOG_2PI * dim); return objf_per_frame * count_;&#125; 和推出来的似然函数保持一致： L(S) = \sum_t\left[\log \mathcal{N}(o_t;\mu(S), \Sigma(S))\sum_{s \in S}\gamma_s^t\right] \\ = -\frac{1}{2}\left(D\log 2\pi + \log|\Sigma| + D \right)\sum_t \sum_{s \in S} \gamma_s^t对$\gamma_s^t$的理解： 为什么似然函数用上式表示 $t$时刻的观测是否来自状态$s$，那么$\gamma^t$最多是一个one-hot的向量 $t$时刻的观测是否来自状态$s$的概率 该过程通过如下几步进行。 把对齐信息按照音素划分，一行tid对应一个音素，存在std::vector&lt;std::vector&lt;int32&gt; &gt;里面。注意一下，原始的对齐信息默认应该是进行过重新排序的，就是将自环放在出环之后。 比如对于Transition Model如下（部分）：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162Transition-state 1: phone = SIL hmm-state = 0 pdf = 0 Transition-id = 1 p = 0.952097 [self-loop] Transition-id = 2 p = 0.01 [0 -&gt; 1] Transition-id = 3 p = 0.01 [0 -&gt; 2] Transition-id = 4 p = 0.0279074 [0 -&gt; 3]Transition-state 2: phone = SIL hmm-state = 1 pdf = 1 Transition-id = 5 p = 0.921613 [self-loop] Transition-id = 6 p = 0.0531309 [1 -&gt; 2] Transition-id = 7 p = 0.01 [1 -&gt; 3] Transition-id = 8 p = 0.0152566 [1 -&gt; 4]Transition-state 3: phone = SIL hmm-state = 2 pdf = 2 Transition-id = 9 p = 0.0146723 [2 -&gt; 1] Transition-id = 10 p = 0.96533 [self-loop] Transition-id = 11 p = 0.01 [2 -&gt; 3] Transition-id = 12 p = 0.01 [2 -&gt; 4]Transition-state 4: phone = SIL hmm-state = 3 pdf = 3 Transition-id = 13 p = 0.01 [3 -&gt; 1] Transition-id = 14 p = 0.01 [3 -&gt; 2] Transition-id = 15 p = 0.928052 [self-loop] Transition-id = 16 p = 0.0519551 [3 -&gt; 4]Transition-state 5: phone = SIL hmm-state = 4 pdf = 4 Transition-id = 17 p = 0.957834 [self-loop] Transition-id = 18 p = 0.0421665 [4 -&gt; 5]...Transition-state 9: phone = ONE hmm-state = 0 pdf = 8 Transition-id = 25 p = 0.865902 [self-loop] Transition-id = 26 p = 0.134098 [0 -&gt; 1]Transition-state 10: phone = ONE hmm-state = 1 pdf = 9 Transition-id = 27 p = 0.921862 [self-loop] Transition-id = 28 p = 0.078138 [1 -&gt; 2]Transition-state 11: phone = ONE hmm-state = 2 pdf = 10 Transition-id = 29 p = 0.936872 [self-loop] Transition-id = 30 p = 0.0631278 [2 -&gt; 3]...Transition-state 24: phone = SIX hmm-state = 0 pdf = 23 Transition-id = 55 p = 0.90631 [self-loop] Transition-id = 56 p = 0.0936895 [0 -&gt; 1]Transition-state 25: phone = SIX hmm-state = 1 pdf = 24 Transition-id = 57 p = 0.783409 [self-loop] Transition-id = 58 p = 0.216591 [1 -&gt; 2]Transition-state 26: phone = SIX hmm-state = 2 pdf = 25 Transition-id = 59 p = 0.931359 [self-loop] Transition-id = 60 p = 0.0686414 [2 -&gt; 3]Transition-state 27: phone = SEVEN hmm-state = 0 pdf = 26 Transition-id = 61 p = 0.916657 [self-loop] Transition-id = 62 p = 0.0833432 [0 -&gt; 1]Transition-state 28: phone = SEVEN hmm-state = 1 pdf = 27 Transition-id = 63 p = 0.886809 [self-loop] Transition-id = 64 p = 0.113191 [1 -&gt; 2]Transition-state 29: phone = SEVEN hmm-state = 2 pdf = 28 Transition-id = 65 p = 0.898122 [self-loop] Transition-id = 66 p = 0.101878 [2 -&gt; 3]...Transition-state 33: phone = NINE hmm-state = 0 pdf = 32 Transition-id = 73 p = 0.842715 [self-loop] Transition-id = 74 p = 0.157285 [0 -&gt; 1]Transition-state 34: phone = NINE hmm-state = 1 pdf = 33 Transition-id = 75 p = 0.78074 [self-loop] Transition-id = 76 p = 0.21926 [1 -&gt; 2]Transition-state 35: phone = NINE hmm-state = 2 pdf = 34 Transition-id = 77 p = 0.902379 [self-loop] Transition-id = 78 p = 0.0976208 [2 -&gt; 3] 那么tid序列可以为174 73 73 73 73 76 75 75 75 75 75 75 78 77 77 77 77 77 77 77 77 77 77 77 77 77 77 62 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 64 63 63 63 63 63 63 63 63 63 63 63 63 63 63 66 65 65 26 28 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 30 4 1 1 1 1 1 16 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 18 56 58 57 57 60 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 26 25 25 25 28 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 30 29 29 按照音素划分之后，得到：12345611 =&gt; [74 73 73 73 73 76 75 75 75 75 75 75 78 77 77 77 77 77 77 77 77 77 77 77 77 77 77 ]9 =&gt; [62 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 61 64 63 63 63 63 63 63 63 63 63 63 63 63 63 63 66 65 65 ]3 =&gt; [26 28 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 30 ]1 =&gt; [4 1 1 1 1 1 16 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 18 ]8 =&gt; [56 58 57 57 60 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 59 ]3 =&gt; [26 25 25 25 28 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 27 30 29 29 ] 对于每一条对齐信息，获取三音素和pdf_class的EventType事件类型，并累加其对应的GaussClusterable统计量。比如说对于以上对齐信息，可以得到音素序列11-9-3-1-8-3三音素的划分和EventType表示如下：1234560-11-9 =&gt; (0:0 1:11 2:9)11-9-3 =&gt; (0:11 1:9 2:3)9-3-1 =&gt; (0:9 1:3 2:1)3-1-8 =&gt; (0:3 1:1 2:8)1-8-3 =&gt; (0:1 1:8 2:3)8-3-0 =&gt; (0:8 1:3 2:0) 对于每一种三音素划分，添加pdf_class即状态信息，并累计统计量，比如对于三音素0-11-9对应的统计量累计过程如下：123tree_stats(0:0 1:11 2:9 kPdfClass:0) += AddStats([74 73 73 73 73])tree_stats(0:0 1:11 2:9 kPdfClass:1) += AddStats([76 75 75 75 75 75 75])tree_stats(0:0 1:11 2:9 kPdfClass:2) += AddStats([78 77 77 77 77 77 77 77 77 77 77 77 77 77 77]) 其他三音素类推。 该过程执行完毕之后，将tree_stats信息写到磁盘中，实际就是EventType和GaussClusterable信息。 音素聚类音素聚类在cluster-phones.cc中的AutomaticallyObtainQuestions中完成，接受统计信息和set.int，输出音素聚类情况，也就是所谓的问题集。 聚类过程音素聚类主要进行如下几步操作 状态过滤默认只保留中间状态（pdf_class = 1）的统计量，这部分代码在FilterStatsByKey中，操作完毕之后，stats转为如下形式（vector存储）： 12345(0:0 1:11 2:9 kPdfClass:1) =&gt; C1(0:11 1:9 2:3 kPdfClass:1) =&gt; C2(0:9 1:3 2:1 kPdfClass:1) =&gt; C3...(0:8 1:3 2:0 kPdfClass:1) =&gt; C6 音素划分按中间位置（P == 1）音素对统计量进行划分，累加，划分之后的统计量以phone_id为索引，这部分代码在SplitStatsByKey和SumStatsVec中实现，完成之后，统计量转换为如下形式： 123456phone_id GaussClusterable 1 C4 3 C3 + C6 8 C5 9 C2 11 C1 按音素集合累加由于在set.int中，可能是多个音素共享一个HMM的，但是他们的phone_id是不同的，所以，需要把这些共享HMM的音素对应的统计量做一个合并，存到std::vector&lt;Clusterable*&gt;之中。完成之后，vector的长度和set.int文件的行数相同。 决策树聚类这部分在函数TreeCluster中完成，输入按音素集合累加之后的std::vector&lt;Clusterable*&gt;。聚类过程使用决策树+KMeans，KMeans算法主要目的是生成获取似然提升的划分方案。内在逻辑在“TreeClusterer的聚类逻辑”中介绍，最终目的是要获取如下信息，以生成问题集（即聚类结果）： 123456std::vector&lt;int32&gt; assignments; // assignment of phones to clusters. dim == summed_stats.size().std::vector&lt;int32&gt; clust_assignments; // Parent of each cluster. Dim == #clusters.int32 num_leaves; // number of leaf-level clusters. == leaf_node_.size() 获取问题集合这部分在函数ObtainSetsOfPhones中实现。函数接受上面决策树聚类得到的三个统计量以及phone_sets（即从set.int读出来的std::vector&lt;std::vector&lt;int32&gt; &gt;），输出一个std::vector&lt;std::vector&lt;int32&gt; &gt;类型的问题集/音素聚类结果。该部分依次完成如下操作： 根据assignments，对phone_sets进行重新组合，每一类（cluster）对应一组phone_id，因为决策树可能把不同行的音素集划分为同一类了。 根据clust_assignments，组合出所有非叶子节点对应的phone_id，实际上就是其子节点phone_id之和，也就是要得到决策树上每一个节点音素id集合 补上原始phone_sets内的向量（暂时不理解），去空 最后将该聚类结果输入到文本question.int中，注意，实际看到的question.int可能还加上了一部分extra_question.int，比如在hkust中就是。展示question.int如下（不是完整的，加工自hkust，把set.int中每一行用对应的行号表示） TreeClusterer的聚类逻辑聚类过程通过TreeClusterer完成，下面主要分析TreeClusterer的聚类逻辑。 根据决策树理论，每一次节点分裂都是需要找到最大似然提升的方案，但是由于事先的这些音素统计量并没有标记信息，即无法根据标记信息制定划分方案，所以，一般采用无监督的方法进行二分类，取其最大的似然提升方案，kaldi中用到了KMeans聚类算法给出一次划分方案。 决策树初始化初始化给决策树建立根节点，并执行一次最优划分FindBestSplit。决策树由一系列Node构成，其中维护了其自身和叶子节点的统计信息。节点信息表示如下：123456789101112131415struct Node &#123; bool is_leaf; int32 index; // index into leaf_nodes or nonleaf_nodes as applicable. Node *parent; Clusterable *node_total; // sum of all data with this node. struct &#123; std::vector&lt;Clusterable*&gt; points; std::vector&lt;int32&gt; point_indices; // index of points BaseFloat best_split; std::vector&lt;Clusterable*&gt; clusters; // [branch_factor]... if we do split. std::vector&lt;int32&gt; assignments; // assignments of points to clusters. &#125; leaf; std::vector&lt;Node*&gt; children; // vector of size branch_factor. if non-leaf. // pointers not owned here but in vectors leaf_nodes_, nonleaf_nodes_. &#125;; FindBestSplit总是在节点的points数据上执行最优划分，划分结果存储在clusters和assignments中。assignments表示point_id属于哪一个cluster。划分成功的话，将获得的最大似然提升和节点信息放在一个优先队列中。 最优划分逻辑一次KMeans分类操作定义在ClusterKMeansOnce中，迭代cfg.num_iters次返回结果（了解KMeans原理就知道为什么这么做了）。一次最优节点分裂FindBestSplit执行一次ClusterKMeans，ClusterKMeans具体操作是执行cfg.num_tries次ClusterKMeansOnce，找到最大获得最大似然提升的方案。 聚类逻辑聚类采取BFS逻辑，不断的取出获取最大似然提升的节点，扩展子节点并在其子节点进行最优划分（这部分操作定义在DoSplit之中，主要是将父节点的leaf信息转移到新建子节点之中，并对子节点执行FindBestSplit），直至队列为空或者叶子节点达到上界，注意，这里的上界一般设为phone_sets的行数，假设set.int中有48组音素，那么聚类结果一定不大于48。 在函数DoSplit中，需要完成以下操作： 根据父节点的leaf.assignments划分结果，初始化子节点的leaf.points和leaf.point_indices 根据父节点的leaf.clusters，初始化子节点的node_total 给子节点的index编号，左节点继承父节点编号，在leaf_nodes_中替换父节点，右节点赋值为leaf_nodes_.size()，加入leaf_nodes_。 将父节点标记为非叶子节点，index赋值为非叶子节点的编号nonleaf_nodes_.size()并加入nonleaf_nodes_ 清空父节点的leaf信息。 生成聚类信息num_leaves_out就是叶子节点的个数，其次主要就是要获取assignments和clust_assignments两类信息。assignments是音素集合id到决策树中叶子节点id的映射关系，只需要遍历所有叶子节点，每一次将对应叶子节点的point_indices集合中元素下标处赋值为叶子节点id即可。clust_assignments用来维护节点之间的父子关系，长度为叶子节点和非叶子节点个数之和。由于节点index都是从0开始的，所以会有冲突。kaldi中把非叶子节点通过clust_assignments.size() - 1 - nonleaf_index映射到区间[leaf_nodes_.size(), clust_assignments.size()] 问题编译该部分接受topo文件和question.int输出编译好的问题集，实际就是Questions这个类结构。定义在compile-question.cc中。Questions维护了EventKeyType和其对应的QuestionsForKey集合，其中QuestionsForKey表示对于特定EventKeyType的查询问题集。事实上，输出的问题集包含以下信息：12345EventKeyType QuestionsForKey 0 PhoneQuestions(question.int) 1 PhoneQuestions(question.int) 2 PhoneQuestions(question.int)kPdfClass PdfClassQuestion 其中pdfClassQuestion根据每个HMM建模的状态数而不同：123MaxNumPdfclasses PdfClassQuestion 3 [[0] [0 1]] 5 [[0] [0 1] [0 1 2] [0 1 2 3]] 决策树构建未完待续……]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加权自动机的索引构造]]></title>
    <url>%2F2017%2F06%2F08%2Fgeneral-indexation-of-weighted-automata%2F</url>
    <content type="text"><![CDATA[现实任务中，我们得到的大量信息都具有很高的不确定性，比如语言识别的结果取N-best的lattice网络，其中就包括了N种可能的带权序列。在对这种不确定信息的检索不同于以往确定信息中的检索模式（显然是权值相关的）。 我们可以将这些不确定的序列统一的用一个加权自动机（状态节点和带权的转移边）表示，那么这个问题就可以抽象成一个对加权自动机的索引构造算法。 提前弄清楚一个概念，之前也说过，因子（factor）。可以简单的理解成子串，前缀（prefix）或者后缀（suffix）都是因子。这种索引算法可以看成是后缀自动机和因子自动机的一种泛化。加权自动机索引构造的主要思想是： 对于$n$个句子，每个句子$u_i$可以用一个带权自动机$A_i$表示（其实就是解码的lattice）。可以构建一个带权转换器$T$，这个转换器可以检出这些自动机集合${A_1, A_2, \dots, A_n}$所接受的所有字符的因子。比如给出一个因子$x$，转换器$T$可以给出$x$出现的自动机集合下标和在对应的自动机中出现期望（的负log）： T_i(x) = -\log(E_{P_i}[C_x])其中$P_i$是$A_i$的概率分布，$C_x$是因子$x$在$u_i$中出现的次数。 由于是WFST框架，符号定义在WFST入门中已经说明了。索引构造的思想很简单，和后缀自动机十分类似，其中的很多优化过程直接使用WFST的标准操作就OK。主要分为两步骤，依次处理$A_i \to T_i$，最后$T = \bigcup T_i$即可。对于第一步，为自动机接受的字符的每一个后缀建立一条转移路径，路径输出是自动机的下标和对应的权值，输入就是后缀。权值通过前向-后向算法进行： 定义$A_i$中状态$q$的前向和后向概率是$f_i[q], b_i[q]$： \begin{align} f_i[q] = \bigoplus_{\pi \in P(I_i, q)}^{\log} \lambda_i[p[\pi]] + w[\pi] \notag \\ b_i[q] = \bigoplus_{\pi \in P(q, F_i)}^{\log} \rho_i[n[\pi]] + w[\pi] \notag \\ \end{align}那么，因子$x$在$T_i$中出现的概率表示为： T_i(x) = \bigoplus_{i[\pi] = x}^{\log} \lambda_i[p[\pi]] + w[\pi] + \rho_i[n[\pi]]$A_i \to T_i$分为如下几步： 预处理：对$A_i$进行weight-push转换为$B_i$ 因子选择：因为$B_i$还是一个acceptor，没有输出，所以先将$B_i$中每条弧的输出初始化为$\epsilon$，之后新增初始节点$s_i$和终止节点$e_i$，为$B_i$中的每一个状态$q$增加两条弧$(s_i, \epsilon, \epsilon, d_i[q], q)$和$(q, \epsilon, i, f_i[q], e_i)$ 优化操作，即$\epsilon$-remove，确定化和最小化 $T_i$的输出信息只有下标$i$，所以将它放在终止边上就行。第三步的优化操作得到和原先等价的转换器，只是在空间复杂度更低，搜索效率更高。得到$T_i$之后，通过$T = \bigcup T_i$和进一步的确定化，得到最终整体的索引转换器。用户的查询表示可以用自动机$X$表示，查询结果$R$有下式给出： R = \Pi_o(X \circ T)举个例子，在论文General Suffix Automaton Construction Algorithm and Space Bounds中实现了从String Acceptor到后缀自动机的通用构造算法，得到后缀自动机之后，将每一个状态设置为final，再执行一些简化操作就可以得到因子自动机了（acceptor），只是没有权值信息。实际上这个构造过程也可以用上面的方式进行，原文给出的例子如下： 按照上面的流程，先对左边的Acceptor进行因子选择： 由于加入的都是$\epsilon$边，所以因子选择实际上构建出了对输入自动机接受的字符串集合的所有因子的索引，只是不够简化而已，接下来对其进行简化操（等价操作）就可以得到最终的索引自动机。首先去除$\epsilon$边。 上面的结果不是确定的，执行确定化操作： 这个结果实际上就是将后缀自动机的每一个状态设为final之后的结果，但是还有优化空间，最小化之后得到最终的形式： 查询操作可以抽象为Compose操作，比如给出$cab$子串，查询结果为$cab$，如果是$cdb$，那么查询结果为$\epsilon$，表示子串不存在。 以上说明没有考虑权值，加权因子索引构造的因子选择是要在$\epsilon$边上加上权值信息的，权值信息可由前向-后向算法完成。 最后说一下TFT，整体看来kaldi-kws的TFT时间因子转换器完全继承了这套方法的衣钵，理解这部分之后再看TFT就相对容易一些。而且这个框架在论文中也提到，具有很高的通用性。TFT的修正在于，1) 将时间间隔信息带入权值之中，以便给出关键词出现的时间区间，2) 加入了聚类标识符，索引不相交的因子。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个简单内存管理器的实现]]></title>
    <url>%2F2017%2F06%2F05%2Fhtk-memheap-demo%2F</url>
    <content type="text"><![CDATA[可能是C/C++用的多一些，看代码的时候总是习惯先看内存分配和管理部分的内容，看完之后心里才觉得踏实。之前看HTK源码的时候发现HTK中实现了一个简单的内存管理器（MemHeap），当时好奇，看了一下实现思路，非常朴素。HTK的内存管理器提供三种内存分配方法： MHEAP 主要针对固定结构的内存分配，初始化的时候确定大小 MSTAK 可以申请任意大小的内存 CHEAP 这个基本就是对malloc的简单封装，HTKBook上也不推荐使用这种 我尝试实现了第一种。本身是想在移植的时候替换的，后来发现没必要就没有使用。 第一种的实现逻辑就是先一次性申请一大块内存区域，称为一个Block，它的大小常常是注册分配单元的整数倍。Block通过一个单向链表管理，当有申请请求到来时，找出第一个非空Block的第一个非空区域首地址返回，并标记该区域已经分配。释放的话，只需要简单的将该标记置为未分配即可。如果没有非空Block，就在链表尾部继续分配一块。因为指针本身就是无符号的地址，所以释放内存时，定位需要“释放”的空间在哪个Block里面就很简单，只要依次和当前Block的首地址比较一下地址关系即可。 Demo提供如下接口：1234567// init and freeSegment *NewSegment(int segLen, int eleLen);void FreeSegment(Segment *seg);// alloc/free itemsbyte* NewItem(Segment *seg);void FreeItem(Segment *seg, byte *addr); 其中Segment定义如下1234567891011typedef unsigned char byte;struct MemHeap&#123; int segLen; int eleLen; int newIdx; byte *vis; // 采用bit标记 byte *data; // 空间地址 MemHeap *next; // next指针&#125;; 由于分配，释放的逻辑在上面已经说明了，代码也很简单，下面直接给出简单实现了。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121Segment *NewSegment(int segLen, int eleLen)&#123; Segment *seg = (Segment*)malloc(sizeof(Segment)); seg-&gt;segLen = segLen; seg-&gt;eleLen = eleLen; seg-&gt;newIdx = 0; seg-&gt;vis = (byte*)malloc(segLen / 8 + 1); seg-&gt;data = (byte*)malloc(segLen * eleLen); seg-&gt;next = NULL; memset(seg-&gt;vis, 0, segLen / 8 + 1); memset(seg-&gt;data, 0, segLen * eleLen); return seg;&#125;void FreeSegment(Segment *seg)&#123; Segment *cur, *next; for(cur = seg; cur != NULL; cur = next) &#123; next = cur-&gt;next; if(cur-&gt;vis) free(cur-&gt;vis); if(cur-&gt;data) free(cur-&gt;data); free(cur); &#125;&#125;void SetSegVisited(Segment *seg, int pos)&#123; if(pos &gt;= seg-&gt;segLen) &#123; fprintf(stderr, "SetSegVisited: Accessed out of index: %d/%d\n", pos, seg-&gt;segLen); return; &#125; seg-&gt;vis[pos &gt;&gt; 3] |= 1 &lt;&lt; (7 - (pos &amp; 7)); return;&#125;void SetSegUnvisited(Segment *seg, int pos)&#123; if(pos &gt;= seg-&gt;segLen) &#123; fprintf(stderr, "SetSegUnvisited: Accessed out of index: %d/%d\n", pos, seg-&gt;segLen); return; &#125; seg-&gt;vis[pos &gt;&gt; 3] &amp;= ~(1 &lt;&lt; (7 - (pos &amp; 7))); return;&#125;bool IsSegVisited(Segment *seg, int pos)&#123; if(pos &gt;= seg-&gt;segLen) &#123; fprintf(stderr, "IsSegVisited: Accessed out of index: %d/%d\n", pos, seg-&gt;segLen); exit(-1); &#125; return (seg-&gt;vis[pos &gt;&gt; 3] &amp; (1 &lt;&lt; (7 - (pos &amp; 7)))) != 0;&#125;bool IsSegUsedUp(Segment *seg)&#123; return seg-&gt;newIdx == seg-&gt;segLen;&#125;Segment* GetNextSeg(Segment *seg)&#123; Segment *cur, *pre; for(cur = seg; cur != NULL; cur = cur-&gt;next) &#123; pre = cur; if(!IsSegUsedUp(cur)) break; &#125; if(cur == NULL) &#123; pre-&gt;next = NewSegment(pre-&gt;segLen, pre-&gt;eleLen); return pre-&gt;next; &#125; return cur;&#125;byte* NewItem(Segment *seg)&#123; Segment *cur = GetNextSeg(seg); byte *p = cur-&gt;data + cur-&gt;eleLen * cur-&gt;newIdx; SetSegVisited(cur, cur-&gt;newIdx); // update newIdx while(cur-&gt;newIdx &lt; cur-&gt;segLen) &#123; if(!IsSegVisited(cur, cur-&gt;newIdx)) break; cur-&gt;newIdx++; &#125; ShowSegUse(seg); return p;&#125;Segment* LocateSeg(Segment *seg, byte *addr)&#123; Segment *cur; for(cur = seg; cur != NULL; cur = cur-&gt;next) if(addr - cur-&gt;data &lt; cur-&gt;segLen * cur-&gt;eleLen) break; return cur;&#125;void FreeItem(Segment *seg, byte *addr)&#123; Segment *cur = LocateSeg(seg, addr); int pos = (addr - cur-&gt;data) / cur-&gt;eleLen; SetSegUnvisited(cur, pos); // update newIdx if(pos &lt; cur-&gt;newIdx) cur-&gt;newIdx = pos; ShowSegUse(seg);&#125; 我觉得这么做在某些情况下还是有较高的可用性的，比如你要（前提是用C）维护一个巨大的Hash表，二叉树，链表，有向图等这些结构的时候，在节点的分配阶段，你不需要注意太多，但是当销毁这些巨大的结构时，特别容易出现所谓的double free错误。有可能在之前动态更新结构的时候，某个节点已经被释放或者重置为NULL了，所以，每次释放，你可能都要无尽的重复着内存合法性的判断。当然，如果用的不是C语言，比如C++的话，我觉得完全没有必要，一方面，析构函数本身就可以处理内存释放的工作，其次就是，数据结构没必要从头自己实现了。]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kaldi中的Transition Model]]></title>
    <url>%2F2017%2F06%2F04%2Fkaldi-transition-model%2F</url>
    <content type="text"><![CDATA[kaldi中的Transition Model主要维护了概率密度函数pdf，HMM拓扑类型，以及所有音素的HMM状态信息（即音素id，状态id，和对应的概率密度函数的id，单独索引的transition-id）。这篇是过去的讲解列表，弄清前面说的几个id之间的关系就行了。 topo文件结构 将topo文件读入HmmTopology123phones_ 音素列表phone2idx_ 该音素建模用哪一种拓扑结构【几状态】entries_ 多少种拓扑结构【2】，每一种拓扑结构实际上由一系列状态描述 如何描述状态 发射概率: pdf，概率密度函数 转移概率：transitions 关于pdfclass &lt;PdfClass&gt;默认forward_pdf_class和self_loop_pdf_class相同 否则分开描述&lt;ForwardPdfClass&gt;，&lt;SelfLoopPdfClass&gt; Transition Model的初始化条件 HmmTopology ContextDependency: 决策树，实际上，这里面维护一个EventMap，输入查询条件，给出查询结果 set.txt文件结构set.txt文件中的一行表示这些因素共享一个一个pdf即GMM模型。所谓的决策树是在此基础之上，构建出索引树结构的。Transition Model初始化的时候只是针对单音素建模。所以决策树结构看起来比较简单（最后面附上两张图吧）。 关于EventMap SE: SplitEventMap：一般给出中心位置的phone-id应答【key = P_】 TE: TableEventMap：一般给出pdf-class应答，默认【key = keyPdfClass =-1】 CE: ConstantEventMap: 一对一，只给出答案 copy-tree --binary=false tree - 看到的是什么: 树结构递归过程中间量的记录 Transition Model的作用 维护音素建模的拓扑结构，就是HmmTopology 维护了模型中所有phone_id，state_id， pdf_id的信息，索引称为transition_state transition_state到firsttransition_id的映射 transition_id到transition_state的映射 transition_id到pdf_id的映射 transition_id对应的转移概率对应存储结构如下：123456HmmTopology topo_;std::vector&lt;Tuple&gt; tuples_;std::vector&lt;int32&gt; state2id_;std::vector&lt;int32&gt; id2state_;std::vector&lt;int32&gt; id2pdf_id_;Vector&lt;BaseFloat&gt; log_probs_; 如何获取Tuples[phone-id，state-id，pdf-id]三元组信息 在索引树中，可以获得【phone-id, pdf-class, pdf-id】信息 将上述结构按pdf-id索引，存入pdf-info中，这个结构的大小，就是我们要建模的pdf数目 12# pdf_id =&gt; [phone_id, pdf_class], [phone_id, pdf_class]...std::vector&lt;std::vector&lt;std::pair&lt;int32, int32&gt; &gt; &gt; pdf_info; 从topo结构中，获取【phone-id, pdf-class, state-id】信息 将上述结构按照【phone-id, pdf-class】索引，存入to_hmm_state_list中 12# phone_id pdf_class =&gt; state1 state2...std::map&lt;std::pair&lt;int32, int32&gt;, std::vector&lt;int32&gt; &gt; to_hmm_state_list; merge【pdf-id: phone-id, pdf-class】和【phone-id, pdf-class: state-id】 1234for pdf_id in range(len(pdf_info)): for phone_id, pdf_class in pdf_info[pdf_id]: for state_id in to_hmm_state_list[phone-id, pdf-class]: tuples.append(phone_id, state_id, pdf_id) 如何获取state2id_,id2state_,id2pdf_id_ transition_state索引从1开始 transition_state的总数就是tuples_的大小，也就是说,tuples_按transition_state索引 获取state2id_ 1234first_tid = 1for state_id in range(1, tuples_.size + 1): state2id_[state_id] = first_tid first_tid += num_of_tids_in_state state2id_倒过来就是id2state_ id2pdf_id_根据tid找到state_id里面的forward_pdf或者self_loop_pdf就行 如何获取log_probs_123456for each tid: find: first_state_id = id2state_[tid] get : pdf_class = tid - first_state_id find: cur_tuple = tuples_[first_state_id - 1] find: tpo_entry by cur_tuple.phone get : log_trans_prob by tpo_entry[cur_tuple.state].transitions[pdf_class].prob 数据格式转换 查看模型transition信息 1show-transitions phones.txt final.mdl 可视化tree，dot命令，详细查询graphviz 123# -Gsize指定大小，-T指定保存类型，可以是png, jpg, pdf等draw-tree phones.txt tree | dot -Gsize=80,100 -Tpng &gt; tree.pngdraw-tree phones.txt tree | dot -Tpdf &gt; tree.pdf GMM模型转文本格式 12# 输出到标准输出gmm-copy --binary=false final.mdl - Tree转文本格式 12# 输出到标准输出eg: copy-tree --binary=false tree -]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小结一下]]></title>
    <url>%2F2017%2F06%2F04%2Fget-things-done%2F</url>
    <content type="text"><![CDATA[从拿下一个腾讯云主机到今天把域名申了，零零星星两个多星期了。为了避免站点上东西太少，我从Cmd Markdown上拿了一部分东西（还是那句话，我只是在意一个markdown编辑器而已……）在markdown上记笔记，整理知识点还是相对随意的，毕竟就是自己看，能会意就行。放在云上，虽然我不会刻意去推广，但是仍然感觉会有误人子弟的潜在风险存在。 我对自身专业的认识就是，这是一个可玩性很高的领域，太多的未知意味着太多的趣味。说实话，真的从理想的角度说，我不想把自己限制在某一个角落，为了很多刻意设置的目标去打拼。小时候我总觉得research是有趣的，可是我不知道为什么我对它感兴趣。长大之后，有了一种模糊的感觉，好奇心作祟，和天生爱玩不无区别。仿佛是不经意间走入某个岔路口，后来惊奇的发现，这条路的风景比原来的有意思多了，就流连与此，无心返程了。重复那么几次之后，早已不知道自己身在何方，要去往何处，心里就只有一个念想，那就是，我要持续这种快乐。真正的痛苦在于舍不得告别。 从高中到大学，我一直觉得，纯粹的东西一旦带有了强烈的目的性，那么原始的趣味就不复存在了。高三我很痛苦，每天都是做过的题，学过的东西，我有想法，实现不了，想改变，无能为力啊。所以到了大学，我唯一的期望在于，能自己忙活自己的东西了。对自己的要求就是，有收获，有快乐，足以。 所以相比于过去的我，已经很不在意外界的评价了。我觉得我在机会触手可及的时候，没有选择去更好的学校，去追求所谓更好的资源，本身就已经是对大学四年的一个总结了。以至于我很多时候都在考虑教育这个问题，最后得出的结论就是，如果XX不能使我快乐，那么我为什么要XX？到这里就有点明白了，这个通用句式填上任意两个相关的词语，只要逻辑关系成立，就是通用的。所以，我是本质上只是一个“贪玩”的人？ 我有时候好奇，是不是现在独生子女都有这个通病，太在意自己，以至于很少考虑外界的感受…… 有点扯远了，以后照常的更新吧。风格上说我不是很喜欢把东西说的太细，毕竟是总结和记录，自己有个印象就行。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Connectionist Temporal Classification]]></title>
    <url>%2F2017%2F06%2F03%2Fctc-conclusion%2F</url>
    <content type="text"><![CDATA[CTC（Connectionist Temporal Classification）是为递归神经网络设计的一种输出层的损失准则。在语音领域，识别任务实际上是一种序列标记任务。比如，识别的目标就是要将观测到的帧序列映射到字符序列。传统的识别方案需要依靠因素分类器（即声学模型）得到当前观测帧的因素后验，之后借助解码网络得到最优路径从而得到字符序列。 但是，分类器并不能很好的进行序列标注任务。因为对于某一标注类别/label，分类器给出的是该类别/label出现可能的预测，这是一个沿时间轴的离散概率分布，对于连续label出现的情况，并不能直直接给出预测，而是要通过后续处理（比如解码，借助语言模型和字典等专业信息完成状态后验到最终的字符序列的映射）的方式完成对label序列概率分布的建模。其次，分类器的训练需要提前获知当前输入的标注信息。但是在实际任务中，比如因素状态分类器，通常无法直接从音频抄本中获知当前帧所对应的状态序列，所以，要借助已有的声学模型来获取，这一过程称为在识别任务中称为强制对齐（Force Alignment）。显然，声学模型，或者说分类器的表现效果十分依赖对齐的结果。 CTC允许RNN网络输出直接对label的标注序列进行预测，比如音素，字，词等等。所以，CTC具有以下优势： CTC损失函数的计算只依赖于对于输入的序列标注信息，对于音频而言，就是抄本，而不需要获得每一次输入的状态标注，比如每一帧对应的因素状态这样的信息。如此，舍去了传统识别框架中的对齐操作，也避免了由于对齐效果差对模型训练造成的负面影响。 CTC层的输出直接给出的是标注序列的出现概率。比如标记的是关键词序列$K = {c_1, c_2, c_3}$，那么，网络可以直接给出对$K$的概率预测，而不需要借助后续处理。因此，相比于分类器的“窗型”输出，CTC的输出呈现尖峰效应，如下图所示（BLSTM+CTC的数字序列预测）。 假设CTC层输出可以将输入映射到label集合$A$，并在集合$A$之外定义一个空label符号$\epsilon$，令$A’ = A \cup {\epsilon}$。$\epsilon$符号表示当前输入不产生任何输出。对于一个长度为$T$的观测序列$\boldsymbol{x}$，CTC输出一条在集合$A’$上的序列$\pi$。假设每一时刻网络的输出概率都是独立的，那么可以得到序列$\pi$在给定长度为$T$的观测$\boldsymbol{x}$下的条件概率： p(\pi | \boldsymbol{x}) = \prod_{t = 1}^{T} y_{\pi_t}^t其中$y_{\pi_t}^t$表示在$t$时刻路径$\pi$对应的label出现的概率。考虑到最终要得到的是在集合$A$上的序列$\boldsymbol{l}$，所以还需要将$A’$上的序列$\pi$对应到$\boldsymbol{l}$上（训练阶段的抄本）。假设$A = {x, y}$，网络给出的路径$\pi$可能为${xx{\epsilon}xy{\epsilon}y, x{\epsilon}yy, x{\epsilon}{\epsilon}y}$，它们都可以对应到$A$上的一条序列$\boldsymbol{l} = xy$。若借助$\mathcal{F}: \pi \to \boldsymbol{l}$来表示这种多到一的映射关系，那么序列$\boldsymbol{l}$在给定观测$\boldsymbol{x}$下的条件概率为： \begin{align} p(\boldsymbol{l} | \boldsymbol{x}) = \sum_{\pi \in \mathcal{F'}(\boldsymbol{l})} p(\pi | \boldsymbol{x}) \tag{1} \end{align}CTC的设计原理就是要通过最大化$\boldsymbol{l}$在观测序列$\boldsymbol{x}$下的条件概率，从而达到优化网络的目的。在识别任务中，$\boldsymbol{l}$为音频对应的抄本，$\boldsymbol{x}$为音频对应的特征。CTC通过映射$\mathcal{F}$成功解决了在序列标注问题中，输入输出维度不一致的问题（抄本序列长度往往低于音频长度）。 定义$\boldsymbol{l}$的长度为$U$，下标为$u$的label $\boldsymbol{l}_u$，那么$p(\boldsymbol{l} | \boldsymbol{x})$计算的是在时刻$T$到达$\boldsymbol{l}_U$的所有可能路径$\pi$在给定观测$\boldsymbol{x}$下的条件概率之和。这个问题如果直接求解，枚举满足条件的$\pi$，计算复杂度很高。可以根据动态规划原理，定义子问题$\alpha_t( u)$（在时刻$t$到达$\boldsymbol{l}_u$的可能路径条件概率之和）和$\beta_t(u)$（从时刻$t$和$\boldsymbol{l}_u$开始到达$\boldsymbol{l}_U$的可能路径条件概率之和）间接求解。他们分别被称为前向，后向概率。 令$F_t(u)$和$B_t(u)$为前向，后向概率计算中的可能路径集合，那么，前向，后向概率由下式计算得到： \begin{align} \alpha_t(u) &= \sum_{\pi \in F_t(u)} \prod_{i = 1}^{t} y_{\pi_t}^t \notag \\ \beta_t(u) &= \sum_{\pi \in B_t(u)} \prod_{i = t}^{T} y_{\pi_t}^t \notag \end{align}据此，可以计算出$(1)$式，令： \theta_t(u) = \alpha_t(u)\beta_t(u) = \sum_{\pi_t = \boldsymbol{l}_u, \mathcal{F}(\pi) = \boldsymbol{l}} \prod_{i = 1}^{T} y_{\pi_t}^t = \sum_{\pi_t = \boldsymbol{l}_u, \mathcal{F}(\pi) = \boldsymbol{l}} p(\pi | \boldsymbol{x}) \notag那么 p(\boldsymbol{l} | \boldsymbol{x}) = \sum_{u = 1}^{|\boldsymbol{l}|} \theta_t(u)实际在CTC的输出层是有空label $\epsilon$的，$\epsilon$被安插在每俩个相邻非空label之间。label序列$\boldsymbol{l}$被拓展为$\boldsymbol{l}’(U’ = 2U + 1)$。如果将前向，后向算法的搜索空间表示出来的话，如下图所示。 在状态$(t, u)$（即在时刻$t$，当前label为$\boldsymbol{l}’_u$），对于前向概率，有如下转移情况： 如果当前label为空，那么$(t, u)$可以由状态$(t - 1, u)$和$(t - 1, u - 1)$得到。 如果当前label非空，那么$(t, u)$可以由状态$(t - 1, u)$，$(t - 1, u - 1)$和$(t - 1, u - 2)$得到。 转移方程表示为： \begin{equation} \alpha_t(u)= \begin{cases} [\alpha_{t-1}(u-1)+\alpha_{t-1}(u)]y_{\boldsymbol{l}'_u}^t, & \boldsymbol{l}'_u=\epsilon \text{ or } \boldsymbol{l'}_u=\boldsymbol{l}'_{u-2} \\ [\alpha_{t-1}(u-2)+\alpha_{t-1}(u-1)+\alpha_{t-1}(u)]y_{\boldsymbol{l}'_u}^t, & \text{otherwise} \end{cases} \notag \end{equation}类似的，对于后向概率转移方程为： \begin{equation} \beta_t(u)= \begin{cases} [\beta_{t+1}(u+1)+\beta_{t+1}(u)]y_{\boldsymbol{l}'_u}^t, & \boldsymbol{l}'_u=\epsilon \text{ or } \boldsymbol{l}'_u=\boldsymbol{l}'_{u+2} \\ [\beta_{t+1}(u+2)+\beta_{t+1}(u+1)+\beta_{t+1}(u)]y_{\boldsymbol{l}'_u}^t, & \text{otherwise} \end{cases} \notag \end{equation}CTC层的损失函数通过似然函数表示，对于单个输入和标记label序列$(\boldsymbol{x}, \boldsymbol{l})$，似然函数为$\mathcal{L}(\boldsymbol{x}, \boldsymbol{l}) = -\ln p(\boldsymbol{l} | \boldsymbol{x})$，依次对CTC输出层的每个输出单元$y_s^t$求导（$1 \leqslant s \leqslant U + 1$）： \begin{align} \frac{\partial \mathcal{L}(\boldsymbol{x}, \boldsymbol{l})}{y_s^t} = -\frac{\partial \ln p(\boldsymbol{l} | \boldsymbol{x})}{y_s^t} &= -\frac{1}{\ln p(\boldsymbol{l} | \boldsymbol{x})} \frac{\partial p(\boldsymbol{l} | \boldsymbol{x})}{y_s^t} \notag \\ &= -\frac{1}{\ln p(\boldsymbol{l} | \boldsymbol{x})} \sum_{u = 1}^{|\boldsymbol{l}'|} \frac{\partial \theta_t(u)}{y_s^t} \notag \\ &= -\frac{1}{\ln p(\boldsymbol{l} | \boldsymbol{x}) y_s^t} \sum_{u \in S(\boldsymbol{l}', s)} \theta_t(u) \notag \end{align}其中$S(\boldsymbol{l’}, s) = {u: \boldsymbol{l’}_u = s}$。得到损失函数对输出层的导数之后，就可以按照RNN中梯度传递规则，对CTC层之前的RNN网络进行训练了。]]></content>
      <tags>
        <tag>ASR</tag>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于kaidi谱特征的语音重构]]></title>
    <url>%2F2017%2F06%2F01%2Fkaldi-based-reconstruction%2F</url>
    <content type="text"><![CDATA[第一次是拿C写的，提谱特征，过增强网络，之后取噪声相位，重构音频，弄了一个星期，后来发现，其实可以不必这么麻烦的。用kaldi得到的增强特征，做一个逆的CMVN，之后拿Python处理一下特征还原就行了。 总结一下，语音重构主要是还原频域特征到时域上，使用原始音频的相位信息，流程如下 获取一帧的谱特征 获取原始音频中对应帧的相位 a. 分帧 b. Remove DC c. 预加重 d. 加窗 e. RFFT，获取相位，返回 对谱特征，取exp，开方得到幅度谱，这里只使用[1: 257]的值，不使用能量 幅度谱和相位点乘，RFFT，取前400维得到一帧数据 加窗 进行OverlapAdd, 实际上就是帧移相加 所有帧处理完之后，加一个低通滤波器 将采样值的范围恢复到原始音频的范围内 代码如下，理清特征处理过程思路就很清晰了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#!/usr/bin/env python"""transform spectrogram to waveform"""import sysimport waveimport numpy as npimport kaldi_ioimport wave_ioif len(sys.argv) != 4: print "format error: %s [spectrum] [origin-wave] [reconst-wave]" % sys.argv[0] sys.exit(1)WAVE_WARPPER = wave_io.WaveWrapper(sys.argv[2])WAVE_RECONST = wave.open(sys.argv[3], "wb")WND_SIZE = WAVE_WARPPER.get_wnd_size()WND_RATE = WAVE_WARPPER.get_wnd_rate()REAL_IFFT = np.fft.irfftHAM_WND = np.hamming(WND_SIZE)with open(sys.argv[1], "rb") as ark: SPECT_ENHANCE = kaldi_io.next_mat_ark(ark) SPECT_ROWS, SPECT_COLS = SPECT_ENHANCE.shape assert WAVE_WARPPER.get_frames_num() == SPECT_ROWS INDEX = 0 SPECT = np.zeros(SPECT_COLS) RECONST_POOL = np.zeros((SPECT_ROWS - 1) * WND_RATE + WND_SIZE) for phase in WAVE_WARPPER.next_frame_phase(): # exclude energy SPECT[1: ] = np.sqrt(np.exp(SPECT_ENHANCE[INDEX][1: ])) RECONST_POOL[INDEX * WND_RATE: INDEX * WND_RATE + WND_SIZE] += \ REAL_IFFT(SPECT * phase)[: WND_SIZE] * HAM_WND INDEX += 1 for x in range(1, RECONST_POOL.size): RECONST_POOL[x] += 0.97 * RECONST_POOL[x - 1] RECONST_POOL = RECONST_POOL / np.max(RECONST_POOL) * WAVE_WARPPER.get_upper_bound() WAVE_RECONST.setnchannels(1) WAVE_RECONST.setnframes(RECONST_POOL.size) WAVE_RECONST.setsampwidth(2) WAVE_RECONST.setframerate(WAVE_WARPPER.get_sample_rate()) WAVE_RECONST.writeframes(np.array(RECONST_POOL, dtype=np.int16).tostring()) WAVE_RECONST.close() 当年python画风好奇怪，顺便补充一下谱特征的正向处理过程，我拿python写的结果和kaldi做了一下对比，在不加随机高斯量的时候，误差还是很小的。 kaldi中默认的普特征提取流程如下 分帧【加一个随机高斯量，可以通过options去掉，默认为真】 Remove DC, 也就是减去帧的均值，移除直流分量 计算原始能量，放在第一维上 预加重 加窗，这里加的是指定类型的窗 RFFT, 取[1, 256]区间，注意，这里是能量log谱，不是幅度log谱 返回一帧的谱特征，继续 Demo代码如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/usr/bin/env python"""compute spectrogram according to kaldi"""import sysimport waveimport mathimport numpy as npif len(sys.argv) != 2: print "format error: %s [wave-in]" % sys.argv[0] sys.exit(1)SRC_WAVE = wave.open(sys.argv[1], "rb")SRC_SAMPLE_RATE, TOT_SAMPLE = SRC_WAVE.getparams()[2: 4]WND_SIZE = int(SRC_SAMPLE_RATE * 0.001 * 25)WND_OFFSET = int(SRC_SAMPLE_RATE * 0.001 * 10)WAVE_DATA = np.fromstring(SRC_WAVE.readframes(TOT_SAMPLE), np.int16)FRAME_NUM = (WAVE_DATA.size - WND_SIZE) / WND_OFFSET + 1# FRAME_VEC = np.zeros(WND_SIZE)SPECT_LEN = 257SPECT_VEC = np.zeros(SPECT_LEN)HAMMING = np.hamming(WND_SIZE)print FRAME_NUMfor index in range(FRAME_NUM): BASE_PNT = index * WND_OFFSET # get frame FRAME_VEC = np.array(WAVE_DATA[BASE_PNT: BASE_PNT + WND_SIZE], dtype=np.float) # dither... # remove dc mean FRAME_VEC -= (np.sum(FRAME_VEC) / WND_SIZE) # calculate log energy energy = math.log(np.sum(FRAME_VEC ** 2)) # preemphasize FRAME_VEC[1: ] -= 0.97 * FRAME_VEC[: -1] FRAME_VEC[0] -= 0.97 * FRAME_VEC[0] # buffer DFT_VALUE = np.zeros((SPECT_LEN - 1) * 2) # hamming DFT_VALUE[: WND_SIZE] = FRAME_VEC * HAMMING # power log SPECT_VEC[0] = energy SPECT_VEC[1: ] = np.log(np.abs(np.fft.rfft(DFT_VALUE)[1: ]) ** 2) # print SPECT_VEC # print np.log(np.abs(np.fft.rfft(DFT_VALUE)) ** 2)]]></content>
      <tags>
        <tag>ASR</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伸展树]]></title>
    <url>%2F2017%2F06%2F01%2Fsplay-tree%2F</url>
    <content type="text"><![CDATA[伸展树是一种二叉平衡树，普通搜索树在构造序列不是很理想的情况下，访问复杂度会退化。相比于较高级的一点平衡树，伸展树实现上还是比较简单的，只有左旋和右旋两个操作。这种数据结构的优化思路是利用数据访问的局部性，将上次访问的数据节点旋转到根节点，而不破坏平衡树的结构。 我自己实现的时候，核心操作只有左旋和右旋（所谓的Zig/Zag）。这两个操作是对称的，所以一个函数就可以搞定。为了方便操作，每个节点维护一个表示自己是左/右子节点的标记index_。节点表示如下（为方便访问，类中无私有变量）12345678910class SplayNode &#123;public: SplayNode(int data, int index, SplayNode *p): data_(data), index_(index), parent_(p) &#123; child_.resize(2, NULL); &#125;; SplayNode *parent_; std::vector&lt;SplayNode*&gt; child_; int data_; int index_;&#125;; 对于一个节点，它的左旋或者右旋涉及他的孩子，父亲和祖父节点，注意，统一考虑的话，实际上孩子节点和祖父节点都是可以不存在的，所以代码里面添加了一些存在性判断。 12345678910111213141516171819202122void ZigOrZag(SplayNode *vis) &#123; int index = vis-&gt;index_ != 0; SplayNode *g = vis-&gt;parent_-&gt;parent_; SplayNode *f = vis-&gt;parent_; SplayNode *c = vis-&gt;child_[1 - index]; f-&gt;child_[index] = c; if (c != NULL) &#123; c-&gt;parent_ = f; c-&gt;index_ = index; &#125; f-&gt;parent_ = vis; vis-&gt;child_[1 - index] = f; vis-&gt;parent_ = g; if (g != NULL) &#123; g-&gt;child_[f-&gt;index_] = vis; vis-&gt;index_ = f-&gt;index_; &#125;&#125; 这么写的目的是双旋操作可以用以上单旋操作来表示。 123456789void DualZigOrZag(SplayNode *vis) &#123; ZigOrZag(vis-&gt;parent_); ZigOrZag(vis);&#125;void CrossZigOrZag(SplayNode *vis) &#123; ZigOrZag(vis); ZigOrZag(vis);&#125; 对于一个访问节点vis而言，伸展树的伸展操作就是要使该节点转到根节点的位置。一次旋转不够就多次旋转，直至成为根节点。旋转方式就是网上双旋加单旋，主要取决于祖父，父亲和该节点的位置关系。代码如下：123456789101112void Splay(SplayNode *vis) &#123; while (vis-&gt;parent_ != NULL) &#123; if (vis-&gt;parent_-&gt;parent_ == NULL) ZigOrZag(vis); else &#123; if (vis-&gt;index_ == vis-&gt;parent_-&gt;index_) DualZigOrZag(vis); else CrossZigOrZag(vis); &#125; &#125;&#125; 为了可视化，最终将树BFS成dot语言格式，可以绘制出来。1234567891011121314151617181920void BFS(SplayNode *root) &#123; std::queue&lt;SplayNode*&gt; Q; Q.push(root); std::cout &lt;&lt; "digraph Splay &#123;" &lt;&lt; std::endl; std::cout &lt;&lt; "\tnode [shape = record, height = .1]" &lt;&lt; std::endl; while (!Q.empty()) &#123; SplayNode *p = Q.front(); Q.pop(); std::cout &lt;&lt; "\t" &lt;&lt; p-&gt;data_ &lt;&lt; "[label = \"&lt;F0&gt; |&lt;F1&gt; " &lt;&lt; p-&gt;data_ &lt;&lt; "|&lt;F2&gt; \"]\n"; for (int i = 0; i &lt; 2; i++) &#123; std::string node = i == 0 ? "F0": "F2"; if (p-&gt;child_[i]) &#123; std::cout &lt;&lt; "\t\"" &lt;&lt; p-&gt;data_ &lt;&lt; "\":" &lt;&lt; node &lt;&lt; " -&gt; " "\"" &lt;&lt; p-&gt;child_[i]-&gt;data_ &lt;&lt;"\":F1;" &lt;&lt; std::endl; Q.push(p-&gt;child_[i]); &#125; &#125; &#125; std::cout &lt;&lt; "&#125;" &lt;&lt; std::endl;&#125; 以5, 4, 1, 2, 3, 8, 7, 6, 9为例，原二叉搜索树如下： 在这棵树上对节点的伸展结果如下： 节点4 节点1 节点7 节点6]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[后缀自动机之DAWG构造]]></title>
    <url>%2F2017%2F05%2F28%2Fdawg-const%2F</url>
    <content type="text"><![CDATA[最近需要参考一下文本检索的思路，所以看了一下后缀自动机并做了实现。 定义：$\text{tail}(w)$表示词$w$中出现不止一次的最长后缀，比如 $\text{tail}(abcbc) = bc, \text{tail}(aaa) = aa, \text{tail}(aab) = \epsilon$。 定义： 当满足如下条件时，$y$被称为$w$中的新左上下文的第一次出现。 $w = w_1yw_2$ $y$在$w_1y$中至少出现两次，而且除了最后一次之外，都必须和一个特定的前缀同时出现比如$w = abcbc$中第二次出现的$bc$就是在新左上下文的第一次出现。 那么： $wa$可以代表等价关系$\equiv_{wa}$上的一个等价类，它包含所有出现在$wa$子词集合中而不在$w$字词集合中的元素。 对于$w$的一个子词$x$，如果$x$表示等价关系$\equiv_w$上的一个等价类，那么它表示$\equiv_{wa}$上的一个等价类。这俩个类中的成员在一下情况下是不同的（意思是如果不满足这两个条件那么这两个集合是相同的）：$x \equiv_{w} \text{tail}(wa)$并且$\text{tail}(wa)$是在新的左上下文的第一次出现。在这种情况下，等价类$[x]_w$可以被划分为两类：词长超过$\text{tail}(wa)$保留在$[x]_{wa}$中，其他的划分进一个新类$[\text{tail}(wa)]_{wa}$，用$\text{tail}(wa)$表示。 在等价关系$\equiv_{wa}$上，除了1，2之外，再没有其他等价类。 说明：上述表示有点抽象，举个例子，比如从$abcb \to abcbc$，拓展前后的划分表示如下： 划分元素 end-set 代表元素 $x$ a 1 a ab 2 ab c, bc, abc 3 abc cb,bcb,abcb 4 abcb b 2,4 b 拓展后： 划分元素 end-set 代表元素 $x$ a 1 a ab 2 ab abc 3 abc cb,bcb,abcb 4 abcb abcbc,bcbc,cbc 5 abcbc b 2,4 b c,bc 3,5 bc 新增的等价类$[abcbc]_{wa}$包含了只在$abcbc$中出现的子串（相比拓展前多了${cbc, bcbc, abcbc}$三个子串） 拓展前的等价类$[abc]_w$在拓展后的串中分裂成了两个划分，分别是$[bc]_{wa}$和$[abc]_{wa}$。令$x = abc$，那么拓展前，有$abc \equiv_{w} bc$（因为$abc$和$bc$在划分$[abc]_w$中），拓展后，$\text{tail}(abcbc) = bc$而且$bc$在$abcbc$中满足新的左上下文的第一次出现。所以要对$[x]_w$，即$[abc]_w$进行分裂。分裂规则是：词长超过$bc$即2的${abc}$被划分进$[abc]_wa$中，其他的被划分进新的划分$[bc]_{wa}$中。其他不满足分裂条件的$x = {a, b, ab}$保持不变，$[x]_w = [x]_{wa}$。 上述过程定义了$D_w \to D_{wa}$的拓展过程，构造后缀自动机的思路是，首先一个字符一个字符的完成$D_W$的构造，之后再完成从$D_W \to M_W$的转换。 定义： 在$D_w$中，每个转移边要么是首要的，要么是次要的。 如果$xa = y$，那么从$x$代表的等价类到$y$代表的等价类的转移边就是首要的，否则就是次要的。 每个状态（除了初始状态）都有一个后缀指针，记录它在$T(w)$中的父节点。 如果$x$表示一个等价类，那么用$SC(x)$表示从$x$开始的后缀链。它是一条从$x$到$T(w)$根节点的路径。 那么 在等价关系$\equiv_{w}$上可以表示等价类的任何子串$x$，$SC(x)$都将$x$的后缀划分成了$|SC(x)|$类。 如果$w \ne \epsilon$，那么$D_w$宿节点的后缀节点指向$[\text{tail}(w)]_w$ 回溯从$D_w$的宿节点到源节点的后缀指针过程中，遇到的第一个含有$a$的转移的等价类肯定有一个到$[\text{tail}((wa))]_w$的$a$转移。如果没有遇到$a$转移，那么$a$只在$wa$中出现一次，因此$\text{tail}(wa) = \epsilon$。 令$\text{tail}(wa) = xa$，那么$x$表示$\equiv_w$上的一个等价类，而且当且仅当从$[x]_w$到$[xa]_{w}$存在次要边的时候，$\text{tail}(wa)$是在左上下文的第一次出现。 设计以上定义的目的是： 在$D_w \to D_{wa}$过程中，后缀指针可以定义具体哪一个等价类需要分裂。 通过次要转移的存在可以确认该等价类是否需要被分裂。 下面给出$abc \to abcb \to abcbc$的拓展过程： 上图中蓝色线条表示后缀指针，虚线表示次要边，实线表示首要边，宿节点默认为上一次拓展操作中添加的节点。算法核心在于拓展节点和分裂节点两步，对于每一个新增字符$a$，拓展节点时，操作如下： 新建一个节点$s$，建立一条从宿节点$e$到$s$的首要边，label为$a$。 确定新建节点的后缀节点。从宿节点开始，沿着后缀节点一路回溯（经过的节点称为回溯节点），直到到达源节点（$0$号节点)或者后缀节点被确定时停止，分为以下三种情况处理：2.1 回溯节点没有label为$a$的边，那么新建一条到$s$的次要边2.2 回溯节点有一条label为$a$的首要边，那么$s$的后缀节点就是这条边的指向2.3 回溯节点有一条label为$a$的次要边，那么对这条边上的父子节点执行分类操作，分裂的新状态就是$s$的后缀节点 如果回溯完成，后缀节点还没确定，就设为源节点 $s$成为新的宿节点 \begin{align} &\text{expand}(a): \\ &\quad \quad e \xrightarrow{a}_{1} s \\ &\quad \quad \text{suffix}[s] = \epsilon\\ &\quad \quad p = \; e\\ &\quad \quad \text{while} \; p \ne 0 \; \text{then} \\ &\quad \quad \quad \quad p = \text{suffix}[p] \\ &\quad \quad \quad \quad a \notin \text{label}(p \to *, * \in \deg(p)) \; \Rightarrow p \xrightarrow{a}_{2} s \\ &\quad \quad \quad \quad p \xrightarrow{a}_1 q \Rightarrow \text{suffix}[s] = q \\ &\quad \quad \quad \quad p \xrightarrow{a}_2 q \Rightarrow \text{suffix}[s] = \text{split}(p, q) \\ &\quad \quad \text{suffix}[s] = \epsilon \Rightarrow \text{suffix}[s] = 0\\ &\quad \quad e = \; s \end{align}分裂操作如下，对于父子节点$p, s$： 新建一个子状态$c$ 将$p \to s$的次要边，更改为$p \to c$的首要边 对于$s$所连接的节点，建立$c$到他们的次要边，label为$a$ $c$的后缀节点更改为$s$的后缀节点，$s$的后缀节点更改为$c$ 从父节点$p$开始回溯，直到到达源节点。如果回溯节点存在和$s$的次要边，将它改为到$c$的次要边，继续回溯，否则停止回溯。 \begin{align} &\text{split}(p, s): \\ &\quad \quad p \xrightarrow{a}_2 s \Rightarrow p \xrightarrow{a}_1 c \\ &\quad \quad c \xrightarrow{a}_2 * \quad \text{for} \; * \in \deg(s) \\ &\quad \quad \text{suffix}[c] = \text{suffix}[s] \\ &\quad \quad \text{suffix}[s] = c\\ &\quad \quad \text{while} \; p \ne 0 \; \text{then} \\ &\quad \quad \quad \quad p = \text{suffix}[p] \\ &\quad \quad \quad \quad p \xrightarrow{a}_2 s \Rightarrow p \xrightarrow{a}_2 c \quad \text{or break}\\ &\quad \quad \text{return} \; c \end{align}以上图作为分析 \begin{align} abc \to abcb:& \quad 0 \xrightarrow{b}_{2} 2 \Rightarrow \text{suffix}[4] = 5 = \text{split}(0, 2) \notag \\ abcb \to abcbc:& \quad 5 \xrightarrow{c}_{2} 3 \Rightarrow \text{suffix}[6] = 7 = \text{split}(5, 3) \notag \end{align}对于$\text{split}(0, 2)$： 0 \xrightarrow{b}_{2} 2 \Rightarrow 0 \xrightarrow{b}_{1} 5 \\ 2 \xrightarrow{c}_1 3 \Rightarrow 5 \xrightarrow{c}_2 3 \\ \text{suffix}[5] = \text{suffix}[2] = 0 \\ \text{suffix}[2] = 5对于$\text{split}(5, 3)$： 5 \xrightarrow{c}_{2} 3 \Rightarrow 5 \xrightarrow{c}_{1} 7 \\ 3 \xrightarrow{b}_1 4 \Rightarrow 7 \xrightarrow{c}_2 4 \\ \text{suffix}[7] = \text{suffix}[3] = 0 \\ \text{suffix}[3] = 7 \\ 0 \xrightarrow{c}_{2} 3 \Rightarrow 0 \xrightarrow{c}_{2} 7以上仅仅是完成了$D_w$的在线构造，但是$D_w$还有简化的空间，后续还有相应的算法完成$D_w \to M_w$的转换，代码照着伪代码的思路写就行了，相比理论而言，简洁很多。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WFST核心算法]]></title>
    <url>%2F2017%2F05%2F28%2Fwfst-kernel%2F</url>
    <content type="text"><![CDATA[论文参考经典之作“Speech Recognition With Weighted Finite-State Transducers”，网上随便就能搜到。 符号化：在半环$\mathbb K(\oplus, \otimes, 0, 1)$之上定义一个WFST def \quad T=(\mathcal A, \mathcal B, Q, I, F, E, \lambda, \rho)其中 \begin{align} \mathcal A:& \text有限的输入字母表 \notag \\ \mathcal B:& \text有限的输入字母表 \notag \\ Q:& \text有限的状态集合 \notag \\ I,F:& \text始末状态 \ I,F \subseteq \ Q \notag \\ E:& 转移集合 \notag \\ \lambda:& 初始状态权值 \notag \\ \rho:& 结束状态权值 \notag \\ \end{align}对于$e \in E$ \begin{align} p[e]:& \text起始状态 \notag \\ n[e]:& \text终止状态 \notag \\ i[e]:& \text输入标签 \notag \\ o[e]:& \text输出标签 \notag \\ w[e]:& \text转移权值 \notag \end{align}对于多次转移形成的一个路径$\pi=e_1 \dots e_k$满足： n[e_i]=p[r_{i+1}]\ i=2,\dots ,k将$p,n,w$这些函数应用到path上,令 n[\pi]=n[e_k] \\ p[\pi]=p[e_1] \\ w[\pi]=w[e_1] \otimes \dots \otimes w[e_k]若存在路径集合$R$，那么 w[R]=\bigoplus_{\pi \in R}w[\pi]另做如下定义： P(q,q'): \ q \to q'\ 的路径集合 \\ P(q,x,y,q'): \ q \to q',x \in \mathcal A, y \in \mathcal B \ 的路径集合 \\ P(q,x,q'): \ q \to q' \ input = x\ 的路径集合上述定义拓展至$R,R’ \subseteq Q$ P(R,R')=\bigcup_{q \in R,\ q' \in R'}P(q,q') \\ P(R,x,y,R')=\bigcup_{q \in R,\ q' \in R'}P(q,x,y,q') \\ P(R,x,R')=\bigcup_{q \in R,\ q' \in R'}P(q,x,q')定义一个transducer $T$在$input/output=(x,y)$时 T(x,y)=\bigoplus_{\pi \in P(I,x,y,F)}\ \lambda[p[\pi]]\otimes w[\pi] \otimes \rho[n[\pi]]同理 T(x)=\bigoplus_{\pi \in P(I,x,F)}\ \lambda[p[\pi]]\otimes w[\pi] \otimes \rho[n[\pi]]Composition操作定义$T_1$，$T_2$的Composition操作如下： T_1\circ T_2=\bigoplus_{z \in \mathcal B^*}T_1(x,z)\otimes T_2(z,y)示例，详细操作见OpenFST 操作的伪代码如下： 算法设置一个队列，初始化两个操作数的$I$集合的笛卡尔积插入队列，之后进行BFS逻辑的流程。每一次迭代过程如下($e$表示一个状态节点的所有输出转移路径) 从队列中取出一个state pair($p_1, p_2$)，这是一对状态节点，第一次pop时必然在$I$集合的笛卡尔集合中 依次比较每个状态节点的输出的转移路径($e_1, e_2$)，若满足$o[e_1] = i[e_2]$又不存在于队列中，加入队列 输出半群中加入一条新的转移路径，从$(p_1, p_2)$到$(n[e_1], n[e_2])$，路径标志为$(o[e_1], i[e_2], w[e_1] \otimes w[e_2])$ 根据上述流程，输出半群的过程也是BFS逻辑的，一次操作可以扩展完节点$(p_1, p_2)$的所有后继。 Determination操作对于一个FST中任意的状态$q$，如果从他出发的边没有着相同的输入，那么就可以说这个FST是deterministic的定义若干符号表示如下 \begin{align} p &: \text{带权子状态集合} \notag \\ Q[p] &: p\text{中的状态集合} \notag \\ E\left[Q[p]\right] &: p\text{中的状态集合的出弧集合} \notag \\ i[E\left[Q[p]\right]] &: p\text{中的状态集合的出弧集合的输入集合} \notag \\ \end{align}算法如下 注意，确定化之后的状态本身是未确定化之前的状态集合和权值的pair 算法采用BFS逻辑，将带权子状态集合$q$放在队列中依次处理，初始化该集合状态为所有initial状态，权值为1 对于每次拿到的$q$，在对应的$i[E\left[Q[p]\right]]$中的每一种输入，做如下操作 拿到有该类输入的出弧累计权值最小的一个权值作为新建出弧的权值$w’$ 把这些出弧的目标状态和相应累计权值减去$w’$的集合，作为新建状态$q’$ 新建$E[q, x, w’, p’]$ 若新建状态$q’$为新，加入BFS队列中待处理 RemoveEps操作RemoveEps去除FST中输入为$\varepsilon$的边，得到的FST和原FST等价，算法分为两步执行 对于每一个状态$p$，计算$\varepsilon$闭包，结果定义为C(p) = \{(q, w): q \in \varepsilon(p), \; d[p, q] = w \in \mathbb{K} - \overline 0\} 对于每一个状态$p$，移除$\varepsilon$边，添加若干拓展边，这部分伪代码如下 在该算法中，有三个状态比较重要 当前正在处理的状态$p$ 可以通过$p$的$\varepsilon$闭包到达的状态$q$ 可以通过状态$p$到达的后继状态$r$ 若$q$是终止节点，那么$p$肯定也是终止节点 举个栗子：]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[状态绑定之决策树似然公式]]></title>
    <url>%2F2017%2F05%2F28%2Fdecision-tree-loglike%2F</url>
    <content type="text"><![CDATA[对于一般决策树而言，每一次的最优划分，是要找到一个标准，使得在这种标准之下进行的划分获取的信息增益最大，这里的信息增益一般表示划分之后信息熵的增量。在ASR中，决策树的划分标准是获取最大似然提升，在GMM模型中，对于一个状态集合$S$，其似然表示为： L(S) = \sum_t\sum_{s \in S}\log \mathcal{N}(o_t;\mu(S), \Sigma(S))\gamma_s^t \\ = \sum_t\left[\log \mathcal{N}(o_t;\mu(S), \Sigma(S))\sum_{s \in S}\gamma_s^t\right]其中 \log \mathcal{N}(o_t;\mu(S), \Sigma(S)) = \log \frac{1}{(2\pi)^{D/2}|\Sigma|^{1/2}}\exp\left(\frac{-(o_t - \mu(S))\Sigma^{-1}(o_t - \mu(S))^T}{2}\right) \\ = -\frac{1}{2}\left[D\log 2\pi + \log|\Sigma| + (o_t - \mu(S))\Sigma^{-1}(o_t - \mu(S))^T \right]方差的定义为 \Sigma = \frac{\sum_t \left\{(\sum_{s \in S}\gamma_s^t) (o_t - \mu(S))(o_t - \mu(S))^T )\right\} }{\sum_t \sum_{s \in S} \gamma_s^t} \\ = \frac{\sum_t \left\{\gamma^t(o_t - \mu(S))(o_t - \mu(S))^T )\right\} }{\sum_t \gamma^t}对于$\gamma_s^t$，有如下两种理解： 时刻t的state occupancy，由于一个时刻只能由一个状态生成，所以值为${0, 1}$ 时刻t的观测由状态s生成的概率 为了计算出$L(S)$，需要得到$\Sigma^{-1}$，由上式： \sum_t \gamma^t \cdot I = \sum_t \left\{\gamma^t(o_t - \mu(S))(o_t - \mu(S))^T )\right\} \Sigma^{-1} \\ = \sum_t \left(\gamma^t(o_t - \mu(S))\left[(o_t - \mu(S))^T \Sigma^{-1}\right]\right) \\ = \sum_t \gamma^t A_t^{D \times 1}B_t^{1 \times D}其中$A_t^{D \times 1} = o_t - \mu(S), B_t^{1 \times D} = (o_t - \mu(S))^T \Sigma^{-1}$ 由$B_t^{1 \times D}A_t^{D \times 1} = \text{tri}(A_t^{D \times 1}B_t^{1 \times D})$： \sum_t\left(\gamma^tB_t^{1 \times D}A_t^{D \times 1}\right) = \text{tr}\left\{\sum_t \gamma^t A_t^{D \times 1}B_t^{1 \times D}\right\} = \text{tr}\sum_t \gamma^t \cdot I = D\sum_t \gamma^t \\ = \sum_t (o_t - \mu(S))^T \Sigma^{-1}(o_t - \mu(S))\gamma^t带回$L(S)$： L(S) = \sum_t\left[\log \mathcal{N}(o_t;\mu(S), \Sigma(S))\sum_{s \in S}\gamma_s^t\right] \\ = \sum_t\left\{-\frac{1}{2}\left[D\log 2\pi + \log|\Sigma| + (o_t - \mu(S))\Sigma^{-1}(o_t - \mu(S))^T \right]\gamma^t\right\} \\ = -\frac{1}{2}\left(D\log 2\pi + \log|\Sigma|\right) \sum_t \gamma^t - \frac{1}{2}D \sum_t \gamma^t\\ = -\frac{1}{2}\left(D\log 2\pi + \log|\Sigma| + D \right)\sum_t \sum_{s \in S} \gamma_s^t得证]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[swig处理C指针参数传递]]></title>
    <url>%2F2017%2F05%2F28%2Fswig-for-cptr%2F</url>
    <content type="text"><![CDATA[用Python调用C模块容易发生的就是参数类型不一致的问题，比如，C函数接收传入指针，python端怎么办？这里使用swig作为一种备选方案，处理方式不一定明智简洁，旨在说明可行性。 方案一：自我定义空间分配，释放，访问，修改等函数，用swig封装 方案二：使用swig内置carrays.i，这里用FFT举个栗子 使用方法，直接在.i文件中声明carrays.i 12345678910# fft.i%module fft%&#123;#define SWIG_FILE_WITH_INIT#include "fft.h"%&#125;%include "fft.h"%include "carrays.i"%array_functions(float, floatArray); 其中array_functions(type, name)会创建一下四个函数 1234type *new_name(int nelements) # 申请内存type *delete_name(type *ary) # 释放内存type name_getitem(type *ary, int index) # 访问void name_setitem(type *ary, int index, type value) # 赋值 定义setup.py如下，也可以手动编译动态库 12345678910111213#!/usr/bin/env pythonfrom distutils.core import setup, Extensionexample_module = Extension(&apos;_fft&apos;, sources=[&apos;fft.cpp&apos;, &apos;fft_wrap.cxx&apos;,], )setup (name = &apos;fft&apos;, version = &apos;0.1&apos;, author = &quot;wujian&quot;, description = &quot;&quot;&quot;FFT implement by C&quot;&quot;&quot;, ext_modules = [example_module], py_modules = [&quot;fft&quot;],) 执行(--inplace使得生成的动态库在当前目录下) 12swig -python -c++ fft.ipython setup.py build_ext --inplace 编写测试文件 1234567891011121314151617181920import fftR = fft.new_floatArray(16)I = fft.new_floatArray(16)for i in range(16): fft.floatArray_setitem(R, i, 0) fft.floatArray_setitem(I, i, 0)for i in range(4): fft.floatArray_setitem(R, i, 1)fft.ComplexFFT(R, I, 16, 0)fft.ComplexFFT(R, I, 16, 1)for i in range(16): print "[%10f %10f]" %(fft.floatArray_getitem(R, i), fft.floatArray_getitem(I, i))fft.delete_floatArray(R)fft.delete_floatArray(I) 测试结果 [ 1.000000 -0.000000] [ 1.000000 -0.000000] [ 1.000000 0.000000] [ 1.000000 -0.000000] [ 0.000000 0.000000] [ -0.000000 0.000000] [ 0.000000 0.000000] [ -0.000000 0.000000] ... 附FFT源码实现 123456// FFT.h#include &lt;string.h&gt;#include &lt;math.h&gt;const float PI = 3.14159265;void ComplexFFT(float *R, float *I, int N, int invert); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include "fft.h"void ComplexFFT(float *R, float *I, int N, int invert)&#123; int n, nn, i, j, m, cnt, inc, k; float tmpR, tmpI, WR, WI, Ri, Ii, Rj, Ij; // 原版本R[0]是数组大小，从R[1]开始是数据区域 R--, I--; n = N, nn = n &gt;&gt; 1; for(j = 0, i = 0; i &lt; n - 1; i++) &#123; if(i &lt; j) &#123; tmpR = R[j + 1], tmpI = I[j + 1]; R[j + 1] = R[i + 1], I[j + 1] = I[i + 1]; R[i + 1] = tmpR, I[i + 1] = tmpI; &#125; m = n &gt;&gt; 1; while(j &gt;= m) &#123; j = j - m; m = m &gt;&gt; 1; &#125; j = j + m; &#125; m = 1; // 1, 2, 4 级 while(m &lt; n) &#123; /* m = 1: [1, 2], [3, 4], [5, 6], [7, 8] 4 m = 2: [1, 3], [2, 4], [5, 7], [6, 8] 2 m = 4: [1, 5], [2, 6], [3, 7], [4, 8] 1 */ //printf("M = %d\n", m); cnt = 0, inc = n / (m &lt;&lt; 1); // inc: 4 2 1 // m : 1 2 4 // W递增inc while(cnt &lt; inc) &#123; // m = 1: 1 3 5 7 // m = 2: 1 5 // m = 4: 1 i = cnt * m * 2 + 1; // W[0, n]: inc // 计算m次 迭代inc次 for(int t = 0; t &lt; m; t++, i++) &#123; j = i + m; k = t * inc; // printf("[%3d, %3d] W[%3d, %3d]\n", i, j, k, nn); k == 0 ? WR = 1.0, WI = 0.0: WR = cos(PI * k / nn), WI = -sin(PI * k / nn); if(invert) WI = - WI; //(R[i], I[i]) = (Ri, Ii) + W * (Rj, Ij) //(R[j], I[j]) = (Ri, Ii) - W * (Rj, Ij) Rj = R[j], Ij = I[j], Ri = R[i], Ii = I[i]; R[i] = Ri + WR * Rj - WI * Ij, I[i] = Ii + WR * Ij + WI * Rj; R[j] = Ri - WR * Rj + WI * Ij, I[j] = Ii - WR * Ij - WI * Rj; &#125; cnt++; &#125; m = m &lt;&lt; 1; &#125; if (invert) for (i = 1; i &lt;= n; i++) R[i] = R[i] / n, I[i] = I[i] / n;&#125;]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python绘制语谱图]]></title>
    <url>%2F2017%2F05%2F28%2Fpython-spectrum%2F</url>
    <content type="text"><![CDATA[Linux上没装matlab，没有audition，开源的audacity程序没法看语谱(找到看的方法了……)，所以当时就简单写了一个，勉强能看。 基本原理是STFT，短时傅里叶变换，下面的程序思想和STFT类似，但是不完全一致，只是绘制了每一帧的幅度谱，效果看着还可以，语谱绘制使用matplotlib的imshow函数，直接传入矩阵即可，但是注意，该函数绘制的时候按列绘制，我在存储每一帧的结果是按行存储的，所以需要转置。 另外，之前还做了预加重，毕竟不是提取特征，不需要，细节看代码（当初的写的有点不规范啊）： 1234567891011121314151617181920212223242526272829303132333435363738394041import scipy.io.wavfile as wavimport numpy as npimport matplotlib.pyplot as pltimport sysimport reif len(sys.argv) != 2: print("Format error: &lt;src wave&gt;") sys.exit()wavpath = sys.argv[1]# samples 返回类型是 numpy.ndarray# 用这个模块读取wav scipy.io.wavfile，之前用的是python的wave模块rate, samples = wav.read(wavpath)m = re.match('(.*)/(.*)', wavpath)wavname = m.group(2)print "process %s..." % wavname# 转成浮点值wave = np.array(samples, dtype = "float")frame_off = 160frame_len = 400spect_len = 512frame_num = (wave.size - frame_len) / frame_off + 1# 生成汉明窗hamwindow = np.hamming(frame_len)spect = np.zeros((frame_num, spect_len / 2 + 1))z = np.zeros(spect_len - frame_len)for idx in range(frame_num): base = idx * frame_off frame = wave[base: base + frame_len] # 分帧 frame = np.append(frame * hamwindow, z) # 加窗 spect[idx:] = np.log10(np.abs(np.fft.rfft(frame))) # FFT，返回幅度谱plt.title(wavname)plt.imshow(np.transpose(spect), origin="lower", cmap = "jet", aspect = "auto", interpolation = "none")plt.show() 给出一个绘制结果 完善：还可以为横纵坐标加上单位（时间和频率），时间信息如下 1234xlocs = np.linspace(0, frame_num - 1, 5)frame_dur = 1 / float(rate) * frame_offplt.xticks(xlocs, [&quot;%.02f&quot; % l for l in (xlocs * frame_dur)])plt.xlabel(&quot;time (s)&quot;) 频率信息待完善…]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu上安装pyfst]]></title>
    <url>%2F2017%2F05%2F28%2Fpyfst-on-ubuntu%2F</url>
    <content type="text"><![CDATA[pyfst是对openfst的python API封装，学习fst过程中，实现代价相对较低，安装的时候只要先装openfst，再pip install pyfst就OK了，但是，问题就出在这俩步上 openfst版本问题我装的时候，openfst已经发布到1.6.1版本了，kaldi里面装的也是，所以安装pyfst的时候，我指定的是1.6.1版本的位置，结果编译的时候就各种问题，后来想到可能是版本问题，装了一个常见的1.3.4，直接ok注意，openfst默认configure的时候，不会编译动态库和静态库，通过--enable-shared和--enable-static让其编译的时候，编译库 pyfst通过pip安装因为openfst安装不在系统目录之下，所以需要给pip提供头文件和链接库的索引位置，命令为123sudo pip install --global-option='build_ext' \ --global-option='-I/home/wujian/Document/git/openfst-1.3.4/include/' \ --global-option='-L/home/wujian/Document/git/openfst-1.3.4/lib' pyfst 注意的是，-I/L和后面的路径之间不能存在空格，否则一样找不到头文件这样的问题在Mac上也出现过，解决思路同上，版本用1.4.3的话还是有问题，&lt;tri/unorder_map&gt;找不到，所以改成1.4.0版本就ok，但是最新版本还是不行。 补充在Mac上pip安装pyaudio的时候，执行：12brew install portaudiosudo pip install pyaudio 也会出现找不到portaudio.h头文件的错误（可是这个头文件就在/usr/local/include下面……），最终的解决方法也是类似的：123sudo pip install --global-option='build_ext' \ --global-option='-I/usr/local/include' \ --global-option='-L/usr/local/lib' pyaudio PS: 之前以为是portaudio的问题，官网下了一个手动编译安装，但是缺少一个pa_mac_core.h头文件，所以卸了用brew了。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地交叉编译Android执行文件]]></title>
    <url>%2F2017%2F05%2F28%2Fx-compile-on-android%2F</url>
    <content type="text"><![CDATA[用NDK很久了，玩一玩交叉编译，其实使用ndk-build和Android.mk，Application.mk文件也可以做这件事，但是因为NDK自带了toolchain的脚本，配置很方便，简单的编译可以依赖cmd了。 真机总是没有权限，adb push不上去，只能玩虚拟机了。问题有点多，一个简单的info程序，有几个卡点。 直接adb push的话，可能会报read-only的error，可以adb remount一下 push上去之后，默认权限中是没有x的，chmod一下 PIE错误如下 之前的编译命令为1i686-linux-android-gcc main.cc -o mac_x86 根据提示改为1i686-linux-android-gcc main.cc -fPIC -pie -o mac_x86 可以正常执行了，如下。 注：adb pull可以取回android上的文件]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JNI下C读写大小端和权限问题]]></title>
    <url>%2F2017%2F05%2F28%2Fjni-write-permission%2F</url>
    <content type="text"><![CDATA[最近搞项目期间需要频繁的操作数据文件，之前都是用C进行操作，转到java的时候出现了一点小问题：在Android平台上进行wave的特征重构，重构的wave文件希望使用C直接输入，因为这部分代码在PC上已经验证通过了。Android的话，Application的Context本身提供了openFileInput和openFileOutput，用于创建，写入存在目录/data/data/package_name/files/里面的文件。所以如果希望java能够读取C的输出文件的话，C在JNI部分的输出目录也应该是上面这个。 经过测试，C端的创建，写入均没有问题，java部分的读取也没有报错，只是第一次读取就失败。问题最终抽象成java读取二进制文件的问题。C端使用如下代码生成一个二进制文件12for (short i = 0; i &lt; 400; ++i) fwrite(&amp;i, sizeof(short), 1, wav); java上原先打算使用DataInputStream来操作的，毕竟他拥有一系列读取各种类型数据的函数，但是上例中使用readShort()并不成功。什么情况下成功呢？如果使用DataOutputStream，写出来的文件可以被上述方式正确读取，而且也是二进制格式，于是我认为该方法可以普遍适用于二进制文件的读取。后来也是受到了java读取wave文件的启发，先读取整块byte的buffer，之后转成相应的数据类型，如下：123456wavWriter.read(wav);for (int i = 0; i &lt; wav.length / 2; i++) &#123; short s0 = (short) (wav[2 * i] &amp; 0xff); short s1 = (short) ((wav[2 * i + 1] &amp; 0xff) &lt;&lt; 8); dat[i] = (short) (s1 | s0);&#125; 莫非这是传说中的大端小端问题？C直接读Java写的二进制文件也有问题，以short为例，转换代码如下，其实和上面是互逆的。123456for (int i = 0; i &lt; FRAME_LEN; ++i)&#123; short s0 = val[i * 2] &amp; 0xff； short s1 = val[i * 2 + 1] &amp; 0xff; wav[i] = (s0 &lt;&lt; 8) | s1);&#125; 总而言之，四个关系中，交叉读取文件是需要进行格式转换的，java中的低位是C中的高位。如果java想直接读取C的二进制文件，在写C的时候，提前做好格式转换也是可以的，比如：12345short s0 = data[i] &amp; 0x00ff;short s1 = data[i] &amp; 0xff00;s0 = (s0 &lt;&lt; 8);s1 = (s1 &gt;&gt; 8);data[i] = (s0 | s1); 另外，如果将文件写在应用的私有包目录之下，应用访问没用问题，但是想pull出来的时候，提示没有权限，所以想换个公有的目录访问。 现在的手机内部存储空间已经能满足大部分用户的需求了，所以少有支持外插SD卡的了，故基本认为存储空间为internal space，我想在/sdcard/目录下操作文件， errno依旧是permission denied。 但是其实adb shell进该目录之下，依旧可以创建删除文件。最终很奇怪，赋予了SD卡读写的权限之后12&lt;uses-permission android:name="android.permission.WRITE_EXTERNAL_STORAGE" /&gt;&lt;uses-permission android:name="android.permission.READ_EXTERNAL_STORAGE" /&gt; 问题解决。补充：后来发现在某些6.0的机器上的权限需要添加动态申请12345678910private static final int REQUEST_EXTERNAL_STORAGE = 1;private static String[] PERMISSIONS_STORAGE = &#123; Manifest.permission.READ_EXTERNAL_STORAGE, Manifest.permission.WRITE_EXTERNAL_STORAGE,&#125;;int permission = ActivityCompat.checkSelfPermission(this, Manifest.permission.WRITE_EXTERNAL_STORAGE);if (permission != PackageManager.PERMISSION_GRANTED) &#123; ActivityCompat.requestPermissions(this, PERMISSIONS_STORAGE, REQUEST_EXTERNAL_STORAGE);&#125;]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JNI在AS下的初步配置]]></title>
    <url>%2F2017%2F05%2F28%2Fjni-config%2F</url>
    <content type="text"><![CDATA[安装ndk之类的东西就不用说了。 local.properties文件设置ndk和sdk的目录12ndk.dir=/Users/wujian/Library/Android/sdk/ndk-bundlesdk.dir=/Users/wujian/Library/Android/sdk gradle.properties文件设置启动ndk1android.useDeprecatedNdk=true build.gradle文件设置ndk part的一些配置参数，最基本的下面三个即可，moduleName在java文件中需要用到，这个只的最后编译的静态链接库的名称，这里面有很多可以配置的情况，最基本的需求的话，保证这些就可以跑起来了。12345ndk &#123; moduleName &quot;WriteLib&quot; ldLibs &quot;log&quot;, &quot;z&quot;, &quot;m&quot; abiFilters &quot;armeabi&quot;, &quot;armeabi-v7a&quot;&#125; java文件基本是要定义一个utility的类，用来做java调用C的接口，注意要加载编译好的库，否则运行的时候是找不到实现的。 c/c++文件这部分比较简单，使用javah命令生成一个头文件，实现函数接口即可。注意，一般来说AS的IDE会高亮C部分的语法的，但是有时候可能会失效，如果不是配置的原因的话，重启一次。正确的画风是这样的，配色美美哒！]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenBlas优化效果测试]]></title>
    <url>%2F2017%2F05%2F28%2Fopenblas-test%2F</url>
    <content type="text"><![CDATA[我目前测试三个版本编译的OpenBlas效果，分别是32位单线程，64位单线程，32位多线程测试为300次网络前向耗时，网络结构为[360, 1024, 1024, 1024, 1024, 1024, 4375]。 代码样例基准代码1234567891011void TransRes_stdc(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, int npre, int npos)&#123; FLOATS tmp = 0; for(int i = 0; i &lt; npos; i++) &#123; tmp = 0; for(int j = 0; j &lt; npre; j++) tmp += x[j] * w[i * npre + j]; y[i] = tmp + b[i]; &#125;&#125; OpenMP优化123456789101112void TransRes_stdc(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, int npre, int npos)&#123; FLOATS tmp = 0;#pragma omp parallel for for(int i = 0; i &lt; npos; i++) &#123; tmp = 0; for(int j = 0; j &lt; npre; j++) tmp += x[j] * w[i * npre + j]; y[i] = tmp + b[i]; &#125;&#125; OpenBlas内积优化123456789void TransRes_blas(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, int npre, int npos)&#123; FLOATS tmp = 0; for(int i = 0; i &lt; npos; i++) &#123; tmp = cblas_sdot(npre, x, 1, w + i * npre, 1); y[i] = tmp + b[i]; &#125;&#125; OpenBlas内积+OpenMP优化12345678910void TransRes_blas(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, int npre, int npos)&#123; FLOATS tmp = 0;#pragma omp parallel for for(int i = 0; i &lt; npos; i++) &#123; tmp = cblas_sdot(npre, x, 1, w + i * npre, 1); y[i] = tmp + b[i]; &#125;&#125; OpenBlas矩阵优化12345void TransRes_blas(FLOATS *x, FLOATS *y, FLOATS *w, FLOATS *b, int npre, int npos)&#123; cblas_scopy(npos, b, 1, y, 1); cblas_sgemv(CblasRowMajor, CblasNoTrans, npos, npre, 1, w, npre, x, 1, 1, y, 1);&#125; 测试结果 32位多线程 基准值：6400ms 内积优化：3900ms OpenMP优化：4000ms OpenMP+OpenBlas内积优化：1950ms * OpenMP矩阵优化：1950 - 2100ms 32位单线程 基准值：6400ms 内积优化：3800ms OpenMP优化：3800ms OpenMP+OpenBlas内积优化：1800ms-2000ms不稳定 OpenMP矩阵优化：2500ms 64位单线程 基准值： 6400ms 内积优化：7800ms OpenMP+OpenBlas内积优化：4200ms OpenMP矩阵优化：3200ms]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用OpenBlas优化]]></title>
    <url>%2F2017%2F05%2F28%2Fuse-openblas%2F</url>
    <content type="text"><![CDATA[当时是需要对一个终端耗时任务做矩阵加速，我选了OpenBlas开源方案，事实证明在ARM平台上能用的开源的方案中，OpenBlas做的算相当可以的了。以后有时间还想自己实现一下矩阵乘法的加速。做优化这个过程还是很吸引人的。 编译准备原理还是一样，首先在本地配置安卓的交叉编译环境，编译出OpenBlas的静态库，用于JNI链接。github上有详细的教程，包括我后来的一个编译错误也是在上面找到了解决方案。详见 How to build OpenBLAS for Android 注意教程上建议在做交叉编译之前先构建一个标准工具链，其实就是交叉编译的环境，第一次我图省事只配置了arm-linux-androideabi-gcc的环境变量，make的时候就会出现找不到头文件的错误。 NDK已经提供了一个脚本做这件事情，在路径/Users/wujian/Library/Android/sdk/ndk-bundle/build/tools下有一个make_standalone_toolchain.py脚本，通过执行命令1make_standalone_toolchain.py --arch arm --api 21 --install-dir /dst/path/ 之后我们对这个文件夹配置环境变量即可。 编译不需要Fortran，针对ARMv71make TARGET=ARMV7 HOSTCC=gcc CC=arm-linux-androideabi-gcc NOFORTRAN=1 &gt; make.log 编译时间不长，几分钟吧，编译完会提示安装，执行1make PREFIX=/dst/path install 最终安装目录下存在头文件和静态库，这个就是我们最终需要的。 AS中使用JNI链接这里有个很恶心的问题，目前我没有找到gradle中如何配置链接静态库的方法，只能借助Android.mk文件，但是由于AS默认是执行gradle的编译过程，所以需要在build.gradle中禁用JNI(否则他还是那么一套规程)，之后手动配置build的过程。禁用AS默认的JNI目录：123sourceSets.main &#123; jni.srcDirs = []&#125; 配置编译规则1234567891011task ndkBuild(type: org.gradle.api.tasks.Exec, description: &quot;compile JNI by NDK&quot;) &#123; commandLine &quot;/Users/wujian/Library/Android/sdk/ndk-bundle/ndk-build&quot;, &apos;NDK_PROJECT_PATH=build/intermediates/ndk&apos;, &apos;NDK_LIBS_OUT=src/main/jniLibs&apos;, &apos;APP_BUILD_SCRIPT=src/main/jni/Android.mk&apos;, &apos;NDK_APPLICATION_MK=src/main/jni/Application.mk&apos;&#125;tasks.withType(JavaCompile) &#123; compileTask-&gt;compileTask.dependsOn ndkBuild&#125; 同时在JNI目录下加入Android.mk和Application.mk文件，如下，具体含义之后再解释，这里先说明配置过程。Android.mk中详细说明了OpenBlas静态库的连接过程。1234567891011121314151617181920212223LOCAL_PATH := $(call my-dir)include $(CLEAR_VARS)LOCAL_MODULE := blasLOCAL_SRC_FILES := libopenblas_armv7p-r0.2.20.dev.ainclude $(PREBUILT_STATIC_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE := mathLOCAL_SRC_FILES := impl.cppifeq ($(TARGET_ARCH_ABI),armeabi-v7a) LOCAL_CFLAGS += -mhard-float -D_NDK_MATH_NO_SOFTFP=1 LOCAL_LDFLAGS += -Wl,--no-warn-mismatch -lm_hard LOCAL_STATIC_LIBRARIES := blasendifLOCAL_CFLAGS += -DUSE_JNILOCAL_CFLAGS += -DPFFFT_SIMD_DISABLELOCAL_LDLIBS += -lloginclude $(BUILD_SHARED_LIBRARY) 12APP_ABI := armeabi-v7aAPP_PLATFORM := android-19 再把OpenBlas的头文件加入JNI目录下，include使用即可，接下来就可以make了。 后续问题我两次做静态链接时都出现了如下问题，第一次是使用NENO库： 后来在网上查了许久，是编译选项和ABI的问题，这在How to build OpenBLAS for Android最后一部分也说明了。我采取的是第二种方案，因为这里是使用Android.mk来配置编译规则的。]]></content>
      <tags>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cmake使用外部链接库]]></title>
    <url>%2F2017%2F05%2F28%2Fcmake-use-lib%2F</url>
    <content type="text"><![CDATA[在Linux下不想每次写Makefile自然就想到替代工具了。由于Clion支持的是cmake，所以我也就粉了它。 C/C++工程使用外部链接库时需要指定头文件和库的所在目录（-I -L），同时编译选项加上对应的库名，对应在cmake中CMakeLists.txt文件即使用如下的三个命令123include_directories: -Ilink_directories: -Ltarget_link_libraries: -lXXX 举个例子编译main.cc时需要使用neno库，库和头文件分别在目录inc和lib之下123456789101112131415161718192021|-- Ne10| |-- CMakeLists.txt| |-- GNUlinux_config.cmake| |-- LICENSE| |-- README.md| |-- android| |-- build| |-- cmake| |-- common| |-- contributing.md| |-- doc| |-- inc| |-- ios| |-- lib| |-- modules| |-- samples| |-- test| |-- tools|-- bench| |-- CMakeLists.txt| |-- main.cc g++ -I ../Ne10/inc/ -L ../Ne10/lib/ main.cc -o demo -lNE10对应的 cmake文件如下所示： 12345678910cmake_minimum_required(VERSION 2.6)project(NENO_benchmark)set(NENO_PREFIX ~/Ne10)include_directories($&#123;NENO_PREFIX&#125;/inc)link_directories($&#123;NENO_PREFIX&#125;/lib)add_executable(demo main.cc)target_link_libraries(demo libNE10.a) validate ok~ 补充一发，KALDI中的option_parser测试 123456789101112cmake_minimum_required(VERSION 3.5)set(KALDI_DIR ~/Document/git/kaldi)set(TARGET test-options-parse)set(SRC test-options.cc)include_directories($&#123;KALDI_DIR&#125;/src $&#123;KALDI_DIR&#125;/tools/openfst/include)link_directories($&#123;KALDI_DIR&#125;/src/lib)add_definitions(-O3 -g -std=c++11)add_executable($&#123;TARGET&#125; $&#123;SRC&#125;)target_link_libraries($&#123;TARGET&#125; kaldi-util kaldi-base)]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Grub手动引导Ubuntu启动]]></title>
    <url>%2F2017%2F05%2F28%2Fgrub-start%2F</url>
    <content type="text"><![CDATA[原先的Ubuntu不小心整崩溃了，在windows下删掉分区，重新安装之后总是找不到boot loader，出现Grub引导界面，如下 第一次见真的挺方的…… 解决方案，手动引导，只需要熟悉几个命令即可 首先要知道/boot和/区安装在具体哪个分区，使用ls可以知道当前磁盘的分区情况，或者直接TAB 执行如下 123linux (hd0, gptX)/vmlinuz-*** root=/dev/sdaXinitrd (hd0, gptX)/initrd-***.imgboot 其中root=指明/挂载在的那个分区，(hd0, gptX)表示/boot所在的分区，后来发现下面的命令也可以123set root=(hd0, gptX)set prefix=(hd0, gptX)/grubnormal 选硬盘和分区时，如果文件系统被识别，那么用TAB键会自动补全的，所以完全可以找到/root的所在分区的，grub目录就在root目录之下。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RedHat下GCC升级安装的若干问题]]></title>
    <url>%2F2017%2F05%2F28%2Fgcc-update%2F</url>
    <content type="text"><![CDATA[大三玩SC的时候，手动升级了好几次GCC，还有Glibc的库（升级失误，整废一个节点），遇到问题在此做个备注。 其实流程跟装普通软件没有什么区别，装之前先完成依赖安装，主要就是下面第一个列表中的三个，装完导一下环境变量。 gmp, mpc, mpfc的安装 正常安装在家目录下面之后，环境变量要导入对应的C_INCLUDE_PATH和LD_LIBRARY_PATH，否则安装GCC时configurecheck不到对应的头文件或者库 GCC编译时，出现error: Unable to find a suitable type for HOST_WIDE_INT 这个貌似是宏定义冲突导致的，重置相关的环境变量，如下 unset LIBRARY_PATH CPATH C_INCLUDE_PATH PKG_CONFIG_PATH CPLUS_INCLUDE_PATH INCLUDE 这个问题出现的很奇怪……此处备忘]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Boost.Python和Boost.Numpy的使用]]></title>
    <url>%2F2017%2F05%2F28%2Fboost-python%2F</url>
    <content type="text"><![CDATA[习惯上python之后，我很自然的就想到怎么和C++代码结合的问题了，毕竟核心计算模块不敢用python做，之前用过swig，但是感觉不够灵活，方便。后来找到了boost库，开始上手会遇到一些乱七八糟的问题，但是做完了回头看看，还是蛮方便的，起码相对于swig来说。 需求其实是要在树莓派上做个KWS模型，提特征和网络前向的代码不想再重新写了（虽然之前已经实现过了），所以突发奇想，基于kaldi给python写一个wrapper调用就行了。 Boost库的安装分为俩类，一类不需要编译成库文件，包含头文件即可使用，另外一类是需要编译安装库文件的，使用的时候加上链接，Boost.Python就属于后一类，安装完成Boost.python之后，默认会编译numpy库，所以可以直接使用boost.numpy Boost Python和Numpy的使用 boost python一般用来封装C++的API给python调用，一般编译成特定的lib，使用python的时候，直接import就行了 boost numpy一般给C++提供直接处理传，返回入numpy矩阵的功能 Boost Python/Numpy初步使用 Boost Python正常定义C++类和成员函数，使用BOOST_PYTHON_MODULE定义模块名和对应的函数导出名就行了，详见boost.python Boost Numpy这个主要是一系列API掌握就行了，详见boost.python(Numpy) 使用boost封装kaldi nnet1的网络前向一个简单的使用例子，基本操作都在里面123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;boost/python.hpp&gt;#include &lt;boost/python/numpy.hpp&gt;#include "nnet/nnet-nnet.h"#include "nnet/nnet-loss.h"using namespace kaldi;using namespace kaldi::nnet1;// 命名空间namespace py = boost::python;namespace np = boost::python::numpy;class NnetWrapper &#123;public: NnetWrapper(std::string nnet_mdl = "final.nnet"); // 传入，返回numpy类型 np::ndarray Predict(np::ndarray &amp;vector);private: Nnet nnet_; // keep memory not free CuMatrix&lt;BaseFloat&gt; nnet_out;&#125;;NnetWrapper::NnetWrapper(std::string nnet_mdl) &#123; nnet_.Read(nnet_mdl);&#125;np::ndarray NnetWrapper::Predict(np::ndarray &amp;vector) &#123; int cols, rows; // 获取内建dtype KALDI_ASSERT(vector.get_dtype() == np::dtype::get_builtin&lt;float&gt;()); // 获取维度 KALDI_ASSERT(vector.get_nd() &lt;= 2); cols = vector.shape(vector.get_nd() - 1); KALDI_ASSERT(cols == nnet_.InputDim()); rows = vector.get_nd() == 1 ? 1: vector.shape(0); // 获取数据指针 CuSubMatrix&lt;BaseFloat&gt; nnet_in(reinterpret_cast&lt;BaseFloat*&gt;(vector.get_data()), rows, cols, vector.strides(0) / sizeof(BaseFloat)); nnet_.Feedforward(nnet_in, &amp;nnet_out); // 有已知数据，建立ndarray类型变量，传参如下： // data_addr, dtype, shape, stride, obj return np::from_data(nnet_out.Data(), np::dtype::get_builtin&lt;float&gt;(), py::make_tuple(rows, nnet_out.NumCols()), py::make_tuple(nnet_out.Stride() * sizeof(BaseFloat), sizeof(BaseFloat)), py::object());&#125;BOOST_PYTHON_MODULE(pynnet1) &#123; using namespace boost::python; // 初始化numpy模块 np::initialize(); // 导出构造函数为init, 可选参数输入，和预测函数Predict为predict class_&lt;NnetWrapper&gt;("nnet1", init&lt;optional&lt;std::string&gt; &gt;()) .def("predict", &amp;NnetWrapper::Predict);&#125; Cmake编译，基于python2.7给python调用肯定编译成库，注意 如果不用numpy，只需要额外链接python2.7和boost_python俩个库 使用numpy的话，链接boost_numpyboost库默认安装在/usr/local/lib之下，头文件在/usr/local/include/boost里面，编译时需要指定这些目录Cmake完整如下 1234567891011121314151617181920cmake_minimum_required(VERSION 3.5)project(PyNnet1)set(CMAKE_CXX_STANDARD 11)set(TARGET pynnet1)set(KALDI_DIR ../../../Document/git/kaldi)set(BOOST_LIB /usr/local/lib)set(PYTHON_INC /usr/include/python2.7)# -Iinclude_directories($&#123;PYTHON_INC&#125; $&#123;KALDI_DIR&#125;/tools/openfst/include $&#123;KALDI_DIR&#125;/tools/CLAPACK $&#123;KALDI_DIR&#125;/src)# -Llink_directories($&#123;KALDI_DIR&#125;/src/lib $&#123;BOOST_LIB&#125;)add_definitions(-O3 -g -std=c++11 -DHAVE_CLAPACK)set(SOURCE_FILES nnet-wrapper.cpp)add_library($&#123;TARGET&#125; SHARED $&#123;SOURCE_FILES&#125;)# 默认生成格式为libXXX.so，现在不需要前缀set_target_properties($&#123;TARGET&#125; PROPERTIES PREFIX "")target_link_libraries($&#123;TARGET&#125; python2.7 boost_numpy boost_python pthread kaldi-base kaldi-cudamatrix kaldi-nnet)]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EM算法对GMM模型进行参数估计]]></title>
    <url>%2F2017%2F05%2F28%2Fgmm-trainning%2F</url>
    <content type="text"><![CDATA[之前学习的EM算法很抽象，以GMM模型为例，看看EM算法如何通过期望-最大化的迭代过程，进行参数的有效估计的。 高斯混合模型对于一个一元变量的高斯分布的概率密度函数(pdf)定义为 \begin{align} P(x) & = \frac{1}{\sqrt{2\pi\mu}}e^{-(\frac{x - \mu}{\sigma})^2 / 2} \notag \\ &= \mathcal N(x;\mu, \sigma)\notag \end{align}拓展到多元高斯分布 \begin{align} P(\boldsymbol x) & = \frac{1}{(2\pi)^{D/2}|\boldsymbol \varSigma|^{1/2}}e^{(\boldsymbol x - \boldsymbol \mu)^T\boldsymbol \varSigma^{-1} (\boldsymbol x - \boldsymbol \mu)} \notag \\ &= \mathcal N(\boldsymbol x;\boldsymbol \mu, \boldsymbol \varSigma)\notag \end{align}再拓展到高斯混合分布： P(\boldsymbol x) = \sum_{m = 1}^Mc_m\mathcal N(\boldsymbol x;\boldsymbol \mu_m, \boldsymbol \varSigma_m)其中$m$为高斯数 GMM的参数估计确定隐变量对于GMM生成的数据，我们并不知道他来自哪一个分布，反映数据来源这部分信息是未知的，定义$h_i^m$表示第$i$个数据是否来自于第$m$个高斯分量 定义： \boldsymbol \Theta = (c_1, c_2, \cdots, c_M; \boldsymbol \mu_1, \boldsymbol \mu_2, \cdots, \boldsymbol \mu_M;\boldsymbol \varSigma_1, \boldsymbol \varSigma_2, \cdots, \boldsymbol \varSigma_M) \\ \boldsymbol Y = (\boldsymbol y_1, \boldsymbol y_2, \cdots, \boldsymbol y_N) \\ \boldsymbol H = \begin{pmatrix} h_1^1 & h_1^2 & \cdots & h_1^M \\ h_2^1 & h_2^2 & \cdots & h_2^M \\ \vdots & \vdots & \ddots & \vdots \\ h_N^1 & h_N^2 & \cdots & h_N^M \\ \end{pmatrix} \\则，完全数据的似然函数为 \begin{align} P(\boldsymbol Y, \boldsymbol H|\boldsymbol \Theta) & = \prod_{n = 1}^NP(\boldsymbol y_n, \boldsymbol H_n|\boldsymbol \Theta) \notag \\ & = \prod_{n = 1}^N\prod_{m = 1}^M \left[c_m \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)\right]^{h_n^m} \notag \end{align}确定$Q$函数在E步，我们要确定$Q$函数，根据$Q$函数定义 Q(\Theta, \Theta^t) = E_H[logP(H,Y|\Theta) | Y, \Theta^t] \begin{align} logP(\boldsymbol Y, \boldsymbol H|\boldsymbol \Theta) & = \sum_{n = 1}^N\sum_{m = 1}^M h_n^m \left\{logc_m + log\left[ \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)\right]\right\} \notag \\ \end{align}可以得到 Q(\Theta, \Theta^t) = \sum_{m = 1}^M \sum_{n = 1}^N\left\{E_{h_n^m} \cdot logc_m + E_{h_n^m} \cdot log \left[ \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)\right]\right\}其中，$E_{h_n^m}$是隐变量在完全数据下的期望 E_{h_n^m} = E(h_n^m|Y_n, \Theta^t) = P(h_n^m = 1 | Y_n, \Theta^t) \\ = \frac{c_m \cdot \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)}{\sum_{m = 1}^{m = M} \mathcal N(\boldsymbol y_n;\boldsymbol \mu_m, \boldsymbol \varSigma_m)}期望最大化得到$E_{h_n^m}$之后，对$Q$函数求偏导，可以得到混合高斯模型中参量的更新公式 $c_m$ c_m^{t + 1} = \frac{\sum_{n = 1}^NE_{h_n^m}}{N} $\boldsymbol \mu_m^{t + 1}$ \boldsymbol \mu_m^{t + 1} = \frac{\sum_{n = 1}^NE_{h_n^m} \cdot Y_n}{\sum_{n = 1}^NE_{h_n^m}} $\boldsymbol \varSigma_m^{t + 1}$ \boldsymbol \varSigma_m^{t + 1} = \frac{\sum_{n = 1}^N E_{h_n^m} \cdot (Y_n - \boldsymbol \mu_n)^2}{\sum_{n = 1}^NE_{h_n^m}}]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[EM算法]]></title>
    <url>%2F2017%2F05%2F28%2Fem-algorithm%2F</url>
    <content type="text"><![CDATA[EM算法优化的目标是观测数据对参数$\theta$的对数似然函数，如果不存在隐变量的话，可以直接用最大似然法估计，在隐变量存在的情况下，使用EM算法进行迭代估计。本篇是当时学李航的统计学习方法写下的笔记，可能有理解不正确的地方。 EM算法重要之处在于传统的语音识别框架中，HMM和GMM的参数学习是靠EM完成的。 在$MLE$（最大似然估计）中，最大化目标函数 P(Y|\Theta) \tag{1}的参数估计，可以通过下式得到 \begin{align} \Theta_{MLE} & = \underset{\Theta}{argmax}L(\Theta) \notag \\ & = \underset{\Theta}{argmax}\prod_YP(Y|\Theta) \tag{2} \end{align}但是在观测不全面的情况下，比如只观测到了训练数据$Y$，为了优化$(1)$中的目标，还需要知道一些隐变量$X$，否则无法进行全面的估计。对于完全数据$(X, Y)$ P(X,Y|\Theta) = P(X|Y,\Theta) \cdot P(Y|\Theta) \tag{3}上面已经提到，我们的目标是优化$(1)$，则 \log P(Y|\Theta) = \log P(X,Y|\Theta) - \log P(X|Y,\Theta) \tag{4}如果我们现在已知分布参数$\Theta^t$，用它计算$P(Y|\Theta)$在$X$上条件分布的期望 \log P(Y|\Theta) = \sum_x \log P(Y|\Theta) \cdot P(X|Y,\Theta^t) \\ = Q(\Theta, \Theta^t) - H(\Theta, \Theta^t)令 Q(\Theta,\Theta^t) = \sum_x \log P(X,Y|\Theta) \cdot P(X|Y,\Theta^t) \\ H(\Theta,\Theta^t) = \sum_x \log P(X|Y,\Theta) \cdot P(X|Y,\Theta^t)EM算法的收敛性EM算法找出 \Theta^{t + 1} = \underset{\Theta}{argmax}Q(\Theta, \Theta^t) \tag{8}进行下一轮迭代，收敛性需证明： logP(Y|\Theta^{t + 1}) - \log P(Y|\Theta^t) \ge 0 \tag{9}由$(8)$，已知： Q(\Theta^{t + 1}, \Theta^t) - Q(\Theta^{t}, \Theta^t) \ge 0 \tag{10}只需 H(\Theta^{t + 1}, \Theta^t) - H(\Theta^{t}, \Theta^t) \le 0 \tag{11}证明: \begin{align} (11) &= \sum_x \log\frac{P(X|Y,\Theta^{t + 1})}{P(X|Y,\Theta^{t})} \cdot P(X|Y,\Theta^t) \notag \\ & \le \log\sum_x\frac{P(X|Y,\Theta^{t + 1})}{P(X|Y,\Theta^{t})}P(X|Y,\Theta^t) \notag \\ & = \log\sum_xP(X|Y,\Theta^{t + 1}) = 0 \notag \\ \end{align}证明过程使用了Jesson不等式 $Q$函数$Q$函数是完全数据的对数似然函数关于在观测数据$Y$和已知参数$\Theta^t$对未观测数据$X$的条件分布$P(X|Y,\Theta^t)$的期望，定义如下： Q(\Theta, \Theta^t) = E_X\left[\log P(X,Y|\Theta) | Y, \Theta^t\right]对$Q$函数展开，写成 Q(\Theta, \Theta^t) = \sum_X \log P(X,Y|\Theta)P(X|Y,\Theta^t)对于$P(X|Y,\Theta^t)$，理解成隐变量在模型参数$\Theta^t$和观测$Y$下的概率。 推到这里还是比较抽象，下面继续就EM算法在HMM，GMM中的应用做相关说明，这个应该就比较具象了。]]></content>
      <tags>
        <tag>ML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kaldi中的GMM模型]]></title>
    <url>%2F2017%2F05%2F28%2Fkaldi-gmm%2F</url>
    <content type="text"><![CDATA[这部分主要记录的是GMM在kaldi中的实现。 kaldi中关于高斯混合模型的表示，更新，主要用到下面这四个类，之间的关系如下： \require{AMScd} \begin{CD} \text{DiagGMM} @>\text{update by}>> \text{AccumDiagGmm} \\ @V{* \to 1}VV @VV{* \to 1}V \\ \text{AmDiagGMM} @>>\text{update by}> \text{AccumAmDiagGmm} \end{CD}具体表述为： DiagGMM表示一个GMM模型，AmDiagGMM存储了一个GMM声学模型中的所有GMM，也就是pdf AccumDiagGmm用来对一个GMM模型进行参数更新，AccumAmDiagGmm中存储了一个AccumDiagGmm向量，可以对整个声学模型进行更新 下面一个一个说明 DiagGMM对于一个GMM模型，pdf可以表示为 \prod_{m = 0}^Mc_m\mathcal{N}(\boldsymbol{x}, \boldsymbol{\mu}_m, \boldsymbol{\varSigma}_m) = \prod_{m=0}^M \frac{c_m}{(2\pi)^{D/2}|\boldsymbol{\varSigma}_m|^{1/2}}e^\frac{(\boldsymbol{x}-\boldsymbol{\mu}_m)^T\boldsymbol{\varSigma}_m^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_m)}{2}对其中一个GMM分量，我们取log可以得到： \log{c_m} - \frac{1}{2}(D\log{2\pi}+\log{\boldsymbol{|\varSigma}_m|}) + \frac{1}{2}(\boldsymbol{x}-\boldsymbol{\mu}_m)^T\boldsymbol{\varSigma}_m^{-1}(\boldsymbol{x}-\boldsymbol{\mu}_m)对于原先的指数部分，展开： \exp = \frac{1}{2}(\boldsymbol{x}^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{x} - \boldsymbol{x}^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{\mu}_m - \boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{x} + \boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{\mu}_m) \\ = \frac{1}{2}\boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{\mu}_m + \frac{1}{2}\boldsymbol{x}^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{x} - \boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{x}DiagGMM中gconst_，weights_，inv_vars_，means_invvars_依次存放的值如下： \log{c_m} - \frac{1}{2}(D\log{2\pi}+\log{\boldsymbol{|\varSigma}_m|}-\boldsymbol{\mu}_m^T\boldsymbol{\varSigma}_m^{-1}\boldsymbol{\mu}_m) \\ c_m \\ \boldsymbol{\varSigma}_m^{-1} \\ \boldsymbol{\mu}_m^T \boldsymbol{\varSigma}_m^{-1}在给定$\boldsymbol{x}$时，计算一个分量的loglikelihood由下式给出 - \text{gconst_} + \text{means_invvars_} \cdot \boldsymbol{x} - \frac{1}{2} \cdot \text{inv_vars_} \cdot \boldsymbol{x}^2由此看来，DiagGMM的作用就是表示一个最基本的GMM模型，给出一个观测，可以给出一个各个GMM分量观测概率(比如在函数LogLikelihoods的作用，可以得到一个观测的后验向量)。对于这单个GMM模型的更新，需要记录EM算法中的一些过程量，这个依靠AccumDiagGmm完成。 AccumDiagGmm结合EM算法，要更新GMM模型中的$(c_m, \mu_m, \varSigma_m)$，必须首先得到隐变量在完全数据下的期望$E_{H_n^m}$： E_{H_n^m} = \frac{c_m \cdot \mathcal{N(\boldsymbol{x}_n;\boldsymbol{\mu}_m, \boldsymbol{\varSigma}_m})}{\sum_{m = 0}^M\mathcal{N(\boldsymbol{x}_n;\boldsymbol{\mu}_m, \boldsymbol{\varSigma}_m})} = \frac{P_m(\boldsymbol{x}_n;\boldsymbol{\mu}_m, \boldsymbol{\varSigma}_m)}{P(\boldsymbol{x}_n;\boldsymbol{\mu}, \boldsymbol{\varSigma})}${P_m} \to {P_m / P}$的映射由函数ApplySoftMax完成，该函数如下 123456789template&lt;typename Real&gt;Real VectorBase&lt;Real&gt;::ApplySoftMax() &#123; Real max = this-&gt;Max(), sum = 0.0; for (MatrixIndexT i = 0; i &lt; dim_; i++) &#123; sum += (data_[i] = Exp(data_[i] - max)); &#125; this-&gt;Scale(1.0 / sum); return max + Log(sum);&#125; 这个函数的功能如下： \{P_m\} \leftarrow \{e^{P_m - P_{max}}\} \\ \text{sum} \; \leftarrow \sum_{m = 0}^MP_m=\frac{1}{e^{P_{max}}}\sum_{m = 0}^Me^{P_m} \\ \{P_m\} \leftarrow \{\frac{P_m}{\text{sum}}\} = \{\frac{e^{P_{max}}}{\sum_{m = 0}^Me^{P_m}} \cdot \frac{e^{P_m}}{e^{P_{max}}}\} = \{\frac{e^{P_m}}{\sum_{m = 0}^Me^{P_m}}\} \\ \text{return} \; \log\sum_{m = 0}^Me^{P_m}由于实际参与运算的${P_m}$实际上都是取过log的，所以，ApplySoftMax完成了${P_m} \to {P_m / P}$映射功能，表示如下： \require{AMScd} \begin{CD} \{\log P_m\} @>\text{softmax}>> \{E_{H_n^m}\} \end{CD}下面把AccumDiagGmm中的三个变量和EM算法中的更新参数结合起来123Vector&lt;double&gt; occupancy_;Matrix&lt;double&gt; mean_accumulator_;Matrix&lt;double&gt; variance_accumulator_; 以上三个变量的对应关系如下： \mathcal{O}_m = \sum_{n = 0}^NE_{H_n^m} \\ \mathcal{M}_m(M \times D) = \sum_{n = 0}^NE_{H_n^m} \cdot X_n \\ \mathcal{V}_m(M \times D) = \sum_{n = 0}^NE_{H_n^m} \cdot X_n \cdot X_n以上过程量$\mathcal{O}, \mathcal{M}, \mathcal{V} $在gmm-acc-stats-ali中完成积累，在gmm-est中完成更新。结合EM算法中更新公式，可以得到： c_m = \frac{\mathcal{O}_m}{\sum_{m = 0}^M \mathcal{O}_m} \\ \boldsymbol{\mu}_m = \frac{\mathcal{M}_m}{\sum_{m = 0}^M \mathcal{O}_m} \\ \boldsymbol{\varSigma}_m = \frac{\mathcal{V}_m}{\sum_{m = 0}^M \mathcal{O}_m} - \boldsymbol{\mu}_m^2kaldi中这部分还进行了GMM高斯数的自动调整，即merge和split操作。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RealFFT算法实现]]></title>
    <url>%2F2017%2F05%2F28%2Frealfft-2%2F</url>
    <content type="text"><![CDATA[FFT最后一步，解释RealFFT的算法原理。RealFFT输入，对于实序列$x_n(0 \le n \le N - 1)$，以$(x_{2n }, x_{2n + 1})$的形式输入，输出为实序列FFT变换结果的前$N / 2$个点。 比如，以长为16的序列${1, 1, 1, 1, 0, \ldots 0 }$输入ComplexFFT和RealFFT，结果输出分别为12345678910111213141516171819202122232425[ 4.000000, 0.000000] [ 3.013670, 2.013670] [ 1.000000, 2.414214] [ -0.248303, 1.248303] [ 0.000000, 0.000000] [ 0.834089, -0.165911] [ 1.000000, 0.414214] [ 0.400544, 0.599456] [ 0.000000, 0.000000] [ 0.400544, -0.599456] [ 1.000000, -0.414214] [ 0.834089, 0.165911] [ 0.000000, 0.000000] [ -0.248303, -1.248303] [ 1.000000, -2.414214] [ 3.013670, -2.013670] =========================[ 4.000000, 0.000000][ 3.013670, 2.013670][ 1.000000, 2.414214][ -0.248303, 1.248303][ 0.000000, 0.000000][ 0.834089, -0.165911][ 1.000000, 0.414214][ 0.400544, 0.599456] 观察可以发现，利用序列的共轭对称性可以补全一些其余的点（有一个点无法补全，即对称中心点）下面说明算法流程 X_k = \sum_{n = 0}^{N - 1}x_nW_N^{kn} \\ = \sum_{n = 0}^{N / 2 - 1}x_{2n}W_N^{2nk} + x_{2n + 1}W_N^{(2n + 1)k} \\ = \sum_{n = 0}^{N / 2 - 1}x_{2n}W_{N/2}^{nk} + W_N^k\sum_{n = 0}^{N / 2 - 1}x_{2n + 1}W_{N/2}^{nk} \\ = F_k + W_N^kG_k共轭对称证明： X_{n-k}^* = F_{n-k}^* + W_N^{*n-k}G_{n-k}^* \\ = F_k + W_N^{*-k}G_k = F_k + W_N^kG_k = X_k之前的$F_k, G_k$已经计算完毕，只需要在上次程序的基础之上计算 F_k + W_N^kG_k即可。 实现如下： 12345678910111213141516171819ComplexFFT(R, I, 0);float FR, FI, GR, GI, YR, YI, CYR, CYI, XR, XI, cosr, sinr;for (int r = 1; r &lt;= MAX_LEN; r++)&#123; if(r == 1) FR = R[r], FI = 0.0, GR = I[r], GI = 0.0; else &#123; YR = R[r], YI = I[r]; CYR = R[MAX_LEN + 2 - r], CYI = -I[MAX_LEN + 2 - r]; FR = (YR + CYR) / 2, FI = (YI + CYI) / 2; GR = (YI - CYI) / 2, GI = (CYR - YR) / 2; &#125; cosr = cos((r - 1) * PI / MAX_LEN); sinr = sin((r - 1) * PI / MAX_LEN); XR = FR + cosr * GR - sinr * GI; XI = FI + cosr * GI + sinr * GR; printf("[%12f, %12f]\n", XR, XI);&#125; 结果经过验证无误。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RealFFT算法铺垫]]></title>
    <url>%2F2017%2F05%2F27%2Frealfft-1%2F</url>
    <content type="text"><![CDATA[继续FFT，上回已经手写FFT了，但是也遗留了一个问题，实际应用中FFT处理的都是实信号，但是为了使用我上回写的ComplexFFT函数，需要给其虚部补0，这一操作不仅浪费空间，而且计算耗时啊。RealFFT算法就是处理实信号的快速算法。 同时，搞信号的重构也让我对实FFT的对称性加深了认识，确实是有用的…… 实信号DFT的对称性 W_N^k=e^{-2kj\pi/N} \\ X_k = \sum_{n = 0}^{N-1}x_nW_N^{nk} 注意这里$x_n$是实数 X_{N - r} = \sum_{n = 0}^{N-1}x_nW_N^{(N - r)k} \\ = \sum_{n = 0}^{N-1}x_nW_N^{-rk}W_N^{Nk} \\ = \sum_{n = 0}^{N-1}x_nW_N^{-rk} = \sum_{n = 0}^{N-1}[x_nW_N^{rk}]^* = X_r^*反之： X_{N - r}^* = X_r \quad \\ (1 \le r\le N-1)在$0$这点： X_0 = \sum_{n = 0}^{N-1}x_n直观一点，看个例子，使用ComplexFFT函数，输入12345678910111213141516[ 0.000078, 0.000000] =&gt; [ 67.890442, 0.000000][ 1.315378, 0.000000] =&gt; [ -13.852791, 1.756794][ 7.556053, 0.000000] =&gt; [ 0.532240, -14.502794][ 4.586502, 0.000000] =&gt; [ -10.848876, 0.947389][ 5.327672, 0.000000] =&gt; [ 8.034233, 8.668694][ 2.189592, 0.000000] =&gt; [ -8.089980, 12.082935][ 0.470446, 0.000000] =&gt; [ -14.220805, 6.269228][ 6.788647, 0.000000] =&gt; [ 5.620103, 0.964417][ 6.792964, 0.000000] =&gt; [ -2.237431, 0.000000][ 9.346930, 0.000000] =&gt; [ 5.620103, -0.964417][ 3.835021, 0.000000] =&gt; [ -14.220805, -6.269228][ 5.194164, 0.000000] =&gt; [ -8.089980, -12.082935][ 8.309653, 0.000000] =&gt; [ 8.034233, -8.668694][ 0.345721, 0.000000] =&gt; [ -10.848876, -0.947389][ 0.534616, 0.000000] =&gt; [ 0.532240, 14.502794][ 5.297002, 0.000000] =&gt; [ -13.852791, -1.756794] 注意，这种对称性不包括直流分量的。使用对称性还可以做许多优化，包括RealFFT。这里的铺垫是指：使用一次FFT计算的结果，得到实部，虚部序列的FFT结果，以下面这个为例子:12345678910111213141516[ 0.000078, 1.315378] =&gt; [ 76.081299, 78.423798][ 7.556053, 4.586502] =&gt; [ -7.566336, 10.051374][ 5.327672, 2.189592] =&gt; [ -2.170276, -19.456476][ 0.470446, 6.788647] =&gt; [ -1.338717, 1.404751][ 6.792964, 9.346930] =&gt; [ -12.029690, -0.553211][ 3.835021, 5.194164] =&gt; [ -1.947378, 5.299602][ 8.309653, 0.345721] =&gt; [ -19.588976, -11.740066][ 0.534616, 5.297002] =&gt; [ -16.009092, 3.573137][ 6.711493, 0.076982] =&gt; [ 11.795471, -13.576748][ 3.834157, 0.668422] =&gt; [ -17.982683, -8.924475][ 4.174860, 6.867727] =&gt; [ -11.516462, -1.057013][ 5.889766, 9.304365] =&gt; [ -32.044506, -12.575722][ 8.461669, 5.269288] =&gt; [ 12.017742, -0.259529][ 0.919649, 6.539190] =&gt; [ 16.961304, 5.201901][ 4.159994, 7.011906] =&gt; [ -0.896533, -20.641878][ 9.103209, 7.621980] =&gt; [ 6.236089, 5.876601] 根据一个虚数序列$(X, Y)$得到的$(R, I)$，我们是可以得到$(X,0)$和$(Y,0)$的FFT结果的。推导如下： X_k = \sum_{n = 0}^{N-1}x_nW_N^{nk} \\ = \sum_{n = 0}^{N-1}(f_n+jg_n)W_N^{nk} \\ = \sum_{n = 0}^{N-1}f_nW_N^{nk}+ j\sum_{n = 0}^{N-1}g_nW_N^{nk} \\ = F_k + jG_k又$f_n,g_n$是实数序列，满足 F_{N - k}^* = F_k \\ G_{N - k}^* = G_k那么 X_{N - k}^* = F_{N - k}^* - jG_{N - k}^* \\ = F_k - jG_k要想从$X_k$中恢复出$F_k$和$G_k$，可以通过下式： F_k = \frac{1}{2}( X_{N - k}^* + X_k) \\ G_k = \frac{j}{2}(X_{N - k}^* - X_k) \\ 1 \le k \le N - 1当$k = 0$时： X_0 = F_0 + jG_0 \\ = \sum_{n = 0}^{N-1}f_n + j\sum_{n = 0}^{N-1}g_n所以： F_0 = R(X_0) \\ G_0 = I(X_0)代码实现123456789101112131415ComplexFFT(R, I, 0); float FrR, FrI, GrR, GrI, YrR, YrI, CyrR, CyrI;for (int r = 1; r &lt;= MAX_LEN; r++)&#123; if(r == 1) FrR = R[r], FrI = 0.0, GrR = I[r], GrI = 0.0; else &#123; YrR = R[r], YrI = I[r]; CyrR = R[MAX_LEN + 2 - r], CyrI = -I[MAX_LEN + 2 - r]; FrR = (YrR + CyrR) / 2, FrI = (YrI + CyrI) / 2; GrR = (YrI - CyrI) / 2, GrI = (-YrR + CyrR) / 2; &#125; printf("[%12f, %12f]\t[%12f, %12f]\n", FrR, FrI, GrR, GrI);&#125; 程序输出12345678910111213141516[ 76.081299, 0.000000] [ 78.423798, 0.000000][ -0.665123, 2.087387] [ 7.963987, 6.901212][ -1.533404, 0.592701] [ -20.049177, 0.636872][ 7.811293, -1.898575] [ 3.303326, 9.150011][ -0.005974, -0.146841] [ -0.406370, 12.023716][ -16.995941, 8.937662] [ -3.638060, -15.048564][ -15.552719, -5.341527] [ -6.398539, 4.036257][ -16.995888, 6.248806] [ -2.675669, -0.986795][ 11.795471, 0.000000] [ -13.576748, 0.000000][ -16.995888, -6.248806] [ -2.675669, 0.986795][ -15.552719, 5.341527] [ -6.398539, -4.036257][ -16.995941, -8.937662] [ -3.638060, 15.048564][ -0.005974, 0.146841] [ -0.406370, -12.023716][ 7.811293, 1.898575] [ 3.303326, -9.150011][ -1.533404, -0.592701] [ -20.049177, -0.636872][ -0.665123, -2.087387] [ 7.963987, -6.901212] 和以$(X,0)$和$(Y,0)$作为输入时的结果做对比12345678910111213141516[ 76.081299, 0.000000] [ 78.423798, 0.000000][ -0.665124, 2.087387] [ 7.963987, 6.901213][ -1.533404, 0.592701] [ -20.049177, 0.636871][ 7.811293, -1.898576] [ 3.303326, 9.150011][ -0.005974, -0.146841] [ -0.406370, 12.023716][ -16.995941, 8.937661] [ -3.638060, -15.048563][ -15.552718, -5.341526] [ -6.398538, 4.036257][ -16.995888, 6.248806] [ -2.675670, -0.986795][ 11.795471, 0.000000] [ -13.576748, 0.000000][ -16.995888, -6.248806] [ -2.675670, 0.986795][ -15.552718, 5.341526] [ -6.398538, -4.036257][ -16.995941, -8.937661] [ -3.638060, 15.048563][ -0.005974, 0.146841] [ -0.406370, -12.023716][ 7.811293, 1.898576] [ 3.303326, -9.150011][ -1.533404, -0.592701] [ -20.049177, -0.636871][ -0.665124, -2.087387] [ 7.963987, -6.901213] 基本无误。熟悉了这部分，下面就可以正式啃RealFFT了。]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFT实现]]></title>
    <url>%2F2017%2F05%2F27%2Fwrite-fft%2F</url>
    <content type="text"><![CDATA[前端时间搞前端处理，遇到RealFFT算法，挺感兴趣的，网上资料太少，就自己实现了一遍。考虑大部分情况下，FFT输入都是实信号，所以一般的实现方法，都是在虚部补0之后，转成虚信号，进行变换，RealFFT就是快速处理实信号的一类算法，这个以后再谈。先是最基本的实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667void ComplexFFT(float *R, float *I, int invert)&#123; int n, nn, i, j, m, cnt, inc, k; float tmpR, tmpI, WR, WI, Ri, Ii, Rj, Ij, dR, dI; n = R[0], nn = n &gt;&gt; 1; for(j = 0, i = 0; i &lt; n - 1; i++) &#123; if(i &lt; j) &#123; tmpR = R[j + 1], tmpI = I[j + 1]; R[j + 1] = R[i + 1], I[j + 1] = I[i + 1]; R[i + 1] = tmpR, I[i + 1] = tmpI; &#125; m = n &gt;&gt; 1; while(j &gt;= m) &#123; j = j - m; m = m &gt;&gt; 1; &#125; j = j + m; &#125; m = 1; // 1, 2, 4 级 while(m &lt; n) &#123; /* m = 1: [1, 2], [3, 4], [5, 6], [7, 8] 4 m = 2: [1, 3], [2, 4], [5, 7], [6, 8] 2 m = 4: [1, 5], [2, 6], [3, 7], [4, 8] 1 */ //printf("M = %d\n", m); cnt = 0, inc = n / (m &lt;&lt; 1); // inc: 4 2 1 // m : 1 2 4 // W递增inc while(cnt &lt; inc) &#123; // m = 1: 1 3 5 7 // m = 2: 1 5 // m = 4: 1 i = cnt * m * 2 + 1; // W[0, n]: inc // 计算m次 迭代inc次 for(int t = 0; t &lt; m; t++, i++) &#123; j = i + m; k = t * inc; // printf("[%3d, %3d] W[%3d, %3d]\n", i, j, k, nn); k == 0 ? WR = 1.0, WI = 0.0: WR = cos(PI * k / nn), WI = sin(PI * k / nn); if(invert) WI = - WI; //(R[i], I[i]) = (Ri, Ii) + W * (Rj, Ij) //(R[j], I[j]) = (Ri, Ii) - W * (Rj, Ij) Rj = R[j], Ij = I[j], Ri = R[i], Ii = I[i]; R[i] = Ri + WR * Rj - WI * Ij, I[i] = Ii + WR * Ij + WI * Rj; R[j] = Ri - WR * Rj + WI * Ij, I[j] = Ii - WR * Ij - WI * Rj; &#125; cnt++; &#125; m = m &lt;&lt; 1; &#125; if (invert) for (i = 1; i &lt;= n; i++) R[i] = R[i] / n, I[i] = I[i] / n;&#125; 用的是最基本的基于时间抽取的算法，写的时候参照下图： 下面对一个窗函数进行16点采样，测试结果如下，一次是输入数据，正变换和逆变换的结果。 最后顺便用C++也写了一下，用了一下虚数库。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;complex&gt;#include &lt;algorithm&gt;using namespace std;const float PI = 3.14159265;void FFT(vector&lt; complex&lt;float&gt; &gt; &amp;sig, bool invert) &#123; int N = sig.size(); for (int i = 0, j = 0; i &lt; N - 1; i++) &#123; if(i &lt; j) &#123; swap(sig[i], sig[j]); &#125; int k = N &gt;&gt; 1; while(j &gt;= k) &#123; j -= k; k = k &gt;&gt; 1; &#125; j += k; &#125; vector&lt; complex&lt;float&gt; &gt; W(N / 2); for (int i = 0; i &lt; W.size(); i++) &#123; W[i] = polar(1.0f, -2 * PI * i / N); if (invert) W[i] = conj(W[i]); &#125; for (int m = 1; m &lt; N; m = m &lt;&lt; 1) &#123; for (int n = 0; n &lt; N; n += (m &lt;&lt; 1)) &#123; int k = 0; for(int j = n; j &lt; n + m; j++, k += N / (m &lt;&lt; 1)) &#123; complex&lt;float&gt; A = sig[j], B = sig[j + m]; sig[j] = A + W[k] * B, sig[j + m] = A - W[k] * B; &#125; &#125; &#125; if (invert) &#123; for_each(sig.begin(), sig.end(), [=] (complex&lt;float&gt; &amp;s) &#123;s /= N;&#125;); &#125;&#125;int main() &#123; vector&lt; complex&lt;float&gt; &gt; signal = &#123;1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0&#125;; FFT(signal, 0); FFT(signal, 1); for_each(signal.begin(), signal.end(), [](complex&lt;float&gt; s) &#123;cout &lt;&lt; abs(s) &lt;&lt; endl;&#125;); return 0;&#125;]]></content>
      <tags>
        <tag>ASR</tag>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一系列简单区间DP问题]]></title>
    <url>%2F2017%2F05%2F25%2Fthink-about-interval-dp%2F</url>
    <content type="text"><![CDATA[和矩阵连乘类似的套路，举几个问题作为例子。 矩阵连乘问题123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;iostream&gt;#include &lt;sstream&gt;#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include &lt;string.h&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;set&gt;#include &lt;math.h&gt;/*=======================================矩阵连乘问题dp(i, j) = min( dp(i, k) + dp(k + 1, j) + S);i &lt; k &lt; j;dp(i, i) = 0;========================================*/#define flush(arr, i) memset(arr, i, sizeof(arr))typedef long long int64;using namespace std;const int MAX_ITEM = 128;//const int oo = 0x7fffffff;const int oo = 0x3f3f3f3f;int dp[MAX_ITEM][MAX_ITEM];int w[MAX_ITEM], pos[MAX_ITEM][MAX_ITEM];int DP(int l, int r)&#123; if(l == r) return 0; if(dp[l][r]) return dp[l][r]; int ans = oo, tmp = 0; for(int i = l; i &lt; r; i++) &#123; tmp = DP(l, i) + DP(i + 1, r) + w[l - 1] * w[i] * w[r]; if(ans &gt; tmp) &#123; ans = tmp; pos[l][r] = i; &#125; &#125; return dp[l][r] = ans;&#125;void display(int l, int r)&#123; if(l == r) &#123; printf("A%d", l); return; &#125; printf("("); display(l, pos[l][r]); display(pos[l][r] + 1, r); printf(")");&#125;int main()&#123; freopen("0-data.txt", "r", stdin); int n; while(scanf("%d", &amp;n) != EOF) &#123; flush(dp, 0); flush(pos, 0); for(int i = 0; i &lt;= n; i++) scanf("%d", w + i); printf("%d\n", DP(1, n)); display(1, n); &#125; return 0;&#125; 最优三角剖分123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#include &lt;iostream&gt;#include &lt;sstream&gt;#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include &lt;string.h&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;set&gt;#include &lt;math.h&gt;#include &lt;time.h&gt;/*=======================================最优三角剖分dp[i][j] = min(dp[i][x] + dp[x][j] + w(i, x, j));i &lt;= x &lt;= j边界条件 dp[i][i + 1] == 0========================================*/#define flush(arr, i) memset(arr, i, sizeof(arr))typedef long long int64;using namespace std;const int MAX_ITEM = 110;const int oo = 0x7fffffff;//const int oo = 0x3f3f3f3f;int dp[MAX_ITEM][MAX_ITEM], wei[MAX_ITEM][MAX_ITEM];int GetWeight(int from, int mid, int to)&#123; return wei[from][mid] + wei[from][to] + wei[mid][to];&#125;int DP(int from, int to)&#123; if(to - from == 1) return 0; if(dp[from][to]) return dp[from][to]; int ans = oo; for(int i = from + 1; i &lt; to; i++) ans = min(ans, DP(from, i) + DP(i, to) + GetWeight(from, i, to)); return dp[from][to] = ans;&#125;int main()&#123; freopen("0-data.txt", "r", stdin); int n; while(scanf("%d", &amp;n) != EOF) &#123; for(int i = 0; i &lt; n; i++) for(int j = 0; j &lt; n; j++) scanf("%d", &amp;wei[i][j]); flush(dp, 0); printf("%d\n", DP(0, n - 1)); &#125; return 0;&#125; 最大m子段和1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071#include &lt;iostream&gt;#include &lt;sstream&gt;#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include &lt;string.h&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;set&gt;#include &lt;math.h&gt;#include &lt;time.h&gt;/*=======================================最大m子段和9 39 8 7 6 5 4 3 2 117dp[k][p]表示前k个元素划分为p个子段最大值的最小值dp[k][p] = min&#123;dp[k][p], max&#123;dp[x][p - 1] + sum[x + 1][k]&#125;&#125;p - 1 &lt;= x &lt;= k - 1========================================*/#define flush(arr, i) memset(arr, i, sizeof(arr))typedef long long int64;using namespace std;const int MAX_ITEM = 110;const int oo = 0x7fffffff;//const int oo = 0x3f3f3f3f;int dp[MAX_ITEM][MAX_ITEM];int sum[MAX_ITEM];int DP(int k, int p)&#123; if(p == 1) return dp[k][p] = sum[k]; if(dp[k][p]) return dp[k][p]; int tmp = 0; dp[k][p] = oo; for(int i = p - 1; i &lt;= k - 1; i++) &#123; tmp = max(DP(i, p - 1), sum[k] - sum[i]); dp[k][p] = min(dp[k][p], tmp); &#125; return dp[k][p];&#125;int main()&#123; int len, p; while(scanf("%d%d", &amp;len, &amp;p) != EOF) &#123; flush(sum, 0); flush(dp, 0); int tmp; for(int i = 1; i &lt;= len; i++) &#123; scanf("%d", &amp;tmp); sum[i] = sum[i - 1] + tmp; &#125; printf("%d\n", DP(len, p)); &#125; return 0;&#125; 石子合并问题12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#include &lt;iostream&gt;#include &lt;sstream&gt;#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include &lt;string.h&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;set&gt;#include &lt;math.h&gt;#include &lt;time.h&gt;/*=======================================石子合并问题自底向上，求步长为k的时候，步长为k - 1问题的解已知dp[i][j]表示i -&gt; j的最优解 得分最多/最少要加上合并的石子总数作为最优值dp[i][j] = max(dp[i][j], dp[i][k] + dp[k + 1][j] + sum[i][j]);========================================*/#define flush(arr, i) memset(arr, i, sizeof(arr))typedef long long int64;using namespace std;const int MAX_ITEM = 110;const int oo = 0x7fffffff;//const int oo = 0x3f3f3f3f;int dp[MAX_ITEM][MAX_ITEM];int sum[MAX_ITEM];int main()&#123; int len; while(scanf("%d", &amp;len) != EOF) &#123; for(int i = 1; i &lt;= len; i++) scanf("%d", sum + i); sum[0] = 0; for(int i = 1; i &lt;= len; i++) sum[i] += sum[i - 1]; flush(dp, 0); for(int sp = 1; sp &lt;= len; sp++) &#123; for(int i = 1; i + sp &lt;= len; i++) &#123; int j = i + sp; for(int k = i; k &lt; j; k++) dp[i][j] = max(dp[i][j], dp[i][k] + dp[k + 1][j] + sum[j] - sum[i - 1]); printf("dp[%d][%d] = %d\n", i, j, dp[i][j]); &#125; &#125; printf("%d\n", dp[1][len]); &#125; return 0;&#125; 最大的算式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;iostream&gt;#include &lt;sstream&gt;#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include &lt;string.h&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;set&gt;#include &lt;math.h&gt;#include &lt;time.h&gt;/*=======================================最大的算式dp[k][p] = max(dp[p - 1 ... k - 1][p - 1] * sum[k][p])表示前i部分插入p个乘号获取的最大值========================================*/#define flush(arr, i) memset(arr, i, sizeof(arr))typedef long long int64;using namespace std;const int MAX_ITEM = 110;const int oo = 0x7fffffff;//const int oo = 0x3f3f3f3f;int dp[MAX_ITEM][MAX_ITEM], sum[MAX_ITEM][MAX_ITEM];int num[MAX_ITEM];void getSum(int len)&#123; flush(sum, 0); flush(dp, 0); for(int i = 1; i &lt;= len; i++) &#123; sum[i][i] = num[i]; for(int j = i + 1; j &lt;= len; j++) sum[i][j] = sum[i][j - 1] + num[j]; &#125;/* for(int i = 1; i &lt;= len; i++) for(int j = i; j &lt;= len; j++) j == len ? printf("%d\n", sum[i][j]) : printf("%d ", sum[i][j]);*/&#125;int DP(int k, int p)&#123; if(p == 0) &#123; dp[k][p] = sum[1][k]; return dp[k][p]; &#125; if(dp[k][p]) return dp[k][p]; int ans = 0; for(int i = p - 1; i &lt;= k - 1; i++) ans = max(ans, DP(i, p - 1) * sum[i + 1][k]); dp[k][p] = ans; return ans;&#125;int main()&#123; int len, p; while(scanf("%d%d", &amp;len, &amp;p) != EOF) &#123; for(int i = 1; i &lt;= len; i++) scanf("%d", num + i); getSum(len); printf("%d\n", DP(len, p)); &#125; return 0;&#125; 最大K乘积问题1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#include &lt;iostream&gt;#include &lt;sstream&gt;#include &lt;stdio.h&gt;#include &lt;algorithm&gt;#include &lt;string.h&gt;#include &lt;stack&gt;#include &lt;queue&gt;#include &lt;set&gt;#include &lt;math.h&gt;#include &lt;time.h&gt;/*=======================================最大k乘积问题dp[k][p] = max(dp[p - 1 ... k - 1][p - 1] * num[k][p])表示前i项分为j部分的最大乘积========================================*/#define flush(arr, i) memset(arr, i, sizeof(arr))typedef long long int64;using namespace std;const int MAX_ITEM = 110;const int oo = 0x7fffffff;//const int oo = 0x3f3f3f3f;int dp[MAX_ITEM][MAX_ITEM], num[MAX_ITEM][MAX_ITEM];char in[MAX_ITEM];int getNum(char *in)&#123; int len = strlen(in); flush(num, 0), flush(dp, 0); for(int i = 1; i &lt;= len; i++) &#123; int mul = 0; for(int j = i; j &lt;= len; j++) &#123; mul = mul * 10 + in[j - 1] - '0'; num[i][j] = mul; &#125; &#125;/* for(int i = 1; i &lt;= len; i++) for(int j = i; j &lt;= len; j++) j != len ? printf("%d ", num[i][j]) : printf("%d\n", num[i][j]);*/&#125;//前k个分为p部分int DP(int k, int p)&#123; if(p == 1) &#123; dp[k][p] = num[1][k]; return num[1][k]; &#125; if(dp[k][p]) return dp[k][p]; int ans = 0; for(int i = p - 1; i &lt;= k - 1; i++) ans = max(ans, DP(i, p - 1) * num[i + 1][k]); dp[k][p] = ans; return ans;&#125;int main()&#123; int p; while(scanf("%s", in) != EOF) &#123; getNum(in); scanf("%d", &amp;p); int len = strlen(in); printf("%d\n", DP(len, p)); &#125; return 0;&#125;]]></content>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[遇见ubuntu]]></title>
    <url>%2F2017%2F05%2F25%2Fmeeting-ubuntu%2F</url>
    <content type="text"><![CDATA[从认识Ubuntu到如今大概不到四年的时间。我记得第一次接触的时候，是在某君的宿舍，一个mentohust命令，将我拉进了Linux的世界。 第一个Ubuntu也是他帮我弄上的，从那之后的几个星期里，我几乎日夜不断的倒腾它，查配置，弄教程，软件装了卸，卸了装，单纯觉得有趣和神奇，每一次的终端操作，都伴随着紧张，期待与激动。后来因为AMD的显卡驱动问题，跑Ubuntu风扇转的不停，掉电太快，就直接在虚拟机上弄了。 一年前，正式转入Ubuntu工作环境。在台式机上，我个人没有什么娱乐需求，甚至连视频都不会看，最多刷刷新闻，听听歌曲。自从解决了QQ问题之后（DeepinQQ + wine，还是很美观的），从实际需求来看，Ubuntu完全满足我的条件了。 目前在乎如下装置： 默认terminal，Ubuntu Mono字体好看，好像也只有在它自己的终端下显示的才优美，换在Mac上都不行…… zsh，主题，插件很丰富，省的自己改bashrc了 JetBrains的Idea，Clion，AS，主题一律monikai，内建终端很方便，编辑器字体首选ubuntu家族的mono，和终端效果相似，其次Droids Sans。 VSCode，之前的Sublime输入不了中文，还有就是，前者免费。 Cmd Markdown，三大平台同步，只喜欢写Markdown，图方便。 Chrome，必备Adlock(Plus)，其他随意了 vimplus，airline要正常的话，从github上装个字体布丁，终端设置改一下就ok，高亮，补全美的不行 其他的细节的东西还有很多，记得再补充吧，对于桌面，下个unity-tweak-tools把主题改成Flatabulous，图标ultra-flat-icons，最重要的，桌面不要放文件夹! 网易云音乐起到这么个作用，干活的时候听听歌，貌似年末了，统计一下自己工作了多长时间&gt;_&lt;。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTK解码器部分代码走读]]></title>
    <url>%2F2017%2F05%2F24%2FHTK-decoder-analysis%2F</url>
    <content type="text"><![CDATA[本篇主要解析Token Passing算法实现的核心过程，主要是四个步奏，配合代码理解如下，最后一部分是词网络拓展，个人感觉复杂度大于解码过程，所以放在最后交代。 1. StartRecognition这部分需要做一些pri和vri的初始化工作，这两个值在前期的InitVRecInfo函数中已经做了更全面的初始化，之后对pri-&gt;net-&gt;initial附着一个实例，往后的解码过程实际上是一个bfs的过程，而AttachInst函数实际上是给pri-&gt;link这个双向链表加了初始的节点。之后的过程大体上是： 从链表中取节点进行节点内token算分，节点间token传递 不断从链表中剪枝，即拿掉不满足某种阈值条件的节点 12345678910111213pri-&gt;net-&gt;final.inst=pri-&gt;net-&gt;initial.inst=NULL;// store previous calculate resultesfor(i=1,pre=pri-&gt;psi-&gt;sPre+1;i&lt;=pri-&gt;psi-&gt;nsp;i++,pre++) pre-&gt;id=-1;for(i=1,pre=pri-&gt;psi-&gt;mPre+1;i&lt;=pri-&gt;psi-&gt;nmp;i++,pre++) pre-&gt;id=-1;/*tact: total active numberframe: current process frame id*/pri-&gt;tact=pri-&gt;nact=pri-&gt;frame=0;// attach a instance to the network entranceAttachInst(&amp;pri-&gt;net-&gt;initial); 节点含义需要搞清楚几个节点的含义，我的理解如下：12345678// n_hmm = 2: HMM 模型节点#define node_hmm(node) ((node)-&gt;type &amp; n_hmm)// n_word = 4: 词节点#define node_word(node) ((node)-&gt;type == n_word)// n_tr0 = 4: 一类特殊的点，貌似可以从start直接调到fin状态#define node_tr0(node) ((node)-&gt;type &amp; n_tr0)// n_wd0 = 1: 最后一个发音节点，如果是5状态的话，就是3节点#define node_wd0(node) ((node)-&gt;type &amp; n_wd0) 最重要的是词节点和模型节点【对音素HMM建模】，token passing算法实现时的多数操作集中在对俩类节点的操作。 AttachInst关于AttachInst函数，很重要的一个作用是对pri-&gt;head这个双向链表加入了初始节点：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990 TokenSet *cur; NetInst *inst; int i,n; inst=(NetInst*) New(&amp;pri-&gt;instHeap,0); // node-&gt;info.hmm-&gt;numState include entry and exit nodes // represent the HMM nodes if (node_hmm(node)) n=node-&gt;info.hmm-&gt;numStates-1; else n=1;// position of the instance in the networkinst-&gt;node=node;// tokenset in HMM non-exit statusinst-&gt;state=(TokenSet*) New(pri-&gt;stHeap+pri-&gt;psi-&gt;stHeapIdx[n],0);// tokenset in HMM exit statusinst-&gt;exit=(TokenSet*) New(pri-&gt;stHeap+pri-&gt;psi-&gt;stHeapIdx[1],0);// const Token null_token=&#123;LZERO, 0.0, NULL, NULL&#125;// 是要传递的token,初始化为空inst-&gt;exit-&gt;tok=null_token;// handle exit nodes// pri-&gt;nToks: maximum tokens to propagate// could be ignored：这一步不求N-best可以忽略if (pri-&gt;nToks&gt;1) &#123; // set: sorted tokens inst-&gt;exit-&gt;set=(RelToken*) New(&amp;pri-&gt;rTokHeap,0); // n: 0 == 1-best keep only one answer // 1 &gt;== N-best: keep N best answers inst-&gt;exit-&gt;n=1; inst-&gt;exit-&gt;set[0]=rmax;&#125;else &#123; // only need to transfer one token：表示1-best inst-&gt;exit-&gt;n=0;&#125;// initial each status nodes, same as exit node// 1 2 3 4for (i=1,cur=inst-&gt;state;i&lt;=n;i++,cur++) &#123; cur-&gt;tok=null_token; if (pri-&gt;nToks&gt;1) &#123; cur-&gt;set=(RelToken*) New(&amp;pri-&gt;rTokHeap,0); cur-&gt;n=1; cur-&gt;set[0]=rmax; &#125; else &#123; cur-&gt;n=0; &#125;&#125;// #define LZERO (-1.0E10) ~log(0)// to prune the likelihood// keep the max likelihood of the status：状态的最大可能值inst-&gt;max=LZERO;// instance: double link// pri-&gt;tail newest pri-&gt;head oldest// append new instance to the pri：拓展网络【实际是链表】// pri-&gt;link will be accessed out of this functioninst-&gt;link=&amp;pri-&gt;tail;inst-&gt;knil=pri-&gt;tail.knil;inst-&gt;link-&gt;knil=inst;inst-&gt;knil-&gt;link=inst;// attach instance to a nodenode-&gt;inst=inst;// Exit token reaches word node in t=0// the last phone nodeif (node_wd0(node)) // inst-&gt;wdlk: Max likelihood of t=0 path to word end node inst-&gt;wdlk=LikeToWord(inst-&gt;node);else inst-&gt;wdlk=LZERO;// num of active nodespri-&gt;nact++;/* New node needs any currently alive following insts moved *//* to be more recent than it to ensure tokens propagated in *//* correct order. */// out of orderinst-&gt;ooo=TRUE; /* Need keep list in propagation order */// move node and it's subsequence into the pri-&gt;linkReOrderList(node); ReOrderListReOrderList是一个DFS逻辑，将该节点的后续节点加入pri-&gt;head这个链表，注意，node-&gt;nlinks可能是1和n，如果是模型节点的话，只能为1，词节点则可能为n。这个函数作用应该是保证节点间token传递的顺序，代码逻辑如下： 123456789101112131415161718192021222324NetLink *dest;int i;// if ordered returnif (node-&gt;inst!=NULL?!node-&gt;inst-&gt;ooo:TRUE) return;// modify flagnode-&gt;inst-&gt;ooo=FALSE;// node-&gt;links: connected nodes// node-&gt;nlinks: num of connected nodes 1 or n[word nodes]for (i=0,dest=node-&gt;links;i&lt;node-&gt;nlinks;i++,dest++) &#123; // Entry token reaches exit in t = 0 if (!node_tr0(dest-&gt;node)) break; // if not NULL, many be added to the list again if (dest-&gt;node-&gt;inst!=NULL) // append to pti-&gt;tail MoveToRecent(dest-&gt;node-&gt;inst);&#125;// DFSfor (i=0,dest=node-&gt;links;i&lt;node-&gt;nlinks;i++,dest++) &#123; if (!node_tr0(dest-&gt;node)) break; if (dest-&gt;node-&gt;inst!=NULL) ReOrderList(dest-&gt;node);&#125; ReOrderList将存在的节点后继加入解码网络，之后继续对每一个存在节点进行DFS逻辑的搜索。 net-&gt;initial的初始化net-&gt;initial这个node是在ExpandWordNet函数中AddInitialFinal实现的，用于初始化表征解码网络的入口和出口initial和final，初始化initial节点如下【实际上该节点的后继是网络根节点的发音实例】：12345678910111213141516171819202122232425262728293031323334353637383940 PronHolder *pInst; NetNode *node; LNode *thisLNode; int ninitial = 0; int i,type; // for num of nodes // a node is a word for (i=0; i &lt; wnet-&gt;nn; i++) // find root node if (wnet-&gt;lnodes[i].pred == NULL) // each word may has multiple prons for (pInst=(PronHolder*)wnet-&gt;lnodes[i].sublat; pInst!=NULL;pInst=pInst-&gt;next) ninitial++; // ninitial: get how many prons // network init nodes net-&gt;initial.type = n_word; net-&gt;initial.tag = NULL; net-&gt;initial.info.pron = NULL; net-&gt;initial.nlinks = 0; net-&gt;initial.links = (NetLink *)New(net-&gt;heap,ninitial*sizeof(NetLink)); for (i=0,thisLNode=wnet-&gt;lnodes; i&lt;wnet-&gt;nn; i++,thisLNode++) &#123; // find root: initial nodes if (thisLNode-&gt;pred != NULL) continue; // node's pron for (pInst=(PronHolder*)thisLNode-&gt;sublat;pInst!=NULL;pInst=pInst-&gt;next) &#123; // Chain of initial models // 指向每一个发音的starts节点 if (xc==0) node=pInst-&gt;starts; else if (pInst-&gt;nphones!=0) node=pInst-&gt;lc[0]; else node=FindWordNode(NULL,pInst-&gt;pron,pInst,n_word); // modify nlinks and point links to the node net-&gt;initial.links[net-&gt;initial.nlinks].node = node; net-&gt;initial.links[net-&gt;initial.nlinks++].like = 0.0; &#125; &#125;// ... 实际上Lattice和Network之间是有一定的关系的，Lattice是最上层词网络拓扑，Lnode表征词节点，LArc表征词词之间的链接，每一个LNode可能会有多个发音，每一个发音建立一个PronHolder，这也是个链表结构，可以通过next寻访到下一个发音，其中有关模型节点的是下面三个结构体：1234NetNode *starts; /* Chain of initial models */NetNode *ends; /* Chain of final models */// point to status node, each node present a single phone modelNetNode *chain; /* Chain of other nodes in word */ 这三个结构和加入pri-&gt;head的实际上是同样的节点。都是模型节点。 执行完AttachInst之后，继续对该节点实例进行初始化，同时加入pri-&gt;head链表。接下来就可以进行token的传递算法了，那里面主要就是对该链表中的Netnode进行反复的节点内外的算分，传递和节点的剪枝，添加。AttachInst剩下的代码如下：12345678910111213141516171819202122232425262728293031// init initial node's instanceinst=pri-&gt;net-&gt;initial.inst;inst-&gt;state-&gt;tok.like=inst-&gt;max=0.0;inst-&gt;state-&gt;tok.lm=0.0;inst-&gt;state-&gt;tok.path=NULL;inst-&gt;state-&gt;n=((pri-&gt;nToks&gt;1)?1:0);vri-&gt;genMaxNode=vri-&gt;wordMaxNode=NULL;vri-&gt;genMaxTok=vri-&gt;wordMaxTok=null_token;// #define LSMALL (-0.5E10) log values &lt; LSMALL are set to LZEROpri-&gt;wordThresh=pri-&gt;genThresh=pri-&gt;nThresh=LSMALL;// Most likely node/word node in the networkpri-&gt;genMaxNode=pri-&gt;wordMaxNode=NULL;pri-&gt;genMaxTok=pri-&gt;wordMaxTok=null_token;// init pri-&gt;head in AttachInst(&amp;pri-&gt;net-&gt;initial)for (inst=pri-&gt;head.link;inst!=NULL &amp;&amp; inst-&gt;node!=NULL;inst=next) // inst-&gt;max: likelihood for pruning of instance // cutoff if (inst-&gt;max&lt;pri-&gt;genThresh) &#123; next=inst-&gt;link; DetachInst(inst-&gt;node); &#125; else &#123; pri-&gt;nxtInst=inst; // call SetEntryState and new instance, append to the pri-&gt;head StepInst2(inst-&gt;node); next=pri-&gt;nxtInst-&gt;link; &#125; 2. ProcessObservation该函数传入Observation，一帧一帧的处理观测序列首先进行必要的赋初值之后，根据链表中的活跃节点数目进行一个全局剪枝，因为是一帧一帧的处理，所以token只会向后传递一层。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253void ProcessObservation(VRecInfo *vri,Observation *obs,int id, AdaptXForm *xform)&#123; NetInst *inst,*next; int j; float thresh; // get private info pri=vri-&gt;pri; inXForm = xform; /* sepcifies the transform to use for this observation */ pri-&gt;psi-&gt;sBuf[1].n=((pri-&gt;nToks&gt;1)?1:0); /* Needed every observation */ // Current frame number pri-&gt;frame++; // Current Observation pri-&gt;obs=obs; if (id&lt;0) pri-&gt;id=(pri-&gt;prid&lt;&lt;20)+pri-&gt;frame; else pri-&gt;id=id; /* Max model pruning is done initially in a separate pass */ // vri-&gt;maxBeam: Maximum model instance beam // pri-&gt;nact: num of active nodes in dual links if (vri-&gt;maxBeam&gt;0 &amp;&amp; pri-&gt;nact&gt;vri-&gt;maxBeam) &#123; // qsn: quick sort num if (pri-&gt;nact&gt;pri-&gt;qsn) &#123; if (pri-&gt;qsn&gt;0) Dispose(&amp;vri-&gt;heap,pri-&gt;qsa); pri-&gt;qsn=(pri-&gt;nact*3)/2; pri-&gt;qsa=(LogFloat*) New(&amp;vri-&gt;heap,pri-&gt;qsn*sizeof(LogFloat)); &#125; // qsa: quick sort array // inst-&gt;max: Likelihood for pruning of instance for (inst=pri-&gt;head.link,j=0;inst!=NULL;inst=inst-&gt;link,j++) pri-&gt;qsa[j]=inst-&gt;max; // num of nodes in dual links more than maxBeam: cutoff if (j&gt;=vri-&gt;maxBeam) &#123; qcksrtM(pri-&gt;qsa,0,j-1,vri-&gt;maxBeam); thresh=pri-&gt;qsa[vri-&gt;maxBeam]; // start cutoff for the first time if (thresh&gt;LSMALL) for (inst=pri-&gt;head.link;inst-&gt;link!=NULL;inst=next) &#123; next=inst-&gt;link; if (inst-&gt;max&lt;thresh) DetachInst(inst-&gt;node); &#125; &#125; &#125; // ...&#125; 节点内传递之后就进行第一个token传递计算，在节点内部，执行完毕，更新maxToken和maxNode1234567891011121314// pri-&gt;genMaxTok: Most likely token// pri-&gt;wordMaxTok: Most likely word end token// update in StepInst1 in StepHMM1pri-&gt;genMaxTok=pri-&gt;wordMaxTok=null_token;pri-&gt;genMaxNode=pri-&gt;wordMaxNode=NULL;// nodes represent phonesfor (inst=pri-&gt;head.link,j=0;inst!=NULL;inst=inst-&gt;link,j++) if (inst-&gt;node) // stepHMM1 stepInst1 // calcu aij + bj(Ot) for each status in the node StepInst1(inst-&gt;node);//... StepInst1StepInst1做了一个分类，主要针对HMM模型节点：1234567891011121314static void StepInst1(NetNode *node) /* First pass of token propagation (Internal) */&#123; // model node if (node_hmm(node)) // inside a single node // calcu max possibility on each status j[1 &lt; j &lt; N] inside a node StepHMM1(node); /* Advance tokens within HMM instance t =&gt; t-1 */ /* Entry tokens valid for t-1, do states 2..N */ else StepWord1(node); node-&gt;inst-&gt;pxd=FALSE;&#125; StepHMM1计算在该节点内部token的传递，在状态节点之间的实现如下，对应的模型应该如图： StepHMM11234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889static void StepHMM1(NetNode *node)&#123; inst=node-&gt;inst; max=null_token; hmm=node-&gt;info.hmm; N=hmm-&gt;numStates; // transition matrix (logs) trP=hmm-&gt;transP; seIndex=pri-&gt;psi-&gt;seIndexes[hmm-&gt;tIdx]; // pri-&gt;psi-&gt;sBuf: Buffer Array[2..N-1] of tokset for StepHMM1_N // pri-&gt;psi-&gt;sBuf: public and each node use it, tmp var and copy back to current nodes // res: tmp buffer, previous calculate results // 2, 3, 4 // Emitting states first for (j=2,res=pri-&gt;psi-&gt;sBuf+2;j&lt;N;j++,res++) &#123; // res: tokenset of status j i=seIndex[j][0]; endi=seIndex[j][3]; // tokenset of status i // from i to endi // 这里为什么要减一有点奇怪 cur=inst-&gt;state+i-1; // res &lt;= cur res-&gt;tok=cur-&gt;tok; res-&gt;n=cur-&gt;n; for (k=0;k&lt;cur-&gt;n;k++) res-&gt;set[k]=cur-&gt;set[k]; // from status i skip to status j // init res to get maximum // tok.like: likelihood of the token res-&gt;tok.like+=trP[i][j]; // following except res // status + i =&gt; status + endi; for (i++,cur++;i&lt;=endi;i++,cur++) &#123; cmp.tok=cur-&gt;tok; // aij cmp.tok.like+=trP[i][j]; // res keep max: status j // keep best one if (res-&gt;n==0) &#123; if (cmp.tok.like &gt; res-&gt;tok.like) res-&gt;tok=cmp.tok; &#125; // don't consider else TokSetMerge(res,&amp;cmp.tok,cur); &#125; // pri-&gt;genThresh: Cutoff from global beam if (res-&gt;tok.like&gt;pri-&gt;genThresh) &#123; // State pruning // calcu bj(Ot) outp=cPOutP(pri-&gt;psi,pri-&gt;obs,hmm-&gt;svec[j].info,pri-&gt;id); res-&gt;tok.like+=outp; // update max status token // max: max aij + bj(Ot) if (res-&gt;tok.like&gt;max.like) max=res-&gt;tok; &#125; else &#123; res-&gt;tok=null_token; res-&gt;n=((pri-&gt;nToks&gt;1)?1:0); &#125; &#125; /* Null entry state ready for external propagation */ /* And copy tokens from buffer to instance */ // copy back for (i=1,res=pri-&gt;psi-&gt;sBuf+1,cur=inst-&gt;state; i&lt;N; i++,res++,cur++) &#123; cur-&gt;n=res-&gt;n; cur-&gt;tok=res-&gt;tok; for (k=0;k&lt;res-&gt;n;k++) cur-&gt;set[k]=res-&gt;set[k]; &#125; /* Set up pruning limits */ // max: max token in a single node: aij + bj(Ot) // update genMaxTok and genMaxNode if (max.like&gt;pri-&gt;genMaxTok.like) &#123; pri-&gt;genMaxTok=max; pri-&gt;genMaxNode=node; &#125; // max status likelihood in a single phone node inst-&gt;max=max.like;&#125; 使用图例可以表示为： 对于exit节点单独处理，处理逻辑和上面处理status节点类似，最后更新了exit节点的token值 1234567891011121314151617181920212223242526272829303132333435363738394041// Exit state (ignoring tee trP) // process exit status, don't need tmp vari=seIndex[N][0]; endi=seIndex[N][5]; // res pointed to the exit noderes=inst-&gt;exit;cur=inst-&gt;state+i-1;res-&gt;n=cur-&gt;n; res-&gt;tok=cur-&gt;tok; for (k=0;k&lt;cur-&gt;n;k++) res-&gt;set[k]=cur-&gt;set[k];res-&gt;tok.like+=trP[i][N];// update exit nodesfor (i++,cur++;i&lt;=endi;i++,cur++) &#123; cmp.tok=cur-&gt;tok; cmp.tok.like+=trP[i][N]; // get maximum token from i -&gt; endi if (res-&gt;n==0) &#123; if (cmp.tok.like &gt; res-&gt;tok.like) res-&gt;tok=cmp.tok; &#125; else TokSetMerge(res,&amp;cmp.tok,cur);&#125;if (res-&gt;tok.like&gt;LSMALL) &#123; // inst-&gt;wdlk: Max likelihood of t=0 path to word end node tok.like=res-&gt;tok.like+inst-&gt;wdlk; // update pri-&gt;wordMaxTok.like if (tok.like &gt; pri-&gt;wordMaxTok.like) &#123; pri-&gt;wordMaxTok=tok; pri-&gt;wordMaxNode=node; &#125;&#125; else &#123; inst-&gt;exit-&gt;tok=null_token; inst-&gt;exit-&gt;n=((pri-&gt;nToks&gt;1)?1:0);&#125; 以上是StepHMM1函数，它实现的是计算一个节点内部2，3，4，exit音素节点在当前观测序列下最大的可能值。在此期间更新的值有如下：12inst-&gt;max: 当前节点上实例中每个状态节点的最大like值pri-&gt;wordMaxNode: 最可能的此节点值 path和align分别对应词级别间的回溯路径和状态级别的回溯路径，只有前者是必要的。上述代码中align这部分已经删除。而path信息则在节点间传递时维护。 节点间传递ProcessObservation函数下面的部分进行节点之间的token传递，实现如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// #define LSMALL (-0.5E10) log values &lt; LSMALL are set to LZERO// update in StepHMM1// vri-&gt;wordBeam: Separte word end beam width// pri-&gt;wordThresh: Cutoff for word end propagation// after StepHMM1, use results to update some global beampri-&gt;wordThresh=pri-&gt;wordMaxTok.like-vri-&gt;wordBeam;if (pri-&gt;wordThresh&lt;LSMALL) pri-&gt;wordThresh=LSMALL;// pri-&gt;genMaxTok.like update in StepHMM1// vri-&gt;genBeam: Global beam width// pri-&gt;genThresh: Cutoff from global beampri-&gt;genThresh=pri-&gt;genMaxTok.like-vri-&gt;genBeam;if (pri-&gt;genThresh&lt;LSMALL) pri-&gt;genThresh=LSMALL;if (pri-&gt;nToks&gt;1) &#123; // vri-&gt;nBeam: Beam width for non-best tokens pri-&gt;nThresh=pri-&gt;genMaxTok.like-vri-&gt;nBeam; if (pri-&gt;nThresh&lt;LSMALL/2) pri-&gt;nThresh=LSMALL/2;&#125; /* Pass 2 Performs external token propagation and pruning */for (inst=pri-&gt;head.link,j=0;inst!=NULL &amp;&amp; inst-&gt;node!=NULL;inst=next,j++) if (inst-&gt;max&lt;pri-&gt;genThresh) &#123; next=inst-&gt;link; // remove from inst list DetachInst(inst-&gt;node); &#125; else &#123; pri-&gt;nxtInst=inst; // call SetEntryState // add new instance to pri-&gt;tail and reorder it StepInst2(inst-&gt;node); next=pri-&gt;nxtInst-&gt;link; &#125; // npth: Current number of path records// cpth: Number of path records after last collection// nalign: Current number of align records// caligh: Number of align records after last collection// wait for the time to collect pathif ((pri-&gt;npth-pri-&gt;cpth) &gt; vri-&gt;pCollThresh || (pri-&gt;nalign-pri-&gt;calign) &gt; vri-&gt;aCollThresh) CollectPaths(); // pri-&gt;tact: total active nodespri-&gt;tact+=pri-&gt;nact;// updatevri-&gt;frame=pri-&gt;frame;vri-&gt;nact=pri-&gt;nact;vri-&gt;genMaxNode=pri-&gt;genMaxNode;vri-&gt;wordMaxNode=pri-&gt;wordMaxNode;vri-&gt;genMaxTok=pri-&gt;genMaxTok;vri-&gt;wordMaxTok=pri-&gt;wordMaxTok; StepInst2StepInst2是对pri-&gt;head链表进行扩展的部分，类似BFS的逻辑在这里实现,还实现了节点之间的token传递1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/* Second pass of token propagation (External) */static void StepInst2(NetNode *node) /* Must be able to survive doing this twice !! */&#123; Token tok; TokenSet xtok; RelToken rtoks[MAX_TOKS]; NetLink *dest; LogFloat lm; int i,k; // == 4 // word end node if (node_word(node)) // P(O) = argmax P(O|W) + LMSF * logP(W) + N * logWIP // add path // inst-&gt;exit-&gt;tok.like // calcu LMSF * logP(W) + N * logWIP and create path // 为当前节点的exit节点建立索引path，该path的prev指向该节点start的索引path，而这个start节点的索引path实际上在SetEntryState被初始化为上一个节点的exit状态的索引path StepWord2(node); /* Merge tokens and update traceback */ // &amp; 4 else if (node_tr0(node) /* &amp;&amp; node_hmm(node) */ // calcu exit status node: 这是个十分特殊的节点 StepHMM2(node); // xtok: node-&gt;inst-&gt;exit // xtok init by node-&gt;inst-&gt;exit // hmm nodes // get exit node's token // 当前音素节点中exit节点的token信息被记录下来了，不管节点类型 // token里面有path和分数信息 tok=node-&gt;inst-&gt;exit-&gt;tok; xtok.tok=tok; xtok.n=node-&gt;inst-&gt;exit-&gt;n; // new RelToken sets xtok.set=rtoks; for (k=0;k&lt;xtok.n;k++) xtok.set[k]=node-&gt;inst-&gt;exit-&gt;set[k]; if (node_word(node)) if (tok.like&lt;pri-&gt;wordThresh) tok=null_token; // ok // tok: exit node if (tok.like&gt;pri-&gt;genThresh) &#123; // connected nodes // words node has many：词节点有多个后继 // hmm has only one：模型节点只有一个，符合常识，如果是模型节点，则相当于把token传递给了之后的那个节点，下一次可以被寻访到 // pass token to next nodes[model nodes] for(i=0,dest=node-&gt;links;i&lt;node-&gt;nlinks;i++,dest++) &#123; // transition likelihood lm=dest-&gt;like; // pri-&gt;scale: LM (Net probs) scale factor xtok.tok.like=tok.like+lm*pri-&gt;scale; // tok.lm: LM likelihood of token xtok.tok.lm=tok.lm+lm; for (k=0;k&lt;xtok.n;k++) xtok.set[k].lm=node-&gt;inst-&gt;exit-&gt;set[k].lm+lm; // pri-&gt;genThresh: Cutoff from global beam if (xtok.tok.like&gt;pri-&gt;genThresh) &#123; // call AttachInst(node) // expand network // pass exit token to dest-&gt;nodes =&gt; xtok SetEntryState(dest-&gt;nodes, &amp;xtok); /* Transfer set of tokens to node, activating when necessary */ /* choosing N most likely after adding transition likelihood */ &#125; &#125; &#125; node-&gt;inst-&gt;pxd=TRUE;&#125; StepWord2StepWord2处理词节点，用新建的path更新inst-&gt;exit-&gt;tok.path，它的prev记录为inst-&gt;state-&gt;tok.path，这个值被前一个节点的inst-&gt;exit-&gt;tok.path初始化，在StepWord2中123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657NetInst *inst;Path *newpth,*oldpth;RelToken *cur;NxtPath *rth;int i,k;inst=node-&gt;inst;// info.pron == NULL ?if (node-&gt;info.pron==NULL &amp;&amp; node-&gt;tag==NULL) &#123; inst-&gt;exit-&gt;tok=inst-&gt;state-&gt;tok; inst-&gt;exit-&gt;n=inst-&gt;state-&gt;n; for (k=0;k&lt;inst-&gt;exit-&gt;n;k++) inst-&gt;exit-&gt;set[k]=inst-&gt;state-&gt;set[k];&#125;else &#123; inst-&gt;exit-&gt;tok=inst-&gt;state-&gt;tok; if (node-&gt;info.pron!=NULL) &#123; // pri-&gt;wordpen: word penity inst-&gt;exit-&gt;tok.like+=pri-&gt;wordpen; // node-&gt;info.pron-&gt;prob: Log probability of pronunciation // pri-&gt;pscale: LM (Net probs) scale factor inst-&gt;exit-&gt;tok.like+=node-&gt;info.pron-&gt;prob * pri-&gt;pscale; // P(O) = argmax P(O|W) + LMSF * logP(W) + N * logWIP &#125; // append new path to pNoRef // path-&gt;chain = NULL // path-&gt;used = FALSE // new path only in word node and pass the path info in StepInst2 when extend pri-&gt;head newpth=NewNRefPath(); // point to the node newpth-&gt;node=node; // ref times == 0 newpth-&gt;usage=0; newpth-&gt;frame=pri-&gt;frame; newpth-&gt;like=inst-&gt;exit-&gt;tok.like; newpth-&gt;lm=inst-&gt;exit-&gt;tok.lm; // not run here if ((newpth-&gt;align=inst-&gt;exit-&gt;tok.align)!=NULL) // MoveAlignYesRef(align) RefAlign(newpth-&gt;align); // assign to exit node and newpath could pass to next nodes by exit-&gt;token inst-&gt;exit-&gt;tok.path=newpth; inst-&gt;exit-&gt;tok.lm=0.0; inst-&gt;exit-&gt;tok.align=NULL; // assign position: in SetEntryState // inst-&gt;state: start status oldpth=inst-&gt;state-&gt;tok.path; // oldpth != NULL if ((newpth-&gt;prev=oldpth)!=NULL) // if usage == 0 MovePathYesRef(path) =&gt; append pYesRef // and then usage++ RefPath(oldpth); 搞清楚path相关的一些问题，些直接关系到解码最后一步的搜索。首先，只有在进行token的外部传递，即处理词节点时才会新建path变量，记录回溯路径，函数NewNRefPath仅仅在StepInst2 =&gt; StepWord2用到。StepWord2函数执行完毕之后，紧接着在StepInst2后半部分执行SetEntryState，path信息伴随着xtok进入了下一个新的节点。 SetEntryStateSetEntryState为当前节点附上一个实例，同时传入上一个词的token，如此token即可在网络中传递了，token中包含上一个节点的路径和分值。1234567891011121314151617181920212223242526272829303132333435// attach instance to the connected nodes// SetEntryState(dest-&gt;node,&amp;xtok)// node: connected next node// src: contains token and path info： 记录前一个节点的tokenstatic void SetEntryState(NetNode *node,TokenSet *src)&#123; NetInst *inst; TokenSet *res; if (node-&gt;inst==NULL) // append to pri-&gt;tail // call ReOrderList(node) AttachInst(node); inst=node-&gt;inst; res=inst-&gt;state; // update instance's token if (res-&gt;n==0) &#123; // path info assigned: inst-&gt;state-&gt;tok.path if (src-&gt;tok.like &gt; res-&gt;tok.like) res-&gt;tok=src-&gt;tok; &#125; else TokSetMerge(res,&amp;src-&gt;tok,src); // inst-&gt;max: Likelihood for pruning of instance if (res-&gt;tok.like&gt;inst-&gt;max) inst-&gt;max=res-&gt;tok.like; if (node-&gt;type==n_word &amp;&amp; (pri-&gt;wordMaxNode==NULL || pri-&gt;wordMaxNode-&gt;inst==NULL || res-&gt;tok.like &gt; pri-&gt;wordMaxNode-&gt;inst-&gt;max)) // Most likely word end node in network pri-&gt;wordMaxNode=node;&#125; 现在path可以由下图表示逻辑 CollectPaths最后一步，定时整理之前维护的path信息，实现在CollectPaths之中，有些执行的部分已经删除，这一部分还有些疑惑。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364static void CollectPaths(void)&#123; NetInst *inst; TokenSet *cur; int i,k,n; Path *path,*plink; Align *align,*alink; // for each status in each inst in the pri-&gt;head // modify path-&gt;used: in current inst link for (inst=pri-&gt;head.link;inst!=NULL;inst=inst-&gt;link) if (inst-&gt;node!=NULL) &#123; // only model nodes have multiple status if (node_hmm(inst-&gt;node)) n=inst-&gt;node-&gt;info.hmm-&gt;numStates-1; else n=1; // n: status num // each status for (i=1,cur=inst-&gt;state;i&lt;=n;i++,cur++) &#123; path=cur-&gt;tok.path; // path-&gt;used: Reference to struct by current inst // not refered in order to avoid duplicate if (path &amp;&amp; !path-&gt;used) &#123; if (path-&gt;usage!=0) MovePathYesRef(path); path-&gt;used=TRUE; &#125; &#125; // exit node path=inst-&gt;exit-&gt;tok.path; if (path &amp;&amp; !path-&gt;used) &#123; if (path-&gt;usage!=0) MovePathYesRef(path); path-&gt;used=TRUE; &#125; &#125; // if no refer, could be deleted for (path=pri-&gt;pNoRef.link;path-&gt;link!=NULL;path=plink) &#123; // not in pri-&gt;head if (!path-&gt;used) &#123; // not run here if (path-&gt;align!=NULL) DeRefAlign(path-&gt;align); // minus path-&gt;prev-&gt;prev-&gt;usage // if == 0 add path-&gt;prev-&gt;prev to pNoRef DeRefPathPrev(path); plink=path-&gt;link; // delete path UnlinkPath(path); &#125; // in pri-&gt;head else &#123; path-&gt;used=FALSE; plink=path-&gt;link; &#125; &#125; for (path=pri-&gt;pYesRef.link;path-&gt;link!=NULL;path=path-&gt;link) &#123; if (!path-&gt;used) break; path-&gt;used=FALSE; &#125; pri-&gt;cpth=pri-&gt;npth; pri-&gt;calign=pri-&gt;nalign;&#125; 以上部分是处理观察序列的主要步骤。 3. CompleteRecognition这部分主要是返回一个Lattice【执行下面这段代码】，同时重置pri这个结构体，为之后的transcript做准备。1CreateLattice(heap,pri-&gt;net-&gt;final.inst-&gt;exit,vri-&gt;frameDur)； 该函数实现如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152static Lattice *CreateLattice(MemHeap *heap,TokenSet *res,HTime framedur)&#123; Lattice *lat; RelToken *cur; Path path; WordPron pron; NxtPath rth[MAX_TOKS]; int nn,nl,ln,i; NetNode node; pron.word=NULL;pron.pnum=0;pron.next=NULL; pron.outSym=NULL;pron.phones=NULL;pron.nphones=0; pron.prob=0.0; path.like=res-&gt;tok.like; path.lm=res-&gt;tok.lm; path.usage=0; path.align=res-&gt;tok.align; path.node=&amp;node; path.node-&gt;tag=NULL; path.node-&gt;info.pron=&amp;pron; path.frame=pri-&gt;frame; path.prev=res-&gt;tok.path; path.chain=NULL; // nn: num of nodes // nl: num of arcs nn=1;nl=0;ln=0; // dfs // modify usage, coding nn, nl MarkPaths(&amp;path,&amp;nn,&amp;nl); // single lattice // lat-&gt;lnodes = new LNode(nn) lat=NewLattice(heap,nn,nl); lat-&gt;voc=pri-&gt;net-&gt;vocab; lat-&gt;lmscale=pri-&gt;scale; lat-&gt;wdpenalty=pri-&gt;wordpen; lat-&gt;prscale=pri-&gt;pscale; lat-&gt;framedur=framedur; // Time of word boundary at node // Word represented by arc // lnodes: Array of lattice nodes lat-&gt;lnodes[0].time=0.0; lat-&gt;lnodes[0].word=NULL; lat-&gt;lnodes[0].tag=NULL; lat-&gt;lnodes[0].score=0.0; LatFromPaths(&amp;path,&amp;ln,lat); return(lat);&#125; MarkPaths函数主要用来在回溯的过程中给path的usage编号，这将会在之后的执行中用到。该函数执行完毕之后，得出的nn和nl为node个数和弧的个数1234567891011121314151617181920/* Number/count nodes (in path-&gt;usage field) and count links */// nn = 1, nl = 0;// modify usagestatic void MarkPaths(Path *path,int *nn,int *nl)&#123; NxtPath *pth; // path-&gt;usage: Times struct ref'd (by next path) if (path-&gt;usage&gt;=0) &#123; // minus path-&gt;usage=-(*nn)++; (*nl)++; if (path-&gt;prev) MarkPaths(path-&gt;prev,nn,nl); // may not run for (pth=path-&gt;chain;pth!=NULL;pth=pth-&gt;chain) &#123; (*nl)++; if (pth-&gt;prev) MarkPaths(pth-&gt;prev,nn,nl); &#125; &#125;&#125; 最主要的函数是LatFromPaths，它将path信息整合到Lattice之中，为最后的TranscriptionFromLattice做准备。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110// ln = 0;// fill lattice from path infostatic void LatFromPaths(Path *path,int *ln,Lattice *lat)&#123; LNode *ne,*ns; LArc *la; // point Word nullwordId; NxtPath tmp,*pth; Align *align,*al,*pr; MLink ml; LabId labid,splabid,labpr = NULL; char buf[80]; int i,frame; double prlk,dur,like,wp; // get id of NULL word nullwordId = GetWord(lat-&gt;voc,GetLabId("!NULL",FALSE),FALSE); // SP: "sp" splabid = GetLabId(SP,FALSE); // tmp &lt;= path // path-&gt;prev: Previous word record tmp.prev=path-&gt;prev; tmp.like=path-&gt;like; // path-&gt;chain: Next of NBest Paths tmp.chain=path-&gt;chain; tmp.lm=path-&gt;lm; // ne: LNode end // why substract? // path-&gt;usage lower than zero // assign ne and init ne ne=lat-&gt;lnodes-path-&gt;usage; // path-&gt;frame: Time (frame) of boundary (end of word) // lat-&gt;framedur: Frame duration in 100ns units // ne-&gt;time: Time of word boundary at node ne-&gt;time=path-&gt;frame*lat-&gt;framedur; // path-&gt;node: Word level traceback info if (path-&gt;node-&gt;info.pron != NULL) ne-&gt;word=path-&gt;node-&gt;info.pron-&gt;word; else ne-&gt;word=nullwordId; ne-&gt;tag=path-&gt;node-&gt;tag; // ne-&gt;v: Pronunciation variant number if (path-&gt;node-&gt;info.pron != NULL) ne-&gt;v=path-&gt;node-&gt;info.pron-&gt;pnum; else ne-&gt;v=1; ne-&gt;score=path-&gt;like; align=path-&gt;align; // pth-&gt;chain: Next of NBest Paths // ln == 0; for(pth=&amp;tmp;pth!=NULL;pth=pth-&gt;chain) &#123; // arcs // ln inited by 0 // modify lat-&gt;larcs // ln++ after get la la=lat-&gt;larcs+(*ln)++; // ns: node start if (pth-&gt;prev) &#123; ns=lat-&gt;lnodes-pth-&gt;prev-&gt;usage,prlk=pth-&gt;prev-&gt;like; &#125; else &#123; ns=lat-&gt;lnodes, prlk=0.0; &#125; // la-&gt;start: Node at start of word: pointer la-&gt;start=ns;la-&gt;end=ne; // wp: word penalty if (ne-&gt;word==NULL || ne-&gt;word==nullwordId) /* no word or NULL node */ wp=0.0; /* No penalty for current word */ else wp=pri-&gt;wordpen; /* Inc penalty for current word */ // la-&gt;aclike: Acoustic likelihood of word la-&gt;aclike=pth-&gt;like-prlk-pth-&gt;lm*pri-&gt;scale-wp; // la-&gt;prlike: Pronunciation likelihood of arc if (path-&gt;node-&gt;info.pron != NULL) &#123; la-&gt;aclike-=path-&gt;node-&gt;info.pron-&gt;prob*pri-&gt;pscale; la-&gt;prlike=path-&gt;node-&gt;info.pron-&gt;prob; &#125; else la-&gt;prlike=0.0; // Language model likelihood of word la-&gt;lmlike=pth-&gt;lm; // Field used for pruning/sorting la-&gt;score=pth-&gt;like; // la-&gt;farc: Next arc following start node // la-&gt;parc: Next arc preceding end node // ns-&gt;foll: Linked list of arcs following node // ne-&gt;pred: Linked list of arcs preceding node la-&gt;farc=ns-&gt;foll;la-&gt;parc=ne-&gt;pred; ns-&gt;foll=ne-&gt;pred=la; // forword search if (pth-&gt;prev!=NULL &amp;&amp; ns-&gt;word==NULL) LatFromPaths(pth-&gt;prev,ln,lat); &#125;&#125; 4. TranscriptionFromLattice这里通过一个A*搜索算法，在上一步骤填充的Lattice拓扑网络中搜索出来一个最优解或者多个，这里只讨论最优解。先看搜索前的处理部分:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970// get best N ans, suppose N = 1ans=(NBestEntry**) New(&amp;gstack,sizeof(NBestEntry*)*N);ans--;// through num of nodesfor (i=0,ln=lat-&gt;lnodes;i&lt;lat-&gt;nn;i++,ln++) &#123; // ln-&gt;foll: following arcs of the nodes // leaf node? if (ln-&gt;foll==NULL) ln-&gt;score=0.0; // ~log(0): -oo else ln-&gt;score=LZERO; // sorted order init all by -1 ln-&gt;n=-1;&#125;n=0;for (i=0,ln=lat-&gt;lnodes;i&lt;lat-&gt;nn;i++,ln++) // not ordered: 没有被排序过 if (ln-&gt;n==-1) /* // nn = 0; num of nodes static void MarkBack(LNode *ln,int *nn) &#123; LArc *la; // modify flag ln-&gt;n=-2; // node ln's previous linked nodes for (la=ln-&gt;pred;la!=NULL;la=la-&gt;parc) // == 1: new node if (la-&gt;start-&gt;n==-1) MarkBack(la-&gt;start,nn); ln-&gt;n=(*nn)++; &#125; */ MarkBack(ln,&amp;n);// n: num of nodes// ln-&gt;n: id of nodes by DFSorder=(int*) New(&amp;gstack, sizeof(int)*lat-&gt;nn);// id in the net mapped to the position in the lnodes// id =&gt; posfor (i=0,ln=lat-&gt;lnodes;i&lt;lat-&gt;nn;i++,ln++) order[ln-&gt;n]=i;// backtrack order// 注意每个节点的score来源/* 5 / \ 1 4 / / \ 0 2 3*/for (i=lat-&gt;nn-1;i&gt;0;i--) &#123; // get the node of position of i in the net ln=lat-&gt;lnodes+order[i]; // get max la-&gt;start-&gt;score // arcs from node: 从该节点出发的弧？ for (la=ln-&gt;pred;la!=NULL;la=la-&gt;parc) &#123; // LArcTotLike: kinds of factor, like, scalar multiplx together in a arcs score=ln-&gt;score+LArcTotLike(lat,la); // update la-&gt;start-&gt;score if (score&gt;la-&gt;start-&gt;score) la-&gt;start-&gt;score=score; &#125;&#125;Dispose(&amp;gstack,order);// ... 之后使用AStar算法搜索出一个最优解，维护一个递增队列，不断的取出头节点，push满足条件的后继到这个队列之中，直至队列为空。这里的队列由双向链表实现，根据score排序。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879// init head and tail// 搜索队列 small =&gt; greathead.link=&amp;tail;head.knil=NULL;tail.link=NULL;tail.knil=&amp;head;tail.score=head.score=LZERO;// all the node in the latticefor (i=0,ln=lat-&gt;lnodes;i&lt;lat-&gt;nn;i++,ln++) &#123; // find root if (ln-&gt;pred!=NULL) continue; // arcs after/pointed to node for (la=ln-&gt;foll;la!=NULL;la=la-&gt;farc) &#123; like=LArcTotLike(lat,la); score=like+la-&gt;end-&gt;score; if (score&lt;LSMALL) continue; // new entity newNBE=(NBestEntry*) New(&amp;gstack,sizeof(NBestEntry)); newNBE-&gt;score=score; newNBE-&gt;like=like; newNBE-&gt;lnode=la-&gt;end; newNBE-&gt;larc=la; newNBE-&gt;prev=NULL; // score: from small to large for (pos=head.link;score&lt;pos-&gt;score;pos=pos-&gt;link); // insert into OPEN link newNBE-&gt;knil=pos-&gt;knil;newNBE-&gt;link=pos; newNBE-&gt;knil-&gt;link=newNBE-&gt;link-&gt;knil=newNBE; &#125;&#125; // from small to large// equal to while(1)for (n=0,best=head.link;n&lt;N &amp;&amp; best!=&amp;tail;best=head.link) &#123; // search until linklist is empty if (head.link==&amp;tail) break; // delete from linklist best=head.link; best-&gt;link-&gt;knil=best-&gt;knil; best-&gt;knil-&gt;link=best-&gt;link; nent--; if (best-&gt;lnode-&gt;foll!=NULL) &#123; nexp++; for (la=best-&gt;lnode-&gt;foll;la!=NULL;la=la-&gt;farc) &#123; // like: like on arcs like=best-&gt;like+LArcTotLike(lat,la); // like plus nodes score score=like+la-&gt;end-&gt;score; if (score&lt;LSMALL) continue; newNBE=(NBestEntry*) New(&amp;gstack,sizeof(NBestEntry)); newNBE-&gt;score=score; newNBE-&gt;like=like; newNBE-&gt;lnode=la-&gt;end; newNBE-&gt;larc=la; newNBE-&gt;prev=best; // add to the linklist for (pos=head.link;score&lt;pos-&gt;score;pos=pos-&gt;link); newNBE-&gt;knil=pos-&gt;knil;newNBE-&gt;link=pos; newNBE-&gt;knil-&gt;link=newNBE-&gt;link-&gt;knil=newNBE; nent++; &#125; continue; &#125; // must be different from previous // one time get an ans // first time n == 0; for (i=1;i&lt;=n;i++) if (WordMatch(best,ans[i])) &#123; best=NULL; break; &#125; if (best!=NULL) &#123; ans[++n]=best; &#125;&#125; 5. 补充：ExpandWordNet该函数返回一个Network结构体，用于后续的解码过程，做的是词网络拓展。调用如下：12// wdNet: Latticenet = ExpandWordNet(&amp;netHeap,wdNet,&amp;vocab,&amp;hset); Lattice通过词网络文件读入内存组织为该结构体：1wdNet = ReadLattice(nf,&amp;netHeap,&amp;vocab,TRUE,FALSE) 先说ReadLattice函数：是通过调用ReadOneLattice来返回Lattice的：12345678910111213141516171819202122232425262728293031323334353637383940414243Lattice *ReadLattice(FILE *file, MemHeap *heap, Vocab *voc, Boolean shortArc, Boolean add2Dict)&#123; Lattice *lat,*list,*fLat; Source source; AttachSource(file,&amp;source); if((lat=ReadOneLattice(&amp;source,heap,voc,shortArc,add2Dict))==NULL) return NULL; // has other lattice if (lat-&gt;subLatId!=NULL) &#123; /* Need to preserve first lattice to return */ // fLat: first Lattice fLat=lat; lat = (Lattice *) New(heap,sizeof(Lattice)); *lat=*fLat; // fLat keep previous one // lat init as previous one do &#123; /* Add SUBLAT to hash table for later lookup */ // add lat into the hash table named subLatId GetSubLat(lat-&gt;subLatId,lat); if((lat=ReadOneLattice(&amp;source,heap,voc,shortArc,add2Dict))==NULL) &#123; Dispose(heap, fLat); /*fLat points to 1st thing on heap*/ return NULL; &#125; &#125;while(lat-&gt;subLatId!=NULL); /* Clear hash table */ GetSubLat(NULL,NULL); /* Set all chain fields to NULL */ lat-&gt;chain=NULL; SubLatList(lat,NULL,1); /* Set chain fields to make linked list */ lat-&gt;chain=lat; list=SubLatList(lat,lat,1); /* Disconnect loop */ list-&gt;chain=NULL; /* Copy last to first Lattices to ensure lat is first thing on stack */ *fLat=*lat; lat=fLat; &#125; return(lat);&#125; 这个函数的简单逻辑应该是如果有多个词网络文件，多次读取否则只读一次。 ReadOneLattice函数是对词网络文件的信息包装到Lattice结构中，包含节点，弧的信息和链接关系以及一些权值，系数的初始化。节点和弧的定义分别为LNode和LArc。他们之间的关系如上下图所示： 函数对Lattice的初始化如下：12345678la-&gt;start=lat-&gt;lnodes+s;la-&gt;end=lat-&gt;lnodes+e;la-&gt;lmlike=lmlike;la-&gt;farc=la-&gt;start-&gt;foll;la-&gt;parc=la-&gt;end-&gt;pred;la-&gt;start-&gt;foll=la;la-&gt;end-&gt;pred=la; 下面就进行词网络拓展部分了，这部分主要是根据文件的配置信息决定如何做音素级别的拓展，因为之前的Lattice只是最上层的词网络，节点表示词，边表示转换关系，还没有发音和HMM模型，这些信息都是在最终解码之前需要的，所以网络需要一步一步的充实。 InitPronHolders首先为了引入发音信息，引入一个PronHolder的结构体，做一个初始化。1234/* First create context arrays and pronunciation instances */// frcSil: global string// net: new networkint nNull = InitPronHolders(net,lat,hci,voc,&amp;holderHeap,frcSil); 首先需要对!NULL做处理，如果是真的空节点，创建一个空的发音实例，否则不做此操作。123456789101112131415161718192021222324252627282930313233343536373839404142 /* Reset hash table prior to processing lattice */ // wnHashTab: NetNode for (i=0; i&lt;WNHASHSIZE; i++) wnHashTab[i]=NULL; /* Determine if we have a real !NULL word */ // nullWord: Word for output when word==NULL net-&gt;nullWord = GetWord(voc,GetLabId("!NULL", TRUE),TRUE); // next: Next pronunciation of word // a word can have kinds of pronunciations for (thisPron=net-&gt;nullWord-&gt;pron;thisPron!=NULL;thisPron=thisPron-&gt;next) // not real NULL word if (thisPron-&gt;nphones!=0) &#123; net-&gt;nullWord=NULL; break; &#125; // nullword without pron // real !NULL word if (net-&gt;nullWord!=NULL) &#123; if (net-&gt;nullWord-&gt;pron==NULL) // add a pron to a given word NewPron(voc,net-&gt;nullWord,0,NULL,net-&gt;nullWord-&gt;wordName,1.0);&#125; // frcSil: Automagically add these sil models to the end of words // confusion: 这部分搞不懂 if (frcSil!=NULL &amp;&amp; strlen(frcSil)&gt;0) &#123; for(nSil=nAdd=0,ptr=frcSil;ptr!=NULL;ptr=nxt) &#123; // finish if ((nxt=ParseString(ptr,name))==NULL) break; if (name[0]=='+' || name[0]=='-') st=name[0],p=name+1; else st=0,p=name; if (strlen(p)==0) labid=NULL; else labid=GetLabId(p,TRUE); if (st=='+' || st==0) addPhones[++nAdd]=labid; if (st=='-' || st==0) silPhones[++nSil]=labid; &#125;&#125;else nSil=nAdd=0; 接下来初始化节点的剪枝信息，有些地方可能不被执行123456789101112131415161718192021222324252627// num of nodesfor (i=0; i&lt;lat-&gt;nn; i++) &#123; float fct; LArc *la; // current node thisLNode = lat-&gt;lnodes+i; fct = 0.0; // factor lm likelihoods throughout words // default: false， may not run if (factorLM &amp;&amp; thisLNode-&gt;pred!=NULL) for (la=thisLNode-&gt;pred,fct=LZERO;la!=NULL;la=la-&gt;parc) if (la-&gt;lmlike&gt;fct) fct=la-&gt;lmlike; // max item in arcs which pointed to itself // Field used for pruning thisLNode-&gt;score = fct;&#125;// factorLM: factor lm likelihoods throughout wordsif (factorLM)for (i=0; i&lt;lat-&gt;na; i++) &#123; LArc *la; // current arcs la=NumbLArc(lat,i); la-&gt;lmlike-=la-&gt;end-&gt;score;&#125;// ... 下面是最重要的部分，为Lattice中的每个节点创建发音实例，一个词的发音可以有多个。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124 /* Create instance for each pronunciation in lattice */ for (i=0,nNull=0,t=0; i &lt; lat-&gt;nn; i++) &#123; // current node in lattice thisLNode = lat-&gt;lnodes+i; // the word that the word represent // init in ReadOneLattice by GetWordId thisWord = thisLNode-&gt;word; // replace by NULL word if (thisWord==NULL) thisWord=voc-&gt;nullWord; thisLNode-&gt;sublat=NULL; // nAdd: get from frcSil, may be 0 pii=(PInstInfo *) New(&amp;gstack,(thisWord-&gt;nprons+1)*(nAdd+1)*sizeof(PInstInfo)); pii--; /* Scan current pronunciations and make modified ones */ // thisWord-&gt;pron init in ReadOneLattice // for each pron in a single word for (j=1,thisPron=thisWord-&gt;pron,npii=0; thisPron!=NULL; j++,thisPron=thisPron-&gt;next) &#123; if (thisPron-&gt;nphones==0) n=0; else // for each phones // n inited by thisPron-&gt;nphones for (k=1,n=thisPron-&gt;nphones;k&lt;=nSil;k++) // each phone end with sil? if (thisPron-&gt;phones[thisPron-&gt;nphones-1]==silPhones[k]) &#123; /* Strip it */ n--;break; &#125; // n: non-sil phones if (thisPron-&gt;nphones==0 || nAdd==0 || n==0) &#123; /* Just need one pronunciation */ // !NULL one if (thisPron-&gt;nphones==0) &#123; nNull++; &#125; if (n==0) n=thisPron-&gt;nphones; pii[++npii].pron=thisPron; pii[npii].silId=-1; pii[npii].n=n;pii[npii].t=n; pii[npii].phones=thisPron-&gt;phones; &#125; // sil phones else &#123; /* Make one instance per silence label */ for (k=1;k&lt;=nAdd;k++) &#123; pii[++npii].pron=thisPron; pii[npii].silId=k; pii[npii].n=pii[npii].t=n; // after modify if (addPhones[k]!=NULL) pii[npii].t++; pii[npii].phones=(LabId *) New(heap,sizeof(LabId)*pii[npii].t); // copy phones for(l=0;l&lt;pii[npii].n;l++) pii[npii].phones[l]=pii[npii].pron-&gt;phones[l]; // add sil if (addPhones[k]!=NULL) pii[npii].phones[pii[npii].n]=addPhones[k]; &#125; &#125; &#125; /* Scan new pronunciations and remove duplicates */ // npii: all the phones in a word // default: true if (remDupPron) // each pron for (j=2; j&lt;=npii; j++) &#123; n=pii[j].t; if (pii[j].pron==NULL) continue; for (k=1; k&lt;j; k++) &#123; if (pii[j].pron==NULL || pii[k].pron==NULL || pii[k].t!=n || pii[j].pron-&gt;prob!=pii[k].pron-&gt;prob) continue; // each phones for(l=0;l&lt;n;l++) if (pii[j].phones[l]!=pii[k].phones[l]) break; // equal if (l==n) pii[j].pron=NULL,t++; &#125; &#125; /* Now make the PronHolders */ for (j=1; j&lt;=npii; j++) &#123; /* Don't add duplicates */ if (pii[j].pron==NULL) continue; /* Build inst for each pron */ pInst=NewPronHolder(heap,hci,pii[j].pron,pii[j].t,pii[j].phones); // ln: Node that created this instance pInst-&gt;ln = thisLNode; // add pInst into the head of lnode pInst-&gt;next = (PronHolder*)thisLNode-&gt;sublat; thisLNode-&gt;sublat = (SubLatDef*) pInst; // pInst-&gt;fct: LM likelihood to be factored into each phone if (pInst-&gt;nphones&lt;=0) pInst-&gt;fct = 0.0; else pInst-&gt;fct = thisLNode-&gt;score/pInst-&gt;nphones; /* Fake connections from SENT_[START/END] */ // Number of cross word contexts if (hci-&gt;xc&gt;0) &#123; // start node ? if (thisLNode-&gt;pred==NULL) // Left contexts pInst-&gt;lc[0]=(NetNode*)lat; // end node ? if (thisLNode-&gt;foll==NULL) &#123; if (pInst-&gt;nphones==0) lc=0; // pInst-&gt;fc: final context else lc = pInst-&gt;fc; type = n_word + lc*n_lcontext; /* rc==0 */ wordNode=FindWordNode(net-&gt;heap,pInst-&gt;pron,pInst,type); wordNode-&gt;tag=SafeCopyString(net-&gt;heap,thisLNode-&gt;tag); wordNode-&gt;nlinks = 0; pInst-&gt;rc[0]=wordNode; &#125; &#125; else if (thisLNode-&gt;foll==NULL) &#123; wordNode = FindWordNode(net-&gt;heap,pInst-&gt;pron,pInst,n_word); wordNode-&gt;tag=SafeCopyString(net-&gt;heap,thisLNode-&gt;tag); wordNode-&gt;nlinks = 0; &#125; &#125; Dispose(&amp;gstack,++pii);&#125; ProcessCrossWordLinks这个函数将被执行两次，第一次heap != NULL，第二次heap == NULL。遍历Lattice网络中所有的弧，弧两端节点的不同pron构成全连接关系，第一次仅仅为开端节点标记tag。 12345678910111213141516171819202122232425262728// through all the arcsfor (i=0; i&lt;lat-&gt;na; i++) &#123; thisLArc = NumbLArc(lat, i); // start word's pron for (lInst=(PronHolder*)thisLArc-&gt;start-&gt;sublat;lInst!=NULL;lInst=lInst-&gt;next) // end word's pron for (rInst=(PronHolder*)thisLArc-&gt;end-&gt;sublat;rInst!=NULL;rInst=rInst-&gt;next) &#123; // xc: Number of cross word contexts // n_word: Node Instance represents word end if (xc==0) &#123; wordNode = FindWordNode(heap,lInst-&gt;pron,lInst,n_word); // first time if (heap!=NULL) wordNode-&gt;tag=SafeCopyString(heap,thisLArc-&gt;start-&gt;tag); if (heap==NULL) &#123; // links: Array[0..nlinks-1] of links to connected nodes // one to multi // wordNode-&gt;nlinks = 0; // wordNode-&gt;links[wordNode-&gt;nlinks].node=rInst-&gt;starts; wordNode-&gt;links[wordNode-&gt;nlinks].like=thisLArc-&gt;lmlike; &#125; // has many linked nodes wordNode-&gt;nlinks++; &#125; &#125;&#125; 接下来，执行CreateWIModels之前，有一块处理没用看明白。还有，CreateWIModels和CreateIEModels函数执行的对象是Lattice中每一个节点对应的词中的每一个发音实例。一个发音实例用三音素或者五因素模型建模。这两个函数主要是处理边界音素和中间音素的。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/* Build models on basis of contexts seen */net-&gt;teeWords=FALSE;// all the nodesfor (i=0; i &lt; lat-&gt;nn; i++) &#123; thisLNode = lat-&gt;lnodes+i; thisWord = thisLNode-&gt;word; if (thisWord==NULL) thisWord=voc-&gt;nullWord; // word's pron for(pInst=(PronHolder*)thisLNode-&gt;sublat;pInst!=NULL;pInst=pInst-&gt;next) &#123; /* !NULL consists only of word ends */ if (pInst-&gt;nphones==0) &#123; /* Flawed */ if (hci-&gt;xc==0) &#123; /* But we need a pointer for xc==0 cases */ wordNode = FindWordNode(NULL,pInst-&gt;pron,pInst,n_word); // Chain of initial models pInst-&gt;starts = wordNode; // Number of models in starts chain pInst-&gt;nstart = 0; /* Stops us adding node into chain twice */ &#125; continue; &#125; /* Determine which bits of word are l and r cd */ if (hci-&gt;xc&gt;0) &#123; for (p=0;p&lt;pInst-&gt;nphones;p++) if (GetHCIContext(hci,pInst-&gt;phones[p])&gt;=0) break; for (q=pInst-&gt;nphones-1;q&gt;=0;q--) if (GetHCIContext(hci,pInst-&gt;phones[q])&gt;=0) break; &#125; else &#123; p=0; // nphones: Number of phones for this instance q=pInst-&gt;nphones-1; &#125; pInst-&gt;tee=TRUE; /* Make wrd-int cd phones (possibly none!) */ // p = 0; q = pInst-&gt;nphones - 1; CreateWIModels(pInst,p,q,net,hci); if (hci-&gt;xc==0) &#123; /* Word internal context only */ CreateIEModels(thisWord,pInst,p,q,net,hci); &#125; &#125;&#125; CreateWIModels这个函数主要处理非边界音素，该处理过程针对一个发音实例，操作完毕之后的结果如图所示： 1234567891011121314151617181920212223242526272829303132NetNode *node;HLink hmm;int j; // num of phones// [0, 4] =&gt; 3 2 1 each phone is differentfor(j=q-1;j&gt;p;j--) &#123; // find HMM model for a single phone hmm=GetHCIModel(hci,FindLContext(hci,pInst,j,0), pInst-&gt;phones[j], FindRContext(hci,pInst,j,0)); // not tee if (hmm-&gt;transP[1][hmm-&gt;numStates]&lt;LSMALL) pInst-&gt;tee=FALSE; nwi++; // new a node by hmm, each has at most one connected node node=NewNode(net-&gt;heap,hmm,(pInst-&gt;chain==NULL?0:1)); if (pInst-&gt;chain!=NULL) &#123; nil++; // each phone pointed to the chain, but chain is modified by current node // so the later one is pointed to the previous one // 2-&gt;3 1-&gt;2 node-&gt;links[0].node=pInst-&gt;chain; node-&gt;links[0].like=pInst-&gt;fct; &#125; // node-&gt;chain may be NULL node-&gt;chain=pInst-&gt;chain; pInst-&gt;chain=node; // 1-&gt;2-&gt;3&#125; CreateIEModels这里针对边界音素，操作结果可以表示如图： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374NetNode *node,*wordNode;HLink hmm;// p = 0 q = nphones - 1: 如果只有一个节点if (q==p) &#123; /* One phone word */ hmm=GetHCIModel(hci,0,pInst-&gt;phones[0],0); if (hmm-&gt;transP[1][hmm-&gt;numStates]&lt;LSMALL) pInst-&gt;tee=FALSE; // the last node is word node wordNode = FindWordNode(NULL,pInst-&gt;pron,pInst,n_word); nin++; nil++; node=NewNode(net-&gt;heap,hmm,1); // pointed to a word node node-&gt;links[0].node=wordNode; node-&gt;links[0].like=pInst-&gt;fct; // Chain of initial models pInst-&gt;starts=node; // Number of models in starts chain pInst-&gt;nstart=1;&#125;// 正常情况else &#123; // 处理exit节点 hmm=GetHCIModel(hci,FindLContext(hci,pInst,q,0), pInst-&gt;phones[q],0); if (hmm-&gt;transP[1][hmm-&gt;numStates]&lt;LSMALL) pInst-&gt;tee=FALSE; // 该节点之后跟着一个词节点 wordNode = FindWordNode(NULL,pInst-&gt;pron,pInst,n_word); nfi++; nil++; node=NewNode(net-&gt;heap,hmm,1); // 指向词节点 node-&gt;links[0].node=wordNode; node-&gt;links[0].like=pInst-&gt;fct; // Chain of final models pInst-&gt;ends=node; // Number of models in ends chain pInst-&gt;nend=1; /* Start */ hmm=GetHCIModel(hci,0,pInst-&gt;phones[p], FindRContext(hci,pInst,p,0)); // #define LSMALL (-0.5E10) if (hmm-&gt;transP[1][hmm-&gt;numStates]&lt;LSMALL) pInst-&gt;tee=FALSE; nin++; nil++; node=NewNode(net-&gt;heap,hmm,1); // 开始节点只需要调整其后继即可 node-&gt;links[0].node=(pInst-&gt;chain?pInst-&gt;chain:pInst-&gt;ends); node-&gt;links[0].like=pInst-&gt;fct; pInst-&gt;starts=node; pInst-&gt;nstart=1; // Chain的最后一个节点指向exit节点 if (pInst-&gt;chain!=NULL) &#123; for (node=pInst-&gt;chain;node-&gt;chain!=NULL;node=node-&gt;chain); // position to last node node-&gt;nlinks=1; nil++; node-&gt;links=(NetLink*) New(net-&gt;heap, sizeof(NetLink)); node-&gt;links[0].node=pInst-&gt;ends; node-&gt;links[0].like=pInst-&gt;fct; &#125;&#125; 最后一部分，进行第二次的ProcessCrossWordLinks，第二次指定开端节点的后继节点，将他们分别指向末端节点发音实例的开始节点，操做完结果图示如下： 上述过程中用到了一个哈希表，寻访Lattice中所有节点所用到的词节点，下面的操作先为这些词节点分配后继空间，之后使用ProcessCrossWordLinks完成这些节点关系的指派。1234567891011121314151617181920212223242526272829303132333435363738394041424344// Allocate NetLinks from hash table stats：分配后继空间// Zero counters // all nodes is word end nodefor (i=0; i&lt;WNHASHSIZE; i++) &#123; /* Build links for each word end model */ for (node=wnHashTab[i];node!=NULL;node=node-&gt;chain) &#123; if (node-&gt;nlinks&gt;0)&#123; // alloc node-&gt;links memory node-&gt;links=(NetLink*) New(net-&gt;heap,sizeof(NetLink)*node-&gt;nlinks); &#125;else node-&gt;links=NULL; nxl+=node-&gt;nlinks; // reset to 1 node-&gt;nlinks=0; node-&gt;aux=0; &#125;&#125;/* Finally put in the cross word links */// 之前构建控件，在这里指派指向关系ProcessCrossWordLinks(NULL,lat,hci-&gt;xc);/* First disassemble wnHashTab and link to end nodes as necessary */// handle init and final nodeAddInitialFinal(lat,net,hci-&gt;xc); // net-&gt;chain指向的是Lattice中所有词节点和模型节点，线性表示for (i=0; i&lt;WNHASHSIZE; i++) &#123; // word node // append word node list to the net's chain AddChain(net,wnHashTab[i]);&#125;/* Finally chain all nodes together */for (i=0; i &lt; lat-&gt;nn; i++) for (pInst=(PronHolder*)lat-&gt;lnodes[i].sublat; pInst!=NULL;pInst=pInst-&gt;next) &#123; if (pInst-&gt;nstart&gt;0) AddChain(net,pInst-&gt;starts); AddChain(net,pInst-&gt;chain); AddChain(net,pInst-&gt;ends); &#125;//... 所以现在总的来看这个层次的网络结构图如下：]]></content>
      <tags>
        <tag>ASR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[非阻塞套接字模型]]></title>
    <url>%2F2017%2F05%2F23%2Fnonblock-socket-demo%2F</url>
    <content type="text"><![CDATA[首先说明这不是近期写的东西，主要想通过它来看看站点显示是否正常。时间应该回退到2016年的七月，由于某些原因，要啃一下grpc的源码，回想起来还是蛮痛苦的（可怜现在已经忘的差不多了……）。 那时候的我还是对网络编程很感兴趣的。 最近发现套接字在使用中阻塞型使用的非常少，在非阻塞模型中，错误码十分关键，一般都是在操作返回之后，根据错误码和返回值判断相应的操作结果，之后做分别处理。 这里简单的写了一个服务端的模型，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091#include &lt;stdio.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/types.h&gt;#include &lt;errno.h&gt;#include &lt;netinet/in.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;#define PORT 10010#define BUFF 256int main(int argc, char const *argv[])&#123; int server_fd = socket(AF_INET, SOCK_STREAM, 0); if(server_fd == -1) &#123; printf("create server socket error[%s]...\n", strerror(errno)); return -1; &#125; struct sockaddr_in server_addr; bzero(&amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htonl(INADDR_ANY); server_addr.sin_port = htons(PORT); if(bind(server_fd, (struct sockaddr*)&amp;server_addr, sizeof(sockaddr)) == -1) &#123; printf("bind on local address error[%s]\n", strerror(errno)); close(server_fd); return -1; &#125; if(listen(server_fd, 1) == -1) &#123; printf("listen on local address error[%s]\n", strerror(errno)); close(server_fd); return -1; &#125; puts("listening on local address..."); struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr), client_fd; if((client_fd = accept(server_fd, (struct sockaddr*)&amp;client_addr, &amp;client_addr_len)) == -1) &#123; printf("accept connection error[%s]\n", strerror(errno)); close(server_fd); return -1; &#125; puts("accept one connection..."); int flags = fcntl(client_fd, F_GETFL, 0); if(fcntl(client_fd, F_SETFL, flags | O_NONBLOCK) &lt; 0) &#123; puts("set socket fd to nonblock failed..."); close(server_fd); return -1; &#125; puts("set client_fd to nonblock..."); int recv_len = 0; char recv_buf[BUFF]; bzero(recv_buf, BUFF); do &#123; do &#123; sleep(1); recv_len = recv(client_fd, recv_buf, BUFF, 0); printf("recv len = %d\n", recv_len); if(errno == EINTR) puts("EINTR"); if(errno == EAGAIN) puts("EAGAIN"); &#125;while(recv_len &lt; 0 &amp;&amp; (errno == EINTR || errno == EAGAIN)); printf("%s\n", recv_buf); bzero(recv_buf, BUFF); &#125;while(recv_len != 0); puts("server done..."); close(client_fd); close(server_fd); return 0;&#125; 使用telnet到端口10010，可以观测到在没有数据到来时，错误码为 EAGAIN退出telnet客户端，这时观察到返回值变为0，程序退出，也就是说，recv返回值为0表示的是链接的断开，而非没有收取到数据。]]></content>
      <tags>
        <tag>C/C++</tag>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在前面]]></title>
    <url>%2F2017%2F05%2F22%2Fwrite-first%2F</url>
    <content type="text"><![CDATA[为什么要搭blog？从实际需要角度来说，我完全必要在腾讯云上搭的这个站点，可能就是，我好奇心重吧…… 目前感觉这里既放不上心灵鸡汤，也拿不出什么技术软文，甚至能写到什么时候都是一个未知数。搭博客也不是什么新鲜事了，作为大学生涯最后一部分的体验吧。开心就好。 另外，可能先会把以前的杂七杂八的东西放上来，这估计要花上点时间。]]></content>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
